FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Chen, Runsheng
TI [Prospects for the Application of Healthcare Big Data Combined With
   Large Language Models].
SO Sichuan da xue xue bao. Yi xue ban = Journal of Sichuan University.
   Medical science edition
VL 54
IS 5
BP 855
EP 856
DI 10.12182/20230960301
DT English Abstract; Journal Article; Review
PD 2023-Sep
PY 2023
AB The application of big data technology combined with large language
   models is expected to make an enormous impact in the field of medicine.
   Herein, the prospects for the application of healthcare big data
   combined with large language models were discussed in several aspects,
   including first in assisting doctors in making diagnosis and
   differential diagnosis and, then, in the field of evidence-based
   medicine. In addition, healthcare big data combined with large language
   models could also be applied in assisting doctors to conduct clinical
   and medical research. Through combining healthcare big data with large
   language models, medical diagnosis and treatment with improved
   precision, efficiency, and intelligence will be realized and greater
   contributions will be made to the field of human health.
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 1
Z9 1
DA 2023-10-26
UT MEDLINE:37866938
PM 37866938
ER

PT J
AU Kunze, Kyle N.
TI Generative Artificial Intelligence and Musculoskeletal Health Care
SO HSS JOURNAL
DI 10.1177/15563316251335334
EA APR 2025
DT Review; Early Access
PY 2025
AB Generative artificial intelligence (AI) comprises a class of AI models
   that generate synthetic outputs based on learning acquired from a
   dataset that trained the model. This means that they can create entirely
   new outputs that resemble real-world data despite not being explicitly
   instructed to do so during training. Regarding technological
   capabilities, computing power, and data availability, generative AI has
   given rise to more advanced and versatile models including diffusion and
   large language models that hold promise in healthcare. In
   musculoskeletal healthcare, generative AI applications may involve the
   enhancement of images, generation of audio and video, automation of
   clinical documentation and administrative tasks, use of surgical
   planning aids, augmentation of treatment decisions, and personalization
   of patient communication. Limitations of the use of generative AI in
   healthcare include hallucinations, model bias, ethical considerations
   during clinical use, knowledge gaps, and lack of transparency. This
   review introduces critical concepts of generative AI, presents clinical
   applications relevant to musculoskeletal healthcare that are in
   development, and highlights limitations preventing deployment in
   clinical settings.
Z8 0
ZB 0
ZS 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-05-05
UT WOS:001476086400001
PM 40297632
ER

PT C
AU Abhinand, A.
   Babu, Aswin K., V
   Rajesh, Goutham
   Parthasaradhi, H.
   Bhadran, Bindhya
GP IEEE COMPUTER SOC
TI Transforming Healthcare: Unified Medical Identification and AI-Enabled
   Treatment Advancements
SO 2024 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND
   INFORMATICS, ICICI 2024
BP 378
EP 382
DI 10.1109/ICICI62254.2024.00068
DT Proceedings Paper
PD 2024
PY 2024
AB In the dynamic realm of healthcare, accurate disease prediction stands
   as a cornerstone for proactive management and personalized care. Through
   the introduction of Unified Medical Identification (UMI), users can
   easily connect to their medical records anywhere at any time. With
   advanced features like rural language support via video-based disease
   prediction integrated with the Large Language Model, the system
   generates a broader bracket of users. An ensembled machine learning
   model is used for general disease prediction. Integrating the CatBoost
   Classifier with the LangChain framework, the model accurately detects
   chronic diseases keeping UMI as the central source of the user's medical
   data. Furthermore, an AI chatbot aids in the enhancement of user
   engagement offering targeted treatment options and suitable lifestyle
   recommendations resulting in better health outcomes. With a remarkable
   92.8% accuracy in general disease prediction and a whopping 95.8%
   accuracy in chronic disease prediction, this revolutionary tool not only
   reforms the healthcare delivery mode but also guarantees that it is well
   accepted and widely available across dissimilar communities.
CT 2nd International Conference on Inventive Computing and Informatics
   (ICICI)
CY JUN 11-12, 2024
CL S E A Coll Engn & Technol, Bangalore, INDIA
HO S E A Coll Engn & Technol
ZB 0
ZA 0
Z8 0
ZR 0
ZS 0
TC 0
Z9 0
DA 2025-01-11
UT WOS:001339363400058
ER

PT J
AU Geevarghese, Ruben
   Solomon, Stephen B.
   Alexander, Erica S.
   Marinelli, Brett
   Chatterjee, Subrata
   Jain, Pulkit
   Cadley, John
   Hollingsworth, Alex
   Chatterjee, Avijit
   Ziv, Etay
TI Utility of a Large Language Model for Extraction of Clinical Findings
   from Healthcare Data following Lung Ablation: A Feasibility Study
SO JOURNAL OF VASCULAR AND INTERVENTIONAL RADIOLOGY
VL 36
IS 4
DI 10.1016/j.jvir.2024.11.029
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB To assess the feasibility of utilizing a large language model (LLM) in
   extracting clinically relevant information from healthcare data in
   patients who have undergone microwave ablation for lung tumors. In this
   single-center retrospective study, radiology reports and clinic notes of
   20 patients were extracted, up to 12 months after treatment. Utilizing
   an LLM (generative pretrained transformer 3.5 Turbo 16k), a zero-shot
   prompt strategy was employed to identify 4 key outcomes from relevant
   healthcare data: (a) recurrence at ablation site, (b) pneumothorax, (c)
   hemoptysis, and (d) hemothorax following ablation. This was validated
   with ground-truth labels obtained through manual chart review. Analysis
   of 104 radiology reports and 37 clinic notes was undertaken. The LLM
   output demonstrated high accuracy (85%-100%) across the 4 outcomes. An
   LLM approach appears to have utility in extraction of clinically
   relevant information from healthcare data. This method may be beneficial
   in facilitating data analysis for future interventional radiology
   studies.
Z8 0
ZB 0
ZA 0
ZR 0
TC 0
ZS 0
Z9 0
DA 2025-04-04
UT WOS:001453244100001
PM 39662619
ER

PT J
AU Denecke, Kerstin
   May, Richard
   Rivera-Romero, Octavio
TI Transformer Models in Healthcare: A Survey and Thematic Analysis of
   Potentials, Shortcomings and Risks
SO JOURNAL OF MEDICAL SYSTEMS
VL 48
IS 1
AR 23
DI 10.1007/s10916-024-02043-5
DT Review
PD FEB 17 2024
PY 2024
AB Large Language Models (LLMs) such as General Pretrained Transformer
   (GPT) and Bidirectional Encoder Representations from Transformers
   (BERT), which use transformer model architectures, have significantly
   advanced artificial intelligence and natural language processing.
   Recognized for their ability to capture associative relationships
   between words based on shared context, these models are poised to
   transform healthcare by improving diagnostic accuracy, tailoring
   treatment plans, and predicting patient outcomes. However, there are
   multiple risks and potentially unintended consequences associated with
   their use in healthcare applications. This study, conducted with 28
   participants using a qualitative approach, explores the benefits,
   shortcomings, and risks of using transformer models in healthcare. It
   analyses responses to seven open-ended questions using a simplified
   thematic analysis. Our research reveals seven benefits, including
   improved operational efficiency, optimized processes and refined
   clinical documentation. Despite these benefits, there are significant
   concerns about the introduction of bias, auditability issues and privacy
   risks. Challenges include the need for specialized expertise, the
   emergence of ethical dilemmas and the potential reduction in the human
   element of patient care. For the medical profession, risks include the
   impact on employment, changes in the patient-doctor dynamic, and the
   need for extensive training in both system operation and data
   interpretation.
ZA 0
TC 17
ZS 0
ZB 2
Z8 0
ZR 0
Z9 17
DA 2024-02-25
UT WOS:001163060200001
PM 38367119
ER

PT J
AU Woo, Brigitte
   Huynh, Tom
   Tang, Arthur
   Bui, Nhat
   Nguyen, Giang
   Tam, Wilson
TI Transforming nursing with large language models: from concept to
   practice
SO EUROPEAN JOURNAL OF CARDIOVASCULAR NURSING
VL 23
IS 5
BP 549
EP 552
DI 10.1093/eurjcn/zvad120
EA JAN 2024
DT Editorial Material
PD JAN 5 2024
PY 2024
AB Large language models (LLMs) such as ChatGPT have emerged as potential
   game-changers in nursing, aiding in patient education, diagnostic
   assistance, treatment recommendations, and administrative task
   efficiency. While these advancements signal promising strides in
   healthcare, integrated LLMs are not without challenges, particularly
   artificial intelligence hallucination and data privacy concerns.
   Methodologies such as prompt engineering, temperature adjustments, model
   fine-tuning, and local deployment are proposed to refine the accuracy of
   LLMs and ensure data security. While LLMs offer transformative
   potential, it is imperative to acknowledge that they cannot substitute
   the intricate expertise of human professionals in the clinical field,
   advocating for a synergistic approach in patient care.
ZS 0
ZR 0
Z8 1
TC 9
ZA 0
ZB 1
Z9 10
DA 2024-01-15
UT WOS:001136706400001
PM 38178303
ER

PT J
AU Leypold, Tim
   Bahm, Jorg
   Beier, Justus P.
   Guillaume, Vincent G. J.
   Ammo, Tekoshin
   Lauer, Henrik
   Kolbenschlag, Jonas
   Schaefer, Benedikt
TI Evaluating ChatGPT o1's Capabilities in Peripheral Nerve Surgery:
   Advancing Artificial Intelligence in Clinical Practice
SO WORLD NEUROSURGERY
VL 196
AR 123753
DI 10.1016/j.wneu.2025.123753
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB  OBJECTIVE: Artificial intelligence (AI) continues to
   advance in healthcare, offering innovative approaches to enhance
   clinical decision-making and patient management. Peripheral nerve
   surgery poses unique challenges due to the complexity of cases and the
   need for precise diagnostic and therapeutic strategies. This study
   investigates the application of OpenAI's generative AI model, o1, in
   assisting with intricate decision-making processes in peripheral nerve
   surgery.  METHODS: Using advanced prompt engineering
   techniques, o1 was configured as a virtual medical assistant (Generative
   Pretrained Transformer-Nerve Surgery [GPTNS]) to process 5 simulated
   clinical scenarios modeled after real-world cases. The AI guided
   surgeons through medical history, diagnostics, and treatment planning,
   culminating in case summaries. A panel of nerve surgery specialists and
   residents evaluated the AI's performance using a Likert scale across 7
   criteria.  RESULTS: GPT-NS demonstrated strong
   capabilities, achieving an average score of 4.3. High ratings were
   observed for understanding clinical issues and case presentation
   clarity. However, areas for improvement were noted in diagnostic
   sequencing and treatment recommendations. Despite a lower score
   indicating human evaluators' perception of their superiority over the AI
   in handling cases, GPT-NS showed promise as a supportive tool in
   clinical practice.  CONCLUSIONS: As the performance of
   large language model AI continues to improve, it is becoming
   increasingly important that absolute experts assess the accuracy of the
   answers to ensure reliable and clinically sound integration into
   healthcare practices. This study underscores the potential of large
   language model AI in augmenting clinical decision-making in highly
   specialized fields like peripheral nerve surgery while demonstrating the
   ongoing importance of human expertise. Future research should explore
   ways to further refine AI capabilities and assess its integration into
   routine surgical workflows.
TC 1
ZA 0
ZS 0
ZB 0
ZR 0
Z8 0
Z9 1
DA 2025-03-18
UT WOS:001442125700001
PM 39924104
ER

PT J
AU Liu, Yihao
   Cao, Xu
   Chen, Tingting
   Jiang, Yankai
   You, Junjie
   Wu, Minghua
   Wang, Xiaosong
   Feng, Mengling
   Jin, Yaochu
   Chen, Jintai
TI From screens to scenes: A survey of embodied AI in healthcare
SO INFORMATION FUSION
VL 119
AR 103033
DI 10.1016/j.inffus.2025.103033
EA FEB 2025
DT Article
PD JUL 2025
PY 2025
AB Healthcare systems worldwide face persistent challenges in efficiency,
   accessibility, and personalization. Modern artificial intelligence (AI)
   has shown promise in addressing these issues through precise predictive
   modeling; however, its impact remains constrained by limited integration
   into clinical workflows. Powered by modern AI technologies such as
   multimodal large language models and world models, Embodied AI (EmAI)
   represents a transformative frontier, offering enhanced autonomy and the
   ability to interact with the physical world to address these challenges.
   As an interdisciplinary and rapidly evolving research domain, "EmAI in
   healthcare"spans diverse fields such as algorithms, robotics, and
   biomedicine. This complexity underscores the importance of timely
   reviews and analyses to track advancements, address challenges, and
   foster cross-disciplinary collaboration. In this paper, we provide a
   comprehensive overview of the "brain"of EmAI for healthcare, wherein we
   introduce foundational AI algorithms for perception, actuation,
   planning, and memory, and focus on presenting the healthcare
   applications spanning clinical interventions, daily care &
   companionship, infrastructure support, and biomedical research, covering
   35 specialized tasks. These significant advancements have the potential
   to enable personalized care, enhance diagnostic accuracy, and optimize
   treatment outcomes. Despite its promise, the development of EmAI for
   healthcare is hindered by critical challenges such as safety concerns,
   gaps between simulation platforms and real-world applications, the
   absence of standardized benchmarks, and uneven progress across
   interdisciplinary domains. We discuss the technical barriers and explore
   ethical considerations, offering a forward-looking perspective on the
   future of EmAI in healthcare. A hierarchical framework of intelligent
   levels for EmAI systems is also introduced to guide further development.
   By providing systematic insights, this work aims to inspire innovation
   and practical applications, paving the way for a new era of intelligent,
   patient-centered healthcare.
ZB 0
ZS 0
TC 0
ZA 0
Z8 0
ZR 0
Z9 0
DA 2025-03-12
UT WOS:001438003500001
ER

PT J
AU Goktas, Polat
   Grzybowski, Andrzej
TI Shaping the Future of Healthcare: Ethical Clinical Challenges and
   Pathways to Trustworthy AI
SO JOURNAL OF CLINICAL MEDICINE
VL 14
IS 5
AR 1605
DI 10.3390/jcm14051605
DT Article
PD MAR 2025
PY 2025
AB Background/Objectives: Artificial intelligence (AI) is transforming
   healthcare, enabling advances in diagnostics, treatment optimization,
   and patient care. Yet, its integration raises ethical, regulatory, and
   societal challenges. Key concerns include data privacy risks,
   algorithmic bias, and regulatory gaps that struggle to keep pace with AI
   advancements. This study aims to synthesize a multidisciplinary
   framework for trustworthy AI in healthcare, focusing on transparency,
   accountability, fairness, sustainability, and global collaboration. It
   moves beyond high-level ethical discussions to provide actionable
   strategies for implementing trustworthy AI in clinical contexts.
   Methods: A structured literature review was conducted using PubMed,
   Scopus, and Web of Science. Studies were selected based on relevance to
   AI ethics, governance, and policy in healthcare, prioritizing
   peer-reviewed articles, policy analyses, case studies, and ethical
   guidelines from authoritative sources published within the last decade.
   The conceptual approach integrates perspectives from clinicians,
   ethicists, policymakers, and technologists, offering a holistic
   "ecosystem" view of AI. No clinical trials or patient-level
   interventions were conducted. Results: The analysis identifies key gaps
   in current AI governance and introduces the Regulatory Genome-an
   adaptive AI oversight framework aligned with global policy trends and
   Sustainable Development Goals. It introduces quantifiable
   trustworthiness metrics, a comparative analysis of AI categories for
   clinical applications, and bias mitigation strategies. Additionally, it
   presents interdisciplinary policy recommendations for aligning AI
   deployment with ethical, regulatory, and environmental sustainability
   goals. This study emphasizes measurable standards, multi-stakeholder
   engagement strategies, and global partnerships to ensure that future AI
   innovations meet ethical and practical healthcare needs. Conclusions:
   Trustworthy AI in healthcare requires more than technical
   advancements-it demands robust ethical safeguards, proactive regulation,
   and continuous collaboration. By adopting the recommended roadmap,
   stakeholders can foster responsible innovation, improve patient
   outcomes, and maintain public trust in AI-driven healthcare.
Z8 0
ZA 0
ZR 0
TC 7
ZB 0
ZS 0
Z9 7
DA 2025-03-21
UT WOS:001443802700001
PM 40095575
ER

PT J
AU Schuetz, Pascal
   Lob, Sina
   Chahed, Hiba
   Dathe, Lisa
   Loewer, Maren
   Reiss, Hannah
   Weigel, Alina
   Albrecht, Joanna
   Tokgoez, Pinar
   Dockweiler, Christoph
TI ChatGPT as an Information Source for Patients with Migraines: A
   Qualitative Case Study
SO HEALTHCARE
VL 12
IS 16
AR 1594
DI 10.3390/healthcare12161594
DT Article
PD AUG 2024
PY 2024
AB Migraines are one of the most common and expensive neurological diseases
   worldwide. Non-pharmacological and digitally delivered treatment options
   have long been used in the treatment of migraines. For instance,
   migraine management tools, online migraine diagnosis or digitally
   networked patients have been used. Recently, applications of ChatGPT are
   used in fields of healthcare ranging from identifying potential research
   topics to assisting professionals in clinical diagnosis and helping
   patients in managing their health. Despite advances in migraine
   management, only a minority of patients are adequately informed and
   treated. It is important to provide these patients with information to
   help them manage the symptoms and their daily activities. The primary
   aim of this case study was to examine the appropriateness of ChatGPT to
   handle symptom descriptions responsibly, suggest supplementary
   assistance from credible sources, provide valuable perspectives on
   treatment options, and exhibit potential influences on daily life for
   patients with migraines. Using a deductive, qualitative study, ten
   interactions with ChatGPT on different migraine types were analyzed
   through semi-structured interviews. ChatGPT provided relevant
   information aligned with common scientific patient resources. Responses
   were generally intelligible and situationally appropriate, providing
   personalized insights despite occasional discrepancies in interaction.
   ChatGPT's empathetic tone and linguistic clarity encouraged user
   engagement. However, source citations were found to be inconsistent and,
   in some cases, not comprehensible, which affected the overall
   comprehensibility of the information. ChatGPT might be promising for
   patients seeking information on migraine conditions. Its user-specific
   responses demonstrate potential benefits over static web-based sources.
   However, reproducibility and accuracy issues highlight the need for
   digital health literacy. The findings underscore the necessity for
   continuously evaluating AI systems and their broader societal
   implications in health communication.
Z8 0
ZA 0
TC 2
ZR 0
ZB 0
ZS 0
Z9 2
DA 2024-09-09
UT WOS:001304740300001
PM 39201153
ER

PT J
AU Mohanty, Prasant Kumar
   Francis, Sharmila Anand John
   Barik, Rabindra Kumar
   Reddy, K. Hemant Kumar
   Roy, Diptendu Sinha
   Saikia, Manob Jyoti
TI IMPACT: an interactive multi-disease prevention and counterfactual
   treatment system using explainable AI and a multimodal LLM
SO PEERJ COMPUTER SCIENCE
VL 11
AR e2839
DI 10.7717/peerj-cs.2839
DT Article
PD APR 29 2025
PY 2025
AB Multi-disease conditions strain the body's defenses, complicating
   recovery and increasing mortality risk. Therefore, effective concurrent
   prevention of multiple diseases is essential for mitigating
   complications and improving overall well-being. Explainable artificial
   intelligence (XAI) with an advanced multimodal large language model
   (LLM) can create an interactive system enabling the general public to
   engage in natural language without any specialized knowledge
   prerequisites. Counterfactual explanation, an XAI method, offers
   valuable insights by suggesting adjustments to patient features to
   minimize disease risks. However, addressing multiple diseases
   simultaneously poses challenging barriers. This article proposes an
   interactive multi-disease prevention system that uses Google Gemini Pro,
   a multimodal LLM, and a non-dominated sorting genetic algorithm, namely
   NSGA-II, to overcome such problems. This system recommends changes in
   feature values to concurrently minimize the risk of diseases such as
   heart attacks and diabetes. The system facilitates personalized feature
   value selection, significantly reducing disease attack probabilities to
   as low as possible. Such an approach holds the potential to
   simultaneously address the unresolved issue of preventing and managing
   multiple diseases for the general public.
ZR 0
ZA 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2025-05-10
UT WOS:001480517000001
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Kral, Jan
   Hradis, Michal
   Buzga, Marek
   Kunovsky, Lumir
TI Exploring the benefits and challenges of AI-driven large language models
   in gastroenterology: Think out of the box
SO BIOMEDICAL PAPERS-OLOMOUC
VL 168
IS 4
BP 277
EP 283
DI 10.5507/bp.2024.027
EA SEP 2024
DT Review
PD DEC 2024
PY 2024
AB Artificial Intelligence (AI) has evolved significantly over the past
   decades, from its early concepts in the 1950s to the present era of deep
   learning and natural language processing. Advanced large language models
   (LLMs), such as Chatbot Generative Pre-Trained Transformer (ChatGPT) is
   trained to generate human-like text responses. This technology has the
   potential to revolutionize various aspects of gastroenterology,
   including diagnosis, treatment, education, and The benefits of using
   LLMs in gastroenterology could include accelerating diagnosis and
   treatment, providing personalized care, enhancing education and
   training, assisting in decision-making, and improving communication with
   patients. However, drawbacks and challenges such as limited AI
   capability, training on possibly biased data, data errors, security and
   privacy concerns, and implementation costs must be addressed to ensure
   the responsible and effective use of this technology. The future of LLMs
   in gastroenterology relies on the ability to process and analyse large
   amounts of data, identify patterns, and summarize information and thus
   assist physicians in creating personalized treatment plans. As AI
   advances, LLMs will become more accurate and efficient, allowing for
   faster diagnosis and treatment of gastroenterological conditions.
   Ensuring effective collaboration between AI developers, healthcare
   professionals, and regulatory bodies is essential for the responsible
   and effective use of this technology. By finding the right balance
   between AI and human expertise and addressing the limitations and risks
   associated with its use, LLMs can play an increasingly significant role
   in gastroenterology, contributing to better patient care and supporting
   doctors in their work.
ZR 0
ZS 0
Z8 0
ZA 0
TC 2
ZB 0
Z9 2
DA 2024-09-12
UT WOS:001306654600001
PM 39234774
ER

PT J
AU Uranbey, Oemer
   Ozbey, Furkan
   Kaygisiz, Omer
   Ayranci, Ferhat
TI Assessing ChatGPT's Diagnostic Accuracy and Therapeutic Strategies in
   Oral Pathologies: A Cross-Sectional Study
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 4
AR e58607
DI 10.7759/cureus.58607
DT Article
PD APR 19 2024
PY 2024
AB Background: The rapid adoption of artificial intelligence (AI) models in
   the medical field is due to their ability to collaborate with clinicians
   in the diagnosis and management of a wide range of conditions. This
   research assesses the diagnostic accuracy and therapeutic strategies of
   Chat Generative Pre -trained Transformer (ChatGPT) in comparison to
   dental professionals across 12 clinical cases. Methodology: ChatGPT 3.5
   was queried for diagnoses and management plans for 12 retrospective
   cases. Physicians were tasked with rating the complexity of clinical
   scenarios and their agreement with the ChatGPT responses using a five
   -point Likert scale. Comparisons were made between the complexity of the
   cases and the accuracy of the diagnoses and treatment plans. Results:
   ChatGPT exhibited high accuracy in providing differential diagnoses and
   acceptable treatment plans. In a survey involving 30 attending
   physicians, scenarios were rated with an overall median difficulty level
   of 3, showing acceptable agreement with ChatGPT's differential diagnosis
   accuracy (overall median 4). Our study revealed lower diagnosis scores
   correlating with decreased treatment management scores, as demonstrated
   by univariate ordinal regression analysis. Conclusions: ChatGPT's rapid
   processing aids healthcare by offering an objective, evidence -based
   approach, reducing human error and workload. However, potential biases
   may affect outcomes and challenge lessexperienced practitioners. AI in
   healthcare, including ChatGPT, is still evolving, and further research
   is needed to understand its full potential in analyzing clinical
   information, establishing diagnoses, and suggesting treatments.
ZB 0
TC 7
ZR 0
ZS 0
ZA 0
Z8 0
Z9 7
DA 2024-05-23
UT WOS:001223827200032
PM 38770501
ER

PT C
AU Calle, Paul
   Shao, Ruosi
   Liu, Yunlong
   Hebert, Emily T.
   Kendzor, Darla
   Neil, Jordan
   Businelle, Michael
   Pan, Chongle
GP ACM
TI Towards AI-Driven Healthcare: Systematic Optimization, Linguistic
   Analysis, and Clinicians' Evaluation of Large Language Models for
   Smoking Cessation Interventions
SO PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYTEMS, CHI 2024
DI 10.1145/3613904.3641965
DT Proceedings Paper
PD 2024
PY 2024
AB Creating intervention messages for smoking cessation is a
   labor-intensive process. Advances in Large Language Models (LLMs) offer
   a promising alternative for automated message generation. Two critical
   questions remain: 1) How to optimize LLMs to mimic human expert writing,
   and 2) Do LLM-generated messages meet clinical standards? We
   systematically examined the message generation and evaluation processes
   through three studies investigating prompt engineering (Study 1),
   decoding optimization (Study 2), and expert review (Study 3). We
   employed computational linguistic analysis in LLM assessment and
   established a comprehensive evaluation framework, incorporating
   automated metrics, linguistic attributes, and expert evaluations.
   Certified tobacco treatment specialists assessed the quality, accuracy,
   credibility, and persuasiveness of LLM-generated messages, using
   expert-written messages as the benchmark. Results indicate that larger
   LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate
   expert writing to generate well-written, accurate, and persuasive
   messages, thereby demonstrating the capability of LLMs in augmenting
   clinical practices of smoking cessation interventions.
CT CHI Conference on Human Factors in Computing Sytems (CHI)
CY MAY 11-16, 2024
CL Honolulu, HI
SP Assoc Comp Machinery; ACM SIGCHI; Apple; Google; NSF; Tianqiao & Chrissy
   Chen Inst
ZB 0
ZS 0
ZR 0
ZA 0
TC 2
Z8 0
Z9 2
DA 2024-10-05
UT WOS:001255317901034
PM 38912297
ER

PT J
AU Kang, Yan
   Yang, Mingjian
   Peng, Yue
   Cai, Jingwen
   Zhao, Lei
   Gao, Zhan
   Li, Ningshu
   Pu, Bin
TI LLM-DG: Leveraging large language model for enhanced disease prediction
   via inter-patient and intra-patient modeling
SO INFORMATION FUSION
VL 121
AR 103145
DI 10.1016/j.inffus.2025.103145
EA APR 2025
DT Article
PD SEP 2025
PY 2025
AB Existing methods play a crucial role in clinical decision support by
   enabling disease prediction and personalizing healthcare based on
   swiftly accumulated electronic Health Records (EHRs). However, these
   methods often overlook multi-source data integration by relying solely
   on specific domain knowledge and fail to model intricate relationships
   among patients as focusing on inter or intra-patient relationships,
   respectively. To address these limitations, we propose LLM-DG, a
   multi-level health event prediction framework enhanced by large language
   models (LLMs). Specifically, LLM performs semantic enhancement for
   patient and discharge summary representations and injects domain
   knowledge into disease modeling, improving prediction accuracy and
   robustness. Moreover, LLM-DG synchronously models inter-patient and
   intra-patient relationships by capturing high-order patient correlations
   and fusing dynamic and static patient features. At the inter-patient
   level, LLM-DG clusters patients based on LLM-enhanced features,
   identifying similar health trajectories. At the intra-patient level, it
   models disease evolution characteristics through a dynamic graph and
   extracts textual information from LLM-enhanced discharge summaries using
   a text encoder. Experiments on MIMIC-III and MIMIC-IV datasets
   demonstrate that LLM-DG significantly outperforms state-of-the-art
   models, achieving a 12.39% improvement in w-F1 on the diagnosis
   prediction task of the MIMIC-IV dataset. Overall, LLM-DG demonstrates
   strong potential in complex healthcare environments by integrating
   patient histories and cross-patient health patterns, highlighting its
   applicability in clinical decision support and personalized treatment
   planning.
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001464997000001
ER

PT J
AU Poole, Shane
   Sisodia, Nikki
   Koshal, Kanishka
   Henderson, Kyra
   Wijangco, Jaeleene
   Paredes, Danelvis
   Chen, Chelsea
   Rowles, William
   Akula, Amit
   Wuerfel, Jens
   Sharma, Vishakha
   Rauschecker, Andreas M.
   Henry, Roland G.
   Bove, Riley
TI Detecting New Lesions Using a Large Language Model: Applications in
   Real-World Multiple Sclerosis Datasets
SO ANNALS OF NEUROLOGY
DI 10.1002/ana.27251
EA APR 2025
DT Article; Early Access
PY 2025
AB Objective: Neuroimaging is routinely utilized to identify new
   inflammatory activity in multiple sclerosis (MS). A large language model
   to classify narrative magnetic resonance imaging reports in the
   electronic health record (EHR) as discrete data could provide
   significant benefits for MS research. The objectives of the current
   study were to develop such a prompt and to illustrate its research
   applications through a common clinical scenario: monitoring response to
   B-cell depleting therapy (BCDT). Methods: An institutional ecosystem
   that securely connects healthcare data with ChatGPT4 was applied to
   clinical MS magnetic resonance imaging reports in a single institutional
   EHR (2000-2022). A prompt (msLesionprompt) was developed and iteratively
   refined to classify the presence or absence of new T2-weighted lesions
   (newT2w) and contrast-enhancing lesions (CEL). The multistep validation
   included evaluating efficiency (time and cost), comparison with manually
   annotated reports using standard confusion matrix, and application to
   identifying predictors of newT2w/CEL after BCDT start. Results: Accuracy
   of msLesionprompt was high for detection of newT2w (97%) and CEL
   (96.8%). All 14,888 available reports were categorized in 4.13 hours
   ($28); 79% showed no newT2w or CEL. Data extracted showed expected
   suppression of new activity by BCDT (>97% monitoring magnetic resonance
   images after an initial "rebaseline" scan). Neighborhood poverty (Area
   Deprivation Index) was identified as a predictor of inflammatory
   activity (newT2w: OR 1.69, 95% CI 1.10-2.59, p = 0.017; CEL: OR 1.54,
   95% CI 1.01-2.34, p = 0.046). Interpretation: Extracting discrete
   information from narrative imaging reports using an large language model
   is feasible and efficient. This approach could augment many real-world
   analyses of MS disease evolution and treatment response. ANN NEUROL
   2025.
ZB 0
TC 0
ZS 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2025-05-05
UT WOS:001476383200001
PM 40277428
ER

PT J
AU Kang, Bongsu
   LeeSangYeon
   Chang-EopKim
AU 배효진
TI Current Status and Direction of Generative Large Language Model
   Applications in Medicine - Focusing on East Asian Medicine -
Z1 생성형 거대언어모델의 의학 적용 현황과 방향 - 동아시아 의학을 중심으로 -
SO Journal of Physiology & Pathology in Korean Medicine
S1 동의생리병리학회지
VL 38
IS 2
BP 49
EP 58
DT research-article
PD 2024
PY 2024
AB The rapid advancement of generative large language models has
   revolutionized various real-life domains, emphasizing the importance of
   exploring their applications in healthcare. This study aims to examine
   how generative large language models are implemented in the medical
   domain, with the specific objective of searching for the possibility and
   potential of integration between generative large language models and
   East Asian medicine. Through a comprehensive current state analysis, we
   identified limitations in the deployment of generative large language
   models within East Asian medicine and proposed directions for future
   research. Our findings highlight the essential need for accumulating and
   generating structured data to improve the capabilities of generative
   large language models in East Asian medicine. Additionally, we tackle
   the issue of hallucination and the necessity for a robust model
   evaluation framework. Despite these challenges, the application of
   generative large language models in East Asian medicine has demonstrated
   promising results. Techniques such as model augmentation, multimodal
   structures, and knowledge distillation have the potential to
   significantly enhance accuracy, efficiency, and accessibility. In
   conclusion, we expect generative large language models to play a pivotal
   role in facilitating precise diagnostics, personalized treatment in
   clinical fields, and fostering innovation in education and research
   within East Asian medicine.
ZR 0
ZB 0
Z8 0
TC 1
ZS 0
ZA 0
Z9 1
DA 2024-05-25
UT KJD:ART003073519
ER

PT J
AU Han, B.
   Chen, Y.
   Buyyounouski, M. K.
   Gensheimer, M. F.
   Xing, L.
TI RadAlonc: Enhancing Decision-Making in Radiation Oncology with a
   GPT-4-Based Prompt-Driven Large Language Model
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 2297
BP E134
EP E134
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892300029
ER

PT C
AU Alshehri, Basma Mohammed J.
   Kraiem, Naoufel
   Sakly, Houneida
   Alasbali, Nada
GP IEEE
TI Enhancing Medication Safety with Large Language Models: Advanced
   Detection and Prediction of Drug-Drug Interactions
SO 2024 IEEE 7TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES, SIGNAL
   AND IMAGE PROCESSING, ATSIP 2024
SE International Conference on Advanced Technologies for Signal and Image
   Processing ATSIP
BP 547
EP 552
DI 10.1109/ATSIP62566.2024.10638993
DT Proceedings Paper
PD 2024
PY 2024
AB Poly-pharmacy means the use of multiple medications for multiple
   Diseases, with impact to the increases of the risk of drug-drug
   interactions (DDIs), and it may cause a threat to patient safety.
   Traditional DDI detection methods are often manual and leads to errors.
   This study investigates the potential of large language models (LLMs) to
   improve the efficiency of personalized DDI prediction and to use the AI
   advancements. By using LLMs' natural language processing capabilities,
   we will develop a system that analyzes comprehensive patient data,
   including medical history, and individual characteristics. The system
   aims to enabling healthcare providers to make informed decisions and
   improve the treatment plans. Initial results, while promising, highlight
   the need for further refinement and larger datasets to improve
   prediction accuracy. However, this research demonstrates the significant
   potential of LLM-based systems in transforming medication safety,
   optimizing treatment regimens, and ultimately enhancing patient care and
   treatment process.
CT IEEE 7th International Conference on Advanced Technologies, Signal and
   Image Processing (ATSIP)
CY JUL 11-13, 2024
CL Sousse, TUNISIA
SP IEEE; IEEE Tunisia Sect; IEEE Signal Proc Soc; IEEE Control Syst Soc;
   Adv Technologies Med & Signals; ATSI; Telecom Paris; Telecom SudParis;
   Telecom ParisTech; SUPCOM; ANST; ENST; SYS; Technopole SFAX; CRNS; ENET
   COM; ATISP; ENIG; MACS; ENIS
ZS 0
TC 1
Z8 0
ZR 0
ZA 0
ZB 0
Z9 1
DA 2024-12-13
UT WOS:001315771700097
ER

PT J
AU Li, Xingyu
   Peng, Lu
   Wang, Yu-Ping
   Zhang, Weihua
TI Open challenges and opportunities in federated foundation models towards
   biomedical healthcare
SO BIODATA MINING
VL 18
IS 1
AR 2
DI 10.1186/s13040-024-00414-9
DT Review
PD JAN 4 2025
PY 2025
AB This survey explores the transformative impact of foundation models
   (FMs) in artificial intelligence, focusing on their integration with
   federated learning (FL) in biomedical research. Foundation models such
   as ChatGPT, LLaMa, and CLIP, which are trained on vast datasets through
   methods including unsupervised pretraining, self-supervised learning,
   instructed fine-tuning, and reinforcement learning from human feedback,
   represent significant advancements in machine learning. These models,
   with their ability to generate coherent text and realistic images, are
   crucial for biomedical applications that require processing diverse data
   forms such as clinical reports, diagnostic images, and multimodal
   patient interactions. The incorporation of FL with these sophisticated
   models presents a promising strategy to harness their analytical power
   while safeguarding the privacy of sensitive medical data. This approach
   not only enhances the capabilities of FMs in medical diagnostics and
   personalized treatment but also addresses critical concerns about data
   privacy and security in healthcare. This survey reviews the current
   applications of FMs in federated settings, underscores the challenges,
   and identifies future research directions including scaling FMs,
   managing data diversity, and enhancing communication efficiency within
   FL frameworks. The objective is to encourage further research into the
   combined potential of FMs and FL, laying the groundwork for healthcare
   innovations.
ZB 1
ZR 0
TC 2
ZA 0
Z8 0
ZS 0
Z9 2
DA 2025-01-09
UT WOS:001389407500001
PM 39755653
ER

PT C
AU Wei, Qizhi
   Chen, Xuanyu
   Ni, Yifei
   Cao, Cong
GP ASSOC COMPUTING MACHINERY
TI A Technical Framework for Recognizing and Interpreting Complex Medical
   Records: Based on Multimodal Large Language Model
SO 2024 THE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND TEACHER
   EDUCATION, ICAITE 2024
BP 76
EP 83
DI 10.1145/3702386.3702396
DT Proceedings Paper
PD 2024
PY 2024
AB This paper brings up a technical framework for Interpreting medical
   documentation that integrates multi-modal large language modals, aiming
   to provide patients and doctors with the ability to read nonstandard
   medical documentation in complex environments and to obtain text
   interpretation based on generative AI. The framework proposes a
   three-stage solution, namely Recognition, Formatting, and AI-Processing,
   involving technologies such as OCR, medical multi-modal models, and
   large language models, abbreviated as the RF-AI framework. This paper
   focuses on explaining the potential issues encountered when applying the
   framework and describes the resolution within the framework. In
   addition, this paper conducts experiments on two key stages of the
   framework, recognition and AI-processing, which effectively demonstrate
   the feasibility of the framework. This framework can significantly
   reduce the difficulty for patients in understanding medical records and
   provides necessary resolution for situations where paper records might
   be used. It helps patients better understand their conditions and
   enhances the efficiency of diagnosis and treatment between doctors and
   patients. Benefiting from a large language model, this framework allows
   developers to expand based on actual needs and can be integrated into
   existing electronic healthcare systems to achieve more comprehensive
   functionality.
CT 2024 International Conference on Artificial Intelligence and Teacher
   Education
CY OCT 12-14, 2024
CL Beijing, PEOPLES R CHINA
Z8 0
ZR 0
ZA 0
TC 0
ZS 0
ZB 0
Z9 0
DA 2025-04-04
UT WOS:001443289300012
ER

PT J
AU Wang, Zhixiang
   Zhang, Zhen
   Traverso, Alberto
   Dekker, Andre
   Qian, Linxue
   Sun, Pengfei
TI Assessing the role of GPT-4 in thyroid ultrasound diagnosis and
   treatment recommendations: enhancing interpretability with a chain of
   thought approach
SO QUANTITATIVE IMAGING IN MEDICINE AND SURGERY
VL 14
IS 2
DI 10.21037/qims-23-1180
EA JAN 2024
DT Article
PD FEB 2024
PY 2024
AB Background: As artificial intelligence (AI) becomes increasingly
   prevalent in the medical field, the effectiveness of AI-generated
   medical reports in disease diagnosis remains to be evaluated. ChatGPT is
   a large language model developed by open AI with a notable capacity for
   text abstraction and comprehension. This study aimed to explore the
   capabilities, limitations, and potential of Generative Pre-trained
   Transformer (GPT)-4 in analyzing thyroid cancer ultrasound reports,
   providing diagnoses, and recommending treatment plans. Methods: Using
   109 diverse thyroid cancer cases, we evaluated GPT-4's performance by
   comparing its generated reports to those from doctors with various
   levels of experience. We also conducted a Turing Test and a consistency
   analysis. To enhance the interpretability of the model, we applied the
   Chain of Thought (CoT) method to deconstruct the decision-making chain
   of the GPT model. Results: GPT-4 demonstrated proficiency in report
   structuring, professional terminology, and clarity of expression, but
   showed limitations in diagnostic accuracy. In addition, our consistency
   analysis highlighted certain discrepancies in the AI's performance. The
   CoT method effectively enhanced the interpretability of the AI's
   decision-making process. Conclusions: GPT-4 exhibits potential as a
   supplementary tool in healthcare, especially for generating thyroid
   gland diagnostic reports. Our proposed online platform, "ThyroAIGuide",
   alongside the CoT method, underscores the potential of AI to augment
   diagnostic processes, elevate healthcare accessibility, and advance
   patient education. However, the journey towards fully integrating AI
   into healthcare is ongoing, requiring continuous research, development,
   and careful monitoring by medical professionals to ensure patient safety
   and quality of care.
Z8 2
TC 15
ZA 0
ZB 0
ZR 0
ZS 0
Z9 17
DA 2024-02-02
UT WOS:001146755700001
PM 38415150
ER

PT J
AU McLean, Aaron Lawson
   Wu, Yonghui
   McLean, Anna C. Lawson
   Hristidis, Vagelis
TI Large language models as decision aids in neuro-oncology: a review of
   shared decision-making applications
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 3
AR 139
DI 10.1007/s00432-024-05673-x
DT Review
PD MAR 19 2024
PY 2024
AB Shared decision-making (SDM) is crucial in neuro-oncology, fostering
   collaborations between patients and healthcare professionals to navigate
   treatment options. However, the complexity of neuro-oncological
   conditions and the cognitive and emotional burdens on patients present
   significant barriers to achieving effective SDM. This discussion
   explores the potential of large language models (LLMs) such as OpenAI's
   ChatGPT and Google's Bard to overcome these barriers, offering a means
   to enhance patient understanding and engagement in their care. LLMs, by
   providing accessible, personalized information, could support but not
   supplant the critical insights of healthcare professionals. The
   hypothesis suggests that patients, better informed through LLMs, may
   participate more actively in their treatment choices. Integrating LLMs
   into neuro-oncology requires navigating ethical considerations,
   including safeguarding patient data and ensuring informed consent,
   alongside the judicious use of AI technologies. Future efforts should
   focus on establishing ethical guidelines, adapting healthcare workflows,
   promoting patient-oriented research, and developing training programs
   for clinicians on the use of LLMs. Continuous evaluation of LLM
   applications will be vital to maintain their effectiveness and alignment
   with patient needs. Ultimately, this exploration contends that the
   thoughtful integration of LLMs into SDM processes could significantly
   enhance patient involvement and strengthen the patient-physician
   relationship in neuro-oncology care.
ZR 0
ZB 1
ZA 0
ZS 0
TC 8
Z8 1
Z9 8
DA 2024-04-01
UT WOS:001187667700003
PM 38503921
ER

PT J
AU Patel, Chetna R.
   Pandya, Sajal K.
   Sojitra, Brijesh M.
TI Perspectives of ChatGPT in Pharmacology Education, and Research in
   Health Care: A Narrative Review
SO JOURNAL OF PHARMACOLOGY & PHARMACOTHERAPEUTICS
VL 14
IS 3
BP 171
EP 177
DI 10.1177/0976500X231210427
EA DEC 2023
DT Review
PD SEP 2023
PY 2023
AB Background: In the era of advanced Open artificial intelligence (AI)
   technology, the large language model tool known as chat generative
   pre-training transformer (ChatGPT) is gaining an increasing number of
   users in various fields such as healthcare, medical education,
   agriculture, and customer support due to its features like information
   retrieval, generating human-like conversations, and natural language
   processing.
   Purpose: The purpose of this narrative review is to present the
   perspectives of ChatGPT in pharmacology and medical education. And
   highlight the limitations of ChatGPT in these areas and draw the
   attention of policymakers in healthcare to implement such technologies
   while taking into consideration ethical issues.
   Methods: To collect information regarding the perspectives of ChatGPT in
   pharmacology and medical education. And highlight the limitations of
   ChatGPT in these areas.
   Results: In health care, it helps in the drug discovery and development
   process, diagnosis, treatment, counseling, assisting in surgical
   procedures, pharmacovigilance, pharmacy, and so on. In medical
   education, this tool plays a crucial role in online tutoring,
   personalized assistance, grading, improvement in grammar, and so on.
   Despite the limitations, ChatGPT is helpful in healthcare, medical
   education, and scientific writing. To overcome such limitations of
   ChatGPT, like ethical issues, emotionlessness, providing information
   before 2021, the risk of biases, uncontrollability, lack of
   transparency, academic dishonesty, and so on, alternatives have been
   developed, but they also fail to entirely resolve the associated
   limitations.
   Conclusion: Looking at the current scenarios, there is an urgent need
   for comprehensive guidelines to address these limitations and provide a
   framework for appropriately utilizing AI tools in healthcare domains.
   This framework should also focus on maintaining a balance between human
   involvement and technological advancements.
ZS 0
ZR 0
ZB 1
ZA 0
Z8 0
TC 5
Z9 5
DA 2024-01-16
UT WOS:001130186400001
ER

PT J
AU Alkhnbashi, Omer S.
   Mohammad, Rasheed
   Hammoudeh, Mohammad
TI Aspect-Based Sentiment Analysis of Patient Feedback Using Large Language
   Models
SO BIG DATA AND COGNITIVE COMPUTING
VL 8
IS 12
AR 167
DI 10.3390/bdcc8120167
DT Article
PD DEC 2024
PY 2024
AB Online medical forums have emerged as vital platforms for patients to
   share their experiences and seek advice, providing a valuable,
   cost-effective source of feedback for medical service management. This
   feedback not only measures patient satisfaction and improves health
   service quality but also offers crucial insights into the effectiveness
   of medical treatments, pain management strategies, and alternative
   therapies. This study systematically identifies and categorizes key
   aspects of patient experiences, emphasizing both positive and negative
   sentiments expressed in their narratives. We collected a dataset of
   approximately 15,000 entries from various sections of the widely used
   medical forum, patient.info. Our innovative approach integrates content
   analysis with aspect-based sentiment analysis, deep learning techniques,
   and a large language model (LLM) to analyze these data. Our methodology
   is designed to uncover a wide range of aspect types reflected in patient
   feedback. The analysis revealed seven distinct aspect types prevalent in
   the feedback, demonstrating that deep learning models can effectively
   predict these aspect types and their corresponding sentiment values.
   Notably, the LLM with few-shot learning outperformed other models. Our
   findings enhance the understanding of patient experiences in online
   forums and underscore the utility of advanced analytical techniques in
   extracting meaningful insights from unstructured patient feedback,
   offering valuable implications for healthcare providers and medical
   service management.
ZR 0
ZB 0
TC 1
ZA 0
Z8 0
ZS 0
Z9 1
DA 2025-01-09
UT WOS:001389594900001
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT J
AU Ding, Sirui
   Ye, Jiancheng
   Hu, Xia
   Zou, Na
TI Distilling the knowledge from large-language model for health event
   prediction
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30675
DI 10.1038/s41598-024-75331-2
DT Article
PD DEC 28 2024
PY 2024
AB Health event prediction is empowered by the rapid and wide application
   of electronic health records (EHR). In the Intensive Care Unit (ICU),
   precisely predicting the health related events in advance is essential
   for providing treatment and intervention to improve the patients
   outcomes. EHR is a kind of multi-modal data containing clinical text,
   time series, structured data, etc. Most health event prediction works
   focus on a single modality, e.g., text or tabular EHR. How to
   effectively learn from the multi-modal EHR for health event prediction
   remains a challenge. Inspired by the strong capability in text
   processing of large language model (LLM), we propose the framework CKLE
   for health event prediction by distilling the knowledge from LLM and
   learning from multi-modal EHR. There are two challenges of applying LLM
   in the health event prediction, the first one is most LLM can only
   handle text data rather than other modalities, e.g., structured data.
   The second challenge is the privacy issue of health applications
   requires the LLM to be locally deployed, which may be limited by the
   computational resource. CKLE solves the challenges of LLM scalability
   and portability in the healthcare domain by distilling the
   cross-modality knowledge from LLM into the health event predictive
   model. To fully take advantage of the strong power of LLM, the raw
   clinical text is refined and augmented with prompt learning. The
   embedding of clinical text are generated by LLM. To effectively distill
   the knowledge of LLM into the predictive model, we design a
   cross-modality knowledge distillation (KD) method. A specially designed
   training objective will be used for the KD process with the
   consideration of multiple modality and patient similarity. The KD loss
   function consists of two parts. The first one is cross-modality
   contrastive loss function, which models the correlation of different
   modalities from the same patient. The second one is patient similarity
   learning loss function to model the correlations between similar
   patients. The cross-modality knowledge distillation can distill the rich
   information in clinical text and the knowledge of LLM into the
   predictive model on structured EHR data. To demonstrate the
   effectiveness of CKLE, we evaluate CKLE on two health event prediction
   tasks in the field of cardiology, heart failure prediction and
   hypertension prediction. We select the 7125 patients from MIMIC-III
   dataset and split them into train/validation/test sets. We can achieve a
   maximum 4.48% improvement in accuracy compared to state-of-the-art
   predictive model designed for health event prediction. The results
   demonstrate CKLE can surpass the baseline prediction models
   significantly on both normal and limited label settings. We also conduct
   the case study on cardiology disease analysis in the heart failure and
   hypertension prediction. Through the feature importance calculation, we
   analyse the salient features related to the cardiology disease which
   corresponds to the medical domain knowledge. The superior performance
   and interpretability of CKLE pave a promising way to leverage the power
   and knowledge of LLM in the health event prediction in real-world
   clinical settings.
Z8 0
ZA 0
TC 2
ZS 0
ZB 0
ZR 0
Z9 2
DA 2025-01-09
UT WOS:001386137300038
PM 39730390
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Jesus-Ribeiro, Joana
   Roza, Eugenia
   Oliveiros, Barbara
   Melo, Joana Barbosa
   Carreno, Mar
TI Comparative assessment of artificial intelligence chatbots' performance
   in responding to healthcare professionals' and caregivers' questions
   about Dravet syndrome
SO EPILEPSIA OPEN
DI 10.1002/epi4.70022
EA APR 2025
DT Article; Early Access
PY 2025
AB ObjectiveArtificial intelligence chatbots have been a game changer in
   healthcare, providing immediate, round-the-clock assistance. However,
   their accuracy across specific medical domains remains under-evaluated.
   Dravet syndrome remains one of the most challenging epileptic
   encephalopathies, with new data continuously emerging in the literature.
   This study aims to evaluate and compare the performance of ChatGPT 3.5
   and Perplexity in responding to questions about Dravet
   Syndrome.MethodsWe curated 96 questions about Dravet syndrome, 43 from
   healthcare professionals and 53 from caregivers. Two epileptologists
   independently graded the chatbots' responses, with a third senior
   epileptologist resolving any disagreements to reach a final consensus.
   Accuracy and completeness of correct answers were rated on predefined
   3-point scales. Incorrect responses were prompted for self-correction
   and re-evaluated. Readability was assessed using Flesch reading ease and
   Flesch-Kincaid grade level.ResultsBoth chatbots had the majority of
   their responses rated as "correct" (ChatGPT 3.5: 66.7%, Perplexity:
   81.3%), with no significant difference in performance between the two
   (chi 2 = 5.30, p = 0.071). ChatGPT 3.5 performed significantly better
   for caregivers than for healthcare professionals (chi 2 = 7.27, p =
   0.026). The topic with the poorest performance was Dravet syndrome's
   treatment, particularly for healthcare professional questions. Both
   models exhibited exemplary completeness, with most responses rated as
   "complete" to "comprehensive" (ChatGPT 3.5: 73.4%, Perplexity: 75.7%).
   Substantial self-correction capabilities were observed: ChatGPT 3.5
   improved 55.6% of responses and Perplexity 80%. The texts were generally
   very difficult to read, requiring an advanced reading level. However,
   Perplexity's responses were significantly more readable than ChatGPT
   3.5's [Flesch reading ease: 29.0 (SD 13.9) vs. 24.1 (SD 15.0), p =
   0.018].SignificanceOur findings underscore the potential of AI chatbots
   in delivering accurate and complete responses to Dravet syndrome
   queries. However, they have limitations, particularly in complex areas
   like treatment. Continuous efforts to update information and improve
   readability are essential.Plain Language SummaryArtificial intelligence
   chatbots have the potential to improve access to medical information,
   including on conditions like Dravet syndrome, but the quality of this
   information is still unclear. In this study, ChatGPT 3.5 and Perplexity
   correctly answered most questions from healthcare professionals and
   caregivers, with ChatGPT 3.5 performing better for caregivers.
   Treatment-related questions had the most incorrect answers, particularly
   those from healthcare professionals. Both chatbots demonstrated the
   ability to correct previous incorrect responses, particularly
   Perplexity. Both chatbots produced text requiring advanced reading
   skills. Further improvements are needed to make the text easier to
   understand and address difficult medical topics.
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
TC 0
Z9 0
DA 2025-04-08
UT WOS:001457614400001
PM 40167029
ER

PT J
AU Goh, Ethan
   Bunning, Bryan
   Khoong, Elaine
   Gallo, Robert
   Milstein, Arnold
   Centola, Damon
   Chen, Jonathan H
TI ChatGPT Influence on Medical Decision-Making, Bias, and Equity: A
   Randomized Study of Clinicians Evaluating Clinical Vignettes.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2023.11.24.23298844
DT Preprint
PD 2023 Nov 27
PY 2023
AB In a randomized, pre-post intervention study, we evaluated the influence
   of a large language model (LLM) generative AI system on accuracy of
   physician decision-making and bias in healthcare. 50 US-licensed
   physicians reviewed a video clinical vignette, featuring actors
   representing different demographics (a White male or a Black female)
   with chest pain. Participants were asked to answer clinical questions
   around triage, risk, and treatment based on these vignettes, then asked
   to reconsider after receiving advice generated by ChatGPT+ (GPT4). The
   primary outcome was the accuracy of clinical decisions based on
   pre-established evidence-based guidelines. Results showed that
   physicians are willing to change their initial clinical impressions
   given AI assistance, and that this led to a significant improvement in
   clinical decision-making accuracy in a chest pain evaluation scenario
   without introducing or exacerbating existing race or gender biases. A
   survey of physician participants indicates that the majority expect LLM
   tools to play a significant role in clinical decision making.
ZS 0
ZB 0
ZR 0
Z8 0
ZA 0
TC 1
Z9 1
DA 2023-12-16
UT MEDLINE:38076944
PM 38076944
ER

PT C
AU Solinsky, Jacob
   Finzel, Raymond
   Michalowski, Martin
   Pakhomov, Serguei
GP Int Speech Commun Assoc
TI Automated Neural Nursing Assistant (ANNA): An Over-The-Phone System for
   Cognitive Monitoring
SO INTERSPEECH 2023
SE Interspeech
BP 684
EP 685
DT Proceedings Paper
PD 2023
PY 2023
AB ANNA is a telephony-based cognitive assessment tool designed to aid
   nurses in caring for patients who require close monitoring for the
   development of confusion or neurological impairment. Of particular
   concern is the treatment of Immune Effector Cell-Associated
   Neurotoxicity Syndrome (ICANS), a condition which occurs quite
   frequently as an adverse outcome of Chimeric Antigen Receptor-T (CAR-T)
   cancer immunotherapy. ANNA employs both traditional verbal tests for
   cognitive impairment and novel linguistic methods which identify
   abnormalities in the patient's speech during ordinary conversation. To
   collect ordinary speech it uses a lightweight instance of the Facebook's
   Large Language Model BlenderBot to engage the patient in a partially
   unscripted conversation. ANNA is designed with easy employment by
   healthcare providers in mind, being sufficiently lightweight to run on
   consumer-grade hardware and needing access only to a patient's phone
   number to interact with them.
CT Interspeech Conference
CY AUG 20-24, 2023
CL Dublin, IRELAND
ZS 0
TC 0
ZB 0
ZA 0
Z8 0
ZR 0
Z9 0
DA 2024-07-04
UT WOS:001186650300144
ER

PT J
AU Ayoub, Marc
   Ballout, Ahmad A.
   Zayek, Rosana A.
   Ayoub, Noel F.
TI Mind
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 15
IS 8
AR e43690
DI 10.7759/cureus.43690
DT Article
PD AUG 18 2023
PY 2023
AB Background Generative artificial intelligence (AI) has integrated into
   various industries as it has demonstrated enormous potential in
   automating elaborate processes and enhancing complex decision-making.
   The ability of these chatbots to critically triage, diagnose, and manage
   complex medical conditions, remains unknown and requires further
   research.Objective This cross-sectional study sought to quantitatively
   analyze the appropriateness of ChatGPT (OpenAI, San Francisco, CA, US)
   in its ability to triage, synthesize differential diagnoses, and
   generate treatment plans for nine diverse but common clinical
   scenarios.Methods Various common clinical scenarios were developed. Each
   was input into ChatGPT, and the chatbot was asked to develop diagnostic
   and treatment plans. Five practicing physicians independently scored
   ChatGPT's responses to the clinical scenarios.Results The average
   overall score for the triage ranking was 4.2 (SD 0.7). The lowest
   overall score was for the completeness of the differential diagnosis at
   4.1 (0.5). The highest overall scores were seen with the accuracy of the
   differential diagnosis, initial treatment plan, and overall usefulness
   of the response (all with an average score of 4.4). Variance among
   physician scores ranged from 0.24 for accuracy of the differential
   diagnosis to 0.49 for appropriateness of triage ranking.Discussion
   ChatGPT has the potential to augment clinical decision-making. More
   extensive research, however, is needed to ensure accuracy and
   appropriate recommendations are provided.
TC 12
ZB 1
ZS 0
Z8 0
ZR 0
ZA 0
Z9 12
DA 2023-10-12
UT WOS:001064944100009
PM 37724211
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT J
AU Marchi, Filippo
   Bellini, Elisa
   Iandelli, Andrea
   Sampieri, Claudio
   Peretti, Giorgio
TI Exploring the landscape of AI-assisted decision-making in head and neck
   cancer treatment: a comparative analysis of NCCN guidelines and ChatGPT
   responses
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 2123
EP 2136
DI 10.1007/s00405-024-08525-z
EA FEB 2024
DT Article
PD APR 2024
PY 2024
AB PurposeRecent breakthroughs in natural language processing and machine
   learning, exemplified by ChatGPT, have spurred a paradigm shift in
   healthcare. Released by OpenAI in November 2022, ChatGPT rapidly gained
   global attention. Trained on massive text datasets, this large language
   model holds immense potential to revolutionize healthcare. However,
   existing literature often overlooks the need for rigorous validation and
   real-world applicability.MethodsThis head-to-head comparative study
   assesses ChatGPT's capabilities in providing therapeutic recommendations
   for head and neck cancers. Simulating every NCCN Guidelines scenarios.
   ChatGPT is queried on primary treatments, adjuvant treatment, and
   follow-up, with responses compared to the NCCN Guidelines. Performance
   metrics, including sensitivity, specificity, and F1 score, are employed
   for assessment.ResultsThe study includes 68 hypothetical cases and 204
   clinical scenarios. ChatGPT exhibits promising capabilities in
   addressing NCCN-related queries, achieving high sensitivity and overall
   accuracy across primary treatment, adjuvant treatment, and follow-up.
   The study's metrics showcase robustness in providing relevant
   suggestions. However, a few inaccuracies are noted, especially in
   primary treatment scenarios.ConclusionOur study highlights the
   proficiency of ChatGPT in providing treatment suggestions. The model's
   alignment with the NCCN Guidelines sets the stage for a nuanced
   exploration of AI's evolving role in oncological decision support.
   However, challenges related to the interpretability of AI in clinical
   decision-making and the importance of clinicians understanding the
   underlying principles of AI models remain unexplored. As AI continues to
   advance, collaborative efforts between models and medical experts are
   deemed essential for unlocking new frontiers in personalized cancer
   care.
ZB 4
ZA 0
TC 18
Z8 0
ZR 0
ZS 0
Z9 18
DA 2024-04-24
UT WOS:001172712200001
PM 38421392
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT J
AU Ho, Cindy N.
   Tian, Tiffany
   Ayers, Alessandra T.
   Aaron, Rachel E.
   Phillips, Vidith
   Wolf, Risa M.
   Mathioudakis, Nestoras
   Dai, Tinglong
   Klonoff, David C.
TI Qualitative metrics from the biomedical literature for evaluating large
   language models in clinical decision-making: a narrative review
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
VL 24
IS 1
AR 357
DI 10.1186/s12911-024-02757-z
DT Article
PD NOV 26 2024
PY 2024
AB BackgroundThe large language models (LLMs), most notably ChatGPT,
   released since November 30, 2022, have prompted shifting attention to
   their use in medicine, particularly for supporting clinical
   decision-making. However, there is little consensus in the medical
   community on how LLM performance in clinical contexts should be
   evaluated.MethodsWe performed a literature review of PubMed to identify
   publications between December 1, 2022, and April 1, 2024, that discussed
   assessments of LLM-generated diagnoses or treatment plans.ResultsWe
   selected 108 relevant articles from PubMed for analysis. The most
   frequently used LLMs were GPT-3.5, GPT-4, Bard, LLaMa/Alpaca-based
   models, and Bing Chat. The five most frequently used criteria for
   scoring LLM outputs were "accuracy", "completeness", "appropriateness",
   "insight", and "consistency".ConclusionsThe most frequently used
   criteria for defining high-quality LLMs have been consistently selected
   by researchers over the past 1.5 years. We identified a high degree of
   variation in how studies reported their findings and assessed LLM
   performance. Standardized reporting of qualitative evaluation metrics
   that assess the quality of LLM outputs can be developed to facilitate
   research studies on LLMs in healthcare.
ZS 0
TC 4
ZA 0
ZB 0
Z8 0
ZR 0
Z9 4
DA 2024-12-03
UT WOS:001364059400003
PM 39593074
ER

PT J
AU Wang, Calvin
   Ong, Joshua
   Wang, Chara
   Ong, Hannah
   Cheng, Rebekah
   Ong, Dennis
TI Potential for GPT Technology to Optimize Future Clinical Decision-Making
   Using Retrieval-Augmented Generation
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 5
BP 1115
EP 1118
DI 10.1007/s10439-023-03327-6
EA AUG 2023
DT Letter
PD MAY 2024
PY 2024
AB Advancements in artificial intelligence (AI) provide many helpful tools
   for healthcare, one of which includes AI chatbots that use natural
   language processing to create humanlike, conversational dialog. These
   chatbots have general cognitive skills and are able to engage with
   clinicians and patients to discuss patients' health conditions and what
   they may be at risk for. While chatbot engines have access to a wide
   range of medical texts and research papers, they currently provide
   high-level, generic responses and are limited in their ability to
   provide diagnostic guidance and clinical advice to patients on an
   individual level. The essay discusses the use of retrieval-augmented
   generation (RAG), which can be used to improve the specificity of
   user-entered prompts and thereby enhance the detail in AI chatbot
   responses. By embedding more recent clinical data and trusted medical
   sources, such as clinical guidelines, into the chatbot models, AI
   chatbots can provide more patient-specific guidance, faster diagnoses
   and treatment recommendations, and greater improvement of patient
   outcomes.
ZA 0
TC 27
ZS 0
ZR 0
ZB 5
Z8 0
Z9 27
DA 2023-08-17
UT WOS:001041791700003
PM 37530906
ER

PT J
AU Liu, Xiaona
   Wang, Qing
   Zhou, Minghao
   Wang, Yanfei
   Wang, Xuefeng
   Zhou, Xiaobo
   Song, Qianqian
TI DrugFormer: Graph-Enhanced Language Model to Predict Drug Sensitivity
SO ADVANCED SCIENCE
VL 11
IS 40
DI 10.1002/advs.202405861
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB Drug resistance poses a crucial challenge in healthcare, with response
   rates to chemotherapy and targeted therapy remaining low. Individual
   patient's resistance is exacerbated by the intricate heterogeneity of
   tumor cells, presenting significant obstacles to effective treatment. To
   address this challenge, DrugFormer, a novel graph-augmented large
   language model designed to predict drug resistance at single-cell level
   is proposed. DrugFormer integrates both serialized gene tokens and
   gene-based knowledge graphs for the accurate predictions of drug
   response. After training on comprehensive single-cell data with drug
   response information, DrugFormer model presents outperformance, with
   higher F1, precision, and recall in predicting drug response. Based on
   the scRNA-seq data from refractory multiple myeloma (MM) and acute
   myeloid leukemia (AML) patients, DrugFormer demonstrates high efficacy
   in identifying resistant cells and uncovering underlying molecular
   mechanisms. Through pseudotime trajectory analysisunique drug-resistant
   cellular states associated with poor patient outcomes are revealed.
   Furthermore, DrugFormer identifies potential therapeutic targets, such
   as COX8A, for overcoming drug resistance across different cancer types.
   In conclusion, DrugFormer represents a significant advancement in the
   field of drug resistance prediction, offering a powerful tool for
   unraveling the heterogeneity of cellular response to drugs and guiding
   personalized treatment strategies.
   DrugFormer, a novel graph-augmented language model, addresses the
   critical challenge of drug resistance in cancer treatment. By
   integrating serialized gene tokens and a gene-based knowledge graph, it
   provides accurate drug response predictions at the single-cell level.
   DrugFormer demonstrates superior performance and identifies resistant
   cells with potential therapeutic targets, offering a promising solution
   for personalized cancer therapy. image
Z8 0
ZA 0
ZS 0
ZB 1
ZR 0
TC 9
Z9 9
DA 2024-09-02
UT WOS:001300001500001
PM 39206872
ER

PT J
AU Ye, Yi
   Zheng, En-dian
   Lan, Qiao-li
   Wu, Le-can
   Sun, Hao-yue
   Xu, Bei-bei
   Wang, Ying
   Teng, Miao-miao
TI Comparative evaluation of the accuracy and reliability of ChatGPT
   versions in providing information on Helicobacter pylori
   infection
SO FRONTIERS IN PUBLIC HEALTH
VL 13
AR 1566982
DI 10.3389/fpubh.2025.1566982
DT Article
PD MAY 15 2025
PY 2025
AB Objective This study aimed to evaluate the accuracy and reliability of
   responses provided by three versions of ChatGPT (ChatGPT-3.5, ChatGPT-4,
   and ChatGPT-4o) to questions related to Helicobacter pylori (Hp)
   infection, as well as to explore their potential applications within the
   healthcare domain. Methods A panel of experts compiled and refined a set
   of 27 clinical questions related to Hp. These questions were presented
   to each ChatGPT version, generating three distinct sets of responses.
   The responses were evaluated and scored by three gastroenterology
   specialists utilizing a 5-point Likert scale, with an emphasis on
   accuracy and comprehensiveness. To assess response stability and
   reliability, each question was submitted three times over three
   consecutive days. Results Statistically significant differences in the
   Likert scale scores were observed among the three ChatGPT versions (p <
   0.0001). ChatGPT-4o demonstrated the best performance, achieving an
   average score of 4.46 (standard deviation 0.82) points. Despite its high
   accuracy, ChatGPT-4o exhibited relatively low repeatability. In
   contrast, ChatGPT-3.5 exhibited the highest stability, although it
   occasionally provided incorrect answers. In terms of readability,
   ChatGPT-4 achieved the highest Flesch Reading Ease score of 24.88
   (standard deviation 0.44), however, no statistically significant
   differences in readability were observed among the versions. Conclusion
   All three versions of ChatGPT were effective in addressing Hp-related
   questions, with ChatGPT-4o delivering the most accurate information.
   These findings suggest that artificial intelligence-driven chat models
   hold significant potential in healthcare, facilitating improved patient
   awareness, self-management, and treatment compliance, as well as
   supporting physicians in making informed medical decisions by providing
   accurate information and personalized recommendations.
ZA 0
TC 0
ZR 0
ZB 0
ZS 0
Z8 0
Z9 0
DA 2025-06-03
UT WOS:001498407800001
PM 40443929
ER

PT C
AU Ding, Xinpeng
   Chu, Yongqiang
   Pi, Renjie
   Wang, Hualiang
   Li, Xiaomeng
BE Linguraru, MG
   Dou, Q
   Feragen, A
   Giannarou, S
   Glocker, B
   Lekadir, K
   Schnabel, JA
TI HiA: Towards Chinese Multimodal LLMs for Comparative High-Resolution
   Joint Diagnosis
SO MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI
   2024, PT XII
SE Lecture Notes in Computer Science
VL 15012
BP 575
EP 586
DI 10.1007/978-3-031-72390-2_54
DT Proceedings Paper
PD 2024
PY 2024
AB Multimodal large language models (MLLMs) have been explored in the
   Chinese medical domain for comprehending complex healthcare. However,
   due to the flaws in training data and architecture design, current
   Chinese medical MLLMs suffer from several limitations: cultural biases
   from English machine translations, limited comparative ability from
   single image input and difficulty in identifying small lesions with
   low-resolution images. To address these problems, we first introduce a
   new instruction-following dataset, Chili-Joint (Chinese Interleaved
   Image-Text Dataset for Joint Diagnosis) collected from the hospital in
   mainland China, avoiding cultural biases and errors caused by machine
   translation. Besides one single image input, Chili-Joint also has
   multiple images obtained at various intervals during a patient's
   treatment, thus facilitating an evaluation of the treatment's outcomes.
   We further propose a novel HiA (High-resolution instruction-aware
   Adapter) to incorporate high-resolutioninstruction-aware visual features
   into LLMs to facilitate the current MLLMs to observe the small lesions
   as well as the comparative analysis. Extensive experiments on
   Chili-Joint demonstrate our HiA can be a plug-and-play method to improve
   the performance of current MLLMs for medical analysis. The code is
   available at https:// github.com/xmed- lab/HiA.
CT 27th International Conference on Medical Image Computing and Computer
   Assisted Intervention (MICCAI)
CY OCT 06-10, 2024
CL Palmeraie Conf Ctr, Marrakesh, MOROCCO
HO Palmeraie Conf Ctr
SP GH Labs; Childrens Natl Hosp; Pierre Fabre; Comp Assisted Med Intervent
   Labex; Multidisciplinary Inst Artificial Intelligence Grenoble Alpes;
   Western Univ, Frugal Biomed Innovat Program; Int Soc Radiol; Medtronic;
   Pasqual Maragall Fdn; Delft Imaging; Univ Barcelona, Artificial
   Intelligence Med Lab; Cadi Ayyad Univ; Natl Ctr Sci & Tech Res
ZA 0
Z8 0
ZS 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2024-12-03
UT WOS:001344002100054
ER

PT C
AU Kumi, Sandra
   Ray, Madhurima
   Walia, Sanskriti
   Lomotey, Richard K.
   Deters, Ralph
BE Paul, R
   Kundu, A
   Bhattacharyya, R
TI Digital Twins for Stress Management Utilizing Synthetic Data
SO 2024 IEEE 5TH ANNUAL WORLD AI IOT CONGRESS, AIIOT 2024
BP 0329
EP 0335
DI 10.1109/AIIoT61789.2024.10579038
DT Proceedings Paper
PD 2024
PY 2024
AB In the era of Medical 4.0, technologies such as big data, wearables, and
   Machine Learning (ML) are being deployed for predictive healthcare
   delivery. In this regard, digital twins have been adopted in healthcare
   to enhance diagnosis and personalized treatment. Health Digital Twins
   (HDTs) are virtual representations of patients' data, mirroring the
   health state of patients to provide insights. Despite its promise, the
   existing works on HDTs relied on large historical data to train ML
   models. These historical data may be difficult to obtain due to privacy
   concerns of data fiduciaries and subjects. In this paper, we propose a
   Digital Twin for Stress Management (DTSM) that employs generative models
   to learn the distribution of patients' data retrieved from a wearable
   device for stress management score prediction. To obtain a virtual
   replica of a patient's data, we used synthetic data generative models
   such as Conditional Tabular Generative Adversarial Network (CTGAN),
   Tabular Variational Autoencoder (TVAE), Gaussian Copula, and Large
   Language Models (LLM) (REaLTabFormer and GReaT). The best result came
   from REaLTabFormer which accurately learns the distributions of the real
   data with a data quality score of approximately 93%. Furthermore, four
   wellknown ML models trained on the synthetic data obtained a mean
   absolute error (MAE) of less than 5% in the prediction of stress score.
   Our experimental results show that the proposed DTSM can be used for the
   prediction of stress management scores.
CT IEEE 5th Annual World AI IoT Congress (AIIoT)
CY MAY 29-31, 2024
CL WA
SP IEEE; SMART; IEEE USA; Inst Engn & Management; Univ Engn & Management
ZR 0
ZA 0
Z8 0
ZB 0
TC 1
ZS 0
Z9 1
DA 2024-10-10
UT WOS:001289206000048
ER

PT J
AU Pagano, Stefano
   Holzapfel, Sabrina
   Kappenschneider, Tobias
   Meyer, Matthias
   Maderbacher, Guenther
   Grifka, Joachim
   Holzapfel, Dominik Emanuel
TI Arthrosis diagnosis and treatment recommendations in clinical practice:
   an exploratory investigation with the generative AI model GPT-4
SO JOURNAL OF ORTHOPAEDICS AND TRAUMATOLOGY
VL 24
IS 1
AR 61
DI 10.1186/s10195-023-00740-4
DT Article
PD NOV 28 2023
PY 2023
AB Background The spread of artificial intelligence (AI) has led to
   transformative advancements in diverse sectors, including healthcare.
   Specifically, generative writing systems have shown potential in various
   applications, but their effectiveness in clinical settings has been
   barely investigated. In this context, we evaluated the proficiency of
   ChatGPT-4 in diagnosing gonarthrosis and coxarthrosis and recommending
   appropriate treatments compared with orthopaedic specialists.Methods A
   retrospective review was conducted using anonymized medical records of
   100 patients previously diagnosed with either knee or hip arthrosis.
   ChatGPT-4 was employed to analyse these historical records, formulating
   both a diagnosis and potential treatment suggestions. Subsequently, a
   comparative analysis was conducted to assess the concordance between the
   AI's conclusions and the original clinical decisions made by the
   physicians.Results In diagnostic evaluations, ChatGPT-4 consistently
   aligned with the conclusions previously drawn by physicians. In terms of
   treatment recommendations, there was an 83% agreement between the AI and
   orthopaedic specialists. The therapeutic concordance was verified by the
   calculation of a Cohen's Kappa coefficient of 0.580 (p < 0.001). This
   indicates a moderate-to-good level of agreement. In recommendations
   pertaining to surgical treatment, the AI demonstrated a sensitivity and
   specificity of 78% and 80%, respectively. Multivariable logistic
   regression demonstrated that the variables reduced quality of life (OR
   49.97, p < 0.001) and start-up pain (OR 12.54, p = 0.028) have an
   influence on ChatGPT-4's recommendation for a surgery.Conclusion This
   study emphasises ChatGPT-4's notable potential in diagnosing conditions
   such as gonarthrosis and coxarthrosis and in aligning its treatment
   recommendations with those of orthopaedic specialists. However, it is
   crucial to acknowledge that AI tools such as ChatGPT-4 are not meant to
   replace the nuanced expertise and clinical judgment of seasoned
   orthopaedic surgeons, particularly in complex decision-making scenarios
   regarding treatment indications. Due to the exploratory nature of the
   study, further research with larger patient populations and more complex
   diagnoses is necessary to validate the findings and explore the broader
   potential of AI in healthcare.
Z8 0
ZS 0
ZR 0
TC 15
ZB 3
ZA 0
Z9 15
DA 2023-12-17
UT WOS:001110492100001
PM 38015298
ER

PT J
AU Xu, Peng
TI Multi-layered data framework for enhancing postoperative outcomes and
   anaesthesia management through natural language processing
SO SLAS TECHNOLOGY
VL 32
AR 100294
DI 10.1016/j.slast.2025.100294
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Anaesthesia management is a critical aspect of perioperative care,
   directly influencing postoperative recovery, pain management, and
   patient outcomes. Despite advancements in anaesthesia techniques,
   variability in patient responses and unexpected postoperative
   complications remain significant challenges. The research proposes a
   multi-layered architecture named Anaesthesia CareNet for analyzing data
   from diverse sources to enhance personalized anaesthesia management and
   postoperative outcome prediction. The architecture is structured into
   two primary layers: Data processing and Predictive Modeling. In the Data
   processing layer, advanced Natural Language Processing (NLP) techniques
   such as Named Entity Recognition (NER), normalization, lemmatization,
   and stemming are applied to clean and standardize the unstructured
   clinical data. Generative Pre-trained Transformer 3 (GPT-3), a Large
   Language Model (LLM) is employed as a feature extraction method,
   allowing the system to process and analyze complex clinical narratives
   and unstructured textual data from patient records. This enables more
   precise and personalized predictions, not only improving anaesthesia
   management but also laying the groundwork for broader applications in
   life sciences. The extracted data is passed into the predictive modeling
   layer, where the Intelligent Golden Eagle Fine-Tuned Logistic Regression
   (IGE-LR) model is applied. By analyzing correlations between patient
   characteristics, surgical details, and postoperative recovery patterns,
   IGELR enables the prediction of complications, pain management
   requirements, and recovery trajectories beyond anaesthesia; the
   methodology has potential applications in diverse areas such as
   diagnostics, drug discovery, and personalized medicine, where
   large-scale data analysis, predictive modeling, and real-time
   adaptability are crucial for improving patient outcomes. The proposed
   IGE-LR method achieves higher performance with 91.7 % accuracy, 90.6 %
   specificity, and 90 % AUC, with a recall of 91.3 %, precision of 90.1 %,
   and an F1-Score of 90.4 %. By leveraging advanced NLP and predictive
   analytics, Anaesthesia CareNet exemplifies how AI-driven frameworks can
   transform life sciences, advancing personalized healthcare and creating
   a more precise, efficient, and dynamic approach to treatment management.
ZR 0
ZS 0
TC 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-10
UT WOS:001479823100001
PM 40252977
ER

PT J
AU Karakas, Cemal
   Brock, Dylan
   Lakhotia, Arpita
TI Leveraging ChatGPT in the Pediatric Neurology Clinic: Practical
   Considerations for Use to Improve Efficiency and Outcomes
SO PEDIATRIC NEUROLOGY
VL 148
BP 157
EP 163
DI 10.1016/j.pediatrneurol.2023.08.035
EA SEP 2023
DT Article
PD NOV 2023
PY 2023
AB Background: Artificial intelligence (AI) is progressively influencing
   healthcare sectors, including pediatric neurology. This paper aims to
   investigate the potential and limitations of using ChatGPT, a large
   language model (LLM) developed by OpenAI, in an outpatient pediatric
   neurology clinic. The analysis focuses on the tool's capabilities in
   enhancing clinical efficiency, productivity, and patient education.
   Method: This is an opinion-based exploration supplemented with practical
   examples. We assessed ChatGPT's utility in administrative and
   educational tasks such as drafting medical necessity letters and
   creating patient educational materials. Results: ChatGPT showed efficacy
   in streamlining administrative work, particularly in drafting
   administrative letters and formulating personalized patient education
   materials. However, the model has limitations in performing higher-order
   tasks like formulating nuanced differential diagnoses. Additionally,
   ethical and legal concerns, including data privacy and the potential
   dissemination of misinformation, warrant cautious implementation.
   Conclusions: The integration of AI tools like ChatGPT in pediatric
   neurology clinics has demonstrated promising results in boosting
   efficiency and patient education, despite present limitations and
   ethical concerns. As technology advances, we anticipate future
   applications may extend to more complex clinical tasks like precise
   differential diagnoses and treatment strategy guidance. Careful,
   patient-centered implementation is essential for leveraging the
   potential benefits of AI in pediatric neurology effectively. (c) 2023
   Elsevier Inc. All rights reserved.
Z8 1
ZB 1
ZS 0
TC 5
ZR 0
ZA 0
Z9 6
DA 2023-10-28
UT WOS:001082330800001
PM 37725885
ER

PT J
AU Bonnechere, Bruno
TI Unlocking the Black Box? A Comprehensive Exploration of Large Language
   Models in Rehabilitation
SO AMERICAN JOURNAL OF PHYSICAL MEDICINE & REHABILITATION
VL 103
IS 6
BP 532
EP 537
DI 10.1097/PHM.0000000000002440
DT Article
PD JUN 2024
PY 2024
AB Rehabilitation is a vital component of health care, aiming to restore
   function and improve the well-being of individuals with disabilities or
   injuries. Nevertheless, the rehabilitation process is often likened to a
   "black box," with complexities that pose challenges for comprehensive
   analysis and optimization. The emergence of large language models offers
   promising solutions to better understand this "black box." Large
   language models excel at comprehending and generating human-like text,
   making them valuable in the healthcare sector. In rehabilitation,
   healthcare professionals must integrate a wide range of data to create
   effective treatment plans, akin to selecting the best ingredients for
   the "black box." Large language models enhance data integration,
   communication, assessment, and prediction.This article delves into the
   ground-breaking use of large language models as a tool to further
   understand the rehabilitation process. Large language models address
   current rehabilitation issues, including data bias, contextual
   comprehension, and ethical concerns. Collaboration with healthcare
   experts and rigorous validation is crucial when deploying large language
   models. Integrating large language models into rehabilitation yields
   insights into this intricate process, enhancing data-driven decision
   making, refining clinical practices, and predicting rehabilitation
   outcomes. Although challenges persist, large language models represent a
   significant stride in rehabilitation, underscoring the importance of
   ethical use and collaboration.
ZR 0
ZS 0
ZA 0
TC 5
Z8 0
ZB 0
Z9 5
DA 2024-06-14
UT WOS:001226541200001
PM 38261757
ER

PT C
AU Chang, Chia-Hsuan
   Lucas, Mary M.
   Lee, Yeawon
   Yang, Christopher C.
   Lu-Yao, Grace
BE Finkelstein, J
   Moskovitch, R
   Parimbelli, E
TI Beyond Self-consistency: Ensemble Reasoning Boosts Consistency and
   Accuracy of LLMs in Cancer Staging
SO ARTIFICIAL INTELLIGENCE IN MEDICINE, PT I, AIME 2024
SE Lecture Notes in Artificial Intelligence
VL 14844
BP 224
EP 228
DI 10.1007/978-3-031-66538-7_23
DT Proceedings Paper
PD 2024
PY 2024
AB Pathologic cancer stage, crucial for treatment decisions, is often
   buried in unstructured pathology reports. This study investigates using
   pre-trained clinical LLMs for stage extraction, leveraging prompting
   techniques like chain-of-thought to enhance model transparency. While
   self-consistency methods further improve LLM performance, they can
   introduce inconsistencies in reasoning paths and predictions. We propose
   an ensemble reasoning approach, aiming for reliable cancer stage
   extraction. Utilizing an open-source clinical LLM on real-world reports,
   we demonstrate that the ensemble approach improves consistency and
   boosts performance, paving the way for utilizing LLMs in healthcare
   settings where reliability and interpretability are paramount.
CT 22nd International Conference on Artificial Intelligence in Medicine
   (AIME)
CY JUL 09-12, 2024
CL Salt Lake City, UT
ZB 1
TC 1
ZR 0
ZA 0
Z8 0
ZS 0
Z9 1
DA 2024-09-29
UT WOS:001295129500023
ER

PT J
AU Hasei, Joe
   Hanzawa, Mana
   Nagano, Akihito
   Maeda, Naoko
   Yoshida, Shinichirou
   Endo, Makoto
   Yokoyama, Nobuhiko
   Ochi, Motoharu
   Ishida, Hisashi
   Katayama, Hideki
   Fujiwara, Tomohiro
   Nakata, Eiji
   Nakahara, Ryuichi
   Kunisada, Toshiyuki
   Tsukahara, Hirokazu
   Ozaki, Toshifumi
TI Empowering pediatric, adolescent, and young adult patients with cancer
   utilizing generative AI chatbots to reduce psychological burden and
   enhance treatment engagement: a pilot study
SO FRONTIERS IN DIGITAL HEALTH
VL 7
AR 1543543
DI 10.3389/fdgth.2025.1543543
DT Article
PD FEB 25 2025
PY 2025
AB Background Pediatric and adolescent/young adult (AYA) cancer patients
   face profound psychological challenges, exacerbated by limited access to
   continuous mental health support. While conventional therapeutic
   interventions often follow structured protocols, the potential of
   generative artificial intelligence (AI) chatbots to provide continuous
   conversational support remains unexplored. This study evaluates the
   feasibility and impact of AI chatbots in alleviating psychological
   distress and enhancing treatment engagement in this vulnerable
   population.Methods Two age-appropriate AI chatbots, leveraging GPT-4,
   were developed to provide natural, empathetic conversations without
   structured therapeutic protocols. Five pediatric and AYA cancer patients
   participated in a two-week intervention, engaging with the chatbots via
   a messaging platform. Pre- and post-intervention anxiety and stress
   levels were self-reported, and usage patterns were analyzed to assess
   the chatbots' effectiveness.Results Four out of five participants
   reported significant reductions in anxiety and stress levels
   post-intervention. Participants engaged with the chatbot every 2-3 days,
   with sessions lasting approximately 10 min. All participants noted
   improved treatment motivation, with 80% disclosing personal concerns to
   the chatbot they had not shared with healthcare providers. The 24/7
   availability particularly benefited patients experiencing nighttime
   anxiety.Conclusions This pilot study demonstrates the potential of
   generative AI chatbots to complement traditional mental health services
   by addressing unmet psychological needs in pediatric and AYA cancer
   patients. The findings suggest these tools can serve as accessible,
   continuous support systems. Further large-scale studies are warranted to
   validate these promising results.
Z8 0
ZB 0
ZA 0
ZS 0
TC 0
ZR 0
Z9 0
DA 2025-03-16
UT WOS:001441098700001
PM 40070545
ER

PT J
AU Davidson, Jayson
   Vashisht, Rohit
   Radtke, Kendra
   Patel, Ayan
   Koliwad, Suneil K
   Butte, Atul J
TI Real-World Type 2 Diabetes Second-Line Treatment Allocation Among
   Patients.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2025.03.26.25324631
DT Journal Article; Preprint
PD 2025 Mar 28
PY 2025
AB Objective: This study aimed to evaluate the impact of socioeconomic
   disparities on the allocation of second-line treatments among patients
   with type 2 diabetes (T2D).
   Materials and Methods: We conducted an observational study using
   real-world data from over 9 million patients across five University of
   California Health centers. The study included patients who initiated a
   second-line T2D medication after metformin, with hemoglobin A1c (HbA1c)
   measurements within ±7 days of treatment initiation from 2012 through
   September 2024. Multinomial regression models assessed the association
   between socioeconomic status and second-line treatment choices.
   Additionally, we used the GPT-4 large language model with a zero-shot
   learning approach to analyze 270 clinical notes from 105 UCSF patients.
   GPT-4 identified adverse social determinants of health (SDOH) across six
   domains: transportation, housing, relationships, patients with children,
   support, and employment.
   Results: Among 15,090 patients (56.7% male, 43.3% female; mean age 59.3
   years; mean HbA1c 8.91%), second-line treatments included sulfonylureas
   (SUs; n = 6,732), DPP4 inhibitors (n = 2,918), GLP-1 receptor agonists
   (n = 2,736), and SGLT2 inhibitors (n = 2,704). Patients from lower
   socioeconomic neighborhoods were more likely to receive SUs over other
   medications: DPP4i (OR = 0.96, [95% CI, 0.95-0.98]), GLP-1RA (OR = 0.94,
   [95% CI, 0.92-0.96]), SGLT2i (OR = 0.95, [95% CI, 0.93-0.97]). In UCSF
   clinical notes, we identified adverse SDOH including housing (n=8),
   transportation (n=1), relationships (n=22), employment (n=12), support
   (n=1), and patients with children (n=25).
   Conclusions: Socioeconomic factors influence second-line T2D treatment
   choices. Addressing these disparities is essential to ensuring equitable
   access to advanced T2D therapies.
Z8 0
TC 0
ZS 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2025-04-10
UT MEDLINE:40196266
PM 40196266
ER

PT J
AU Agrawal, Anjali
TI Fairness in AI-Driven Oncology: Investigating Racial and Gender Biases
   in Large Language Models
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 9
AR e69541
DI 10.7759/cureus.69541
DT Article
PD SEP 16 2024
PY 2024
AB Introduction: Large language model (LLM) chatbots have many applications
   in medical settings. However, these tools can potentially perpetuate
   racial and gender biases through their responses, worsening disparities
   in healthcare. With the ongoing discussion of LLM chatbots in oncology
   and the widespread goal of addressing cancer disparities, this study
   focuses on biases propagated by LLM chatbots in oncology. Methods: Chat
   Generative Pre-trained Transformer (Chat GPT; OpenAI, San Francisco, CA,
   USA) was asked to determine what occupation a generic description of
   "assesses cancer patients" would correspond to for different
   demographics. Chat GPT, Gemini (Alphabet Inc., Mountain View, CA, USA),
   and Bing Chat (Microsoft Corp., Redmond, WA, USA) were prompted to
   provide oncologist recommendations in the top U.S. cities and
   demographic information (race, gender) of recommendations was compared
   against national distributions. Chat GPT was also asked to generate a
   job description for oncologists with different demographic backgrounds.
   Finally, Chat GPT, Gemini, and Bing Chat were asked to generate
   hypothetical cancer patients with race, smoking, and drinking histories.
   Results: LLM chatbots are about two times more likely to predict Blacks
   and Native Americans as oncology nurses than oncologists, compared to
   Asians (p < 0.01 and < 0.001, respectively). Similarly, they are also
   significantly more likely to predict females than males as oncology
   nurses (p < 0.001). Chat GPT's real-world oncologist recommendations
   overrepresent Asians by almost double and underrepresent Blacks by
   double and Hispanics by seven times. Chatbots also generate different
   job descriptions based on demographics, including cultural competency
   and advocacy and excluding treatment administration for underrepresented
   backgrounds. AI-generated cancer cases are not fully representative of
   real-world demographic distributions and encode stereotypes on substance
   abuse, such as Hispanics having a greater proportion of smokers than
   Whites by about 20% in Chat GPT breast cancer cases. Conclusion: To our
   knowledge, this is the first study of its kind to investigate racial and
   gender biases of such a diverse set of AI chatbots, and that too, within
   oncology. The methodology presented in this study provides a framework
   for targeted bias evaluation of LLMs in various fields across medicine.
ZB 0
Z8 0
ZA 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2024-09-29
UT WOS:001318056600011
PM 39416584
ER

PT J
AU Okada, Yohei
   Mertens, Mayli
   Liu, Nan
   Lam, Sean Shao Wei
   Ong, Marcus Eng Hock
TI AI and machine learning in resuscitation: Ongoing research, new
   concepts, and key challenges
SO RESUSCITATION PLUS
VL 15
AR 100435
DI 10.1016/j.resplu.2023.100435
EA JUL 2023
DT Article
PD SEP 2023
PY 2023
AB Aim: Artificial intelligence (AI) and machine learning (ML) are
   important areas of computer science that have recently attracted
   attention for their application to medicine. However, as techniques
   continue to advance and become more complex, it is increasingly
   challenging for clinicians to stay abreast of the latest research. This
   overview aims to translate research concepts and potential concerns to
   healthcare professionals interested in applying AI and ML to
   resuscitation research but who are not experts in the field.Main text:
   We present various research including prediction models using structured
   and unstructured data, exploring treatment heterogeneity, reinforcement
   learning, language processing, and large-scale language models. These
   studies potentially offer valuable insights for optimizing treatment
   strategies and clinical workflows. However, implementing AI and ML in
   clinical settings presents its own set of challenges. The availability
   of high quality and reliable data is crucial for developing accurate ML
   models. A rigorous validation process and the integration of ML into
   clinical practice is essential for practical implementation. We
   furthermore highlight the potential risks associated with
   self-fulfilling prophecies and feedback loops, emphasizing the
   importance of transparency, interpretability, and trustworthiness in AI
   and ML models. These issues need to be addressed in order to establish
   reliable and trustworthy AI and ML models.Conclusion: In this article,
   we overview concepts and examples of AI and ML research in the
   resuscitation field. Moving forward, appropriate understanding of ML and
   collaboration with relevant experts will be essential for researchers
   and clinicians to overcome the challenges and harness the full potential
   of AI and ML in resuscitation.
Z8 0
ZS 0
ZR 0
ZB 2
TC 20
ZA 0
Z9 20
DA 2023-09-01
UT WOS:001051946400001
PM 37547540
ER

PT J
AU Balci, Ali Safa
   Cakmak, Semih
TI Evaluating the Accuracy and Readability of ChatGPT-4o's Responses to
   Patient-Based Questions about Keratoconus
SO OPHTHALMIC EPIDEMIOLOGY
DI 10.1080/09286586.2025.2484760
EA MAR 2025
DT Article; Early Access
PY 2025
AB Purpose: This study aimed to evaluate the accuracy and readability of
   responses generated by ChatGPT-4o, an advanced large language model, to
   frequently asked patient-centered questions about keratoconus. Methods:
   A cross-sectional, observational study was conducted using ChatGPT-4o to
   answer 30 potential questions that could be asked by patients with
   keratoconus. The accuracy of the responses was evaluated by two
   board-certified ophthalmologists and scored on a scale of 1 to 5.
   Readability was assessed using the Simple Measure of Gobbledygook
   (SMOG), Flesch-Kincaid Grade Level (FKGL), and Flesch Reading Ease (FRE)
   scores. Descriptive, treatment-related, and follow-up-related questions
   were analyzed, and statistical comparisons between these categories were
   performed. Results: The mean accuracy score for the responses was 4.48
   +/- 0.57 on a 5-point Likert scale. The interrater reliability, with an
   intraclass correlation coefficient of 0.769, indicated a strong level of
   agreement. Readability scores revealed a SMOG score of 15.49 +/- 1.74,
   an FKGL score of 14.95 +/- 1.95, and an FRE score of 27.41 +/- 9.71,
   indicating that a high level of education is required to comprehend the
   responses. There was no significant difference in accuracy among the
   different question categories (p = 0.161), but readability varied
   significantly, with treatment-related questions being the easiest to
   understand. Conclusion: ChatGPT-4o provides highly accurate responses to
   patient-centered questions about keratoconus, though the complexity of
   its language may limit accessibility for the general population. Further
   development is needed to enhance the readability of AI-generated medical
   content.
ZR 0
Z8 0
ZB 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2025-04-05
UT WOS:001455819900001
PM 40154955
ER

PT J
AU Farias, Humberto
   Aroca, Joaquin Gonzalez
   Ortiz, Daniel
TI Chatbot Based on Large Language Model to Improve Adherence to
   Exercise-Based Treatment in People with Knee Osteoarthritis: System
   Development
SO TECHNOLOGIES
VL 13
IS 4
AR 140
DI 10.3390/technologies13040140
DT Article
PD APR 4 2025
PY 2025
AB Knee osteoarthritis (KOA) is a prevalent condition globally, leading to
   significant pain and disability, particularly in individuals over the
   age of 40. While exercise has been shown to reduce symptoms and improve
   physical function and quality of life in patients with KOA, long-term
   adherence to exercise programs remains a challenge due to the lack of
   ongoing support. To address this, a chatbot was developed using large
   language models (LLMs) to provide evidence-based guidance and promote
   adherence to treatment. A systematic review conducted under the PRISMA
   framework identified relevant clinical guidelines that served as the
   foundational knowledge base for the chatbot. The Mistral 7B model,
   optimized with Parameter-Efficient Fine-Tuning (PEFT) and
   Mixture-of-Experts (MoE) techniques, was integrated to ensure
   computational efficiency and mitigate hallucinations, a critical concern
   in medical applications. Additionally, the chatbot employs
   Self-Reflective Retrieval-Augmented Generation (SELF-RAG) combined with
   Chain of Thought (CoT) reasoning, enabling dynamic query reformulation
   and the generation of accurate, evidence-based responses tailored to
   patient needs. The chatbot was evaluated by comparing pre- and
   post-improvement versions and against a reference model (ChatGPT), using
   metrics of accuracy, relevance, and consistency. The results
   demonstrated significant improvements in response quality and
   conversational coherence, emphasizing the potential of integrating
   advanced LLMs with retrieval and reasoning methods to address critical
   challenges in healthcare. This approach not only enhances treatment
   adherence but also strengthens patient-provider interactions in managing
   chronic conditions like KOA.
ZR 0
ZA 0
ZB 0
Z8 0
TC 1
ZS 0
Z9 1
DA 2025-05-03
UT WOS:001474312700001
ER

PT J
AU Zhang, Sainan
   Song, Jisung
TI A chatbot based question and answer system for the auxiliary diagnosis
   of chronic diseases based on large language model
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 17118
DI 10.1038/s41598-024-67429-4
DT Article
PD JUL 25 2024
PY 2024
AB In recent years, artificial intelligence has made remarkable strides,
   improving various aspects of our daily lives. One notable application is
   in intelligent chatbots that use deep learning models. These systems
   have shown tremendous promise in the medical sector, enhancing
   healthcare quality, treatment efficiency, and cost-effectiveness.
   However, their role in aiding disease diagnosis, particularly chronic
   conditions, remains underexplored. Addressing this issue, this study
   employs large language models from the GPT series, in conjunction with
   deep learning techniques, to design and develop a diagnostic system
   targeted at chronic diseases. Specifically, performed transfer learning
   and fine-tuning on the GPT-2 model, enabling it to assist in accurately
   diagnosing 24 common chronic diseases. To provide a user-friendly
   interface and seamless interactive experience, we further developed a
   dialog-based interface, naming it Chat Ella. This system can make
   precise predictions for chronic diseases based on the symptoms described
   by users. Experimental results indicate that our model achieved an
   accuracy rate of 97.50% on the validation set, and an area under the
   curve (AUC) value reaching 99.91%. Moreover, conducted user satisfaction
   tests, which revealed that 68.7% of participants approved of Chat Ella,
   while 45.3% of participants found the system made daily medical
   consultations more convenient. It can rapidly and accurately assess a
   patient's condition based on the symptoms described and provide timely
   feedback, making it of significant value in the design of medical
   auxiliary products for household use.
ZB 0
ZR 0
ZA 0
TC 6
ZS 0
Z8 0
Z9 6
DA 2024-08-03
UT WOS:001278002800002
PM 39054346
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU Tustumi, Francisco
   Andreollo, Nelson Adami
   de Aguilar-Nascimento, Jose Eduardo
TI FUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT
SO ABCD-ARQUIVOS BRASILEIROS DE CIRURGIA DIGESTIVA-BRAZILIAN ARCHIVES OF
   DIGESTIVE SURGERY
VL 36
IS 1
AR e1727
DI 10.1590/0102-672020230002e1727
DT Review
PD 2023
PY 2023
AB The field of medicine has always been at the forefront of technological
   innovation, Fabricio Ferreira COELHO3 , Paulo HERMAN3 constantly seeking
   new strategies to diagnose, treat, and prevent diseases. Guidelines for
   clinical practice to orientate medical teams regarding diagnosis,
   treatment, and prevention measures have increased over the years. The
   purpose is to gather the most medical knowledge to construct an
   orientation for practice. Evidence-based guidelines follow several main
   characteristics of a systematic RESUMO -Racmonal: O tratamento de
   escolha para pacientes com ipertensao portal review, including
   systematic and unbiased search, selection, and extraction of the source
   of evidence. esquistossomotica com sangramento de varizes e a desconexao
   azigo-portal mais In recent years, the rapid advancement of artificial
   intelligence has provided clinicians and patients esplenetomia (DAPE)
   associad a terapa endoscoica. Porem, estuds mostram aumento with access
   to personalized, data-driven insights, suport and new opportunities for
   healthcare do calibre das varizes em alguns pacientes durante o
   seguimento em longo prazo. Objetmvo: professionals to improve patient
   outcomes, increase efficiency, and reduce costs. One of the most Avaliar
   o impacto da DAPE e tratamento endoscopico pos-operatorio no
   comportamento exciting developments in Artificial Intelligence has been
   the emergence of chatbots. A chatbot is a computer program used to
   simulate conversations with human users. Recently, OpenAI, a research
   das varizes esofagicas e recidiva hemorragica, de pacientes
   esquistossomoticos. Metodos: organization focused on machine learning,
   developed ChatGPT, a large language model that Foram estudados 36
   pacientes com eguimento superior a cinco anos, distribuidos em generates
   human-like text. ChatGPT uses a type of AI known as a deep learning
   model. ChatGPT dois grupos: qued a prssao portal abaixo de 30% e acima
   de 30% compaados com o can quickly search a nd select pieces of evidence
   through numerous databases to provide answers calibre das varizes
   esofagicas no pos-operatorio precoce e tardio alem do indice de recidiva
   to complex questions, reducing the time and effort required to research
   a particular topic manually. hemorragica. Resultados Consequently,
   language models can accelerate the creation of clinical practice
   guidelines. While there is no doubt that ChatGPT has the potential to
   revolutionize the way healthcare is delivered, esofagicas que, durante o
   seguimento aumentaram de calibre e foram controladas com it is essential
   to note that it should not be used as a substitute for human healthcare
   professionals. Instead, ChatGPT should be considered a tool that can be
   used to augment and support the work of o comportamento do calibre das
   varizes no pos-opeatorio precoce nem tardio nem os healthcare
   professionals, helping them to provide better care to their patients.
ZB 6
TC 41
ZR 0
ZA 0
Z8 0
ZS 1
Z9 41
DA 2023-06-08
UT WOS:000993819100001
PM 37162073
ER

PT J
AU Gu, Zishan
   Liu, Fenglin
   Chen, Jiayuan
   Yin, Changchang
   Zhang, Ping
TI A Proactive Agent Collaborative Framework for Zero-Shot Multimodal
   Medical Reasoning
SO ADVANCED INTELLIGENT SYSTEMS
DI 10.1002/aisy.202400840
EA FEB 2025
DT Article; Early Access
PY 2025
AB The adoption of large language models (LLMs) in healthcare has garnered
   significant research interest, yet their performance remains limited due
   to a lack of domain-specific knowledge, medical reasoning skills, and
   their unimodal nature, which restricts them to text-only inputs. To
   address these limitations, we propose MultiMedRes, a multimodal medical
   collaborative reasoning framework that simulates human physicians'
   communication by incorporating a learner agent to proactively acquire
   information from domain-specific expert models. MultiMedRes addresses
   medical multimodal reasoning problems through three steps i) Inquire:
   The learner agent decomposes complex medical reasoning problems into
   multiple domain-specific sub-problems; ii) Interact: The agent engages
   in iterative "ask-answer" interactions with expert models to obtain
   domain-specific knowledge; and iii) Integrate: The agent integrates all
   the acquired domain-specific knowledge to address the medical reasoning
   problems (e.g., identifying the difference of disease levels and
   abnormality sizes between medical images). We validate the effectiveness
   of our method on the task of difference visual question answering for
   X-ray images. The experiments show that our zero-shot prediction
   achieves state-of-the-art performance, surpassing fully supervised
   methods, which demonstrates that MultiMedRes could offer trustworthy and
   interpretable assistance to physicians in monitoring the treatment
   progression of patients, paving the way for effective human-AI
   interaction and collaboration.
Z8 0
ZB 0
ZR 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2025-02-10
UT WOS:001413605200001
ER

PT C
AU Oduro-Afriyie, Joel
   Jamil, Hasan M.
GP ACM
TI Enabling the Informed Patient Paradigm with Secure and Personalized
   Medical Question Answering
SO 14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH
   INFORMATICS, BCB 2023
DI 10.1145/3584371.3613016
DT Proceedings Paper
PD 2023
PY 2023
AB Quality patient care is a complex and multifaceted problem requiring the
   integration of data from multiple sources. We propose Medicient, a
   knowledge-graph-based question answering system that processes
   heterogeneous data sources, including patient health records, drug
   databases, and medical literature, into a unified knowledge graph with
   zero training. The knowledge graph is then utilized to provide
   personalized recommendations for treatment or medication. The system
   leverages the power of large language models for question understanding
   and natural language response generation, while hiding sensitive patient
   information. We compare our system to a large language model (ChatGPT),
   which does not have access to patient health records, and show that our
   system provides better recommendations. This study contributes to a
   growing body of research on knowledge graphs and their applications in
   healthcare.
CT 14th ACM Conference on Bioinformatics, Computational Biology, and Health
   Informatics (ACM-BCB)
CY SEP 03-06, 2023
CL Houston, TX
SP Assoc Comp Machinery; ACM Special Interest Grp Bioinformat, Computat
   Biol, & Biomed Informat
ZR 0
ZA 0
Z8 0
TC 2
ZB 0
ZS 0
Z9 3
DA 2024-03-19
UT WOS:001143941200033
ER

PT J
AU Chuang, Yu-Neng
   Tang, Ruixiang
   Jiang, Xiaoqian
   Hu, Xia
TI SPeC: A Soft Prompt-Based Calibration on Performance Variability of
   Large Language Model in Clinical Notes Summarization
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 151
AR 104606
DI 10.1016/j.jbi.2024.104606
EA FEB 2024
DT Article
PD MAR 2024
PY 2024
AB Electronic health records (EHRs) store an extensive array of patient
   information, encompassing medical histories, diagnoses, treatments, and
   test outcomes. These records are crucial for enabling healthcare
   providers to make well-informed decisions regarding patient care.
   Summarizing clinical notes further assists healthcare professionals in
   pinpointing potential health risks and making better -informed
   decisions. This process contributes to reducing errors and enhancing
   patient outcomes by ensuring providers have access to the most pertinent
   and current patient data. Recent research has shown that incorporating
   instruction prompts with large language models (LLMs) substantially
   boosts the efficacy of summarization tasks. However, we show that this
   approach also leads to increased performance variance, resulting in
   significantly distinct summaries even when instruction prompts share
   similar meanings. To tackle this challenge, we introduce a model
   -agnostic Soft Prompt-BasedCalibration (SPeC) pipeline that employs soft
   prompts to lower variance while preserving the advantages of prompt
   -based summarization. Experimental findings on multiple clinical note
   tasks and LLMs indicate that our method not only bolsters performance
   but also effectively regulates variance across different LLMs, providing
   a more consistent and reliable approach to summarizing critical medical
   information.
TC 9
ZB 2
ZS 0
Z8 1
ZA 0
ZR 0
Z9 9
DA 2024-04-01
UT WOS:001187921900001
PM 38325698
ER

PT J
AU Yang, Yifan
   Liu, Xiaoyu
   Jin, Qiao
   Huang, Furong
   Lu, Zhiyong
TI Unmasking and quantifying racial bias of large language models in
   medical report generation
SO COMMUNICATIONS MEDICINE
VL 4
IS 1
AR 176
DI 10.1038/s43856-024-00601-z
DT Article
PD SEP 10 2024
PY 2024
AB BackgroundLarge language models like GPT-3.5-turbo and GPT-4 hold
   promise for healthcare professionals, but they may inadvertently inherit
   biases during their training, potentially affecting their utility in
   medical applications. Despite few attempts in the past, the precise
   impact and extent of these biases remain uncertain.MethodsWe use LLMs to
   generate responses that predict hospitalization, cost and mortality
   based on real patient cases. We manually examine the generated responses
   to identify biases.ResultsWe find that these models tend to project
   higher costs and longer hospitalizations for white populations and
   exhibit optimistic views in challenging medical scenarios with much
   higher survival rates. These biases, which mirror real-world healthcare
   disparities, are evident in the generation of patient backgrounds, the
   association of specific diseases with certain racial and ethnic groups,
   and disparities in treatment recommendations, etc.ConclusionsOur
   findings underscore the critical need for future research to address and
   mitigate biases in language models, especially in critical healthcare
   applications, to ensure fair and accurate outcomes for all patients.
   Large language models (LLMs) such as GPT-3.5-turbo and GPT-4 are
   advanced computer programs that can understand and generate text. They
   have the potential to help doctors and other healthcare professionals to
   improve patient care. We looked at how well these models predicted the
   cost of healthcare for patients, and the chances of them being
   hospitalized or dying. We found that these models often projected higher
   costs and longer hospital stays for white people than people from other
   racial or ethnicity groups. These biases mirror the disparities in
   real-world healthcare. Our findings show the need for more research to
   ensure that inappropriate biases are removed from LLMs to ensure fair
   and accurate healthcare predictions of possible outcomes for all
   patients. This will help ensure that these tools can be used effectively
   to improve healthcare for everyone.
   Yang et al. investigate racial biases in GPT-3.5-turbo and GPT-4
   generated predictions for hospitalization, cost, and mortality obtained
   from real patient cases. They find tendencies to project differing costs
   and hospitalizations depending on race, highlighting the need for
   further research to mitigate racial biases and enable fair and accurate
   healthcare outcomes.
TC 9
Z8 0
ZS 0
ZR 0
ZA 0
ZB 0
Z9 9
DA 2024-09-17
UT WOS:001309361700001
PM 39256622
ER

PT J
AU Chang, Ying
   Yin, Jian-ming
   Li, Jian-min
   Liu, Chang
   Cao, Ling-yong
   Lin, Shu-yuan
TI Applications and Future Prospects of Medical LLMs: A Survey Based on the
   M-KAT Conceptual Framework
SO JOURNAL OF MEDICAL SYSTEMS
VL 48
IS 1
AR 112
DI 10.1007/s10916-024-02132-5
DT Review
PD DEC 27 2024
PY 2024
AB The success of large language models (LLMs) in general areas have
   sparked a wave of research into their applications in the medical field.
   However, enhancing the medical professionalism of these models remains a
   major challenge. This study proposed a novel model training theoretical
   framework, the M-KAT framework, which integrated domain-specific
   training methods for LLMs with the unique characteristics of the medical
   discipline. This framework aimed to improve the medical professionalism
   of the models from three perspectives: general knowledge acquisition,
   specialized skill development, and alignment with clinical thinking.
   This study summarized the outcomes of medical LLMs across four tasks:
   clinical diagnosis and treatment, medical question answering, medical
   research, and health management. Using the M-KAT framework, we analyzed
   the contribution to enhancement of professionalism of models through
   different training stages. At the same time, for some of the potential
   risks associated with medical LLMs, targeted solutions can be achieved
   through pre-training, SFT, and model alignment based on cultivated
   professional capabilities. Additionally, this study identified main
   directions for future research on medical LLMs: advancing professional
   evaluation datasets and metrics tailored to the needs of medical tasks,
   conducting in-depth studies on medical multimodal large language models
   (MLLMs) capable of integrating diverse data types, and exploring the
   forms of medical agents and multi-agent frameworks that can interact
   with real healthcare environments and support clinical decision-making.
   It is hoped that predictions of work can provide a reference for
   subsequent research.
ZS 0
Z8 0
TC 1
ZB 0
ZR 0
ZA 0
Z9 1
DA 2024-12-30
UT WOS:001383525300001
PM 39725770
ER

PT J
AU Piao, Ying
   Chen, Hongtao
   Wu, Shihai
   Li, Xianming
   Li, Zihuang
   Yang, Dong
TI Assessing the performance of large language models (LLMs) in answering
   medical questions regarding breast cancer in the Chinese context
SO DIGITAL HEALTH
VL 10
AR 20552076241284771
DI 10.1177/20552076241284771
DT Article
PD 2024
PY 2024
AB Purpose Large language models (LLMs) are deep learning models designed
   to comprehend and generate meaningful responses, which have gained
   public attention in recent years. The purpose of this study is to
   evaluate and compare the performance of LLMs in answering questions
   regarding breast cancer in the Chinese context. Material and Methods
   ChatGPT, ERNIE Bot, and ChatGLM were chosen to answer 60 questions
   related to breast cancer posed by two oncologists. Responses were scored
   as comprehensive, correct but inadequate, mixed with correct and
   incorrect data, completely incorrect, or unanswered. The accuracy,
   length, and readability among answers from different models were
   evaluated using statistical software. Results ChatGPT answered 60
   questions, with 40 (66.7%) comprehensive answers and six (10.0%) correct
   but inadequate answers. ERNIE Bot answered 60 questions, with 34 (56.7%)
   comprehensive answers and seven (11.7%) correct but inadequate answers.
   ChatGLM generated 60 answers, with 35 (58.3%) comprehensive answers and
   six (10.0%) correct but inadequate answers. The differences for chosen
   accuracy metrics among the three LLMs did not reach statistical
   significance, but only ChatGPT demonstrated a sense of human compassion.
   The accuracy of the three models in answering questions regarding breast
   cancer treatment was the lowest, with an average of 44.4%. ERNIE Bot's
   responses were significantly shorter compared to ChatGPT and ChatGLM (p
   < .001 for both). The readability scores of the three models showed no
   statistical significance. Conclusions In the Chinese context, the
   capabilities of ChatGPT, ERNIE Bot, and ChatGLM are similar in answering
   breast cancer-related questions at present. These three LLMs may serve
   as adjunct informational tools for breast cancer patients in the Chinese
   context, offering guidance for general inquiries. However, for highly
   specialized issues, particularly in the realm of breast cancer
   treatment, LLMs cannot deliver reliable performance. It is necessary to
   utilize them under the supervision of healthcare professionals.
ZA 0
Z8 0
ZS 0
ZB 1
ZR 0
TC 4
Z9 4
DA 2024-10-18
UT WOS:001331508800001
PM 39386109
ER

PT J
AU Schwartz, Ilan S.
   Link, Katherine E.
   Daneshjou, Roxana
   Cortes-Penfield, Nicolas
TI Black Box Warning: Large Language Models and the Future of Infectious
   Diseases Consultation
SO CLINICAL INFECTIOUS DISEASES
VL 78
IS 4
BP 860
EP 866
DI 10.1093/cid/ciad633
EA NOV 2023
DT Article
PD APR 10 2024
PY 2024
AB Large language models (LLMs) are artificial intelligence systems trained
   by deep learning algorithms to process natural language and generate
   text responses to user prompts. Some approach physician performance on a
   range of medical challenges, leading some proponents to advocate for
   their potential use in clinical consultation and prompting some
   consternation about the future of cognitive specialties. However, LLMs
   currently have limitations that preclude safe clinical deployment in
   performing specialist consultations, including frequent confabulations,
   lack of contextual awareness crucial for nuanced diagnostic and
   treatment plans, inscrutable and unexplainable training data and
   methods, and propensity to recapitulate biases. Nonetheless, considering
   the rapid improvement in this technology, growing calls for clinical
   integration, and healthcare systems that chronically undervalue
   cognitive specialties, it is critical that infectious diseases
   clinicians engage with LLMs to enable informed advocacy for how they
   should-and shouldn't-be used to augment specialist care.
   Large language models (LLMs), advanced artificial intelligence systems
   capable of generating natural language, could revolutionize healthcare,
   including current models of specialist consultation. Infectious diseases
   clinicians must urgently engage with and understand limitations of LLMs
   to advocate for their responsible integration.
   Graphical Abstract
   https://tidbitapp.io/tidbits/black-box-warning-large-language-models-and
   -clinical-consultation-in-infectious-disease
ZB 10
ZR 0
TC 50
Z8 1
ZS 0
ZA 0
Z9 51
DA 2023-11-30
UT WOS:001102860600001
PM 37971399
ER

PT J
AU Zhang, Jingqing
   Sun, Kai
   Jagadeesh, Akshay
   Falakaflaki, Parastoo
   Kayayan, Elena
   Tao, Guanyu
   Ghahfarokhi, Mahta Haghighat
   Gupta, Deepa
   Gupta, Ashok
   Gupta, Vibhor
   Guo, Yike
TI The potential and pitfalls of using a large language model such as
   ChatGPT, GPT-4, or LLaMA as a clinical assistant
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 9
BP 1884
EP 1891
DI 10.1093/jamia/ocae184
EA JUL 2024
DT Article
PD JUL 17 2024
PY 2024
AB Objectives This study aims to evaluate the utility of large language
   models (LLMs) in healthcare, focusing on their applications in enhancing
   patient care through improved diagnostic, decision-making processes, and
   as ancillary tools for healthcare professionals.Materials and Methods We
   evaluated ChatGPT, GPT-4, and LLaMA in identifying patients with
   specific diseases using gold-labeled Electronic Health Records (EHRs)
   from the MIMIC-III database, covering three prevalent diseases-Chronic
   Obstructive Pulmonary Disease (COPD), Chronic Kidney Disease (CKD)-along
   with the rare condition, Primary Biliary Cirrhosis (PBC), and the
   hard-to-diagnose condition Cancer Cachexia.Results In patient
   identification, GPT-4 had near similar or better performance compared to
   the corresponding disease-specific Machine Learning models (F1-score >=
   85%) on COPD, CKD, and PBC. GPT-4 excelled in the PBC use case,
   achieving a 4.23% higher F1-score compared to disease-specific
   "Traditional Machine Learning" models. ChatGPT and LLaMA3 demonstrated
   lower performance than GPT-4 across all diseases and almost all metrics.
   Few-shot prompts also help ChatGPT, GPT-4, and LLaMA3 achieve higher
   precision and specificity but lower sensitivity and Negative Predictive
   Value.Discussion The study highlights the potential and limitations of
   LLMs in healthcare. Issues with errors, explanatory limitations and
   ethical concerns like data privacy and model transparency suggest that
   these models would be in clinical settings. Future studies should
   improve training datasets and model designs for LLMs to gain better
   utility in healthcare.Conclusion The study shows that LLMs have the
   potential to assist clinicians for tasks such as patient identification
   but false positives and false negatives must be mitigated before LLMs
   are adequate for real-world clinical assistance.
ZA 0
ZS 0
ZB 1
ZR 0
TC 15
Z8 1
Z9 16
DA 2024-07-23
UT WOS:001269939400001
PM 39018498
ER

PT C
AU Shi, Wenqi
   Zhuang, Yuchen
   Zhu, Yuanda
   Iwinski, Henry J.
   Wattenbarger, J. Michael
   Wang, May D.
GP ACM
TI Retrieval-Augmented Large Language Models for Adolescent Idiopathic
   Scoliosis Patients in Shared Decision-Making
SO 14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH
   INFORMATICS, BCB 2023
DI 10.1145/3584371.3612956
DT Proceedings Paper
PD 2023
PY 2023
AB As health-related decision-making evolves, patients increasingly seek
   help from additional online resources such as "Dr. Google" and ChatGPT.
   Despite their potential, these tools encounter limitations, including
   the risk of potentially inaccurate information, a lack of specialized
   medical knowledge, the risk of generating unrealistic outputs
   (hallucinations), and significant computational demands. In this study,
   we develop and validate an innovative shared decision-making (SDM) tool,
   Chat-Orthopedist, for adolescent idiopathic scoliosis (AIS) patients and
   families to prepare a meaningful discussion with clinicians based on
   retrieval-augmented large language models. Firstly, we establish an
   external knowledge base with information on AIS disease and treatment
   options. Secondly, we develop a retrieval-augmented ChatGPT to feed LLMs
   with AIS domain knowledge, providing accurate and comprehensible
   responses to patient inquiries. In addition, we perform a cyclical
   process of human-in-the-loop evaluations for system validation and
   improvement. Chat-Orthopedist may optimize SDM workflow by enabling
   better interactive learning experiences, more effective clinical visits,
   and better-informed treatment decision-making.
CT 14th ACM Conference on Bioinformatics, Computational Biology, and Health
   Informatics (ACM-BCB)
CY SEP 03-06, 2023
CL Houston, TX
SP Assoc Comp Machinery; ACM Special Interest Grp Bioinformat, Computat
   Biol, & Biomed Informat
TC 9
Z8 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 9
DA 2024-03-19
UT WOS:001143941200014
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Sabanayagam, Charumathi
   Banu, Riswana
   Lim, Cynthia
   Tham, Yih Chung
   Cheng, Ching-Yu
   Tan, Gavin
   Ekinci, Elif
   Sheng, Bin
   Mckay, Gareth
   Shaw, Jonathan E.
   Matsushita, Kunihiro
   Tangri, Navdeep
   Choo, Jason
   Wong, Tien Y.
TI Artificial intelligence in chronic kidney disease management: a scoping
   review
SO THERANOSTICS
VL 15
IS 10
BP 4566
EP 4578
DI 10.7150/thno.108552
DT Review
PD 2025
PY 2025
AB Rationale: Chronic kidney disease (CKD) is a major public health problem
   worldwide associated with cardiovascular disease, renal failure, and
   mortality. To effectively address this growing burden, innovative
   solutions to management are urgently required. We conducted a scoping
   review to identify key use cases in which artificial intelligence (AI)
   could be leveraged for improving management of CKD. Additionally, we
   examined the challenges faced by AI in CKD management, proposed
   potential solutions to overcome these barriers. Methods: We reviewed 41
   articles published between 2014-2024 which examined various AI
   techniques including machine learning (ML) and deep learning (DL),
   unsupervised clustering, digital twin, natural language processing (NLP)
   and large language models (LLMs) in CKD management. We focused on four
   areas: early detection, risk stratification and prediction, treatment
   recommendations and patient care and communication. Results: We
   identified 41 articles published between 2014-2024 that assessed
   image-based DL models for early detection (n = 6), ML models for risk
   stratification and prediction (n = 14) and treatment recommendations (n
   = 4), and NLP and LLMs for patient care and communication (n = 17). Key
   challenges in integrating AI models into healthcare include technical
   issues such as data quality and access, model accuracy, and
   interpretability, alongside adoption barriers like workflow integration,
   user training, and regulatory approval. Conclusions: There is tremendous
   potential of integrating AI into clinical care of CKD patients to enable
   early detection, prediction, and improved patient outcomes.
   Collaboration among healthcare providers, researchers, regulators, and
   industries is crucial to developing robust protocols that ensure
   compliance with legal standards, while minimizing risks and maintaining
   patient
Z8 0
ZA 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-05-02
UT WOS:001473295700018
PM 40225559
ER

PT J
AU Gu, Zhanzhong
   He, Xiangjian
   Yu, Ping
   Jia, Wenjing
   Yang, Xiguang
   Peng, Gang
   Hu, Penghui
   Chen, Shiyan
   Chen, Hongjie
   Lin, Yiguang
TI Automatic quantitative stroke severity assessment based on Chinese
   clinical named entity recognition with domain-adaptive pre-trained large
   language model
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
VL 150
AR 102822
DI 10.1016/j.artmed.2024.102822
EA FEB 2024
DT Article
PD APR 2024
PY 2024
AB Background: Stroke is a prevalent disease with a significant global
   impact. Effective assessment of stroke severity is vital for an accurate
   diagnosis, appropriate treatment, and optimal clinical outcomes. The
   National Institutes of Health Stroke Scale (NIHSS) is a widely used
   scale for quantitatively assessing stroke severity. However, the current
   manual scoring of NIHSS is labor-intensive, time-consuming, and
   sometimes unreliable. Applying artificial intelligence (AI) techniques
   to automate the quantitative assessment of stroke on vast amounts of
   electronic health records (EHRs) has attracted much interest. Objective:
   This study aims to develop an automatic, quantitative stroke severity
   assessment framework through automating the entire NIHSS scoring process
   on Chinese clinical EHRs. Methods: Our approach consists of two major
   parts: Chinese clinical named entity recognition (CNER) with a domain
   -adaptive pre -trained large language model (LLM) and automated NIHSS
   scoring. To build a highperforming CNER model, we first construct a
   stroke -specific, densely annotated dataset "Chinese Stroke Clinical
   Records"(CSCR) from EHRs provided by our partner hospital, based on a
   stroke ontology that defines semantically related entities for stroke
   assessment. We then pre -train a Chinese clinical LLM coined
   "CliRoberta"through domain -adaptive transfer learning and construct a
   deep learning -based CNER model that can accurately extract entities
   directly from Chinese EHRs. Finally, an automated, end -to -end NIHSS
   scoring pipeline is proposed by mapping the extracted entities to
   relevant NIHSS items and values, to quantitatively assess the stroke
   severity. Results: Results obtained on a benchmark dataset CCKS2019 and
   our newly created CSCR dataset demonstrate the superior performance of
   our domain -adaptive pre -trained LLM and the CNER model, compared with
   the existing benchmark LLMs and CNER models. The high F1 score of 0.990
   ensures the reliability of our model in accurately extracting the
   entities for the subsequent automatic NIHSS scoring. Subsequently, our
   automated, end -to -end NIHSS scoring approach achieved excellent inter
   -rater agreement (0.823) and intraclass consistency (0.986) with the
   ground truth and significantly reduced the processing time from minutes
   to a few seconds. Conclusion: Our proposed automatic and quantitative
   framework for assessing stroke severity demonstrates exceptional
   performance and reliability through directly scoring the NIHSS from
   diagnostic notes in Chinese clinical EHRs. Moreover, this study also
   contributes a new clinical dataset, a pre -trained clinical LLM, and an
   effective deep learning -based CNER model. The deployment of these
   advanced algorithms can improve the accuracy and efficiency of clinical
   assessment, and help improve the quality, affordability and productivity
   of healthcare services.
ZS 0
TC 7
ZA 0
Z8 0
ZR 0
ZB 1
Z9 7
DA 2024-04-13
UT WOS:001197568100001
PM 38553162
ER

PT J
AU Lorge, Isabelle
   Joyce, Dan W
   Taylor, Niall
   Nevado-Holgado, Alejo
   Cipriani, Andrea
   Kormilitzin, Andrey
TI Detecting the clinical features of difficult-to-treat depression using
   synthetic data from large language models.
SO Computers in biology and medicine
VL 194
BP 110246
EP 110246
DI 10.1016/j.compbiomed.2025.110246
DT Journal Article
PD 2025-Jun-10
PY 2025
AB Difficult-to-treat depression (DTD) has been proposed as a broader and
   more clinically comprehensive perspective on a person's depressive
   disorder where, despite treatment, they continue to experience
   significant burden. We sought to develop a tool capable of interrogating
   routinely-collected narrative (free-text) electronic health record (EHR)
   data to locate known prognostic factors identified from the scientific
   literature that capture the clinical syndrome of DTD. Thus, we aim to
   address the upstream aspect of DTD detection, that is the identification
   of relevant factors. In this work, we use Large Language Model
   (LLM)-generated synthetic data (GPT3.5) and a Non-Maximum Suppression
   (NMS) algorithm to train a BERT-based span extraction model. The model
   is trained to extract and label spans related to a variety of relevant
   positive and negative factors (i.e. spans of text that increase or
   decrease the likelihood of a patient matching the DTD syndrome). We test
   the model on both a synthetic and a clinical test set. We obtain good
   overall performance (0.70 F1 across polarity) on clinical data from EHRs
   for extracting as many as 20 different factors considered as predictors
   of DTD and high performance (0.85 F1 with 0.95 precision) on a subset of
   important DTD factors such as history of abuse, family history of
   affective disorder, illness severity and suicidality. We show it is
   possible to train a model exclusively on synthetic data to extract
   prognostic factors in clinical data. Our results show promise for future
   healthcare applications especially in applications where traditionally,
   highly confidential medical data and costly human-expert annotations
   would normally be required.
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
TC 0
Z9 0
DA 2025-06-14
UT MEDLINE:40499374
PM 40499374
ER

PT J
AU Saxena, Sarah
   Barreto Chang, Odmara L
   Suppan, Melanie
   Meco, Basak Ceyda
   Vacas, Susana
   Radtke, Finn
   Matot, Idit
   Devos, Arnout
   Maze, Mervyn
   Gisselbaek, Mia
   Berger-Estilita, Joana
TI A comparison of large language model-generated and published
   perioperative neurocognitive disorder recommendations: a cross-sectional
   web-based analysis.
SO British journal of anaesthesia
DI 10.1016/j.bja.2025.01.001
DT Journal Article
PD 2025-Feb-07
PY 2025
AB BACKGROUND: Perioperative neurocognitive disorders (PNDs) are common
   complications after surgery and anaesthesia, particularly in older
   adults, leading to increased morbidity, mortality, and healthcare costs.
   Therefore, major medical societies have developed recommendations for
   the prevention and treatment of PNDs. Our study evaluated the
   reliability of large language models, specifically ChatGPT-4 and Gemini,
   in generating recommendations for PND management and comparing them with
   published guidelines.
   METHODS: We conducted an online cross-sectional web-based analysis over
   48 h in June 2024. Artificial intelligence (AI)-generated
   recommendations were produced in six different locations across five
   countries (Switzerland, Belgium, Turkey, Canada, and the East and West
   Coasts of the USA). The English prompt 'a table of a bundle of care for
   perioperative neurocognitive disorders' was entered into ChatGPT-4 and
   Gemini, generating tables evaluated by independent reviewers. The
   primary outcomes were the Total Disagreement Score (TDS) and Quality
   Assessment of Medical Artificial Intelligence (QAMAI), which compared
   AI-generated recommendations with published guidelines.
   RESULTS: The study generated 14 tables, with TDS and QAMAI scores
   showing similar results for ChatGPT-4 and Gemini (2 [1-3] vs 2 [2-3],
   P=0.636 and 4 [4-4] vs 4 [3-4], P=0.424, respectively). AI-generated
   recommendations aligned well with published guidelines, with the highest
   alignment observed in ChatGPT-4-generated recommendations. No complete
   agreement with guidelines was achieved, and lack of cited sources was a
   noted limitation.
   CONCLUSIONS: Large language models can generate perioperative
   neurocognitive disorder recommendations that align closely with
   published guidelines. However, further validation and integration of
   clinician feedback are required before clinical application.
ZS 0
Z8 0
ZR 0
ZB 0
TC 0
ZA 0
Z9 0
DA 2025-02-10
UT MEDLINE:39922789
PM 39922789
ER

PT J
AU Zheng, Jie
   Ding, Xiaoqian
   Pu, Jingya Jane
   Chung, Sze Man
   Ai, Qi Yong H.
   Hung, Kuo Feng
   Shan, Zhiyi
TI Unlocking the Potentials of Large Language Models in Orthodontics: A
   Scoping Review
SO BIOENGINEERING-BASEL
VL 11
IS 11
AR 1145
DI 10.3390/bioengineering11111145
DT Review
PD NOV 2024
PY 2024
AB (1) Background: In recent years, large language models (LLMs) such as
   ChatGPT have gained significant attention in various fields, including
   dentistry. This scoping review aims to examine the current applications
   and explore potential uses of LLMs in the orthodontic domain, shedding
   light on how they might improve dental healthcare. (2) Methods: We
   carried out a comprehensive search in five electronic databases, namely
   PubMed, Scopus, Embase, ProQuest and Web of Science. Two authors
   independently screened articles and performed data extraction according
   to the eligibility criteria, following the PRISMA-ScR guideline. The
   main findings from the included articles were synthesized and analyzed
   in a narrative way. (3) Results: A total of 706 articles were searched,
   and 12 papers were eventually included. The applications of LLMs include
   improving diagnostic and treatment efficiency in orthodontics as well as
   enhancing communication with patients. (4) Conclusions: There is
   emerging research in countries worldwide on the use of LLMs in
   orthodontics, suggesting an upward trend in their acceptance within this
   field. However, the potential application of LLMs remains in its early
   stage, with a noticeable lack of extensive studies and tailored products
   to address specific clinical needs.
Z8 0
TC 0
ZB 0
ZA 0
ZR 0
ZS 0
Z9 0
DA 2024-12-07
UT WOS:001366774600001
PM 39593805
ER

PT J
AU Cohen, Natalie D.
   Ho, Milan
   Mcintire, Donald
   Smith, Katherine
   Kho, Kimberly A.
TI A comparative analysis of generative artificial intelligence responses
   from leading chatbots to questions about endometriosis
SO AJOG GLOBAL REPORTS
VL 5
IS 1
AR 100405
DI 10.1016/j.xagr.2024.100405
EA DEC 2024
DT Article
PD FEB 2025
PY 2025
AB INTRODUCTION: The use of generative artificial intelligence (AI) has
   begun to permeate most industries, including medicine, and patients will
   inevitably start using these large language model (LLM) chatbots as a
   modality for education. As healthcare information technology evolves, it
   is imperative to evaluate chatbots and the accuracy of the information
   they provide to patients and to determine if there is variability
   between them. OBJECTIVE: This study aimed to evaluate the accuracy and
   comprehensiveness of three chatbots in addressing questions related to
   endometriosis and determine the level of variability between them. STUDY
   DESIGN: Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic),
   and Bard (Google) were asked to generate answers to 10 commonly asked
   questions about endometriosis. The responses were qualitatively compared
   to current guidelines and expert opinion on endometriosis and rated on a
   scale by nine gynecologists. The grading scale included the following:
   (1) Completely incorrect, (2) mostly incorrect and some correct, (3)
   mostly correct and some incorrect, (4) correct but inadequate, (5)
   correct and comprehensive. Final scores were averaged between the nine
   reviewers. Kendall's Wand the related chi-square test were used to
   evaluate the reviewers' strength of agreement in ranking the LLMs'
   responses for each item. RESULTS: Average scores for the 10 answers
   amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7,
   respectively. Two questions showed significant disagreement between the
   nine reviewers. There were no questions the models could answer
   comprehensively or correctly across the reviewers. The model most
   associated with comprehensive and correct responses was ChatGPT.
   Chatbots showed an improved ability to accurately answer questions about
   symptoms and pathophysiology over treatment and risk of recurrence.
   CONCLUSION: The analysis of LLMs revealed that, on average, they mainly
   provided correct but inadequate responses to commonly asked patient
   questions about endometriosis. While chatbot responses can serve as
   valuable supplements to information provided by licensed medical
   professionals, it is crucial to maintain a thorough ongoing evaluation
   process for outputs to provide the most comprehensive and accurate
   information to patients. Further research into this technology and its
   role in patient education and treatment is crucial as generative AI
   becomes more embedded in the medical field.
ZA 0
Z8 0
TC 1
ZS 0
ZB 0
ZR 0
Z9 1
DA 2025-05-06
UT WOS:001476609200001
PM 39810943
ER

PT J
AU Huo, Bright
   Calabrese, Elisa
   Sylla, Patricia
   Kumar, Sunjay
   Ignacio, Romeo C.
   Oviedo, Rodolfo
   Hassan, Imran
   Slater, Bethany J.
   Kaiser, Andreas
   Walsh, Danielle S.
   Vosburg, Wesley
TI The performance of artificial intelligence large language model-linked
   chatbots in surgical decision-making for gastroesophageal reflux disease
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
VL 38
IS 5
BP 2320
EP 2330
DI 10.1007/s00464-024-10807-w
EA APR 2024
DT Article
PD MAY 2024
PY 2024
AB BackgroundLarge language model (LLM)-linked chatbots may be an efficient
   source of clinical recommendations for healthcare providers and
   patients. This study evaluated the performance of LLM-linked chatbots in
   providing recommendations for the surgical management of
   gastroesophageal reflux disease (GERD).MethodsNine patient cases were
   created based on key questions addressed by the Society of American
   Gastrointestinal and Endoscopic Surgeons (SAGES) guidelines for the
   surgical treatment of GERD. ChatGPT-3.5, ChatGPT-4, Copilot, Google
   Bard, and Perplexity AI were queried on November 16th, 2023, for
   recommendations regarding the surgical management of GERD. Accurate
   chatbot performance was defined as the number of responses aligning with
   SAGES guideline recommendations. Outcomes were reported with counts and
   percentages.ResultsSurgeons were given accurate recommendations for the
   surgical management of GERD in an adult patient for 5/7 (71.4%) KQs by
   ChatGPT-4, 3/7 (42.9%) KQs by Copilot, 6/7 (85.7%) KQs by Google Bard,
   and 3/7 (42.9%) KQs by Perplexity according to the SAGES guidelines.
   Patients were given accurate recommendations for 3/5 (60.0%) KQs by
   ChatGPT-4, 2/5 (40.0%) KQs by Copilot, 4/5 (80.0%) KQs by Google Bard,
   and 1/5 (20.0%) KQs by Perplexity, respectively. In a pediatric patient,
   surgeons were given accurate recommendations for 2/3 (66.7%) KQs by
   ChatGPT-4, 3/3 (100.0%) KQs by Copilot, 3/3 (100.0%) KQs by Google Bard,
   and 2/3 (66.7%) KQs by Perplexity. Patients were given appropriate
   guidance for 2/2 (100.0%) KQs by ChatGPT-4, 2/2 (100.0%) KQs by Copilot,
   1/2 (50.0%) KQs by Google Bard, and 1/2 (50.0%) KQs by
   Perplexity.ConclusionsGastrointestinal surgeons, gastroenterologists,
   and patients should recognize both the promise and pitfalls of LLM's
   when utilized for advice on surgical management of GERD. Additional
   training of LLM's using evidence-based health information is needed.
ZA 0
ZR 0
Z8 0
ZB 0
TC 8
ZS 0
Z9 8
DA 2024-05-15
UT WOS:001204657100004
PM 38630178
ER

PT C
AU Bandara, Eranga
   Foytik, Peter
   Shetty, Sachin
   Mukkamala, Ravi
   Rahman, Abdul
   Liang, Xueping
   Keon, Ng Wee
   De Zoysa, Kasun
GP IEEE
TI WedaGPT - Generative-AI (with Custom-Trained Meta's Llama2 LLM),
   Blockchain, Self Sovereign Identity, NFT and Model Card Enabled
   Indigenous Medicine Platform
SO 2024 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, ISCC 2024
SE IEEE Symposium on Computers and Communications ISCC
DI 10.1109/ISCC61673.2024.10733674
DT Proceedings Paper
PD 2024
PY 2024
AB Traditional and indigenous medicine, deeply rooted in ancient traditions
   and wisdom, plays a crucial role in global healthcare and cultural
   identity. These practices provide treatments for illnesses such as
   cancer and bone injuries, which often lack effective remedies in Western
   medicine. However, these valuable systems face challenges like potential
   knowledge loss, undervaluation of practitioners' expertise, and the risk
   of fraud due to the absence of credential verification mechanisms. In
   this research, we introduce "WedaGPT," a Generative AI-enabled platform
   that utilizes a custom-trained Meta's Llama2 Large Language Model (LLM),
   Blockchain, self-sovereign identity (SSI), Non-Fungible Tokens (NFTs),
   and model cards to share traditional medical knowledge and address these
   issues. WedaGPT creates a collaborative ecosystem connecting doctors,
   medicine providers, therapists, patients, and technology experts, all
   committed to preserving and advancing traditional healing practices.
   This platform enables secure and transparent contributions from all
   stakeholders to patient well-being. Ancient medical recipe books are
   translated into English and digitized into PDF formats to enrich the
   platform's knowledge base. These texts are used to fine-tune the Llama2
   LLM, which has been quantized and optimized with Qlora for performance
   on consumer-grade hardware. Through a chat-based interface in the
   SSI-enabled mobile wallet, users can interact with the LLM and access
   detailed information on treatments, recipes, prescriptions, and healing
   methods. Additionally, users can consult remotely with doctors who
   prescribe treatments through this wallet. A key feature of WedaGPT is
   transforming ancient medicinal recipes into NFT tokens for sale on NFT
   marketplaces, giving traditional knowledge digital authenticity and
   economic value. Revenue from these sales is distributed among platform
   contributors, promoting equitable ownership and recognition. Medical
   recipe data, including treatment histories and physician details, are
   encapsulated in Model Cards and securely stored on the blockchain. This
   system offers mechanisms to verify doctors and treatments in a
   privacy-preserving way, potentially reducing fraud and medication
   errors.
CT 29th IEEE Symposium on Computers and Communications (IEEE ISCC)
CY JUN 26-29, 2024
CL Paris, FRANCE
SP IEEE
Z8 0
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-01-03
UT WOS:001363176200111
ER

PT J
AU Pan, Jie
   Lee, Seungwon
   Cheligeer, Cheligeer
   Martin, Elliot A
   Riazi, Kiarash
   Quan, Hude
   Li, Na
TI Integrating large language models with human expertise for disease
   detection in electronic health records.
SO Computers in biology and medicine
VL 191
BP 110161
EP 110161
DI 10.1016/j.compbiomed.2025.110161
DT Journal Article
PD 2025-Jun
PY 2025
AB OBJECTIVE: Electronic health records (EHR) are widely available to
   complement administrative data-based disease surveillance and healthcare
   performance evaluation. Defining conditions from EHR is labour-intensive
   and requires extensive manual labelling of disease outcomes. This study
   developed an efficient strategy based on advanced large language models
   to identify multiple conditions from EHR clinical notes.
   METHODS: We linked a cardiac registry cohort in 2015 with an EHR system
   in Alberta, Canada. We developed a pipeline that leveraged a generative
   large language model (LLM) to analyze, understand, and interpret EHR
   notes by prompts based on specific diagnosis, treatment management, and
   clinical guidelines. The pipeline was applied to detect acute myocardial
   infarction (AMI), diabetes, and hypertension. The performance was
   compared against clinician-validated diagnoses as the reference standard
   and widely adopted International Classification of Diseases (ICD)
   codes-based methods.
   RESULTS: The study cohort accounted for 3088 patients and 551,095
   clinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI,
   diabetes, and hypertension, respectively. The performance of the
   LLM-based pipeline for detecting conditions varied: AMI had 88%
   sensitivity, 63% specificity, and 77% positive predictive value (PPV);
   diabetes had 91% sensitivity, 86% specificity, and 71% PPV; and
   hypertension had 94% sensitivity, 32% specificity, and 72% PPV. Compared
   with ICD codes, the LLM-based method demonstrated improved sensitivity
   and negative predictive value across all conditions. The monthly
   percentage trends from the detected cases by LLM and reference standard
   showed consistent patterns.
   CONCLUSION: The proposed LLM-based pipeline demonstrated reasonable
   accuracy and high efficiency in disease detection for multiple
   conditions. Human expert knowledge can be integrated into the pipeline
   to guide EHR note analysis without manually curated labels. The method
   could enable comprehensive real-time disease surveillance using EHRs.
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-04-11
UT MEDLINE:40198990
PM 40198990
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   Pugliese, Nicola
   You, Kisung
   Shung, Dennis L.
TI Optimizing large language models in digestive disease: strategies and
   challenges to improve clinical outcomes
SO LIVER INTERNATIONAL
VL 44
IS 9
BP 2114
EP 2124
DI 10.1111/liv.15974
EA MAY 2024
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs) are transformer-based neural networks with
   billions of parameters trained on very large text corpora from diverse
   sources. LLMs have the potential to improve healthcare due to their
   capability to parse complex concepts and generate context-based
   responses. The interest in LLMs has not spared digestive disease
   academics, who have mainly investigated foundational LLM accuracy, which
   ranges from 25% to 90% and is influenced by the lack of standardized
   rules to report methodologies and results for LLM-oriented research. In
   addition, a critical issue is the absence of a universally accepted
   definition of accuracy, varying from binary to scalar interpretations,
   often tied to grader expertise without reference to clinical guidelines.
   We address strategies and challenges to increase accuracy. In
   particular, LLMs can be infused with domain knowledge using Retrieval
   Augmented Generation (RAG) or Supervised Fine-Tuning (SFT) with
   reinforcement learning from human feedback (RLHF). RAG faces challenges
   with in-context window limits and accurate information retrieval from
   the provided context. SFT, a deeper adaptation method, is
   computationally demanding and requires specialized knowledge. LLMs may
   increase patient quality of care across the field of digestive diseases,
   where physicians are often engaged in screening, treatment and
   surveillance for a broad range of pathologies for which in-context
   learning or SFT with RLHF could improve clinical decision-making and
   patient outcomes. However, despite their potential, the safe deployment
   of LLMs in healthcare still needs to overcome hurdles in accuracy,
   suggesting a need for strategies that integrate human feedback with
   advanced model training.
ZR 0
TC 16
ZA 0
Z8 2
ZS 0
ZB 3
Z9 16
DA 2024-06-06
UT WOS:001235783300001
PM 38819632
ER

PT J
AU Baughman, Derek J.
   Qassem, Layth
   Sulieman, Lina
   Matheny, Michael E.
   Fabbri, Daniel
   Tindle, Hilary A.
   Goodman, Aubrey Cole
   Nelson, Scott D.
   Wright, Adam
TI Real-time automated billing for tobacco treatment: developing and
   validating a scalable machine learning approach
SO JAMIA OPEN
VL 8
IS 3
AR ooaf039
DI 10.1093/jamiaopen/ooaf039
DT Article
PD JUN 2025
PY 2025
AB Objectives To develop CigStopper, a real-time, automated medical billing
   prototype designed to identify eligible tobacco cessation care codes,
   thereby reducing administrative workload while improving billing
   accuracy.Materials and Methods ChatGPT prompt engineering generated a
   synthetic corpus of physician-style clinical notes categorized for CPT
   codes 99406/99407. Practicing clinicians annotated the dataset to train
   multiple machine learning (ML) models focused on accurately predicting
   billing code eligibility.Results Decision tree and random forest models
   performed best. Mean performance across all models: PRC AUC = 0.857, F1
   score = 0.835. Generalizability testing on deidentified notes confirmed
   that tree-based models performed best.Discussion CigStopper shows
   promise for streamlining manual billing inefficiencies that hinder
   tobacco cessation care. ML methods lay the groundwork for clinical
   implementation based on good performance using synthetic data.
   Automating high-volume, low-value tasks simplify complexities in a
   multi-payer system and promote financial sustainability for healthcare
   practices.Conclusion CigStopper validates foundational methods for
   automating the discernment of appropriate billing codes for eligible
   smoking cessation counseling care.
   CigStopper is an AI-powered tool created to simplify medical billing for
   clinical care that helps people quit smoking. Using synthetic clinical
   notes developed with a large language model, CigStopper reviews doctors'
   notes and automatically identifies and applies the correct billing codes
   for tobacco cessation care. This is crucial because accurate billing
   ensures healthcare providers are recognized and paid for offering these
   services. Automating this process can minimize the time doctors and
   staff spend on paperwork, and ensure proper reimbursment for clinical
   efforts. A proof-of-concept test was conducted by analyzing synthetic
   medical notes with CigStopper. The objective was to differentiate
   between notes eligible for billing and those that were not. To achieve
   this, artificial intelligence (AI) models were used to validate
   industry-standard performance measures on machine learning, which
   revealed good performance. The success of the CigStopper project
   demonstrates the potential of AI to reduce the administrative burden on
   healthcare providers, allowing them to focus more on patient care rather
   than billing logistics. It also highlights the tool's ability to
   navigate the complexities of the US healthcare payment system, making it
   easier for practices to sustain their services financially. Thus,
   CigStopper is a modern solution for an old problem, making smoking
   cessation care more efficient and less burdensome for clinicians, while
   also recovering revenue for practices to sustain valuable preventative
   care for patients.
TC 0
Z8 0
ZS 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2025-06-15
UT WOS:001506633200001
PM 40510807
ER

PT J
AU Liu, Jonathan
   Segal, Kathryn
   Daher, Mohammad
   Ozolin, Jordan
   Binder, William
   Bergen, Michael
   McDonald, Christopher L.
   Owens, Brett
   Antoci, Valentin
TI Artificial intelligence versus orthopedic surgeons as an orthopedic
   consultant in the emergency department
SO INJURY-INTERNATIONAL JOURNAL OF THE CARE OF THE INJURED
VL 56
IS 4
AR 112297
DI 10.1016/j.injury.2025.112297
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB Introduction: ChatGPT, a widely accessible AI program, has demonstrated
   potential in various healthcare applications, including emergency
   department (ED) triage, differential diagnosis, and patient education.
   However, its potential in providing recommendations to emergency
   department providers with orthopedic consultations has not been
   evaluated yet. Methods: This study compared the performance of four
   board certified orthopedic surgeons, two attendings and two trauma
   fellows who take independent call at the same institution and ChatGPT-4
   in responding to clinical scenarios commonly encountered in emergency
   departments. Five common orthopedic ED scenarios were developed (lateral
   malleolar ankle fractures, distal radius fractures, septic arthritis of
   the knee, shoulder dislocations, and Achilles tendon ruptures), each
   with four questions related to diagnosis, management, surgical
   indication, and patient counseling, totaling 20 questions. Responses
   were anonymized, coded, and evaluated by independent reviewers including
   emergency medicine physicians using a five-point Likert scale across
   five criteria: accuracy, completeness, helpfulness, specificity, and
   overall quality. Results: When comparing the ratings of AI answers to
   non-AI responders, the AI answers were shown to be superior in
   completeness, helpfulness, specificity, and overall quality with no
   difference in regards to accuracy (p < 0.05). When considering question
   subtypes including diagnosis, management, treatment, and patient
   counseling, AI was shown to have superior scores in helpfulness, and
   specificity in diagnostic questions(p < 0.05). In addition, AI responses
   were superior in all the assessed categories when looking at the patient
   counseling questions (p < 0.05). When considering different clinical
   scenarios, AI outperformed non-AI groups in completeness in the distal
   radius fracture scenario. Furthermore, AI outperformed non-AI groups in
   helpfulness in the lateral malleolus fracture scenario. In the shoulder
   dislocation scenario, AI responses were more complete, helpful, and had
   a better overall quality. AI responses were non-inferior in the
   remaining categories of the different scenarios. Conclusion: Artificial
   intelligence exhibited non-inferior and often superior performance in
   common orthopedic-ED consultations compared to board certified
   orthopedic surgeons While current AI models are limited in their ability
   to integrate specific images and patient scenarios, our findings suggest
   AI can provide high quality recommendations for generic orthopedic
   consultations and with further development, will likely have an
   increasing role in the future.
ZA 0
TC 0
ZS 0
ZB 0
ZR 0
Z8 0
Z9 0
DA 2025-05-21
UT WOS:001489449700001
PM 40147063
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT B
AU Raghunath, Ananditha
Z2  
TI <strong>Please Mind the Sociotechnical Gap</strong>: Building,
   Contextualizing and Scaling Mobile Technologies Towards Improved Human
   Outcomes at the Margins
DT Dissertation/Thesis
PD Jan 01 2025
PY 2025
TC 0
Z8 0
ZS 0
ZR 0
ZA 0
ZB 0
Z9 0
UT PQDT:123119288
ER

PT J
AU Ying, Lingwen
   Li, Sichen
   Chen, Chunyang
   Yang, Fan
   Li, Xin
   Chen, Yao
   Ding, Yu
   Chang, Guoying
   Li, Juan
   Wang, Xiumin
TI Screening/diagnosis of pediatric endocrine disorders through the
   artificial intelligence model in different language settings
SO EUROPEAN JOURNAL OF PEDIATRICS
VL 183
IS 6
BP 2655
EP 2661
DI 10.1007/s00431-024-05527-1
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB This study is aimed at examining the impact of ChatGPT on pediatric
   endocrine and metabolic conditions, particularly in the areas of
   screening and diagnosis, in both Chinese and English modes. A
   40-question questionnaire covering the four most common pediatric
   endocrine and metabolic conditions was posed to ChatGPT in both Chinese
   and English three times each. Six pediatric endocrinologists evaluated
   the responses. ChatGPT performed better when responding to questions in
   English, with an unreliable rate of 7.5% compared to 27.5% for Chinese
   questions, indicating a more consistent response pattern in English.
   Among the reliable questions, the answers were more comprehensive and
   satisfactory in the English mode. We also found disparities in ChatGPT's
   performance when interacting with different target groups and diseases,
   with improved performance for questions posed by clinicians in English
   and better performance for questions related to diabetes and
   overweight/obesity in Chinese for both clinicians and patients. Language
   comprehension, providing incomprehensive answers, and errors in key data
   were the main contributors to the low scores, according to reviewer
   feedback.Conclusion: Despite these limitations, as ChatGPT continues to
   evolve and expand its network, it has significant potential as a
   practical and effective tool for clinical diagnosis and treatment. What
   is Known:center dot The deep learning-based large-language model ChatGPT
   holds great promise for improving clinical practice for both physicians
   and patients and has the potential to increase the speed and accuracy of
   disease screening and diagnosis, as well as enhance the overall
   efficiency of the medical process. However, the reliability and
   appropriateness of AI model responses in specific field remains
   unclear.center dot This study focused on the reliability and
   appropriateness of AI model responses to straightforward and fundamental
   questions related to the four most prevalent pediatric endocrine and
   metabolic disorders, for both healthcare providers and patients, in
   different language scenarios.What is New:center dot The AI model
   performed better when responding to questions in English, with more
   consistent, as well as more comprehensive and satisfactory responses. In
   addition, we also found disparities in ChatGPT's performance when
   interacting with different target groups and different diseases.center
   dot Despite these limitations, as ChatGPT continues to evolve and expand
   its network, it has significant potential as a practical and effective
   tool for clinical diagnosis and treatment.
Z8 0
ZS 0
ZB 0
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-04-01
UT WOS:001187459700002
PM 38502320
ER

PT J
AU Xu, Shenbo
   Cobzaru, Raluca
   Finkelstein, Stan N
   Welsch, Roy E
   Ng, Kenney
   Middleton, Lefkos
TI Foundational model aided automatic high-throughput drug screening using
   self-controlled cohort study.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2024.08.04.24311480
DT Journal Article; Preprint
PD 2024 Sep 16
PY 2024
AB Background: Developing medicine from scratch to governmental
   authorization and detecting adverse drug reactions (ADR) have barely
   been economical, expeditious, and risk-averse investments. The
   availability of large-scale observational healthcare databases and the
   popularity of large language models offer an unparalleled opportunity to
   enable automatic high-throughput drug screening for both repurposing and
   pharmacovigilance.
   Objectives: To demonstrate a general workflow for automatic
   high-throughput drug screening with the following advantages: (i) the
   association of various exposure on diseases can be estimated; (ii) both
   repurposing and pharmacovigilance are integrated; (iii) accurate
   exposure length for each prescription is parsed from clinical texts;
   (iv) intrinsic relationship between drugs and diseases are removed
   jointly by bioinformatic mapping and large language model - ChatGPT; (v)
   causal-wise interpretations for incidence rate contrasts are provided.
   Methods: Using a self-controlled cohort study design where subjects
   serve as their own control group, we tested the intention-to-treat
   association between medications on the incidence of diseases. Exposure
   length for each prescription is determined by parsing common dosages in
   English free text into a structured format. Exposure period starts from
   initial prescription to treatment discontinuation. A same exposure
   length preceding initial treatment is the control period. Clinical
   outcomes and categories are identified using existing phenotyping
   algorithms. Incident rate ratios (IRR) are tested using uniformly most
   powerful (UMP) unbiased tests.
   Results: We assessed 3,444 medications on 276 diseases on 6,613,198
   patients from the Clinical Practice Research Datalink (CPRD), an UK
   primary care electronic health records (EHR) spanning from 1987 to 2018.
   Due to the built-in selection bias of self-controlled cohort studies,
   ingredients-disease pairs confounded by deterministic medical
   relationships are removed by existing map from RxNorm and nonexistent
   maps by calling ChatGPT. A total of 16,901 drug-disease pairs reveals
   significant risk reduction, which can be considered as candidates for
   repurposing, while a total of 11,089 pairs showed significant risk
   increase, where drug safety might be of a concern instead.
   Conclusions: This work developed a data-driven, nonparametric,
   hypothesis generating, and automatic high-throughput workflow, which
   reveals the potential of natural language processing in
   pharmacoepidemiology. We demonstrate the paradigm to a large
   observational health dataset to help discover potential novel therapies
   and adverse drug effects. The framework of this study can be extended to
   other observational medical databases.
ZS 0
TC 0
ZR 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-08-17
UT MEDLINE:39148849
PM 39148849
ER

PT J
AU Dhanasekaran, Renumathy
   Daugherty, Tami
   Kwo, Paul Yien
   Ghaziani, T. Tara
   Masuoka, Howard
   Elango, Vetri Venthan
TI DEVELOPING A HIGH-PERFORMING CUSTOMIZED AI TUMOR BOARD TOOL FOR HCC
   STAGING AND MANAGEMENT
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1965
BP S884
EP S884
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
TC 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837703466
ER

PT J
AU Al Tibi, Ghaith
   Alexander, Melvin
   Miller, Samuel
   Chronos, Nicolas
TI A Retrospective Comparison of Medication Recommendations Between a
   Cardiologist and ChatGPT-4 for Hypertension Patients in a Rural Clinic
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 3
AR e55789
DI 10.7759/cureus.55789
DT Article
PD MAR 8 2024
PY 2024
AB Background With ChatGPT demonstrating impressive abilities in solving
   clinical vignettes and medical questions, there is still a lack of
   studies assessing ChatGPT using real patient data. With real -world
   cases offering added complexity, ChatGPT's utility in treatment using
   such data must be tested to better assess its accuracy and
   dependability. In this study, we compared a rural cardiologist's
   medication recommendations to that of GPT4 for patients with lab review
   appointments. Methodology We reviewed the lab review appointments of 40
   hypertension patients, noting their age, sex, medical conditions,
   medications and dosage, and current and past lab values. The
   cardiologist's medication recommendations (decreasing dose, increasing
   dose, stopping, or adding medications) from the most recent lab visit,
   if any, were recorded for each patient. Data collected from each patient
   was inputted into GPT-4 using a set prompt and the resulting medication
   recommendations from the model were recorded. Results Out of the 40
   patients, 95% had conflicting overall recommendations between the
   physician and GPT-4, with only 10.2% of the specific medication
   recommendations matching between the two. Cohen's kappa coefficient was
   -0.0127, indicating no agreement between the cardiologist and GPT-4 for
   providing medication changes overall for a patient. Possible reasons for
   this discrepancy can be differing optimal lab value ranges, lack of
   holistic analysis by GPT-4, and a need for providing further
   supplementary information to the model. Conclusions The study findings
   showed a significant difference between the cardiologist's medication
   recommendations and that of ChatGPT-4. Future research should continue
   to test GPT-4 in clinical settings to validate its abilities in the real
   world where more intricacies and challenges exist.
ZR 0
ZA 0
ZS 0
Z8 0
ZB 0
TC 2
Z9 2
DA 2024-04-25
UT WOS:001201420100010
PM 38586651
ER

PT J
AU Fonseca, Angelo
   Ferreira, Axel
   Ribeiro, Luis
   Moreira, Sandra
   Duque, Cristina
TI Embracing the future-is artificial intelligence already better? A
   comparative study of artificial intelligence performance in diagnostic
   accuracy and decision-making
SO EUROPEAN JOURNAL OF NEUROLOGY
VL 31
IS 4
DI 10.1111/ene.16195
EA JAN 2024
DT Article
PD APR 2024
PY 2024
AB Background and purposeThe integration of artificial intelligence (AI) in
   healthcare has the potential to revolutionize patient care and clinical
   decision-making. This study aimed to explore the reliability of large
   language models in neurology by comparing the performance of an AI
   chatbot with neurologists in diagnostic accuracy and
   decision-making.MethodsA cross-sectional observational study was
   conducted. A pool of clinical cases from the American Academy of
   Neurology's Question of the Day application was used as the basis for
   the study. The AI chatbot used was ChatGPT, based on GPT-3.5. The
   results were then compared to neurology peers who also answered the
   questions-a mean of 1500 neurologists/neurology residents.ResultsThe
   study included 188 questions across 22 different categories. The AI
   chatbot demonstrated a mean success rate of 71.3% in providing correct
   answers, with varying levels of proficiency across different neurology
   categories. Compared to neurology peers, the AI chatbot performed at a
   similar level, with a mean success rate of 69.2% amongst peers.
   Additionally, the AI chatbot achieved a correct diagnosis in 85.0% of
   cases and it provided an adequate justification for its correct
   responses in 96.1%.ConclusionsThe study highlights the potential of AI,
   particularly large language models, in assisting with clinical reasoning
   and decision-making in neurology and emphasizes the importance of AI as
   a complementary tool to human expertise. Future advancements and
   refinements are needed to enhance the AI chatbot's performance and
   broaden its application across various medical specialties.
ZA 0
ZS 0
Z8 0
ZB 0
ZR 0
TC 7
Z9 7
DA 2024-01-24
UT WOS:001144093900001
PM 38235841
ER

PT J
AU Delleani, Mattia
   D'Amico, Saverio
   Sauta, Elisabetta
   Asti, Gianluca
   Zazzetti, Elena
   Campagna, Alessia
   Lanino, Luca
   Maggioni, Giulia
   Grondelli, Maria Chiara
   Barrero, Alessandro Forcina
   Morandini, Pierandrea
   Ubezio, Marta
   Todisco, Gabriele
   Russo, Antonio
   Tentori, Cristina Astrid
   Buizza, Alessandro
   Bonometti, Arturo
   Lancellotti, Cesare
   Di Tommaso, Luca
   Rahal, Daoud
   Bicchieri, Marilena
   Savevski, Victor
   Santoro, Armando
   Santini, Valeria
   Sole, Francesc
   Platzbecker, Uwe
   Fenaux, Pierre
   Diez-Campelo, Maria
   Komrokji, Rami S.
   Garcia-Manero, Guillermo
   Haferlach, Torsten
   Kordasti, Shahram
   Zeidan, Amer M.
   Castellani, Gastone
   Della Porta, Matteo Giovanni
TI The "David Vs Goliath" Study: Application of Large
   Language Models (LLM) for Automatic Medical Information Retrieval from
   Multiple Data Sources to Accelerate Clinical and Translational Research
   in Hematology
SO BLOOD
VL 144
BP 3597
EP 3599
DI 10.1182/blood-2024-205621
SU 1
DT Meeting Abstract
PD NOV 5 2024
PY 2024
ZR 0
ZA 0
Z8 0
ZB 0
TC 0
ZS 0
Z9 0
DA 2025-02-20
UT WOS:001412307500014
ER

PT J
AU Biswas, Sayantan
   Logan, Nicola S. S.
   Davies, Leon N. N.
   Sheppard, Amy L. L.
   Wolffsohn, James S. S.
TI Assessing the utility of ChatGPT as an artificial intelligence-based
   large language model for information to answer questions on myopia
SO OPHTHALMIC AND PHYSIOLOGICAL OPTICS
VL 43
IS 6
BP 1562
EP 1570
DI 10.1111/opo.13207
EA JUL 2023
DT Article
PD NOV 2023
PY 2023
AB Purpose: ChatGPT is an artificial intelligence language model, which
   uses natural language processing to simulate human conversation. It has
   seen a wide range of applications including healthcare education,
   research and clinical practice. This study evaluated the accuracy of
   ChatGPT in providing accurate and quality information to answer
   questions on myopia.Methods: A series of 11 questions (nine categories
   of general summary, cause, symptom, onset, prevention, complication,
   natural history, treatment and prognosis) were generated for this
   cross-sectional study. Each question was entered five times into fresh
   ChatGPT sessions (free from influence of prior questions). The responses
   were evaluated by a five-member team of optometry teaching and research
   staff. The evaluators individually rated the accuracy and quality of
   responses on a Likert scale, where a higher score indicated greater
   quality of information (1: very poor; 2: poor; 3: acceptable; 4: good;
   5: very good). Median scores for each question were estimated and
   compared between evaluators. Agreement between the five evaluators and
   the reliability statistics of the questions were estimated.Results: Of
   the 11 questions on myopia, ChatGPT provided good quality information
   (median scores: 4.0) for 10 questions and acceptable responses (median
   scores: 3.0) for one question. Out of 275 responses in total, 66 (24%)
   were rated very good, 134 (49%) were rated good, whereas 60 (22%) were
   rated acceptable, 10 (3.6%) were rated poor and 5 (1.8%) were rated very
   poor. Cronbach's a of 0.807 indicated good level of agreement between
   test items. Evaluators' ratings demonstrated 'slight agreement'
   (Fleiss's ?, 0.005) with a significant difference in scoring among the
   evaluators (Kruskal-Wallis test, p < 0.001).Conclusion: Overall, ChatGPT
   generated good quality information to answer questions on myopia.
   Although ChatGPT shows great potential in rapidly providing information
   on myopia, the presence of inaccurate responses demonstrates that
   further evaluation and awareness concerning its limitations are crucial
   to avoid potential misinterpretation.
Z8 2
ZA 0
TC 54
ZB 5
ZS 0
ZR 0
Z9 56
DA 2023-08-08
UT WOS:001033765800001
PM 37476960
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Ostrowska, Magdalena
   Kacala, Paulina
   Onolememen, Deborah
   Vaughan-Lane, Katie
   Sisily Joseph, Anitta
   Ostrowski, Adam
   Pietruszewska, Wioletta
   Banaszewski, Jacek
   Wrobel, Maciej J.
TI To trust or not to trust: evaluating the reliability and safety of AI
   responses to laryngeal cancer queries
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6069
EP 6081
DI 10.1007/s00405-024-08643-8
EA APR 2024
DT Article
PD NOV 2024
PY 2024
AB Purpose As online health information-seeking surges, concerns mount over
   the quality and safety of accessible content, potentially leading to
   patient harm through misinformation. On one hand, the emergence of
   Artificial Intelligence (AI) in healthcare could prevent it; on the
   other hand, questions raise regarding the quality and safety of the
   medical information provided. As laryngeal cancer is a prevalent head
   and neck malignancy, this study aims to evaluate the utility and safety
   of three large language models (LLMs) as sources of patient information
   about laryngeal cancer.Methods A cross-sectional study was conducted
   using three LLMs (ChatGPT 3.5, ChatGPT 4.0, and Bard). A questionnaire
   comprising 36 inquiries about laryngeal cancer was categorised into
   diagnosis (11 questions), treatment (9 questions), novelties and
   upcoming treatments (4 questions), controversies (8 questions), and
   sources of information (4 questions). The population of reviewers
   consisted of 3 groups, including ENT specialists, junior physicians, and
   non-medicals, who graded the responses. Each physician evaluated each
   question twice for each model, while non-medicals only once. Everyone
   was blinded to the model type, and the question order was shuffled.
   Outcome evaluations were based on a safety score (1-3) and a Global
   Quality Score (GQS, 1-5). Results were compared between LLMs. The study
   included iterative assessments and statistical validations.Results
   Analysis revealed that ChatGPT 3.5 scored highest in both safety (mean:
   2.70) and GQS (mean: 3.95). ChatGPT 4.0 and Bard had lower safety scores
   of 2.56 and 2.42, respectively, with corresponding quality scores of
   3.65 and 3.38. Inter-rater reliability was consistent, with less than 3%
   discrepancy. About 4.2% of responses fell into the lowest safety
   category (1), particularly in the novelty category. Non-medical
   reviewers' quality assessments correlated moderately (r = 0.67) with
   response length.Conclusions LLMs can be valuable resources for patients
   seeking information on laryngeal cancer. ChatGPT 3.5 provided the most
   reliable and safe responses among the models evaluated.
TC 11
ZS 1
ZB 1
ZR 0
ZA 0
Z8 0
Z9 10
DA 2024-04-27
UT WOS:001207064800002
PM 38652298
ER

PT J
AU Busch, Felix
   Hoffmann, Lena
   Rueger, Christopher
   van Dijk, Elon H. C.
   Kader, Rawen
   Ortiz-Prado, Esteban
   Makowski, Marcus R.
   Saba, Luca
   Hadamitzky, Martin
   Kather, Jakob Nikolas
   Truhn, Daniel
   Cuocolo, Renato
   Adams, Lisa C.
   Bressem, Keno K.
TI Current applications and challenges in large language models for patient
   care: a systematic review
SO COMMUNICATIONS MEDICINE
VL 5
IS 1
AR 26
DI 10.1038/s43856-024-00717-2
DT Article
PD JAN 21 2025
PY 2025
AB BackgroundThe introduction of large language models (LLMs) into clinical
   practice promises to improve patient education and empowerment, thereby
   personalizing medical care and broadening access to medical knowledge.
   Despite the popularity of LLMs, there is a significant gap in
   systematized information on their use in patient care. Therefore, this
   systematic review aims to synthesize current applications and
   limitations of LLMs in patient care.MethodsWe systematically searched 5
   databases for qualitative, quantitative, and mixed methods articles on
   LLMs in patient care published between 2022 and 2023. From 4349 initial
   records, 89 studies across 29 medical specialties were included. Quality
   assessment was performed using the Mixed Methods Appraisal Tool 2018. A
   data-driven convergent synthesis approach was applied for thematic
   syntheses of LLM applications and limitations using free line-by-line
   coding in Dedoose.ResultsWe show that most studies investigate
   Generative Pre-trained Transformers (GPT)-3.5 (53.2%, n = 66 of 124
   different LLMs examined) and GPT-4 (26.6%, n = 33/124) in answering
   medical questions, followed by patient information generation, including
   medical text summarization or translation, and clinical documentation.
   Our analysis delineates two primary domains of LLM limitations: design
   and output. Design limitations include 6 second-order and 12 third-order
   codes, such as lack of medical domain optimization, data transparency,
   and accessibility issues, while output limitations include 9
   second-order and 32 third-order codes, for example, non-reproducibility,
   non-comprehensiveness, incorrectness, unsafety, and bias.ConclusionsThis
   review systematically maps LLM applications and limitations in patient
   care, providing a foundational framework and taxonomy for their
   implementation and evaluation in healthcare settings.
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 8
Z9 8
DA 2025-01-29
UT WOS:001402540700001
PM 39838160
ER

PT J
AU Mathis, Walter S.
   Zhao, Sophia
   Pratt, Nicholas
   Weleff, Jeremy
   De Paoli, Stefano
TI Inductive thematic analysis of healthcare qualitative interviews using
   open-source large language models: How does it compare to traditional
   methods?
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 255
AR 108356
DI 10.1016/j.cmpb.2024.108356
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background: Large language models (LLMs) are generative artificial
   intelligence that have ignited much interest and discussion about their
   utility in clinical and research settings. Despite this interest there
   is sparse analysis of their use in qualitative thematic analysis
   comparing their current ability to that of human coding and analysis. In
   addition, there has been no published analysis of their use in
   real-world, protected health information. Objective: Here we fill that
   gap in the literature by comparing an LLM to standard human thematic
   analysis in real-world, semi-structured interviews of both patients and
   clinicians within a psychiatric setting. Methods: Using a 70 billion
   parameter open-source LLM running on local hardware and advanced prompt
   engineering techniques, we produced themes that summarized a full corpus
   of interviews in minutes. Subsequently we used three different
   evaluation methods for quantifying similarity between themes produced by
   the LLM and those produced by humans. Results: These revealed
   similarities ranging from moderate to substantial (Jaccard similarity
   coefficients 0.44-0.69), which are promising preliminary results.
   Conclusion: Our study demonstrates that open-source LLMs can effectively
   generate robust themes from qualitative data, achieving substantial
   similarity to human-generated themes. The validation of LLMs in thematic
   analysis, coupled with evaluation methodologies, highlights their
   potential to enhance and democratize qualitative research across diverse
   fields.
TC 7
ZS 0
ZR 0
ZB 0
Z8 0
ZA 0
Z9 7
DA 2024-08-10
UT WOS:001283539000001
PM 39067136
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

EF