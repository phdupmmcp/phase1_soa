FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Chen, Runsheng
TI [Prospects for the Application of Healthcare Big Data Combined With
   Large Language Models].
SO Sichuan da xue xue bao. Yi xue ban = Journal of Sichuan University.
   Medical science edition
VL 54
IS 5
BP 855
EP 856
DI 10.12182/20230960301
DT English Abstract; Journal Article; Review
PD 2023-Sep
PY 2023
AB The application of big data technology combined with large language
   models is expected to make an enormous impact in the field of medicine.
   Herein, the prospects for the application of healthcare big data
   combined with large language models were discussed in several aspects,
   including first in assisting doctors in making diagnosis and
   differential diagnosis and, then, in the field of evidence-based
   medicine. In addition, healthcare big data combined with large language
   models could also be applied in assisting doctors to conduct clinical
   and medical research. Through combining healthcare big data with large
   language models, medical diagnosis and treatment with improved
   precision, efficiency, and intelligence will be realized and greater
   contributions will be made to the field of human health.
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 1
Z9 1
DA 2023-10-26
UT MEDLINE:37866938
PM 37866938
ER

PT J
AU Qiu, Jianing
   Lam, Kyle
   Li, Guohao
   Acharya, Amish
   Wong, Tien Yin
   Darzi, Ara
   Yuan, Wu
   Topol, Eric J.
TI LLM-based agentic systems in medicine and healthcare
SO NATURE MACHINE INTELLIGENCE
VL 6
IS 12
BP 1418
EP 1420
DI 10.1038/s42256-024-00944-1
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB Large language model-based agentic systems can process input
   information, plan and decide, recall and reflect, interact and
   collaborate, leverage various tools and act. This opens up a wealth of
   opportunities within medicine and healthcare, ranging from clinical
   workflow automation to multi-agent-aided diagnosis.
ZS 0
Z8 0
TC 6
ZR 0
ZA 0
ZB 1
Z9 6
DA 2024-12-11
UT WOS:001370695300001
ER

PT J
AU Wang, Lan
   Tang, Kaiqiang
   Wang, Yan
   Zhang, Peng
   Li, Shao
TI Advancements in Artificial Intelligence-Driven Diagnostic Models for
   Traditional Chinese Medicine
SO AMERICAN JOURNAL OF CHINESE MEDICINE
VL 53
IS 03
BP 647
EP 673
DI 10.1142/S0192415X25500259
DT Article
PD 2025
PY 2025
AB Traditional Chinese medicine (TCM) is an ancient medical system with
   distinctive ethnic characteristics. TCM diagnosis, underpinned by unique
   theoretical frameworks and methodologies, continues to play a
   significant role in contemporary healthcare. The four fundamental
   diagnostic methods, inspection, auscultation-olfaction, inquiry and
   palpation, are inherently subjective, relying on practitioner
   experience. Despite its unique advantages and practical value, TCM must
   still take advantage of modern advancements to enhance its effectiveness
   and accessibility. With the rapid development of computer technology,
   intelligent TCM diagnosis has emerged as a promising frontier.
   Integrating artificial intelligence (AI), particularly through large
   language models (LLMs), offers new avenues for enhancing TCM diagnostic
   practices. However, the systematic review and analysis of these
   technologies remains limited. This paper provides a comprehensive
   overview of the development and recent advancements in TCM diagnostic
   technologies, focusing on the applications of ML across various data
   modalities, and including images, text, and waveforms. Additionally, it
   explores the latest applications of LLMs within the TCM diagnostic
   field. Furthermore, the review discusses the prospects and challenges
   associated with AI-based TCM diagnosis. By systematically summarizing
   the latest research achievements and technological advancements, this
   study aims to provide directional guidance and decision support for
   future research and practical applications in the intersection of AI and
   TCM. Ultimately, this review seeks to foster the continued development
   and integration of intelligent TCM diagnosis into modern healthcare.
ZR 0
Z8 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
DA 2025-05-20
UT WOS:001488594200010
PM 40374369
ER

PT J
AU Saddik, Abdulmotaleb El
   Ghaboura, Sara
TI The Integration of ChatGPT With the Metaverse for Medical Consultations
SO IEEE CONSUMER ELECTRONICS MAGAZINE
VL 13
IS 3
BP 6
EP 15
DI 10.1109/MCE.2023.3324978
DT Article
PD MAY 2024
PY 2024
AB Recent years witnessed a promising synergy between healthcare and the
   Metaverse leading to the development of virtual healthcare environments.
   This convergence offers accessible and immersive healthcare experiences
   and holds the potential for transforming the delivery of medical
   services and enhancing patient outcomes. However, the reliance on
   specialist presence in the metaverse for medical support remains a
   challenge. On the other hand, the newly launched large language model
   chatbot, the ChatGPT of OpenAI, has emerged as a game-changer, providing
   human-like responses and facilitating interactive conversations. By
   integrating this cutting-edge language model with the Metaverse for
   medical purposes, we can potentially revolutionize healthcare delivery,
   enhance access to care, and increase patient engagement. This study
   proposes a new medical Metaverse model utilizing GPT-4 as a content
   creator, highlighting its potential, addressing challenges and
   limitations, and exploring various application fields. We conclude by
   outlining our ongoing efforts to transform this concept into a practical
   reality.
Z8 0
ZA 0
ZS 0
ZB 0
ZR 0
TC 6
Z9 6
DA 2024-04-10
UT WOS:001184800600009
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Shah, Krish
   Xu, Andrew Y.
   Sharma, Yatharth
   Daher, Mohammed
   Mcdonald, Christopher
   Diebo, Bassel G.
   Daniels, Alan H.
TI Large Language Model Prompting Techniques for Advancement in Clinical
   Medicine
SO JOURNAL OF CLINICAL MEDICINE
VL 13
IS 17
AR 5101
DI 10.3390/jcm13175101
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs have the potential to revolutionize clinical
   medicine by enhancing healthcare access, diagnosis, surgical planning,
   and education. However, their utilization requires careful, prompt
   engineering to mitigate challenges like hallucinations and biases.
   Proper utilization of LLMs involves understanding foundational concepts
   such as tokenization, embeddings, and attention mechanisms, alongside
   strategic prompting techniques to ensure accurate outputs. For
   innovative healthcare solutions, it is essential to maintain ongoing
   collaboration between AI technology and medical professionals. Ethical
   considerations, including data security and bias mitigation, are
   critical to their application. By leveraging LLMs as supplementary
   resources in research and education, we can enhance learning and support
   knowledge-based inquiries, ultimately advancing the quality and
   accessibility of medical care. Continued research and development are
   necessary to fully realize the potential of LLMs in transforming
   healthcare.
ZB 1
ZS 0
Z8 0
TC 9
ZA 0
ZR 0
Z9 9
DA 2024-09-21
UT WOS:001311343800001
PM 39274316
ER

PT J
AU Thesen, Thomas
   Alilonu, Nsomma A.
   Stone, Simon
TI AI Patient Actor: An Open-Access Generative-AI App for Communication
   Training in Health Professions
SO MEDICAL SCIENCE EDUCATOR
VL 35
IS 1
BP 25
EP 27
DI 10.1007/s40670-024-02250-2
EA DEC 2024
DT Article
PD FEB 2025
PY 2025
AB The AI Patient Actor is an openly available web-based app powered by a
   Large-Language Model that allows medical trainees to practice diagnosis
   and communication skills while receiving individualized formative
   feedback. Healthcare educators can generate and upload their own cases
   for use with their students.
ZA 0
TC 3
ZR 0
ZS 0
ZB 0
Z8 0
Z9 3
DA 2024-12-21
UT WOS:001377489800001
PM 40144116
ER

PT C
AU Chang, Jocelyn J.
   Chang, Edward Y.
GP IEEE COMPUTER SOC
TI SocraHealth: hnhancing Medical Diagnosis and Correcting Historical
   Records
SO 2023 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL
   INTELLIGENCE, CSCI 2023
SE International Conference on Computational Science and Computational
   Intelligence
BP 1400
EP 1405
DI 10.1109/CSCI62032.2023.00229
DT Proceedings Paper
PD 2023
PY 2023
AB This study introduces SocraHealth, an innovative method using Large
   Language Models (LLMs) for medical diagnostics. By engaging LLM-based
   agents in structured debates, Socrallealth not only refines diagnoses
   but also corrects historical record inaccuracies, utilizing patient data
   effectively. The case study, featuring GPT-4 and Bard across two
   experiments, showcases this approach's success in producing logical,
   hallucination free debates. Demonstrating a significant advancement over
   traditional diagnostic techniques, Socrallealth highlights the
   transformative power of LLMs in healthcare, especially in enhancing
   diagnostic accuracy and rectifying past diagnostic errors.
CT International Conference on Computational Science and Computational
   Intelligence (CSCI)
CY DEC 13-15, 2023
CL Las Vegas, NV
SP IEEE
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
ZA 0
Z9 0
DA 2024-09-07
UT WOS:001283930300235
ER

PT J
AU Alsaif, Khalid
   Albeshri, Aiiad
   Khemakhem, Maher
   Eassa, Fathy
TI Healthcare 4.0: A Large Language Model-Based Blockchain Framework for
   Medical Device Fault Detection and Diagnostics
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
VL 16
IS 4
BP 980
EP 992
DT Article
PD 2025
PY 2025
AB This paper introduces a novel framework integrating Large Language
   Models (LLMs) with blockchain technology for medical device fault
   detection and diagnostics in Healthcare 4.0 environments. The proposed
   framework addresses key challenges, including real-time fault detection,
   data security, and automated diagnostics through a multi-layered
   architecture incorporating Internet of Things (IoT) integration,
   blockchain-based security, and LLM-driven diagnostics. Experimental
   evaluations demonstrate substantial improvements in diagnostic accuracy
   and response time while maintaining stringent security standards and
   regulatory compliance. The system provides enhanced fault detection with
   real-time monitoring capabilities and secure maintenance record
   management for smart healthcare. Comparative analysis of different LLMs
   and traditional Machine Learning (ML) methods shows that Deepseek-R1:7b
   achieved 97.6% classification accuracy, while O3-mini reached 90.4% and
   91.2% in diagnosis accuracy and problem identification, respectively.
   Claude demonstrated the highest technical accuracy (98.4%), while
   Traditional ML excelled in processing time (11.7) and processing rate
   (10.68). Deepseek-R1:7b's offline capabilities ensure stringent
   security, privacy, and confidentiality with restricted connectivity,
   making it particularly suitable for sensitive healthcare applications
   where data protection is paramount.
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-06-14
UT WOS:001503392900001
ER

PT J
AU Schuetz, Pascal
   Lob, Sina
   Chahed, Hiba
   Dathe, Lisa
   Loewer, Maren
   Reiss, Hannah
   Weigel, Alina
   Albrecht, Joanna
   Tokgoez, Pinar
   Dockweiler, Christoph
TI ChatGPT as an Information Source for Patients with Migraines: A
   Qualitative Case Study
SO HEALTHCARE
VL 12
IS 16
AR 1594
DI 10.3390/healthcare12161594
DT Article
PD AUG 2024
PY 2024
AB Migraines are one of the most common and expensive neurological diseases
   worldwide. Non-pharmacological and digitally delivered treatment options
   have long been used in the treatment of migraines. For instance,
   migraine management tools, online migraine diagnosis or digitally
   networked patients have been used. Recently, applications of ChatGPT are
   used in fields of healthcare ranging from identifying potential research
   topics to assisting professionals in clinical diagnosis and helping
   patients in managing their health. Despite advances in migraine
   management, only a minority of patients are adequately informed and
   treated. It is important to provide these patients with information to
   help them manage the symptoms and their daily activities. The primary
   aim of this case study was to examine the appropriateness of ChatGPT to
   handle symptom descriptions responsibly, suggest supplementary
   assistance from credible sources, provide valuable perspectives on
   treatment options, and exhibit potential influences on daily life for
   patients with migraines. Using a deductive, qualitative study, ten
   interactions with ChatGPT on different migraine types were analyzed
   through semi-structured interviews. ChatGPT provided relevant
   information aligned with common scientific patient resources. Responses
   were generally intelligible and situationally appropriate, providing
   personalized insights despite occasional discrepancies in interaction.
   ChatGPT's empathetic tone and linguistic clarity encouraged user
   engagement. However, source citations were found to be inconsistent and,
   in some cases, not comprehensible, which affected the overall
   comprehensibility of the information. ChatGPT might be promising for
   patients seeking information on migraine conditions. Its user-specific
   responses demonstrate potential benefits over static web-based sources.
   However, reproducibility and accuracy issues highlight the need for
   digital health literacy. The findings underscore the necessity for
   continuously evaluating AI systems and their broader societal
   implications in health communication.
Z8 0
ZA 0
TC 2
ZR 0
ZB 0
ZS 0
Z9 2
DA 2024-09-09
UT WOS:001304740300001
PM 39201153
ER

PT J
AU Gaber, Farieda
   Shaik, Maqsood
   Allega, Fabio
   Bilecz, Agnes Julia
   Busch, Felix
   Goon, Kelsey
   Franke, Vedran
   Akalin, Altuna
TI Evaluating large language model workflows in clinical decision support
   for triage and referral and diagnosis
SO NPJ DIGITAL MEDICINE
VL 8
IS 1
AR 263
DI 10.1038/s41746-025-01684-1
DT Article
PD MAY 9 2025
PY 2025
AB Accurate medical decision-making is critical for both patients and
   clinicians. Patients often struggle to interpret their symptoms,
   determine their severity, and select the right specialist.
   Simultaneously, clinicians face challenges in integrating complex
   patient data to make timely, accurate diagnoses. Recent advances in
   large language models (LLMs) offer the potential to bridge this gap by
   supporting decision-making for both patients and healthcare providers.
   In this study, we benchmark multiple LLM versions and an LLM-based
   workflow incorporating retrieval-augmented generation (RAG) on a curated
   dataset of 2000 medical cases derived from the Medical Information Mart
   for Intensive Care database. Our findings show that these LLMs are
   capable of providing personalized insights into likely diagnoses,
   suggesting appropriate specialists, and assessing urgent care needs.
   These models may also support clinicians in refining diagnoses and
   decision-making, offering a promising approach to improving patient
   outcomes and streamlining healthcare delivery.
Z8 0
ZR 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
DA 2025-05-16
UT WOS:001485848400003
PM 40346344
ER

PT C
AU del Hoyo, Pablo
   Schez-Sobrino, Santiago
   Garcia, Francisco
   Cardoso, Jorge C. S.
   Albusac, Javier
   Vallejo, David
BE Bravo, J
   Nugent, C
   Cleland, I
TI PrimARy: Intelligent System Based on Mixed Reality for Diagnosis and
   Assistance in Primary Care
SO PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING AND
   AMBIENT INTELLIGENCE, UCAMI 2024
SE Lecture Notes in Networks and Systems
VL 1212
BP 45
EP 56
DI 10.1007/978-3-031-77571-0_5
DT Proceedings Paper
PD 2024
PY 2024
AB This research aims to improve the diagnostic and support capabilities of
   healthcare professionals in primary care settings. We present PrimARy, a
   system that enables primary care workers to follow medical protocols in
   a guided manner using Mixed Reality and Artificial Intelligence. These
   protocols, defined using a node-based visual editor, can be
   automatically integrated into the Mixed Reality application, extending
   the system's capabilities to different healthcare scenarios. The
   protocols can be enriched with documents and multimedia, and serve as
   the basis for the virtual assistant built into PrimARy to guide users in
   following a medical protocol. This functionality makes use of a Large
   Language Model deployed on a dedicated server for inference processes.
   As a practical application, the integration of a visual triage process
   to assess overweight and obesity is proposed. The ultimate goal is to
   scale our proposal for use in primary care centers, patients' homes, and
   emergency situations by medical and nursing staff.
CT 16th International Conference on Ubiquitous Computing and Ambient
   Intelligence
CY NOV 27-29, 2024
CL Belfast, IRELAND
ZA 0
TC 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 0
DA 2025-04-05
UT WOS:001443925900005
ER

PT J
AU Kral, Jan
   Hradis, Michal
   Buzga, Marek
   Kunovsky, Lumir
TI Exploring the benefits and challenges of AI-driven large language models
   in gastroenterology: Think out of the box
SO BIOMEDICAL PAPERS-OLOMOUC
VL 168
IS 4
BP 277
EP 283
DI 10.5507/bp.2024.027
EA SEP 2024
DT Review
PD DEC 2024
PY 2024
AB Artificial Intelligence (AI) has evolved significantly over the past
   decades, from its early concepts in the 1950s to the present era of deep
   learning and natural language processing. Advanced large language models
   (LLMs), such as Chatbot Generative Pre-Trained Transformer (ChatGPT) is
   trained to generate human-like text responses. This technology has the
   potential to revolutionize various aspects of gastroenterology,
   including diagnosis, treatment, education, and The benefits of using
   LLMs in gastroenterology could include accelerating diagnosis and
   treatment, providing personalized care, enhancing education and
   training, assisting in decision-making, and improving communication with
   patients. However, drawbacks and challenges such as limited AI
   capability, training on possibly biased data, data errors, security and
   privacy concerns, and implementation costs must be addressed to ensure
   the responsible and effective use of this technology. The future of LLMs
   in gastroenterology relies on the ability to process and analyse large
   amounts of data, identify patterns, and summarize information and thus
   assist physicians in creating personalized treatment plans. As AI
   advances, LLMs will become more accurate and efficient, allowing for
   faster diagnosis and treatment of gastroenterological conditions.
   Ensuring effective collaboration between AI developers, healthcare
   professionals, and regulatory bodies is essential for the responsible
   and effective use of this technology. By finding the right balance
   between AI and human expertise and addressing the limitations and risks
   associated with its use, LLMs can play an increasingly significant role
   in gastroenterology, contributing to better patient care and supporting
   doctors in their work.
ZR 0
ZS 0
Z8 0
ZA 0
TC 2
ZB 0
Z9 2
DA 2024-09-12
UT WOS:001306654600001
PM 39234774
ER

PT J
AU Uranbey, Oemer
   Ozbey, Furkan
   Kaygisiz, Omer
   Ayranci, Ferhat
TI Assessing ChatGPT's Diagnostic Accuracy and Therapeutic Strategies in
   Oral Pathologies: A Cross-Sectional Study
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 4
AR e58607
DI 10.7759/cureus.58607
DT Article
PD APR 19 2024
PY 2024
AB Background: The rapid adoption of artificial intelligence (AI) models in
   the medical field is due to their ability to collaborate with clinicians
   in the diagnosis and management of a wide range of conditions. This
   research assesses the diagnostic accuracy and therapeutic strategies of
   Chat Generative Pre -trained Transformer (ChatGPT) in comparison to
   dental professionals across 12 clinical cases. Methodology: ChatGPT 3.5
   was queried for diagnoses and management plans for 12 retrospective
   cases. Physicians were tasked with rating the complexity of clinical
   scenarios and their agreement with the ChatGPT responses using a five
   -point Likert scale. Comparisons were made between the complexity of the
   cases and the accuracy of the diagnoses and treatment plans. Results:
   ChatGPT exhibited high accuracy in providing differential diagnoses and
   acceptable treatment plans. In a survey involving 30 attending
   physicians, scenarios were rated with an overall median difficulty level
   of 3, showing acceptable agreement with ChatGPT's differential diagnosis
   accuracy (overall median 4). Our study revealed lower diagnosis scores
   correlating with decreased treatment management scores, as demonstrated
   by univariate ordinal regression analysis. Conclusions: ChatGPT's rapid
   processing aids healthcare by offering an objective, evidence -based
   approach, reducing human error and workload. However, potential biases
   may affect outcomes and challenge lessexperienced practitioners. AI in
   healthcare, including ChatGPT, is still evolving, and further research
   is needed to understand its full potential in analyzing clinical
   information, establishing diagnoses, and suggesting treatments.
ZB 0
TC 7
ZR 0
ZS 0
ZA 0
Z8 0
Z9 7
DA 2024-05-23
UT WOS:001223827200032
PM 38770501
ER

PT J
AU Gupta, Ayushi
   Al-Kazwini, Hussein
TI Evaluating ChatGPT's Diagnostic Accuracy in Detecting Fundus Images.
SO Cureus
VL 16
IS 11
BP e73660
EP e73660
DI 10.7759/cureus.73660
DT Journal Article
PD 2024-Nov
PY 2024
AB Introduction Artificial intelligence is rapidly advancing in healthcare.
   Ophthalmology, with its reliance on imaging for diagnosis and
   management, has the potential to benefit from this technology. Deep
   learning models are currently used in image analysis in ophthalmology.
   ChatGPT (OpenAI, San Francisco, CA), a large language model, has
   recently expanded to include image analysis, creating new opportunities
   for diagnostic applications. While prior research shows potential in
   text-based diagnostics for ophthalmology, there is limited literature on
   AI's diagnostic accuracy in interpreting retinal images. Methods We
   selected 12 fundus images from key diseases identified by the Royal
   College of Ophthalmology curricula for medical students, foundation
   doctors, and trainees. Each image was presented to ChatGPT 4.0 using a
   standardised prompt to identify the most likely diagnosis. Responses
   were recorded, and the model's accuracy was assessed by comparing its
   diagnoses to the confirmed conditions. Results ChatGPT accurately
   diagnosed four out of 12 diseases (papilloedema, dry age-related macular
   degeneration (ARMD), glaucoma and vitreous haemorrhage) and provided one
   partially correct diagnosis (diabetic retinopathy). However, the model
   struggled with seven cases, including central retinal artery occlusion,
   central retinal vein occlusion, dry ARMD, rhegmatogenous retinal
   detachment, tractional retinal detachment, epiretinal membrane and
   macular hole. Conclusion ChatGPT demonstrates the potential for
   diagnosis of retinal conditions from fundus photography. However, it
   currently lacks the accuracy required for clinical application; the
   model often hallucinates when unsure, which has diagnostic implications.
   Further work is required to refine these models and expand their
   diagnostic potential.
ZB 0
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2024-12-18
UT MEDLINE:39677217
PM 39677217
ER

PT J
AU Wang, Yue
   Yang, Shuo
   Zeng, Chengcheng
   Xie, Yingwei
   Shen, Ya
   Li, Jian
   Huang, Xiao
   Wei, Ruili
   Chen, Yuqing
TI Evaluating the performance of ChatGPT in patient consultation and
   image-based preliminary diagnosis in thyroid eye disease
SO FRONTIERS IN MEDICINE
VL 12
AR 1546706
DI 10.3389/fmed.2025.1546706
DT Article
PD FEB 18 2025
PY 2025
AB Background The emergence of Large Language Model (LLM) chatbots, such as
   ChatGPT, has great promise for enhancing healthcare practice. Online
   consultation, accurate pre-diagnosis, and clinical efforts are of
   fundamental importance for the patient-oriented management
   system.Objective This cross-sectional study aims to evaluate the
   performance of ChatGPT in inquiries across ophthalmic domains and to
   focus on Thyroid Eye Disease (TED) consultation and image-based
   preliminary diagnosis in a non-English language.Methods We obtained
   frequently consulted clinical inquiries from a published reference based
   on patient consultation data, titled A Comprehensive Collection of
   Thyroid Eye Disease Knowledge. Additionally, we collected facial and
   Computed Tomography (CT) images from 16 patients with a definitive
   diagnosis of TED. From 18 to 30 May 2024, inquiries about the TED
   consultation and preliminary diagnosis were posed to ChatGPT using a new
   chat for each question. Responses to questions from ChatGPT-4, 4o, and
   an experienced ocular professor were compiled into three questionnaires,
   which were evaluated by patients and ophthalmologists on four
   dimensions: accuracy, comprehensiveness, conciseness, and satisfaction.
   The preliminary diagnosis of TED was deemed accurate, and the
   differences in the accuracy rates were further calculated.Results For
   common TED consultation questions, ChatGPT-4o delivered more accurate
   information with logical consistency, adhering to a structured format of
   disease definition, detailed sections, and summarized conclusions.
   Notably, the answers generated by ChatGPT-4o were rated higher than
   those of ChatGPT-4 and the professor, with accuracy (4.33 [0.69]),
   comprehensiveness (4.17 [0.75]), conciseness (4.12 [0.77]), and
   satisfaction (4.28 [0.70]). The characteristics of the evaluators, the
   response variables, and other quality scores were all correlated with
   overall satisfaction levels. Based on several facial images, ChatGPT-4
   twice failed to make diagnoses because of lacking characteristic
   symptoms or a complete medical history, whereas ChatGPT-4o accurately
   identified the pathologic conditions in 31.25% of cases (95% confidence
   interval, CI: 11.02-58.66%). Furthermore, in combination with CT images,
   ChatGPT-4o performed comparably to the professor in terms of diagnosis
   accuracy (87.5, 95% CI 61.65-98.45%).Conclusion ChatGPT-4o excelled in
   comprehensive and satisfactory patient consultation and imaging
   interpretation, indicating the potential to improve clinical practice
   efficiency. However, limitations in disinformation management and legal
   permissions remain major concerns, which require further investigation
   in clinical practice.
TC 1
ZB 0
ZS 0
ZA 0
Z8 0
ZR 0
Z9 1
DA 2025-03-08
UT WOS:001435934700001
PM 40041459
ER

PT C
AU Liu, Zhengliang
   Zhong, Aoxiao
   Li, Yiwei
   Yang, Longtao
   Ju, Chao
   Wu, Zihao
   Ma, Chong
   Shu, Peng
   Chen, Cheng
   Kim, Sekeun
   Dai, Haixing
   Zhao, Lin
   Zhu, Dajiang
   Liu, Jun
   Liu, Wei
   Shen, Dinggang
   Li, Quanzheng
   Liu, Tianming
   Li, Xiang
BE Cao, X
   Xu, X
   Rekik, I
   Cui, Z
   Ouyang, X
TI Tailoring Large Language Models to Radiology: A Preliminary Approach to
   LLM Adaptation for a Highly Specialized Domain
SO MACHINE LEARNING IN MEDICAL IMAGING, MLMI 2023, PT I
SE Lecture Notes in Computer Science
VL 14348
BP 464
EP 473
DI 10.1007/978-3-031-45673-2_46
DT Proceedings Paper
PD 2024
PY 2024
AB In this preliminary work, we present a domain fine-tuned LLM model for
   radiology, an experimental large language model adapted for radiology.
   This model, created through an exploratory application of instruction
   tuning on a comprehensive dataset of radiological information,
   demonstrates promising performance when compared with broader language
   models such as StableLM, Dolly, and LLaMA. This model exhibits initial
   versatility in applications related to radiological diagnosis, research,
   and communication. Our work contributes an early but encouraging step
   towards the evolution of clinical NLP by implementing a large language
   model that is local and domain-specific, conforming to stringent privacy
   norms like HIPAA. The hypothesis of creating customized, large-scale
   language models catering to distinct requirements of various medical
   specialties, presents a thought-provoking direction. The blending of
   conversational prowess and specific domain knowledge in these models
   kindles hope for future enhancements in healthcare AI. While it is still
   in its early stages, the potential of generative large language models
   is intriguing and worthy of further exploration. The demonstration code
   of our domain fine-tuned LLM model for radiology can be accessed at
   https://anonymous.4open.science/r/radiology-llm-demo-C3E2/.
CT 14th International Workshop on Machine Learning in Medical Imaging
   (MLMI)
CY OCT 08, 2023
CL Vancouver, CANADA
Z8 0
ZA 0
ZR 0
ZB 0
TC 10
ZS 0
Z9 10
DA 2024-01-04
UT WOS:001109643200046
ER

PT J
AU Hirata, Kenji
   Matsui, Yusuke
   Yamada, Akira
   Fujioka, Tomoyuki
   Yanagawa, Masahiro
   Nakaura, Takeshi
   Ito, Rintaro
   Ueda, Daiju
   Fujita, Shohei
   Tatsugami, Fuminari
   Fushimi, Yasutaka
   Tsuboyama, Takahiro
   Kamagata, Koji
   Nozaki, Taiki
   Fujima, Noriyuki
   Kawamura, Mariko
   Naganawa, Shinji
TI Generative AI and large language models in nuclear medicine: current
   status and future prospects
SO ANNALS OF NUCLEAR MEDICINE
VL 38
IS 11
BP 853
EP 864
DI 10.1007/s12149-024-01981-x
EA SEP 2024
DT Review
PD NOV 2024
PY 2024
AB This review explores the potential applications of Large Language Models
   (LLMs) in nuclear medicine, especially nuclear medicine examinations
   such as PET and SPECT, reviewing recent advancements in both fields.
   Despite the rapid adoption of LLMs in various medical specialties, their
   integration into nuclear medicine has not yet been sufficiently
   explored. We first discuss the latest developments in nuclear medicine,
   including new radiopharmaceuticals, imaging techniques, and clinical
   applications. We then analyze how LLMs are being utilized in radiology,
   particularly in report generation, image interpretation, and medical
   education. We highlight the potential of LLMs to enhance nuclear
   medicine practices, such as improving report structuring, assisting in
   diagnosis, and facilitating research. However, challenges remain,
   including the need for improved reliability, explainability, and bias
   reduction in LLMs. The review also addresses the ethical considerations
   and potential limitations of AI in healthcare. In conclusion, LLMs have
   significant potential to transform existing frameworks in nuclear
   medicine, making it a critical area for future research and development.
ZR 0
ZA 0
TC 4
ZB 1
ZS 0
Z8 0
Z9 4
DA 2024-09-30
UT WOS:001319554200001
PM 39320419
ER

PT J
AU Kang, Yan
   Yang, Mingjian
   Peng, Yue
   Cai, Jingwen
   Zhao, Lei
   Gao, Zhan
   Li, Ningshu
   Pu, Bin
TI LLM-DG: Leveraging large language model for enhanced disease prediction
   via inter-patient and intra-patient modeling
SO INFORMATION FUSION
VL 121
AR 103145
DI 10.1016/j.inffus.2025.103145
EA APR 2025
DT Article
PD SEP 2025
PY 2025
AB Existing methods play a crucial role in clinical decision support by
   enabling disease prediction and personalizing healthcare based on
   swiftly accumulated electronic Health Records (EHRs). However, these
   methods often overlook multi-source data integration by relying solely
   on specific domain knowledge and fail to model intricate relationships
   among patients as focusing on inter or intra-patient relationships,
   respectively. To address these limitations, we propose LLM-DG, a
   multi-level health event prediction framework enhanced by large language
   models (LLMs). Specifically, LLM performs semantic enhancement for
   patient and discharge summary representations and injects domain
   knowledge into disease modeling, improving prediction accuracy and
   robustness. Moreover, LLM-DG synchronously models inter-patient and
   intra-patient relationships by capturing high-order patient correlations
   and fusing dynamic and static patient features. At the inter-patient
   level, LLM-DG clusters patients based on LLM-enhanced features,
   identifying similar health trajectories. At the intra-patient level, it
   models disease evolution characteristics through a dynamic graph and
   extracts textual information from LLM-enhanced discharge summaries using
   a text encoder. Experiments on MIMIC-III and MIMIC-IV datasets
   demonstrate that LLM-DG significantly outperforms state-of-the-art
   models, achieving a 12.39% improvement in w-F1 on the diagnosis
   prediction task of the MIMIC-IV dataset. Overall, LLM-DG demonstrates
   strong potential in complex healthcare environments by integrating
   patient histories and cross-patient health patterns, highlighting its
   applicability in clinical decision support and personalized treatment
   planning.
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001464997000001
ER

PT J
AU Lee, Jung-Hyun
   Choi, Eunhee
   Angulo, Sergio L.
   Mcdougal, Robert A.
   Lytton, William W.
TI Neurological history both twinned and queried by generative artificial
   intelligence
SO FRONTIERS IN MEDICINE
VL 11
AR 1496866
DI 10.3389/fmed.2024.1496866
DT Article
PD JAN 17 2025
PY 2025
AB Background and objectives We propose the use of GPT-4 to facilitate
   initial history-taking in neurology and other medical specialties. A
   large language model (LLM) could be utilized as a digital twin which
   could enhance queryable electronic medical record (EMR) systems and
   provide healthcare conversational agents (HCAs) to replace waiting-room
   questionnaires.Methods In this observational pilot study, we presented
   verbatim history of present illness (HPI) narratives from published case
   reports of headache, stroke, and neurodegenerative diseases. Three
   standard GPT-4 models were designated Models P: patient digital twin; N:
   neurologist to query Model P; and S: supervisor to synthesize the N-P
   dialogue into a derived HPI and formulate the differential diagnosis.
   Given the random variability of GPT-4 output, each case was presented
   five separate times to check consistency and reliability.Results The
   study achieved an overall HPI content retrieval accuracy of 81%, with
   accuracies of 84% for headache, 82% for stroke, and 77% for
   neurodegenerative diseases. Retrieval accuracies for individual HPI
   components were as follows: 93% for chief complaints, 47% for associated
   symptoms and review of systems, 76% for relevant symptom details, and
   94% for histories of past medical, surgical, allergies, social, and
   family factors. The ranking of case diagnoses in the differential
   diagnosis list averaged in the 89th percentile.Discussion Our tripartite
   LLM model demonstrated accuracy in extracting essential information from
   published case reports. Further validation with EMR HPIs, and then with
   direct patient care will be needed to move toward adaptation of enhanced
   diagnostic digital twins that incorporate real-time data from
   health-monitoring devices and self-monitoring assessments.
ZS 0
ZB 0
ZR 0
Z8 0
TC 0
ZA 0
Z9 0
DA 2025-02-05
UT WOS:001409771700001
PM 39895821
ER

PT J
AU Iqbal, Usman
   Tanweer, Afifa
   Rahmanti, Annisa Ristya
   Greenfield, David
   Lee, Leon Tsung-Ju
   Li, Yu-Chuan Jack
TI Impact of large language model (ChatGPT) in healthcare: an umbrella
   review and evidence synthesis
SO JOURNAL OF BIOMEDICAL SCIENCE
VL 32
IS 1
AR 45
DI 10.1186/s12929-025-01131-z
DT Article
PD MAY 7 2025
PY 2025
AB Background The emergence of Artificial Intelligence (AI), particularly
   Chat Generative Pre-Trained Transformer (ChatGPT), a Large Language
   Model (LLM), in healthcare promises to reshape patient care, clinical
   decision-making, and medical education. This review aims to synthesise
   research findings to consolidate the implications of ChatGPT integration
   in healthcare and identify research gaps. Main body The umbrella review
   was conducted following Preferred Reporting Items for Systematic Reviews
   and Meta-Analyses (PRISMA) guidelines. The Cochrane Library, PubMed,
   Scopus, Web of Science, and Google Scholar were searched from inception
   until February 2024. Due to the heterogeneity of the included studies,
   no quantitative analysis was performed. Instead, information was
   extracted, summarised, synthesised, and presented in a narrative form.
   Two reviewers undertook title, abstract, and full text screening
   independently. The methodological quality and overall rating of the
   included reviews were assessed using the A Measurement Tool to Assess
   systematic Reviews (AMSTAR-2) checklist. The review examined 17 studies,
   comprising 15 systematic reviews and 2 meta-analyses, on ChatGPT in
   healthcare, revealing diverse focuses. The AMSTAR-2 assessment
   identified 5 moderate and 12 low-quality reviews, with deficiencies like
   study design justification and funding source reporting. The most
   reported theme that emerged was ChatGPT's use in disease diagnosis or
   clinical decision-making. While 82.4% of studies focused on its general
   usage, 17.6% explored unique topics like its role in medical
   examinations and conducting systematic reviews. Among these, 52.9%
   targeted general healthcare, with 41.2% focusing on specific domains
   like radiology, neurosurgery, gastroenterology, public health dentistry,
   and ophthalmology. ChatGPT's use for manuscript review or writing was
   mentioned in 17.6% of reviews. Promising applications include enhancing
   patient care and clinical decision-making, though ethical, legal, and
   accuracy concerns require cautious integration. Conclusion We summarise
   the identified areas in reviews regarding ChatGPT's transformative
   impact in healthcare, highlighting patient care, decision-making, and
   medical education. Emphasising the importance of ethical regulations and
   the involvement of policymakers, we urge further investigation to ensure
   the reliability of ChatGPT and to promote trust in healthcare and
   research.
ZR 0
TC 0
ZA 0
ZS 0
ZB 0
Z8 0
Z9 0
DA 2025-05-16
UT WOS:001485796900001
PM 40335969
ER

PT J
AU Wang, Zhixiang
   Zhang, Zhen
   Traverso, Alberto
   Dekker, Andre
   Qian, Linxue
   Sun, Pengfei
TI Assessing the role of GPT-4 in thyroid ultrasound diagnosis and
   treatment recommendations: enhancing interpretability with a chain of
   thought approach
SO QUANTITATIVE IMAGING IN MEDICINE AND SURGERY
VL 14
IS 2
DI 10.21037/qims-23-1180
EA JAN 2024
DT Article
PD FEB 2024
PY 2024
AB Background: As artificial intelligence (AI) becomes increasingly
   prevalent in the medical field, the effectiveness of AI-generated
   medical reports in disease diagnosis remains to be evaluated. ChatGPT is
   a large language model developed by open AI with a notable capacity for
   text abstraction and comprehension. This study aimed to explore the
   capabilities, limitations, and potential of Generative Pre-trained
   Transformer (GPT)-4 in analyzing thyroid cancer ultrasound reports,
   providing diagnoses, and recommending treatment plans. Methods: Using
   109 diverse thyroid cancer cases, we evaluated GPT-4's performance by
   comparing its generated reports to those from doctors with various
   levels of experience. We also conducted a Turing Test and a consistency
   analysis. To enhance the interpretability of the model, we applied the
   Chain of Thought (CoT) method to deconstruct the decision-making chain
   of the GPT model. Results: GPT-4 demonstrated proficiency in report
   structuring, professional terminology, and clarity of expression, but
   showed limitations in diagnostic accuracy. In addition, our consistency
   analysis highlighted certain discrepancies in the AI's performance. The
   CoT method effectively enhanced the interpretability of the AI's
   decision-making process. Conclusions: GPT-4 exhibits potential as a
   supplementary tool in healthcare, especially for generating thyroid
   gland diagnostic reports. Our proposed online platform, "ThyroAIGuide",
   alongside the CoT method, underscores the potential of AI to augment
   diagnostic processes, elevate healthcare accessibility, and advance
   patient education. However, the journey towards fully integrating AI
   into healthcare is ongoing, requiring continuous research, development,
   and careful monitoring by medical professionals to ensure patient safety
   and quality of care.
Z8 2
TC 15
ZA 0
ZB 0
ZR 0
ZS 0
Z9 17
DA 2024-02-02
UT WOS:001146755700001
PM 38415150
ER

PT J
AU Beheshti, Mohammad
   Toubal, Imad Eddine
   Alaboud, Khuder
   Almalaysha, Mohammed
   Ogundele, Olabode B.
   Turabieh, Hamza
   Abdalnabi, Nader
   Boren, Suzanne A.
   Scott, Grant J.
   Dahu, Butros M.
TI Evaluating the Reliability of ChatGPT for Health-Related Questions: A
   Systematic Review
SO INFORMATICS-BASEL
VL 12
IS 1
AR 9
DI 10.3390/informatics12010009
DT Review
PD JAN 17 2025
PY 2025
AB The rapid advancement of large language models like ChatGPT has
   significantly impacted natural language processing, expanding its
   applications across various fields, including healthcare. However, there
   remains a significant gap in understanding the consistency and
   reliability of ChatGPT's performance across different medical domains.
   We conducted this systematic review according to an LLM-assisted PRISMA
   setup. The high-recall search term "ChatGPT" yielded 1101 articles from
   2023 onwards. Through a dual-phase screening process, initially
   automated via ChatGPT and subsequently manually by human reviewers, 128
   studies were included. The studies covered a range of medical
   specialties, focusing on diagnosis, disease management, and patient
   education. The assessment metrics varied, but most studies compared
   ChatGPT's accuracy against evaluations by clinicians or reliable
   references. In several areas, ChatGPT demonstrated high accuracy,
   underscoring its effectiveness. However, performance varied, and some
   contexts revealed lower accuracy. The mixed outcomes across different
   medical domains emphasize the challenges and opportunities of
   integrating AI like ChatGPT into healthcare. The high accuracy in
   certain areas suggests that ChatGPT has substantial utility, yet the
   inconsistent performance across all applications indicates a need for
   ongoing evaluation and refinement. This review highlights ChatGPT's
   potential to improve healthcare delivery alongside the necessity for
   continued research to ensure its reliability.
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
TC 0
Z9 0
DA 2025-03-31
UT WOS:001452439400001
ER

PT J
AU Sakurada, Kazuhiro
   Ishikawa, Tetsuo
   Oba, Junna
   Kuno, Masahiro
   Okano, Yuji
   Sakamaki, Tomomi
   Tamura, Tomohiro
TI Medical AI and AI for Medical Sciences
SO JMA JOURNAL
VL 8
IS 1
BP 26
EP 37
DI 10.31662/jmaj.2024-0185
EA NOV 2024
DT Review
PD JAN 15 2025
PY 2025
AB Digital transformation of healthcare is rapidly progressing. Digital
   transformation improves the quality of services and access to health
   information for users, reduces the workload and associated costs for
   healthcare providers, and supports clinical decision-making. Data and
   artificial intelligence (AI) play a key role in this process. The AI
   used for this purpose is called medical AI. Medical AI is currently
   undergoing a shift from task-specific to general-purpose models. Large
   language models have the potential to systematize existing medical
   knowledge in a standardized way.
   The usage of AI in medicine is not limited to digital transformation; it
   plays a pivotal role in fundamentally changing the state of medical
   science. This approach, known as "AI for Medical Science," focuses on
   pioneering a form of medical science that predicts the onset and
   progression of disease based on the underlying causes of disease. The
   key to such predictive medicine is the concept of "states," which can be
   sought through machine learning. Using states instead of symptoms not
   only dramatically improves the accuracy of identification (diagnosis)
   and prediction (prognosis) but also potentially pioneers P4 medicine by
   integrating it with empirical knowledge and theories based on natural
   principles.
ZA 0
ZR 0
ZS 0
Z8 0
TC 2
ZB 0
Z9 1
DA 2024-12-01
UT WOS:001364088600001
PM 39926067
ER

PT J
AU Gabriel, Rodney A.
   Litake, Onkar
   Simpson, Sierra
   Burton, Brittany N.
   Waterman, Ruth S.
   Macias, Alvaro A.
TI On the development and validation of large language model- based
   classifiers for identifying social determinants of health
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
VL 121
IS 39
AR e2320716121
DI 10.1073/pnas.2320716121
DT Article
PD SEP 24 2024
PY 2024
AB The assessment of social determinants of health (SDoH) within healthcare
   systems is crucial for comprehensive patient care and addressing health
   disparities. Current challenges arise from the limited inclusion of
   structured SDoH information within electronic health record (EHR)
   systems, often due to the lack of standardized diagnosis codes. This
   study delves into the transformative potential of large language models
   (LLM) to overcome these challenges. LLM-based classifiers-using
   Bidirectional Encoder Representations from Transformers (BERT) and A
   Robustly Optimized BERT Pretraining Approach (RoBERTa)-were developed
   for SDoH concepts, including homelessness, food insecurity, and domestic
   violence, using synthetic training datasets generated by generative pre-
   trained transformers combined with authentic clinical notes. Models were
   then validated on separate datasets: Medical Information Mart for
   Intensive Care- III and our institutional EHR data. When training the
   model with a combination of synthetic and authentic notes, validation on
   our institutional dataset yielded an area under the receiver operating
   characteristics curve of 0.78 for detecting homelessness, 0.72 for
   detecting food insecurity, and 0.83 for detecting domestic violence.
   This study underscores the potential of LLMs in extracting SDoH
   information from clinical text. Automated detection of SDoH may be
   instrumental for healthcare providers in identifying at- risk patients,
   guiding targeted interventions, and contributing to population health
   initiatives aimed at mitigating disparities.
TC 5
ZA 0
ZS 0
ZR 0
ZB 2
Z8 0
Z9 5
DA 2024-12-11
UT WOS:001369554000005
PM 39284061
ER

PT J
AU Ueda, Daiju
   Walston, Shannon L.
   Matsumoto, Toshimasa
   Deguchi, Ryo
   Tatekawa, Hiroyuki
   Miki, Yukio
TI Evaluating GPT-4-based ChatGPT's clinical potential on the NEJM quiz
SO BMC DIGITAL HEALTH
VL 2
IS 1
AR 4
DI 10.1186/s44247-023-00058-5
DT Article
PD JAN 11 2024
PY 2024
AB BackgroundGPT-4-based ChatGPT demonstrates significant potential in
   various industries; however, its potential clinical applications remain
   largely unexplored.MethodsWe employed the New England Journal of
   Medicine (NEJM) quiz "Image Challenge" from October 2021 to March 2023
   to assess ChatGPT's clinical capabilities. The quiz, designed for
   healthcare professionals, tests the ability to analyze clinical
   scenarios and make appropriate decisions. We evaluated ChatGPT's
   performance on the NEJM quiz, analyzing its accuracy rate by questioning
   type and specialty after excluding quizzes which were impossible to
   answer without images. ChatGPT was first asked to answer without the
   five multiple-choice options, and then after being given the
   options.ResultsChatGPT achieved an 87% (54/62) accuracy without choices
   and a 97% (60/62) accuracy with choices, after excluding 16 image-based
   quizzes. Upon analyzing performance by quiz type, ChatGPT excelled in
   the Diagnosis category, attaining 89% (49/55) accuracy without choices
   and 98% (54/55) with choices. Although other categories featured fewer
   cases, ChatGPT's performance remained consistent. It demonstrated strong
   performance across the majority of medical specialties; however,
   Genetics had the lowest accuracy at 67% (2/3).ConclusionChatGPT
   demonstrates potential for diagnostic applications, suggesting its
   usefulness in supporting healthcare professionals in making differential
   diagnoses and enhancing AI-driven healthcare.
Z8 0
ZB 3
TC 13
ZS 0
ZA 0
ZR 0
Z9 13
DA 2024-01-11
UT WOS:001461607300001
ER

PT C
AU Wei, Qizhi
   Chen, Xuanyu
   Ni, Yifei
   Cao, Cong
GP ASSOC COMPUTING MACHINERY
TI A Technical Framework for Recognizing and Interpreting Complex Medical
   Records: Based on Multimodal Large Language Model
SO 2024 THE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND TEACHER
   EDUCATION, ICAITE 2024
BP 76
EP 83
DI 10.1145/3702386.3702396
DT Proceedings Paper
PD 2024
PY 2024
AB This paper brings up a technical framework for Interpreting medical
   documentation that integrates multi-modal large language modals, aiming
   to provide patients and doctors with the ability to read nonstandard
   medical documentation in complex environments and to obtain text
   interpretation based on generative AI. The framework proposes a
   three-stage solution, namely Recognition, Formatting, and AI-Processing,
   involving technologies such as OCR, medical multi-modal models, and
   large language models, abbreviated as the RF-AI framework. This paper
   focuses on explaining the potential issues encountered when applying the
   framework and describes the resolution within the framework. In
   addition, this paper conducts experiments on two key stages of the
   framework, recognition and AI-processing, which effectively demonstrate
   the feasibility of the framework. This framework can significantly
   reduce the difficulty for patients in understanding medical records and
   provides necessary resolution for situations where paper records might
   be used. It helps patients better understand their conditions and
   enhances the efficiency of diagnosis and treatment between doctors and
   patients. Benefiting from a large language model, this framework allows
   developers to expand based on actual needs and can be integrated into
   existing electronic healthcare systems to achieve more comprehensive
   functionality.
CT 2024 International Conference on Artificial Intelligence and Teacher
   Education
CY OCT 12-14, 2024
CL Beijing, PEOPLES R CHINA
Z8 0
ZR 0
ZA 0
TC 0
ZS 0
ZB 0
Z9 0
DA 2025-04-04
UT WOS:001443289300012
ER

PT J
AU Bannett, Yair
   Gunturkun, Fatma
   Pillai, Malvika
   Herrmann, Jessica E
   Luo, Ingrid
   Huffman, Lynne C
   Feldman, Heidi M
TI Leveraging a Large Language Model to Assess Quality-of-Care: Monitoring
   ADHD Medication Side Effects.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2024.04.23.24306225
DT Preprint
PD 2024 Apr 24
PY 2024
AB Objective: To assess the accuracy of a large language model (LLM) in
   measuring clinician adherence to practice guidelines for monitoring side
   effects after prescribing medications for children with
   attention-deficit/hyperactivity disorder (ADHD).
   Methods: Retrospective population-based cohort study of electronic
   health records. Cohort included children aged 6-11 years with ADHD
   diagnosis and ≥2 ADHD medication encounters (stimulants or
   non-stimulants prescribed) between 2015-2022 in a community-based
   primary healthcare network (n=1247). To identify documentation of side
   effects inquiry, we trained, tested, and deployed an open-source LLM
   (LLaMA) on all clinical notes from ADHD-related encounters (ADHD
   diagnosis or ADHD medication prescription), including
   in-clinic/telehealth and telephone encounters (n=15,593 notes). Model
   performance was assessed using holdout and deployment test sets,
   compared to manual chart review.
   Results: The LLaMA model achieved excellent performance in classifying
   notes that contain side effects inquiry (sensitivity= 87.2%,
   specificity=86.3/90.3%, area under curve (AUC)=0.93/0.92 on
   holdout/deployment test sets). Analyses revealed no model bias in
   relation to patient age, sex, or insurance. Mean age (SD) at first
   prescription was 8.8 (1.6) years; patient characteristics were similar
   across patients with and without documented side effects inquiry. Rates
   of documented side effects inquiry were lower in telephone encounters
   than in-clinic/telehealth encounters (51.9% vs. 73.0%, p<0.01). Side
   effects inquiry was documented in 61% of encounters following stimulant
   prescriptions and 48% of encounters following non-stimulant
   prescriptions (p<0.01).
   Conclusions: Deploying an LLM on a variable set of clinical notes,
   including telephone notes, offered scalable measurement of
   quality-of-care and uncovered opportunities to improve
   psychopharmacological medication management in primary care.
ZS 0
TC 0
ZR 0
ZB 0
Z8 0
ZA 0
Z9 0
DA 2024-05-09
UT MEDLINE:38712037
PM 38712037
ER

PT J
AU Zhang, Sainan
   Song, Jisung
TI A chatbot based question and answer system for the auxiliary diagnosis
   of chronic diseases based on large language model
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 17118
DI 10.1038/s41598-024-67429-4
DT Article
PD JUL 25 2024
PY 2024
AB In recent years, artificial intelligence has made remarkable strides,
   improving various aspects of our daily lives. One notable application is
   in intelligent chatbots that use deep learning models. These systems
   have shown tremendous promise in the medical sector, enhancing
   healthcare quality, treatment efficiency, and cost-effectiveness.
   However, their role in aiding disease diagnosis, particularly chronic
   conditions, remains underexplored. Addressing this issue, this study
   employs large language models from the GPT series, in conjunction with
   deep learning techniques, to design and develop a diagnostic system
   targeted at chronic diseases. Specifically, performed transfer learning
   and fine-tuning on the GPT-2 model, enabling it to assist in accurately
   diagnosing 24 common chronic diseases. To provide a user-friendly
   interface and seamless interactive experience, we further developed a
   dialog-based interface, naming it Chat Ella. This system can make
   precise predictions for chronic diseases based on the symptoms described
   by users. Experimental results indicate that our model achieved an
   accuracy rate of 97.50% on the validation set, and an area under the
   curve (AUC) value reaching 99.91%. Moreover, conducted user satisfaction
   tests, which revealed that 68.7% of participants approved of Chat Ella,
   while 45.3% of participants found the system made daily medical
   consultations more convenient. It can rapidly and accurately assess a
   patient's condition based on the symptoms described and provide timely
   feedback, making it of significant value in the design of medical
   auxiliary products for household use.
ZB 0
ZR 0
ZA 0
TC 6
ZS 0
Z8 0
Z9 6
DA 2024-08-03
UT WOS:001278002800002
PM 39054346
ER

PT J
AU Patel, Chetna R.
   Pandya, Sajal K.
   Sojitra, Brijesh M.
TI Perspectives of ChatGPT in Pharmacology Education, and Research in
   Health Care: A Narrative Review
SO JOURNAL OF PHARMACOLOGY & PHARMACOTHERAPEUTICS
VL 14
IS 3
BP 171
EP 177
DI 10.1177/0976500X231210427
EA DEC 2023
DT Review
PD SEP 2023
PY 2023
AB Background: In the era of advanced Open artificial intelligence (AI)
   technology, the large language model tool known as chat generative
   pre-training transformer (ChatGPT) is gaining an increasing number of
   users in various fields such as healthcare, medical education,
   agriculture, and customer support due to its features like information
   retrieval, generating human-like conversations, and natural language
   processing.
   Purpose: The purpose of this narrative review is to present the
   perspectives of ChatGPT in pharmacology and medical education. And
   highlight the limitations of ChatGPT in these areas and draw the
   attention of policymakers in healthcare to implement such technologies
   while taking into consideration ethical issues.
   Methods: To collect information regarding the perspectives of ChatGPT in
   pharmacology and medical education. And highlight the limitations of
   ChatGPT in these areas.
   Results: In health care, it helps in the drug discovery and development
   process, diagnosis, treatment, counseling, assisting in surgical
   procedures, pharmacovigilance, pharmacy, and so on. In medical
   education, this tool plays a crucial role in online tutoring,
   personalized assistance, grading, improvement in grammar, and so on.
   Despite the limitations, ChatGPT is helpful in healthcare, medical
   education, and scientific writing. To overcome such limitations of
   ChatGPT, like ethical issues, emotionlessness, providing information
   before 2021, the risk of biases, uncontrollability, lack of
   transparency, academic dishonesty, and so on, alternatives have been
   developed, but they also fail to entirely resolve the associated
   limitations.
   Conclusion: Looking at the current scenarios, there is an urgent need
   for comprehensive guidelines to address these limitations and provide a
   framework for appropriately utilizing AI tools in healthcare domains.
   This framework should also focus on maintaining a balance between human
   involvement and technological advancements.
ZS 0
ZR 0
ZB 1
ZA 0
Z8 0
TC 5
Z9 5
DA 2024-01-16
UT WOS:001130186400001
ER

PT J
AU Kozaily, Elie
   Geagea, Mabelissa
   Akdogan, Ecem R.
   Atkins, Jessica
   Elshazly, Mohamed B.
   Guglin, Maya
   Tedford, Ryan J.
   Wehbe, Ramsey M.
TI Accuracy and consistency of online large language model-based artificial
   intelligence chat platforms in answering patients' questions about heart
   failure
SO INTERNATIONAL JOURNAL OF CARDIOLOGY
VL 408
AR 132115
DI 10.1016/j.ijcard.2024.132115
EA MAY 2024
DT Article
PD AUG 1 2024
PY 2024
AB Background: Heart failure (HF) is a prevalent condition associated with
   significant morbidity. Patients may have questions that they feel
   embarrassed to ask or will face delays awaiting responses from their
   healthcare providers which may impact their health behavior. We aimed to
   investigate the potential of large language model (LLM) based artificial
   intelligence (AI) chat platforms in complementing the delivery of
   patient -centered care. Methods: Using online patient forums and
   physician experience, we created 30 questions related to diagnosis,
   management and prognosis of HF. The questions were posed to two
   LLM-based AI chat platforms (OpenAI's ChatGPT-3.5 and Google's Bard).
   Each set of answers was evaluated by two HF experts, independently and
   blinded to each other, for accuracy (adequacy of content) and
   consistency of content. Results: ChatGPT provided mostly appropriate
   answers (27/30, 90%) and showed a high degree of consistency (93%). Bard
   provided a similar content in its answers and thus was evaluated only
   for adequacy (23/30, 77%). The two HF experts' grades were concordant in
   83% and 67% of the questions for ChatGPT and Bard, respectively.
   Conclusion: LLM-based AI chat platforms demonstrate potential in
   improving HF education and empowering patients, however, these platforms
   currently suffer from issues related to factual errors and difficulty
   with more contemporary recommendations. This inaccurate information may
   pose serious and life -threatening implications for patients that should
   be considered and addressed in future research.
TC 13
ZB 0
ZS 0
ZR 0
ZA 0
Z8 0
Z9 13
DA 2024-06-15
UT WOS:001240180400001
PM 38697402
ER

PT J
AU Stanley, Jack
   Rabot, Emmett
   Reddy, Siva
   Belilovsky, Eugene
   Mottron, Laurent
   Bzdok, Danilo
TI Large language models deconstruct the clinical intuition behind
   diagnosing autism
SO CELL
VL 188
IS 8
DI 10.1016/j.cell.2025.02.025
EA APR 2025
DT Article
PD APR 17 2025
PY 2025
AB Efforts to use genome-wide assays or brain scans to diagnose autism have
   seen diminishing returns. Yet the clinical intuition of healthcare
   professionals, based on longstanding first-hand experience, remains the
   gold standard for diagnosis of autism. We leveraged deep learning to
   deconstruct and interrogate the logic of expert clinician intuition from
   clinical reports to inform our understanding of autism. After
   pre-training on hundreds of millions of general sentences, we finessed
   large language models (LLMs) on >4,000 free-form health records from
   healthcare professionals to distinguish confirmed versus suspected
   autism cases. By introducing an explainability strategy, our extended
   language model architecture could pin down the most salient single
   sentences in what drives clinical thinking toward correct diagnoses. Our
   framework flagged the most autism-critical DSM-5 criteria to be
   stereotyped repetitive behaviors, special interests, and
   perception-based behaviors, which challenges today's focus on deficits
   in social interplay, suggesting necessary revision of long-trusted
   diagnostic criteria in gold-standard instruments.
ZS 0
ZB 0
ZA 0
ZR 0
Z8 0
TC 0
Z9 0
DA 2025-05-06
UT WOS:001476532200001
PM 40147442
ER

PT J
AU Gracias, Dylan
   Siu, Adrian
   Seth, Ishith
   Dooreemeah, Dilshad
   Lee, Angus
TI Exploring the role of an artificial intelligence chatbot on appendicitis
   management: an experimental study on ChatGPT
SO ANZ JOURNAL OF SURGERY
VL 94
IS 3
BP 342
EP 352
DI 10.1111/ans.18736
EA OCT 2023
DT Article
PD MAR 2024
PY 2024
AB Background: Appendicitis is a common surgical condition that requires
   urgent medical attention. Recent advancements in artificial intelligence
   and large language processing, such as ChatGPT, have demonstrated
   potential in supporting healthcare management and scientific research.
   This study aims to evaluate the accuracy and comprehensiveness of
   ChatGPT's knowledge on appendicitis management.Methods: Six questions
   related to appendicitis management were created by experienced RACS
   qualified general surgeons to assess ChatGPT's ability to provide
   accurate information. The criteria of ChatGPT answers' accuracy were
   compared with current healthcare guidelines for appendicitis and
   subjective evaluation by two RACS qualified General Surgeons.
   Additionally, ChatGPT was then asked to provide five high level evidence
   references to support its responses.Results: ChatGPT provided clinically
   relevant information on appendicitis management, however, was
   inconsistent in doing so and often provided superficial information.
   Further to this, ChatGPT encountered difficulties in generating relevant
   references, with some being either non-existent or incorrect.Conclusion:
   ChatGPT has the potential to provide timely and comprehensible medical
   information on appendicitis management to laypersons. However, its issue
   of inaccuracy in information and production of non-existent or erroneous
   references presents a challenge for researchers and clinicians who may
   inadvertently employ such information in their research or healthcare.
   Therefore, clinicians should exercise caution when using ChatGPT for
   these purposes.
ZR 0
TC 9
ZA 0
ZB 1
Z8 0
ZS 0
Z9 9
DA 2023-11-03
UT WOS:001086439700001
PM 37855397
ER

PT J
AU Hirosawa, Takanobu
   Shimizu, Taro
TI Enhancing clinical reasoning with Chat Generative Pre-trained
   Transformer: a practical guide
SO DIAGNOSIS
VL 11
IS 1
BP 102
EP 105
DI 10.1515/dx-2023-0116
EA OCT 2023
DT Article
PD FEB 19 2024
PY 2024
AB Objectives: This study aimed to elucidate effective methodologies for
   utilizing the generative artificial intelligence (AI) system, namely the
   Chat Generative Pre-trained Transformer (ChatGPT), in improving clinical
   reasoning abilities among clinicians.Methods: We conducted a
   comprehensive exploration of the capabilities of ChatGPT, emphasizing
   two main areas: (1) efficient utilization of ChatGPT, with a focus on
   application and language selection, input methodology, and output
   verification; and (2) specific strategies to bolster clinical reasoning
   using ChatGPT, including self-learning via simulated clinical case
   creation and engagement with published case reports.Results: Effective
   AI-based clinical reasoning development requires a clear delineation of
   both system roles and user needs. All outputs from the system
   necessitate rigorous verification against credible medical resources.
   When used in self-learning scenarios, capabilities of ChatGPT in
   clinical case creation notably enhanced disease
   comprehension.Conclusions: The efficient use of generative AIs, as
   exemplified by ChatGPT, can impressively enhance clinical reasoning
   among medical professionals. Adopting these cutting-edge tools promises
   a bright future for continuous advancements in clinicians' diagnostic
   skills, heralding a transformative era in digital healthcare.
TC 6
Z8 0
ZS 0
ZR 0
ZA 0
ZB 1
Z9 6
DA 2023-10-14
UT WOS:001077103200001
PM 37779351
ER

PT J
AU Ayoub, Marc
   Ballout, Ahmad A.
   Zayek, Rosana A.
   Ayoub, Noel F.
TI Mind
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 15
IS 8
AR e43690
DI 10.7759/cureus.43690
DT Article
PD AUG 18 2023
PY 2023
AB Background Generative artificial intelligence (AI) has integrated into
   various industries as it has demonstrated enormous potential in
   automating elaborate processes and enhancing complex decision-making.
   The ability of these chatbots to critically triage, diagnose, and manage
   complex medical conditions, remains unknown and requires further
   research.Objective This cross-sectional study sought to quantitatively
   analyze the appropriateness of ChatGPT (OpenAI, San Francisco, CA, US)
   in its ability to triage, synthesize differential diagnoses, and
   generate treatment plans for nine diverse but common clinical
   scenarios.Methods Various common clinical scenarios were developed. Each
   was input into ChatGPT, and the chatbot was asked to develop diagnostic
   and treatment plans. Five practicing physicians independently scored
   ChatGPT's responses to the clinical scenarios.Results The average
   overall score for the triage ranking was 4.2 (SD 0.7). The lowest
   overall score was for the completeness of the differential diagnosis at
   4.1 (0.5). The highest overall scores were seen with the accuracy of the
   differential diagnosis, initial treatment plan, and overall usefulness
   of the response (all with an average score of 4.4). Variance among
   physician scores ranged from 0.24 for accuracy of the differential
   diagnosis to 0.49 for appropriateness of triage ranking.Discussion
   ChatGPT has the potential to augment clinical decision-making. More
   extensive research, however, is needed to ensure accuracy and
   appropriate recommendations are provided.
TC 12
ZB 1
ZS 0
Z8 0
ZR 0
ZA 0
Z9 12
DA 2023-10-12
UT WOS:001064944100009
PM 37724211
ER

PT J
AU Attai, Kingsley
   Ekpenyong, Moses
   Amannah, Constance
   Asuquo, Daniel
   Ajuga, Peterben
   Obot, Okure
   Johnson, Ekemini
   John, Anietie
   Maduka, Omosivie
   Akwaowo, Christie
   Uzoka, Faith-Michael
TI Enhancing the Interpretability of Malaria and Typhoid Diagnosis with
   Explainable AI and Large Language Models
SO TROPICAL MEDICINE AND INFECTIOUS DISEASE
VL 9
IS 9
AR 216
DI 10.3390/tropicalmed9090216
DT Article
PD SEP 2024
PY 2024
AB Malaria and Typhoid fever are prevalent diseases in tropical regions,
   and both are exacerbated by unclear protocols, drug resistance, and
   environmental factors. Prompt and accurate diagnosis is crucial to
   improve accessibility and reduce mortality rates. Traditional diagnosis
   methods cannot effectively capture the complexities of these diseases
   due to the presence of similar symptoms. Although machine learning (ML)
   models offer accurate predictions, they operate as "black boxes" with
   non-interpretable decision-making processes, making it challenging for
   healthcare providers to comprehend how the conclusions are reached. This
   study employs explainable AI (XAI) models such as Local Interpretable
   Model-agnostic Explanations (LIME), and Large Language Models (LLMs)
   like GPT to clarify diagnostic results for healthcare workers, building
   trust and transparency in medical diagnostics by describing which
   symptoms had the greatest impact on the model's decisions and providing
   clear, understandable explanations. The models were implemented on
   Google Colab and Visual Studio Code because of their rich libraries and
   extensions. Results showed that the Random Forest model outperformed the
   other tested models; in addition, important features were identified
   with the LIME plots while ChatGPT 3.5 had a comparative advantage over
   other LLMs. The study integrates RF, LIME, and GPT in building a mobile
   app to enhance the interpretability and transparency in malaria and
   typhoid diagnosis system. Despite its promising results, the system's
   performance is constrained by the quality of the dataset. Additionally,
   while LIME and GPT improve transparency, they may introduce complexities
   in real-time deployment due to computational demands and the need for
   internet service to maintain relevance and accuracy. The findings
   suggest that AI-driven diagnostic systems can significantly enhance
   healthcare delivery in environments with limited resources, and future
   works can explore the applicability of this framework to other medical
   conditions and datasets.
ZA 0
ZR 0
ZB 0
TC 1
ZS 0
Z8 0
Z9 1
DA 2024-10-07
UT WOS:001322854400001
PM 39330905
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Mira, Felipe Ahumada
   Favier, Valentin
   Nunes, Heloisa dos Santos Sobreira
   de Castro, Joana Vaz
   Carsuzaa, Florent
   Meccariello, Giuseppe
   Vicini, Claudio
   De Vito, Andrea
   Lechien, Jerome R.
   Estomba, Carlos Chiesa
   Maniaci, Antonino
   Iannella, Giannicola
   Rojas, Eduardo Pena
   Cornejo, Jenifer Barros
   Cammaroto, Giovanni
TI Chat GPT for the management of obstructive sleep apnea: do we have a
   polar star?
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 2087
EP 2093
DI 10.1007/s00405-023-08270-9
EA NOV 2023
DT Article
PD APR 2024
PY 2024
AB PurposeThis study explores the potential of the Chat-Generative
   Pre-Trained Transformer (Chat-GPT), a Large Language Model (LLM), in
   assisting healthcare professionals in the diagnosis of obstructive sleep
   apnea (OSA). It aims to assess the agreement between Chat-GPT's
   responses and those of expert otolaryngologists, shedding light on the
   role of AI-generated content in medical decision-making.MethodsA
   prospective, cross-sectional study was conducted, involving 350
   otolaryngologists from 25 countries who responded to a specialized OSA
   survey. Chat-GPT was tasked with providing answers to the same survey
   questions. Responses were assessed by both super-experts and
   statistically analyzed for agreement.ResultsThe study revealed that
   Chat-GPT and expert responses shared a common answer in over 75% of
   cases for individual questions. However, the overall consensus was
   achieved in only four questions. Super-expert assessments showed a
   moderate agreement level, with Chat-GPT scoring slightly lower than
   experts. Statistically, Chat-GPT's responses differed significantly from
   experts' opinions (p = 0.0009). Sub-analysis revealed areas of
   improvement for Chat-GPT, particularly in questions where super-experts
   rated its responses lower than expert consensus.ConclusionsChat-GPT
   demonstrates potential as a valuable resource for OSA diagnosis,
   especially where access to specialists is limited. The study emphasizes
   the importance of AI-human collaboration, with Chat-GPT serving as a
   complementary tool rather than a replacement for medical professionals.
   This research contributes to the discourse in otolaryngology and
   encourages further exploration of AI-driven healthcare applications.
   While Chat-GPT exhibits a commendable level of consensus with expert
   responses, ongoing refinements in AI-based healthcare tools hold
   significant promise for the future of medicine, addressing the
   underdiagnosis and undertreatment of OSA and improving patient outcomes.
ZS 0
ZB 5
Z8 0
TC 23
ZR 0
ZA 0
Z9 23
DA 2023-12-07
UT WOS:001103635400001
PM 37980605
ER

PT J
AU Laios, Alexandros
   Theophilou, Georgios
   De Jong, Diederick
   Kalampokis, Evangelos
TI The Future of AI in Ovarian Cancer Research: The Large Language Models
   Perspective
SO CANCER CONTROL
VL 30
AR 10732748231197915
DI 10.1177/10732748231197915
DT Editorial Material
PD AUG 2023
PY 2023
AB Conversational large language model (LLM)-based chatbots utilize neural
   networks to process natural language. By generating highly sophisticated
   outputs from contextual input text, they revolutionize the access to
   further learning, leading to the development of new skills and
   personalized interactions. Although they are not developed to provide
   healthcare, their potential to address biomedical issues is rather
   unexplored. Healthcare digitalization and documentation of electronic
   health records is now developing into a standard practice. Developing
   tools to facilitate clinical review of unstructured data such as LLMs
   can derive clinical meaningful insights for ovarian cancer, a
   heterogeneous but devastating disease. Compared to standard approaches,
   they can host capacity to condense results and optimize analysis time.
   To help accelerate research in biomedical language processing and
   improve the validity of scientific writing, task-specific and
   domain-specific language models may be required. In turn, we propose a
   bespoke, proprietary ovarian cancer-specific natural language using
   solely in-domain text, whereas transfer learning drifts away from the
   pretrained language models to fine-tune task-specific models for all
   possible downstream applications. This venture will be fueled by the
   abundance of unstructured text information in the electronic health
   records resulting in ovarian cancer research ultimately reaching its
   linguistic home.
Z8 0
ZB 0
ZR 0
TC 5
ZS 0
ZA 0
Z9 5
DA 2023-09-25
UT WOS:001064803500001
PM 37624621
ER

PT J
AU Gallifant, Jack
   Afshar, Majid
   Ameen, Saleem
   Aphinyanaphongs, Yindalon
   Chen, Shan
   Cacciamani, Giovanni
   Demner-Fushman, Dina
   Dligach, Dmitriy
   Daneshjou, Roxana
   Fernandes, Chrystinne
   Hansen, Lasse Hyldig
   Landman, Adam
   Lehmann, Lisa
   Mccoy, Liam G.
   Miller, Timothy
   Moreno, Amy
   Munch, Nikolaj
   Restrepo, David
   Savova, Guergana
   Umeton, Renato
   Gichoya, Judy Wawira
   Collins, Gary S.
   Moons, Karel G. M.
   Celi, Leo A.
   Bitterman, Danielle S.
TI The TRIPOD-LLM reporting guideline for studies using large language
   models
SO NATURE MEDICINE
VL 31
IS 1
DI 10.1038/s41591-024-03425-5
EA JAN 2025
DT Review
PD JAN 2025
PY 2025
AB Large language models (LLMs) are rapidly being adopted in healthcare,
   necessitating standardized reporting guidelines. We present transparent
   reporting of a multivariable model for individual prognosis or diagnosis
   (TRIPOD)-LLM, an extension of the TRIPOD + artificial intelligence
   statement, addressing the unique challenges of LLMs in biomedical
   applications. TRIPOD-LLM provides a comprehensive checklist of 19 main
   items and 50 subitems, covering key aspects from title to discussion.
   The guidelines introduce a modular format accommodating various LLM
   research designs and tasks, with 14 main items and 32 subitems
   applicable across all categories. Developed through an expedited Delphi
   process and expert consensus, TRIPOD-LLM emphasizes transparency, human
   oversight and task-specific performance reporting. We also introduce an
   interactive website (https://tripod-llm.vercel.app/) facilitating easy
   guideline completion and PDF generation for submission. As a living
   document, TRIPOD-LLM will evolve with the field, aiming to enhance the
   quality, reproducibility and clinical applicability of LLM research in
   healthcare through comprehensive reporting.
TC 15
ZR 0
Z8 0
ZB 1
ZA 0
ZS 0
Z9 15
DA 2025-01-13
UT WOS:001391790800001
PM 39779929
ER

PT C
AU Ding, Xinpeng
   Chu, Yongqiang
   Pi, Renjie
   Wang, Hualiang
   Li, Xiaomeng
BE Linguraru, MG
   Dou, Q
   Feragen, A
   Giannarou, S
   Glocker, B
   Lekadir, K
   Schnabel, JA
TI HiA: Towards Chinese Multimodal LLMs for Comparative High-Resolution
   Joint Diagnosis
SO MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI
   2024, PT XII
SE Lecture Notes in Computer Science
VL 15012
BP 575
EP 586
DI 10.1007/978-3-031-72390-2_54
DT Proceedings Paper
PD 2024
PY 2024
AB Multimodal large language models (MLLMs) have been explored in the
   Chinese medical domain for comprehending complex healthcare. However,
   due to the flaws in training data and architecture design, current
   Chinese medical MLLMs suffer from several limitations: cultural biases
   from English machine translations, limited comparative ability from
   single image input and difficulty in identifying small lesions with
   low-resolution images. To address these problems, we first introduce a
   new instruction-following dataset, Chili-Joint (Chinese Interleaved
   Image-Text Dataset for Joint Diagnosis) collected from the hospital in
   mainland China, avoiding cultural biases and errors caused by machine
   translation. Besides one single image input, Chili-Joint also has
   multiple images obtained at various intervals during a patient's
   treatment, thus facilitating an evaluation of the treatment's outcomes.
   We further propose a novel HiA (High-resolution instruction-aware
   Adapter) to incorporate high-resolutioninstruction-aware visual features
   into LLMs to facilitate the current MLLMs to observe the small lesions
   as well as the comparative analysis. Extensive experiments on
   Chili-Joint demonstrate our HiA can be a plug-and-play method to improve
   the performance of current MLLMs for medical analysis. The code is
   available at https:// github.com/xmed- lab/HiA.
CT 27th International Conference on Medical Image Computing and Computer
   Assisted Intervention (MICCAI)
CY OCT 06-10, 2024
CL Palmeraie Conf Ctr, Marrakesh, MOROCCO
HO Palmeraie Conf Ctr
SP GH Labs; Childrens Natl Hosp; Pierre Fabre; Comp Assisted Med Intervent
   Labex; Multidisciplinary Inst Artificial Intelligence Grenoble Alpes;
   Western Univ, Frugal Biomed Innovat Program; Int Soc Radiol; Medtronic;
   Pasqual Maragall Fdn; Delft Imaging; Univ Barcelona, Artificial
   Intelligence Med Lab; Cadi Ayyad Univ; Natl Ctr Sci & Tech Res
ZA 0
Z8 0
ZS 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2024-12-03
UT WOS:001344002100054
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT C
AU Kumi, Sandra
   Ray, Madhurima
   Walia, Sanskriti
   Lomotey, Richard K.
   Deters, Ralph
BE Paul, R
   Kundu, A
   Bhattacharyya, R
TI Digital Twins for Stress Management Utilizing Synthetic Data
SO 2024 IEEE 5TH ANNUAL WORLD AI IOT CONGRESS, AIIOT 2024
BP 0329
EP 0335
DI 10.1109/AIIoT61789.2024.10579038
DT Proceedings Paper
PD 2024
PY 2024
AB In the era of Medical 4.0, technologies such as big data, wearables, and
   Machine Learning (ML) are being deployed for predictive healthcare
   delivery. In this regard, digital twins have been adopted in healthcare
   to enhance diagnosis and personalized treatment. Health Digital Twins
   (HDTs) are virtual representations of patients' data, mirroring the
   health state of patients to provide insights. Despite its promise, the
   existing works on HDTs relied on large historical data to train ML
   models. These historical data may be difficult to obtain due to privacy
   concerns of data fiduciaries and subjects. In this paper, we propose a
   Digital Twin for Stress Management (DTSM) that employs generative models
   to learn the distribution of patients' data retrieved from a wearable
   device for stress management score prediction. To obtain a virtual
   replica of a patient's data, we used synthetic data generative models
   such as Conditional Tabular Generative Adversarial Network (CTGAN),
   Tabular Variational Autoencoder (TVAE), Gaussian Copula, and Large
   Language Models (LLM) (REaLTabFormer and GReaT). The best result came
   from REaLTabFormer which accurately learns the distributions of the real
   data with a data quality score of approximately 93%. Furthermore, four
   wellknown ML models trained on the synthetic data obtained a mean
   absolute error (MAE) of less than 5% in the prediction of stress score.
   Our experimental results show that the proposed DTSM can be used for the
   prediction of stress management scores.
CT IEEE 5th Annual World AI IoT Congress (AIIoT)
CY MAY 29-31, 2024
CL WA
SP IEEE; SMART; IEEE USA; Inst Engn & Management; Univ Engn & Management
ZR 0
ZA 0
Z8 0
ZB 0
TC 1
ZS 0
Z9 1
DA 2024-10-10
UT WOS:001289206000048
ER

PT J
AU Heston, Thomas F.
   Lewis, Lawrence M.
TI ChatGPT provides inconsistent risk-stratification of patients with
   atraumatic chest pain
SO PLOS ONE
VL 19
IS 4
AR e0301854
DI 10.1371/journal.pone.0301854
DT Article
PD APR 16 2024
PY 2024
AB Background ChatGPT-4 is a large language model with promising healthcare
   applications. However, its ability to analyze complex clinical data and
   provide consistent results is poorly known. Compared to validated tools,
   this study evaluated ChatGPT-4's risk stratification of simulated
   patients with acute nontraumatic chest pain.Methods Three datasets of
   simulated case studies were created: one based on the TIMI score
   variables, another on HEART score variables, and a third comprising 44
   randomized variables related to non-traumatic chest pain presentations.
   ChatGPT-4 independently scored each dataset five times. Its risk scores
   were compared to calculated TIMI and HEART scores. A model trained on 44
   clinical variables was evaluated for consistency.Results ChatGPT-4
   showed a high correlation with TIMI and HEART scores (r = 0.898 and
   0.928, respectively), but the distribution of individual risk
   assessments was broad. ChatGPT-4 gave a different risk 45-48% of the
   time for a fixed TIMI or HEART score. On the 44-variable model, a
   majority of the five ChatGPT-4 models agreed on a diagnosis category
   only 56% of the time, and risk scores were poorly correlated (r =
   0.605).Conclusion While ChatGPT-4 correlates closely with established
   risk stratification tools regarding mean scores, its inconsistency when
   presented with identical patient data on separate occasions raises
   concerns about its reliability. The findings suggest that while large
   language models like ChatGPT-4 hold promise for healthcare applications,
   further refinement and customization are necessary, particularly in the
   clinical risk assessment of atraumatic chest pain patients.
ZS 0
ZA 0
TC 7
ZR 0
Z8 1
ZB 2
Z9 7
DA 2024-06-15
UT WOS:001205750000117
PM 38626142
ER

PT J
AU Zeinali, Nahid
   Albashayreh, Alaa
   Fan, Weiguo
   White, Stephanie Gilbertson
TI Symptom-BERT: Enhancing Cancer Symptom Detection in EHR Clinical Notes
SO JOURNAL OF PAIN AND SYMPTOM MANAGEMENT
VL 68
IS 2
DI 10.1016/j.jpainsymman.2024.05.015
EA JUL 2024
DT Article
PD AUG 2024
PY 2024
AB Context. Extracting cancer symptom documentation allows clinicians to
   develop highly individualized symptom prediction algorithms to deliver
   symptom management care. Leveraging advanced language models to detect
   symptom data in clinical narratives can significantly fi cantly enhance
   this process. Objective. This study uses a pretrained large
   language model to detect and extract cancer symptoms in clinical
   notes. Methods. We developed a pretrained language model to
   identify cancer symptoms in clinical notes based on a clinical corpus
   from the Enterprise Data Warehouse for Research at a healthcare system
   in the Midwestern United States. This study was conducted in 4 phases:1
   1 pretraining a Bio-Clinical BERT model on one million unlabeled
   clinical documents,2 2 fi ne-tuning Symptom-BERT for detecting 13 cancer
   symptom groups within 1112 annotated clinical notes,3 3 generating 180
   synthetic clinical notes using ChatGPT-4 for external validation, and4 4
   comparing the internal and external performance of Symptom-BERT against
   a non-pretrained version and six other BERT implementations.
   Results. The Symptom-BERT model effectively detected cancer symptoms in
   clinical notes. It achieved results with a micro- averaged F1-score of
   0.933, an AUC of 0.929 internally, and 0.831 and 0.834 externally. Our
   analysis shows that physical symptoms, like Pruritus, are typically
   identified fi ed with higher performance than psychological symptoms,
   such as anxiety. Conclusion. This study underscores the
   transformative potential of specialized pretraining on domain-specific
   fi c data in boosting the performance of language models for medical
   applications. The Symptom-BERT model's ' s exceptional efficacy fi cacy
   in detecting cancer symptoms heralds a groundbreaking stride in
   patient-centered AI technologies, offering a promising path to elevate
   symptom management and cultivate superior patient self-care outcomes. J
   Pain Symptom Manage 2024;68:190-198. - 198. (c) 2024 American Academy of
   Hospice and Palliative Medicine. Published by Elsevier Inc. All rights
   are reserved, including those for text and data mining, AI training, and
   similar technologies.
ZR 0
ZB 0
Z8 0
ZA 0
TC 6
ZS 0
Z9 6
DA 2024-10-11
UT WOS:001326766200001
PM 38789092
ER

PT J
AU Izhar, Amaan
   Idris, Norisma
   Japar, Nurul
TI Engaging Preference Optimization Alignment in Large Language Model for
   Continual Radiology Report Generation: A Hybrid Approach
SO COGNITIVE COMPUTATION
VL 17
IS 1
AR 53
DI 10.1007/s12559-025-10404-6
DT Letter
PD FEB 2025
PY 2025
AB Large language models (LLMs) remain relatively underutilized in medical
   imaging, particularly in radiology, which is essential for disease
   diagnosis and management. Nonetheless, radiology report generation (RRG)
   is a time-consuming task that can result in delays and inconsistencies.
   To address these challenges, we present a novel hybrid approach that
   integrates multi-modal radiology information and preference optimization
   alignment in LLM for continual RRG. Our method integrates a pre-trained
   small multi-modal model to analyze radiology images and generate an
   initial report, which is subsequently refined and aligned by an LLM
   using odds ratio preference optimization (ORPO) and with historical
   patient data and assessments to mimic radiologist-like responses,
   bypassing reinforcement learning from human feedback-based (RLHF)
   alignment. This two-stage fusion-supervised fine-tuning followed by
   preference optimization-ensures high accuracy while minimizing
   hallucinations and errors. We also propose a data field curation
   strategy extendable to various other RRG modality datasets, focusing on
   selecting relevant responses for preference alignment. We evaluate our
   approach on two public datasets, achieving state-of-the-art performance
   with average Bleu scores of 0.375 and 0.647, Meteor scores of 0.495 and
   0.714, Rouge-L scores of 0.483 and 0.732, and average F1-RadGraph scores
   of 0.488 and 0.487, for chest X-rays and lung CT scan datasets,
   respectively. We further provide in-depth qualitative analyses and
   ablation studies to explain the workings of our model and grasp the
   clinical relevance for RRG. This work presents the first application of
   preference optimization in continual RRG, representing a significant
   advancement in automating clinically reliable report generation. By
   reducing cognitive burdens on radiologists through AI-powered reasoning
   and alignment in LLMs, the proposed model improves decision-making,
   perception, and diagnostic precision, streamlining workflows and
   enhancing patient care. Our code is available at
   https://github.com/AI-14/r2gpoallm.
Z8 0
ZB 0
TC 1
ZS 0
ZR 0
ZA 0
Z9 1
DA 2025-02-01
UT WOS:001407936900001
ER

PT J
AU Liu, Xiaoguang
   Liu, Peize
   Yang, Bo
   Chen, Yizhan
TI One multi-receiver certificateless searchable public key encryption
   scheme for IoMT assisted by LLM
SO JOURNAL OF INFORMATION SECURITY AND APPLICATIONS
VL 90
AR 104011
DI 10.1016/j.jisa.2025.104011
EA MAR 2025
DT Article
PD MAY 2025
PY 2025
AB The Internet of Medical Things (IoMT) has become widely adopted across
   the healthcare sector, offering transformative benefits. By utilizing a
   range of wearable medical devices and cloud servers, IoMT enables the
   rapid transmission of data over networks, which supports timely health
   monitoring and data-driven decision- making. In recent years, some
   applications have used the Large Language Model (LLM) to assist in
   diagnosis, significantly improving diagnostic efficiency in IoMT.
   However, secure transmission of sensitive medical information remains a
   key concern. To address this, we propose a multi-receiver
   certificateless searchable public key encryption (mCLSPE) scheme that
   leverages proxy re-encryption. This scheme not only addresses the
   inherent issues in searchable public key encryption (SPE) but also
   allows for more flexible addition of receivers and enhances data-sharing
   flexibility. The proposed scheme is proven secure in the random oracle
   model. The performance analysis shows that it has ideal comprehensive
   performance. The growth rate of communication overhead with the increase
   in users is significantly lower compared to other mCLSPE schemes.
   Finally, we design a specific IoMT assisted by LLM application scenario
   based on this scheme.
ZS 0
Z8 0
ZR 0
ZB 0
TC 2
ZA 0
Z9 2
DA 2025-03-21
UT WOS:001443103200001
ER

PT J
AU Park, SaYoon
   Chang-EopKim
TI Enhancing Korean Medicine Education with Large Language Models: Focusing
   on the Development of Educational Artificial Intelligence
Z1 거대언어모델을 활용한 한의학 교육 강화: 교육용 인공지능 개발을 중심으로
SO Journal of Physiology & Pathology in Korean Medicine
S1 동의생리병리학회지
VL 37
IS 5
BP 134
EP 138
DT research-article
PD 2023
PY 2023
AB Large language models (LLMs) have introduced groundbreaking innovations
   in various fields, including healthcare, where they augment medical
   diagnosis, decision-making, and facilitate patient-doctor communication
   through their exceptional contextual understanding and inferential
   abilities. In the realm of Korean medicine (KM), the utilization of LLMs
   is highly anticipated. However, it demands additional training with
   domain-specific KM data for seamless integration of KM knowledge. There
   are two predominant strategies for training domain-specific LLMs in the
   KM domain. The first approach entails direct manipulation of the LLM's
   internals by either pretraining a base model on an extensive corpus of
   KM data or fine-tuning a pretrained model's parameters using KM-related
   question-answering datasets. The second approach avoids internal model
   manipulation and leverages techniques like prompt engineering, retrieval
   augmented generation, and cognitive augmentation. Domain-specific LLMs
   specialized for KM hold the potential for diverse applications, ranging
   from personalized medical education plans and content generation to
   knowledge integration, curriculum development, automated student
   assessment, virtual patient simulations, and advanced research and
   scholarly activities. These advancements are poised to significantly
   impact the field of KM and medical education at large.
ZB 0
Z8 0
TC 0
ZA 0
ZS 0
ZR 0
Z9 0
DA 2023-01-01
UT KJD:ART003011785
ER

PT J
AU Wu, Wanying
   Guo, Yuhu
   Li, Qi
   Jia, Congzhuo
TI Exploring the potential of large language models in identifying
   metabolic dysfunction-associated steatotic liver disease: A comparative
   study of non-invasive tests and artificial intelligence-generated
   responses
SO LIVER INTERNATIONAL
VL 45
IS 4
DI 10.1111/liv.16112
EA NOV 2024
DT Article
PD APR 2025
PY 2025
AB Background and AimsThis study sought to assess the capabilities of large
   language models (LLMs) in identifying clinically significant metabolic
   dysfunction-associated steatotic liver disease (MASLD).MethodsWe
   included individuals from NHANES 2017-2018. The validity and reliability
   of MASLD diagnosis by GPT-3.5 and GPT-4 were quantitatively examined and
   compared with those of the Fatty Liver Index (FLI) and United States FLI
   (USFLI). A receiver operating characteristic curve was conducted to
   assess the accuracy of MASLD diagnosis via different scoring systems.
   Additionally, GPT-4V's potential in clinical diagnosis using ultrasound
   images from MASLD patients was evaluated to provide assessments of LLM
   capabilities in both textual and visual data interpretation.ResultsGPT-4
   demonstrated comparable performance in MASLD diagnosis to FLI and USFLI
   with the AUROC values of .831 (95% CI .796-.867), .817 (95% CI
   .797-.837) and .827 (95% CI .807-.848), respectively. GPT-4 exhibited a
   trend of enhanced accuracy, clinical relevance and efficiency compared
   to GPT-3.5 based on clinician evaluation. Additionally, Pearson's r
   values between GPT-4 and FLI, as well as USFLI, were .718 and .695,
   respectively, indicating robust and moderate correlations. Moreover,
   GPT-4V showed potential in understanding characteristics from hepatic
   ultrasound imaging but exhibited limited interpretive accuracy in
   diagnosing MASLD compared to skilled radiologists.ConclusionsGPT-4
   achieved performance comparable to traditional risk scores in diagnosing
   MASLD and exhibited improved convenience, versatility and the capacity
   to offer user-friendly outputs. The integration of GPT-4V highlights the
   capacities of LLMs in handling both textual and visual medical data,
   reinforcing their expansive utility in healthcare practice.
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
DA 2024-11-23
UT WOS:001354198800001
PM 39526465
ER

PT J
AU Burgisser, Nils
   Chalot, Etienne
   Mehouachi, Samia
   Buclin, Clement P.
   Lauper, Kim
   Courvoisier, Delphine S.
   Mongin, Denis
TI Large language models for accurate disease detection in electronic
   health records: the examples of crystal arthropathies
SO RMD OPEN
VL 10
IS 4
AR e005003
DI 10.1136/rmdopen-2024-005003
DT Article
PD DEC 19 2024
PY 2024
AB Objectives We propose and test a framework to detect disease diagnosis
   using a recent large language model (LLM), Meta's Llama-3-8B, on
   French-language electronic health record (EHR) documents. Specifically,
   it focuses on detecting gout ('goutte' in French), a ubiquitous French
   term that has multiple meanings beyond the disease. The study compares
   the performance of the LLM-based framework with traditional natural
   language processing techniques and tests its dependence on the parameter
   used.Methods The framework was developed using a training and testing
   set of 700 paragraphs assessing 'gout' from a random selection of EHR
   documents from a tertiary university hospital in Geneva, Switzerland.
   All paragraphs were manually reviewed and classified by two healthcare
   professionals into disease (true gout) and non-disease (gold standard).
   The LLM's accuracy was tested using few-shot and chain-of-thought
   prompting and compared with a regular expression (regex)-based method,
   focusing on the effects of model parameters and prompt structure. The
   framework was further validated on 600 paragraphs assessing 'Calcium
   Pyrophosphate Deposition Disease (CPPD)'.Results The LLM-based algorithm
   outperformed the regex method, achieving a 92.7% (88.7%-95.4%) positive
   predictive value, a 96.6% (94.6%-97.8%) negative predictive value and an
   accuracy of 95.4% (93.6%-96.7%) for gout. In the validation set on CPPD,
   accuracy was 94.1% (90.2%-97.6%). The LLM framework performed well over
   a wide range of parameter values.Conclusion LLMs accurately detected
   disease diagnoses from EHRs, even in non-English languages. They could
   facilitate creating large disease registers in any language, improving
   disease care assessment and patient recruitment for clinical trials.
ZS 0
ZA 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
DA 2024-12-27
UT WOS:001381748400001
PM 39794274
ER

PT J
AU Bhasuran, Balu
   Jin, Qiao
   Xie, Yuzhang
   Yang, Carl
   Hanna, Karim
   Costa, Jennifer
   Shavor, Cindy
   Han, Wenshan
   Lu, Zhiyong
   He, Zhe
TI Preliminary analysis of the impact of lab results on large language
   model generated differential diagnoses
SO NPJ DIGITAL MEDICINE
VL 8
IS 1
AR 166
DI 10.1038/s41746-025-01556-8
DT Article
PD MAR 18 2025
PY 2025
AB Differential diagnosis (DDx) is crucial for medicine as it helps
   healthcare providers systematically distinguish between conditions that
   share similar symptoms. This study evaluates the influence of lab test
   results on DDx accuracy generated by large language models (LLMs).
   Clinical vignettes from 50 randomly selected case reports from
   PMC-Patients were created, incorporating demographics, symptoms, and lab
   data. Five LLMs-GPT-4, GPT-3.5, Llama-2-70b, Claude-2, and
   Mixtral-8x7B-were tested to generate Top 10, Top 5, and Top 1 DDx with
   and without lab data. Results show that incorporating lab data enhances
   accuracy by up to 30% across models. GPT-4 achieved the highest
   performance, with Top 1 accuracy of 55% (0.41-0.69) and lenient accuracy
   reaching 79% (0.68-0.90). Statistically significant improvements
   (Holm-adjusted p values < 0.05) were observed, with GPT-4 and Mixtral
   excelling. Lab tests, including liver function, metabolic/toxicology
   panels, and serology, were generally interpreted correctly by LLMs for
   DDx.
Z8 0
TC 1
ZS 0
ZR 0
ZB 0
ZA 0
Z9 1
DA 2025-03-27
UT WOS:001449534900001
PM 40102561
ER

PT J
AU Ye, Yi
   Zheng, En-dian
   Lan, Qiao-li
   Wu, Le-can
   Sun, Hao-yue
   Xu, Bei-bei
   Wang, Ying
   Teng, Miao-miao
TI Comparative evaluation of the accuracy and reliability of ChatGPT
   versions in providing information on Helicobacter pylori
   infection
SO FRONTIERS IN PUBLIC HEALTH
VL 13
AR 1566982
DI 10.3389/fpubh.2025.1566982
DT Article
PD MAY 15 2025
PY 2025
AB Objective This study aimed to evaluate the accuracy and reliability of
   responses provided by three versions of ChatGPT (ChatGPT-3.5, ChatGPT-4,
   and ChatGPT-4o) to questions related to Helicobacter pylori (Hp)
   infection, as well as to explore their potential applications within the
   healthcare domain. Methods A panel of experts compiled and refined a set
   of 27 clinical questions related to Hp. These questions were presented
   to each ChatGPT version, generating three distinct sets of responses.
   The responses were evaluated and scored by three gastroenterology
   specialists utilizing a 5-point Likert scale, with an emphasis on
   accuracy and comprehensiveness. To assess response stability and
   reliability, each question was submitted three times over three
   consecutive days. Results Statistically significant differences in the
   Likert scale scores were observed among the three ChatGPT versions (p <
   0.0001). ChatGPT-4o demonstrated the best performance, achieving an
   average score of 4.46 (standard deviation 0.82) points. Despite its high
   accuracy, ChatGPT-4o exhibited relatively low repeatability. In
   contrast, ChatGPT-3.5 exhibited the highest stability, although it
   occasionally provided incorrect answers. In terms of readability,
   ChatGPT-4 achieved the highest Flesch Reading Ease score of 24.88
   (standard deviation 0.44), however, no statistically significant
   differences in readability were observed among the versions. Conclusion
   All three versions of ChatGPT were effective in addressing Hp-related
   questions, with ChatGPT-4o delivering the most accurate information.
   These findings suggest that artificial intelligence-driven chat models
   hold significant potential in healthcare, facilitating improved patient
   awareness, self-management, and treatment compliance, as well as
   supporting physicians in making informed medical decisions by providing
   accurate information and personalized recommendations.
ZA 0
TC 0
ZR 0
ZB 0
ZS 0
Z8 0
Z9 0
DA 2025-06-03
UT WOS:001498407800001
PM 40443929
ER

PT C
AU Makram, Manal
   Mohammed, Ammar
BE AbdelRaouf, A
   Shorim, N
   Hatem, S
   Kandil, Y
   Bahaa-Eldin, A
TI AI Applications in Medical Reporting and Diagnosis
SO 2024 INTERNATIONAL MOBILE, INTELLIGENT, AND UBIQUITOUS COMPUTING
   CONFERENCE, MIUCC 2024
BP 185
EP 192
DI 10.1109/MIUCC62295.2024.10783552
DT Proceedings Paper
PD 2024
PY 2024
AB The integration of artificial intelligence (AI) in healthcare is
   revolutionizing diagnosis and patient care by improving clinical
   documentation and the management of electronic health records that
   depend on medical image interpretation, increasing accuracy, and
   reducing time. Egypt ranks first in liver disease and second in liver
   cancer mortality worldwide in 2020. Large language models, a subset of
   AI techniques, can assist in disease diagnosis. LLM models with
   multimodal capabilities can classify and describe patient scan images
   and extract information from clinical notes. These models can extract
   vital diagnoses with the support of prompt engineering, as one of these
   models can answer questions, summarize information, and translate
   complex medical terminology into plain language, enabling patients to
   understand their medical reports and diagnoses. There are two primary
   approaches to achieving this. First, fine-tuning can adapt the model to
   medical data, which can be resource-intensive. The second approach,
   pre-trained LLM models can be utilized to leverage pre-trained models to
   perform the necessary tasks, focusing on effectively using prompts to
   guide the model for precise and relevant outputs. This study highlights
   the role of generative AI models by focusing on prompt engineering, and
   how carefully crafting prompts can enhance the effectiveness of LLM
   models in medical applications with high accuracy. It demonstrates this
   through experiments using pre-trained models based on semantic
   similarity with GPT-4o and BioGPT. Implementing a zero-shot model for
   liver tumor classification is one of the prompt engineering techniques.
   The performance metrics achieved were impressive, accuracy, precision,
   recall, and F1-scores are 88, 81, 88, and 83 percent, respectively.
CT 4th International Mobile, Intelligent, and Ubiquitous Computing
   Conference
CY NOV 13-14, 2024
CL Cairo, EGYPT
SP Misr International University
ZS 0
Z8 0
ZB 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-03-07
UT WOS:001416363600027
ER

PT J
AU Reicher, Lee
   Lutsker, Guy
   Michaan, Nadav
   Grisaru, Dan
   Laskov, Ido
TI Exploring the role of artificial intelligence, large language models:
   Comparing patient-focused information and clinical decision support
   capabilities to the gynecologic oncology guidelines
SO INTERNATIONAL JOURNAL OF GYNECOLOGY & OBSTETRICS
VL 168
IS 2
BP 419
EP 427
DI 10.1002/ijgo.15869
EA AUG 2024
DT Review
PD FEB 2025
PY 2025
AB Gynecologic cancer requires personalized care to improve outcomes. Large
   language models (LLMs) hold the potential to provide intelligent
   question-answering with reliable information about medical queries in
   clear and plain English, which can be understood by both healthcare
   providers and patients. We aimed to evaluate two freely available LLMs
   (ChatGPT and Google's Bard) in answering questions regarding the
   management of gynecologic cancer. The LLMs' performances were evaluated
   by developing a set questions that addressed common gynecologic
   oncologic findings from a patient's perspective and more complex
   questions to elicit recommendations from a clinician's perspective. Each
   question was presented to the LLM interface, and the responses generated
   by the artificial intelligence (AI) model were recorded. The responses
   were assessed based on the adherence to the National Comprehensive
   Cancer Network and European Society of Gynecological Oncology
   guidelines. This evaluation aimed to determine the accuracy and
   appropriateness of the information provided by LLMs. We showed that the
   models provided largely appropriate responses to questions regarding
   common cervical cancer screening tests and BRCA-related questions. Less
   useful answers were received to complex and controversial gynecologic
   oncology cases, as assessed by reviewing the common guidelines. ChatGPT
   and Bard lacked knowledge of regional guideline variations, However, it
   provided practical and multifaceted advice to patients and caregivers
   regarding the next steps of management and follow up. We conclude that
   LLMs may have a role as an adjunct informational tool to improve
   outcomes.
   ChatGPT and Bard provide appropriate responses to patient's perspective
   gynecologic oncologic questions, but is less useful for complex
   questions compared with the National Comprehensive Cancer
   Network/European Society of Gynecological Oncology guidelines.
TC 5
ZR 0
Z8 0
ZA 0
ZB 0
ZS 0
Z9 5
DA 2024-08-23
UT WOS:001293448800001
PM 39161265
ER

PT J
AU Wu, Xuzhou
   Li, Guangxin
   Wang, Xing
   Xu, Zeyu
   Wang, Yingni
   Lei, Shuge
   Xian, Jianming
   Wang, Xueyu
   Zhang, Yibao
   Li, Gong
   Yuan, Kehong
TI Diagnosis assistant for liver cancer utilizing a large language model
   with three types of knowledge
SO PHYSICS IN MEDICINE AND BIOLOGY
VL 70
IS 9
AR 095009
DI 10.1088/1361-6560/adcb17
DT Article
PD MAY 4 2025
PY 2025
AB Objective. Liver cancer has a high incidence rate, but experienced
   doctors are lacking in primary healthcare settings. The development of
   large models offers new possibilities for diagnosis. However, in liver
   cancer diagnosis, large models face certain limitations, such as
   insufficient understanding of specific medical images, inadequate
   consideration of liver vessel factors, and inaccuracies in reasoning
   logic. Therefore, this study proposes a diagnostic assistance tool
   specific to liver cancer to enhance the diagnostic capabilities of
   primary care doctors. Approach. A liver cancer diagnosis framework
   combining large and small models is proposed. A more accurate model for
   liver tumor segmentation and a more precise model for liver vessel
   segmentation are developed. The features extracted from the segmentation
   results of the small models are combined with the patient's medical
   records and then provided to the large model. The large model employs
   chain of thought prompts to simulate expert diagnostic reasoning and
   uses Retrieval-Augmented Generation to provide reliable answers based on
   trusted medical knowledge and cases. Main results. In the small model
   part, the proposed liver tumor and liver vessel segmentation methods
   achieve improved performance. In the large model part, this approach
   receives higher evaluation scores from doctors when analyzing patient
   imaging and medical records. Significance. First, a diagnostic framework
   combining small models and large models is proposed to optimize the
   liver cancer diagnosis process. Second, two segmentation models are
   introduced to compensate for the large model's shortcomings in
   extracting semantic information from images. Third, by simulating
   doctors' reasoning and integrating trusted knowledge, the framework
   enhances the reliability and interpretability of the large model's
   responses while reducing hallucination phenomena.
Z8 0
ZS 0
ZA 0
ZR 0
TC 0
ZB 0
Z9 0
DA 2025-05-08
UT WOS:001480266600001
PM 40203862
ER

PT J
AU Abi-Rafeh, Jad
   Hanna, Steven
   Bassiri-Tehrani, Brian
   Kazan, Roy
   Nahai, Foad
TI Complications Following Facelift and Neck Lift: Implementation and
   Assessment of Large Language Model and Artificial Intelligence (ChatGPT)
   Performance Across 16 Simulated Patient Presentations
SO AESTHETIC PLASTIC SURGERY
DI 10.1007/s00266-023-03538-1
EA AUG 2023
DT Article; Early Access
PY 2023
AB Introduction ChatGPT represents a potential resource for patient
   guidance and education, with the possibility for quality improvement in
   healthcare delivery. The present study evaluates the role of ChatGPT as
   an interactive patient resource, and assesses its performance in
   identifying, triaging, and guiding patients with concerns of
   postoperative complications following facelift and neck lift
   surgery.Methods Sixteen patient profiles were generated to simulate
   postoperative patient presentations, with complications of varying
   acuity and severity. ChatGPT was assessed for its accuracy in generating
   a differential diagnosis, soliciting a history, providing the
   most-likely diagnosis, the appropriate disposition,
   treatments/interventions to begin from home, and red-flag symptoms
   necessitating an urgent presentation to the emergency department.Results
   Overall accuracy in providing a complete differential diagnosis in
   response to simulated presentations was 85%, with an accuracy of 88% in
   identifying the most-likely diagnosis after history-taking. However,
   appropriate patient dispositions were suggested in only 56% of cases.
   Relevant home treatments/interventions were suggested with an 82%
   accuracy, and red-flag symptoms with a 73% accuracy. A detailed
   analysis, stratified according to latency of postoperative presentation
   (<48 h, 48 h-1 week, or >1 week), and according to acuity of
   complications, is presented herein.Conclusions ChatGPT overestimated the
   urgency of indicated patient dispositions in 44% of cases, concerning
   for potential unnecessary increase in healthcare resource utilization.
   Imperfect performance, and the tool's tendency for overinclusion in its
   responses, risk increasing patient anxiety and straining
   physician-patient relationships. While artificial intelligence has great
   potential in triaging postoperative patient concerns, and improving
   efficiency and resource utilization, ChatGPT's performance, in its
   current form, demonstrates a need for further refinement before its safe
   and effective implementation in facial aesthetic surgical practice.
ZA 0
ZS 0
TC 20
ZB 0
ZR 0
Z8 0
Z9 20
DA 2023-08-31
UT WOS:001050406400004
PM 37589944
ER

PT J
AU Tustumi, Francisco
   Andreollo, Nelson Adami
   de Aguilar-Nascimento, Jose Eduardo
TI FUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT
SO ABCD-ARQUIVOS BRASILEIROS DE CIRURGIA DIGESTIVA-BRAZILIAN ARCHIVES OF
   DIGESTIVE SURGERY
VL 36
IS 1
AR e1727
DI 10.1590/0102-672020230002e1727
DT Review
PD 2023
PY 2023
AB The field of medicine has always been at the forefront of technological
   innovation, Fabricio Ferreira COELHO3 , Paulo HERMAN3 constantly seeking
   new strategies to diagnose, treat, and prevent diseases. Guidelines for
   clinical practice to orientate medical teams regarding diagnosis,
   treatment, and prevention measures have increased over the years. The
   purpose is to gather the most medical knowledge to construct an
   orientation for practice. Evidence-based guidelines follow several main
   characteristics of a systematic RESUMO -Racmonal: O tratamento de
   escolha para pacientes com ipertensao portal review, including
   systematic and unbiased search, selection, and extraction of the source
   of evidence. esquistossomotica com sangramento de varizes e a desconexao
   azigo-portal mais In recent years, the rapid advancement of artificial
   intelligence has provided clinicians and patients esplenetomia (DAPE)
   associad a terapa endoscoica. Porem, estuds mostram aumento with access
   to personalized, data-driven insights, suport and new opportunities for
   healthcare do calibre das varizes em alguns pacientes durante o
   seguimento em longo prazo. Objetmvo: professionals to improve patient
   outcomes, increase efficiency, and reduce costs. One of the most Avaliar
   o impacto da DAPE e tratamento endoscopico pos-operatorio no
   comportamento exciting developments in Artificial Intelligence has been
   the emergence of chatbots. A chatbot is a computer program used to
   simulate conversations with human users. Recently, OpenAI, a research
   das varizes esofagicas e recidiva hemorragica, de pacientes
   esquistossomoticos. Metodos: organization focused on machine learning,
   developed ChatGPT, a large language model that Foram estudados 36
   pacientes com eguimento superior a cinco anos, distribuidos em generates
   human-like text. ChatGPT uses a type of AI known as a deep learning
   model. ChatGPT dois grupos: qued a prssao portal abaixo de 30% e acima
   de 30% compaados com o can quickly search a nd select pieces of evidence
   through numerous databases to provide answers calibre das varizes
   esofagicas no pos-operatorio precoce e tardio alem do indice de recidiva
   to complex questions, reducing the time and effort required to research
   a particular topic manually. hemorragica. Resultados Consequently,
   language models can accelerate the creation of clinical practice
   guidelines. While there is no doubt that ChatGPT has the potential to
   revolutionize the way healthcare is delivered, esofagicas que, durante o
   seguimento aumentaram de calibre e foram controladas com it is essential
   to note that it should not be used as a substitute for human healthcare
   professionals. Instead, ChatGPT should be considered a tool that can be
   used to augment and support the work of o comportamento do calibre das
   varizes no pos-opeatorio precoce nem tardio nem os healthcare
   professionals, helping them to provide better care to their patients.
ZB 6
TC 41
ZR 0
ZA 0
Z8 0
ZS 1
Z9 41
DA 2023-06-08
UT WOS:000993819100001
PM 37162073
ER

PT J
AU Hwang, Yeon-Mi
   Hah, Jennifer M.
   Bramen, Jennifer E.
   Hadlock, Jennifer J.
   Hernandez-Boussard, Tina
TI Short-term mortality after opioid initiation among opioid-naïve and
   non-naïve patients with dementia: a retrospective cohort study
SO BMC MEDICINE
VL 23
IS 1
AR 340
DI 10.1186/s12916-025-04172-1
DT Article
PD JUN 9 2025
PY 2025
AB Background In the ongoing opioid epidemic, the mortality risk of opioid
   initiation in patients with dementia or mild cognitive impairment (MCI)
   remains understudied despite their vulnerability. This study evaluates
   mortality risks associated with opioid exposure in patients diagnosed
   with dementia or MCI by comparing outcomes between the initiation and
   continuation groups. Methods We conducted a retrospective cohort study
   using data from a Northern California academic healthcare system
   (Stanford Health Care Alliance; 2015/01/01-2024/07/31), including 27,757
   patients aged 50-100 with dementia or MCI. Of these, 14,105 received
   opioids after diagnosis and were classified as initiation (opioid-na &
   iuml;ve; n=9443) or continuation (non-na & iuml;ve; n=4662) groups. Cox
   regression assessed 14-day mortality risk. Aalen's additive model
   examined time-varying impact up to 180 days. Potential causes of death
   were extracted from clinical notes using GPT-3.5-Turbo. We also analyzed
   an independent community healthcare system cohort (Providence Health &
   Service; n=208,306) from western US states (2015/01/01-2023/05/31) as a
   replication cohort. Results In the primary cohort, 4.1% (572/14,105) of
   patients died within 14 days of opioid exposure. The initiation group
   had a significantly higher 14-day mortality risk than the continuation
   group (adjusted hazard ratio (aHR), 2.00 (1.59-2.52); P<0.0001). The
   replication cohort had a 14-day mortality rate of 6.2% (7022/113,343)
   with a smaller difference between the initiation (n=77,168) and
   continuation (n=36,175) groups (aHR 1.22 (1.16-1.30); P<0.0001). In both
   cohorts, elevated risk stabilized after day 30. In the primary cohort,
   respiratory conditions (62% vs. 48%, P<0.1), particularly pneumonia (38%
   vs. 19%, P<0.05), were more prevalent among the initiation group who
   died early. Conclusions Starting opioids in patients with dementia or
   MCI is associated with elevated short-term mortality risks, with the
   initiation group having twice the 14-day mortality risk in academic
   settings and a smaller but significant increase in community healthcare
   systems. The first 30 days after initiation represent a critical risk
   window, likely due to a lack of tolerance to opioid adverse effects.
   These findings underscore the need for cautious initiation, tailored
   follow-up protocols accounting for healthcare setting characteristics,
   and close monitoring during the first month in this vulnerable
   population.
ZA 0
TC 0
ZR 0
ZB 0
ZS 0
Z8 0
Z9 0
DA 2025-06-12
UT WOS:001504505000007
PM 40484923
ER

PT J
AU Pagano, Stefano
   Holzapfel, Sabrina
   Kappenschneider, Tobias
   Meyer, Matthias
   Maderbacher, Guenther
   Grifka, Joachim
   Holzapfel, Dominik Emanuel
TI Arthrosis diagnosis and treatment recommendations in clinical practice:
   an exploratory investigation with the generative AI model GPT-4
SO JOURNAL OF ORTHOPAEDICS AND TRAUMATOLOGY
VL 24
IS 1
AR 61
DI 10.1186/s10195-023-00740-4
DT Article
PD NOV 28 2023
PY 2023
AB Background The spread of artificial intelligence (AI) has led to
   transformative advancements in diverse sectors, including healthcare.
   Specifically, generative writing systems have shown potential in various
   applications, but their effectiveness in clinical settings has been
   barely investigated. In this context, we evaluated the proficiency of
   ChatGPT-4 in diagnosing gonarthrosis and coxarthrosis and recommending
   appropriate treatments compared with orthopaedic specialists.Methods A
   retrospective review was conducted using anonymized medical records of
   100 patients previously diagnosed with either knee or hip arthrosis.
   ChatGPT-4 was employed to analyse these historical records, formulating
   both a diagnosis and potential treatment suggestions. Subsequently, a
   comparative analysis was conducted to assess the concordance between the
   AI's conclusions and the original clinical decisions made by the
   physicians.Results In diagnostic evaluations, ChatGPT-4 consistently
   aligned with the conclusions previously drawn by physicians. In terms of
   treatment recommendations, there was an 83% agreement between the AI and
   orthopaedic specialists. The therapeutic concordance was verified by the
   calculation of a Cohen's Kappa coefficient of 0.580 (p < 0.001). This
   indicates a moderate-to-good level of agreement. In recommendations
   pertaining to surgical treatment, the AI demonstrated a sensitivity and
   specificity of 78% and 80%, respectively. Multivariable logistic
   regression demonstrated that the variables reduced quality of life (OR
   49.97, p < 0.001) and start-up pain (OR 12.54, p = 0.028) have an
   influence on ChatGPT-4's recommendation for a surgery.Conclusion This
   study emphasises ChatGPT-4's notable potential in diagnosing conditions
   such as gonarthrosis and coxarthrosis and in aligning its treatment
   recommendations with those of orthopaedic specialists. However, it is
   crucial to acknowledge that AI tools such as ChatGPT-4 are not meant to
   replace the nuanced expertise and clinical judgment of seasoned
   orthopaedic surgeons, particularly in complex decision-making scenarios
   regarding treatment indications. Due to the exploratory nature of the
   study, further research with larger patient populations and more complex
   diagnoses is necessary to validate the findings and explore the broader
   potential of AI in healthcare.
Z8 0
ZS 0
ZR 0
TC 15
ZB 3
ZA 0
Z9 15
DA 2023-12-17
UT WOS:001110492100001
PM 38015298
ER

PT J
AU Zhang, Jingqing
   Sun, Kai
   Jagadeesh, Akshay
   Falakaflaki, Parastoo
   Kayayan, Elena
   Tao, Guanyu
   Ghahfarokhi, Mahta Haghighat
   Gupta, Deepa
   Gupta, Ashok
   Gupta, Vibhor
   Guo, Yike
TI The potential and pitfalls of using a large language model such as
   ChatGPT, GPT-4, or LLaMA as a clinical assistant
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 9
BP 1884
EP 1891
DI 10.1093/jamia/ocae184
EA JUL 2024
DT Article
PD JUL 17 2024
PY 2024
AB Objectives This study aims to evaluate the utility of large language
   models (LLMs) in healthcare, focusing on their applications in enhancing
   patient care through improved diagnostic, decision-making processes, and
   as ancillary tools for healthcare professionals.Materials and Methods We
   evaluated ChatGPT, GPT-4, and LLaMA in identifying patients with
   specific diseases using gold-labeled Electronic Health Records (EHRs)
   from the MIMIC-III database, covering three prevalent diseases-Chronic
   Obstructive Pulmonary Disease (COPD), Chronic Kidney Disease (CKD)-along
   with the rare condition, Primary Biliary Cirrhosis (PBC), and the
   hard-to-diagnose condition Cancer Cachexia.Results In patient
   identification, GPT-4 had near similar or better performance compared to
   the corresponding disease-specific Machine Learning models (F1-score >=
   85%) on COPD, CKD, and PBC. GPT-4 excelled in the PBC use case,
   achieving a 4.23% higher F1-score compared to disease-specific
   "Traditional Machine Learning" models. ChatGPT and LLaMA3 demonstrated
   lower performance than GPT-4 across all diseases and almost all metrics.
   Few-shot prompts also help ChatGPT, GPT-4, and LLaMA3 achieve higher
   precision and specificity but lower sensitivity and Negative Predictive
   Value.Discussion The study highlights the potential and limitations of
   LLMs in healthcare. Issues with errors, explanatory limitations and
   ethical concerns like data privacy and model transparency suggest that
   these models would be in clinical settings. Future studies should
   improve training datasets and model designs for LLMs to gain better
   utility in healthcare.Conclusion The study shows that LLMs have the
   potential to assist clinicians for tasks such as patient identification
   but false positives and false negatives must be mitigated before LLMs
   are adequate for real-world clinical assistance.
ZA 0
ZS 0
ZB 1
ZR 0
TC 15
Z8 1
Z9 16
DA 2024-07-23
UT WOS:001269939400001
PM 39018498
ER

PT J
AU Gilbert, M.
   Crutchfield, A.
   Luo, B.
   Thind, K.
   Ghanem, A. I.
   Siddiqui, F.
TI Using a Large Language Model (LLM) for Automated Extraction of Discrete
   Elements from Clinical Notes for Creation of Cancer Databases
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3371
BP E625
EP E625
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
ZA 0
ZS 0
ZB 0
ZR 0
TC 1
Z9 1
DA 2024-12-16
UT WOS:001325892302054
ER

PT J
AU Rosskopf, Steffen
   Meder, Benjamin
TI Healthcare 4.0-Medizin im Wandel
SO HERZ
VL 49
IS 5
BP 350
EP 354
DI 10.1007/s00059-024-05267-w
EA AUG 2024
DT Review
PD OCT 2024
PY 2024
AB Healthcare 4.0 describes the future transformation of the healthcare
   sector driven by the combination of digital technologies, such as
   artificial intelligence (AI), big data and the Internet of Medical
   Things, enabling the advancement of precision medicine. This overview
   article addresses various areas such as large language models (LLM),
   diagnostics and robotics, shedding light on the positive aspects of
   Healthcare 4.0 and showcasing exciting methods and application examples
   in cardiology. It delves into the broad knowledge base and enormous
   potential of LLMs, highlighting their immediate benefits as digital
   assistants or for administrative tasks. In diagnostics, the increasing
   usefulness of wearables is emphasized and an AI for predicting heart
   filling pressures based on cardiac magnetic resonance imaging (MRI) is
   introduced. Additionally, it discusses the revolutionary methodology of
   a digital simulation of the physical heart (digital twin). Finally, it
   addresses both regulatory frameworks and a brief vision of data-driven
   healthcare delivery, explaining the need for investments in technical
   personnel and infrastructure to achieve a more effective medicine.
Z8 0
ZB 0
ZS 0
ZA 0
TC 0
ZR 0
Z9 0
DA 2024-08-14
UT WOS:001287384100001
PM 39115627
ER

PT C
AU Nisar, Hareem
   Anwar, Syed Muhammad
   Jiang, Zhifan
   Parida, Abhijeet
   Sanchez-Jacob, Ramon
   Nath, Vishwesh
   Roth, Holger R.
   Linguraru, Marius George
BE Deng, Z
   Shen, Y
   Kim, HJ
   Jeong, WK
   Aviles-Rivero, AI
   He, J
   Zhang, S
TI D-Rax: Domain-Specific Radiologic Assistant Leveraging Multi-modal Data
   and eXpert Model Predictions
SO FOUNDATION MODELS FOR GENERAL MEDICAL AI, MEDAGI 2024
SE Lecture Notes in Computer Science
VL 15184
BP 91
EP 102
DI 10.1007/978-3-031-73471-7_10
DT Proceedings Paper
PD 2025
PY 2025
AB Large vision language models (VLMs) have progressed incredibly from
   research to applicability for general-purpose use cases. LLaVA-Med, a
   pioneering large language and vision assistant for biomedicine, can
   perform multi-modal biomedical image and data analysis to provide a
   natural language interface for radiologists. While it is highly
   generalizable and works with multi-modal data, it is currently limited
   by well-known challenges in the large language model space.
   Hallucinations and imprecision in responses can lead to misdiagnosis,
   which currently hinders VLMs' clinical adaptability. To create precise,
   user-friendly models in healthcare, we propose D-Rax- a domain-specific,
   conversational, radiologic assistance tool that can be used to gain
   insights about a particular radiologic image. In this study, we enhance
   the conversational analysis of chest X-ray (CXR) images to support
   radiological reporting, offering comprehensive insights from medical
   imaging and aiding in the formulation of accurate diagnosis. D-Rax is
   achieved by fine-tuning the LLaVA-Med architecture on our curated
   enhanced instruction-following data, comprising of images, instructions,
   as well as disease diagnosis and demographic predictions derived from
   MIMIC-CXR imaging data, CXR-related visual question answer (VQA) pairs,
   and predictive outcomes from multiple expert AI models. We observe
   statistically significant improvement in responses when evaluated for
   both open and close-ended conversations. Leveraging the power of
   state-of-the-art diagnostic models combined with VLMs, D-Rax empowers
   clinicians to interact with medical images using natural language, which
   could potentially streamline their decision-making process, enhance
   diagnostic accuracy, and conserve their time.
CT 2nd International Workshop on Foundation Models for General Medical AI
CY OCT 06, 2024
CL Marrakesh, MOROCCO
ZA 0
ZR 0
ZB 0
Z8 0
TC 0
ZS 0
Z9 0
DA 2025-03-21
UT WOS:001426955400010
ER

PT J
AU Chang, Ying
   Yin, Jian-ming
   Li, Jian-min
   Liu, Chang
   Cao, Ling-yong
   Lin, Shu-yuan
TI Applications and Future Prospects of Medical LLMs: A Survey Based on the
   M-KAT Conceptual Framework
SO JOURNAL OF MEDICAL SYSTEMS
VL 48
IS 1
AR 112
DI 10.1007/s10916-024-02132-5
DT Review
PD DEC 27 2024
PY 2024
AB The success of large language models (LLMs) in general areas have
   sparked a wave of research into their applications in the medical field.
   However, enhancing the medical professionalism of these models remains a
   major challenge. This study proposed a novel model training theoretical
   framework, the M-KAT framework, which integrated domain-specific
   training methods for LLMs with the unique characteristics of the medical
   discipline. This framework aimed to improve the medical professionalism
   of the models from three perspectives: general knowledge acquisition,
   specialized skill development, and alignment with clinical thinking.
   This study summarized the outcomes of medical LLMs across four tasks:
   clinical diagnosis and treatment, medical question answering, medical
   research, and health management. Using the M-KAT framework, we analyzed
   the contribution to enhancement of professionalism of models through
   different training stages. At the same time, for some of the potential
   risks associated with medical LLMs, targeted solutions can be achieved
   through pre-training, SFT, and model alignment based on cultivated
   professional capabilities. Additionally, this study identified main
   directions for future research on medical LLMs: advancing professional
   evaluation datasets and metrics tailored to the needs of medical tasks,
   conducting in-depth studies on medical multimodal large language models
   (MLLMs) capable of integrating diverse data types, and exploring the
   forms of medical agents and multi-agent frameworks that can interact
   with real healthcare environments and support clinical decision-making.
   It is hoped that predictions of work can provide a reference for
   subsequent research.
ZS 0
Z8 0
TC 1
ZB 0
ZR 0
ZA 0
Z9 1
DA 2024-12-30
UT WOS:001383525300001
PM 39725770
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT J
AU Gabriel, Rodney A.
   Park, Brian H.
   Hsu, Chun-Nan
   Macias, Alvaro A.
TI A Review of Leveraging Artificial Intelligence to Predict Persistent
   Postoperative Opioid Use and Opioid Use Disorder and its Ethical
   Considerations
SO CURRENT PAIN AND HEADACHE REPORTS
VL 29
IS 1
AR 30
DI 10.1007/s11916-024-01319-2
DT Review
PD DEC 2025
PY 2025
AB Purpose of ReviewArtificial intelligence (AI) offers a new frontier for
   aiding in the management of both acute and chronic pain, which may
   potentially transform opioid prescribing practices and addiction
   prevention strategies. In this review paper, not only do we discuss some
   of the current literature around predicting various opioid-related
   outcomes, but we also briefly point out the next steps to improve
   trustworthiness of these AI models prior to real-time use in clinical
   workflow.Recent FindingsMachine learning-based predictive models for
   identifying risk for persistent postoperative opioid use have been
   reported for spine surgery, knee arthroplasty, hip arthroplasty,
   arthroscopic joint surgery, outpatient surgery, and mixed surgical
   populations. Several machine learning-based models have been described
   to predict an individual's propensity for opioid use disorder and opioid
   overdose. Natural language processing and large language model
   approaches have been described to detect opioid use disorder and
   persistent postsurgical opioid use from clinical notes.Summary AI holds
   significant promise in enhancing the management of acute and chronic
   opioids, which may offer tools to help optimize dosing, predict
   addiction risks, and personalize pain management strategies. By
   harnessing the power of AI, healthcare providers can potentially improve
   patient outcomes, reduce the burden of opioid addiction, and contribute
   to solving the opioid crisis.
ZB 0
ZR 0
ZS 0
Z8 0
TC 1
ZA 0
Z9 1
DA 2025-01-28
UT WOS:001403182600002
PM 39847176
ER

PT J
AU Gu, Zhanzhong
   He, Xiangjian
   Yu, Ping
   Jia, Wenjing
   Yang, Xiguang
   Peng, Gang
   Hu, Penghui
   Chen, Shiyan
   Chen, Hongjie
   Lin, Yiguang
TI Automatic quantitative stroke severity assessment based on Chinese
   clinical named entity recognition with domain-adaptive pre-trained large
   language model
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
VL 150
AR 102822
DI 10.1016/j.artmed.2024.102822
EA FEB 2024
DT Article
PD APR 2024
PY 2024
AB Background: Stroke is a prevalent disease with a significant global
   impact. Effective assessment of stroke severity is vital for an accurate
   diagnosis, appropriate treatment, and optimal clinical outcomes. The
   National Institutes of Health Stroke Scale (NIHSS) is a widely used
   scale for quantitatively assessing stroke severity. However, the current
   manual scoring of NIHSS is labor-intensive, time-consuming, and
   sometimes unreliable. Applying artificial intelligence (AI) techniques
   to automate the quantitative assessment of stroke on vast amounts of
   electronic health records (EHRs) has attracted much interest. Objective:
   This study aims to develop an automatic, quantitative stroke severity
   assessment framework through automating the entire NIHSS scoring process
   on Chinese clinical EHRs. Methods: Our approach consists of two major
   parts: Chinese clinical named entity recognition (CNER) with a domain
   -adaptive pre -trained large language model (LLM) and automated NIHSS
   scoring. To build a highperforming CNER model, we first construct a
   stroke -specific, densely annotated dataset "Chinese Stroke Clinical
   Records"(CSCR) from EHRs provided by our partner hospital, based on a
   stroke ontology that defines semantically related entities for stroke
   assessment. We then pre -train a Chinese clinical LLM coined
   "CliRoberta"through domain -adaptive transfer learning and construct a
   deep learning -based CNER model that can accurately extract entities
   directly from Chinese EHRs. Finally, an automated, end -to -end NIHSS
   scoring pipeline is proposed by mapping the extracted entities to
   relevant NIHSS items and values, to quantitatively assess the stroke
   severity. Results: Results obtained on a benchmark dataset CCKS2019 and
   our newly created CSCR dataset demonstrate the superior performance of
   our domain -adaptive pre -trained LLM and the CNER model, compared with
   the existing benchmark LLMs and CNER models. The high F1 score of 0.990
   ensures the reliability of our model in accurately extracting the
   entities for the subsequent automatic NIHSS scoring. Subsequently, our
   automated, end -to -end NIHSS scoring approach achieved excellent inter
   -rater agreement (0.823) and intraclass consistency (0.986) with the
   ground truth and significantly reduced the processing time from minutes
   to a few seconds. Conclusion: Our proposed automatic and quantitative
   framework for assessing stroke severity demonstrates exceptional
   performance and reliability through directly scoring the NIHSS from
   diagnostic notes in Chinese clinical EHRs. Moreover, this study also
   contributes a new clinical dataset, a pre -trained clinical LLM, and an
   effective deep learning -based CNER model. The deployment of these
   advanced algorithms can improve the accuracy and efficiency of clinical
   assessment, and help improve the quality, affordability and productivity
   of healthcare services.
ZS 0
TC 7
ZA 0
Z8 0
ZR 0
ZB 1
Z9 7
DA 2024-04-13
UT WOS:001197568100001
PM 38553162
ER

PT J
AU Xu, Xiaowei
   Jiang, Ruixuan
   Zheng, Si
   Wang, Min
   Ju, Yi
   Li, Jiao
TI Classification of Chronic Dizziness Using Large Language Models
SO JOURNAL OF HEALTHCARE INFORMATICS RESEARCH
VL 9
IS 1
BP 88
EP 102
DI 10.1007/s41666-024-00178-1
EA NOV 2024
DT Article
PD MAR 2025
PY 2025
AB Efficiently classifying chronic dizziness disorders, including
   persistent postural-perceptual dizziness (PPPD), anxiety, and depressive
   disorders, is crucial, particularly in primary healthcare settings. This
   study introduces DizzyInsight, an innovative etiological classification
   model, designed to enhance the accuracy and reliability of large
   language model (LLM) and machine learning approaches for etiological
   classification of chronic dizziness. Eight physicians specializing in
   chronic dizziness diagnosis, affiliated with the Clinical Center for
   Vertigo and Balance Disturbance at Beijing Tiantan Hospital, Capital
   Medical University, furnished comprehensive definitions and evaluations
   of chronic dizziness characteristics. The study included 260 patients,
   consisting of 105 males and 155 females, with a mean age of 59.52 +/- 13
   years. These patients were recruited from the same center between July
   2021 and October 2023. For comparative analysis, we utilized the general
   models bidirectional encoder representations from transformers (BERT)
   and LLM to assess different outcomes. Seven major categories and 33
   subcategory evidence have been defined for etiological classification of
   chronic dizziness. With DizzyInsight, we constructed the feature dataset
   regarding chronic dizziness. The DizzyInsight based on the identified
   evidence of LLM method yielded a positive predictive value of 0.69, a
   sensitivity of 0.86 for persistent postural-perceptual dizziness (PPPD),
   a positive predictive value of 0.81, and a sensitivity of 0.66 for
   anxiety and depressive disorders. These findings highlight the potential
   of DizzyInsight leveraging LLM to improve the efficacy and
   interpretability of machine learning models in etiological
   classification of chronic dizziness disorders. Further research and
   model development are necessary to improve the accuracy of evidence
   identification and assess the applicability of DizzyInsight in primary
   care settings, as well as to evaluate its external validity.
TC 0
ZS 0
Z8 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2024-11-30
UT WOS:001361419000001
PM 39897102
ER

PT J
AU Kashyap, Aditya M.
   Rao, Delip
   Boland, Mary Regina
   Shen, Li
   Callison-Burch, Chris
TI Predicting explainable dementia types with LLM-aided feature engineering
SO BIOINFORMATICS
VL 41
IS 4
AR btaf156
DI 10.1093/bioinformatics/btaf156
DT Article
PD APR 2025
PY 2025
AB Motivation The integration of Machine Learning and Artificial
   Intelligence (AI) into healthcare has immense potential due to the
   rapidly growing volume of clinical data. However, existing AI models,
   particularly Large Language Models (LLMs) like GPT-4, face significant
   challenges in terms of explainability and reliability, particularly in
   high-stakes domains like healthcare.Results This paper proposes a novel
   LLM-aided feature engineering approach that enhances interpretability by
   extracting clinically relevant features from the Oxford Textbook of
   Medicine. By converting clinical notes into concept vector
   representations and employing a linear classifier, our method achieved
   an accuracy of 0.72, outperforming a traditional n-gram Logistic
   Regression baseline (0.64) and the GPT-4 baseline (0.48), while focusing
   on high-level clinical features. We also explore using Text Embeddings
   to reduce the overall time and cost of our approach by 97%.Availability
   and implementation All code relevant to this paper is available at:
   https://github.com/AdityaKashyap423/Dementia_LLM_Feature_Engineering/tre
   e/main.
TC 0
ZR 0
ZS 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-02
UT WOS:001473768800001
PM 40199828
ER

PT J
AU Sorin, Vera
   Kapelushnik, Noa
   Hecht, Idan
   Zloto, Ofira
   Glicksberg, Benjamin S.
   Bufman, Hila
   Livne, Adva
   Barash, Yiftach
   Nadkarni, Girish N.
   Klang, Eyal
TI Integrated visual and text-based analysis of ophthalmology clinical
   cases using a large language model
SO SCIENTIFIC REPORTS
VL 15
IS 1
AR 4999
DI 10.1038/s41598-025-88948-8
DT Article
PD FEB 10 2025
PY 2025
AB Recent advancements in generative artificial intelligence have enabled
   analysis of text with visual data, which could have important
   implications in healthcare. Diagnosis in ophthalmology is often based on
   a combination of ocular examination, and clinical context. The aim of
   this study was to evaluate the performance of multimodal GPT-4 (GPT-4 V)
   in an integrated analysis of ocular images and clinical text. This
   retrospective study included 40 patients seen in our institution with
   images of their ocular examinations. Cases were selected by a
   board-certified ophthalmologist, to represent various pathologies. We
   provided the model with each patient image, without and then with the
   clinical context. We also asked two non-ophthalmology physicians to
   write diagnoses for each image, without and then with the clinical
   context. Answers for both GPT-4 V and the non-ophthalmologists were
   evaluated by two board-certified ophthalmologists. Performance
   accuracies were calculated and compared. GPT-4 V provided the correct
   diagnosis in 19/40 (47.5%) cases based on images without clinical
   context, and in 27/40 (67.5%) cases when clinical context was provided.
   Non-ophthalmologist physicians provided the correct diagnoses in 24/40
   (60.0%), and 23/40 (57.5%) of cases without clinical context, and in
   29/40 (72.5%) and 27/40 (67.5%) with clinical context. For all study
   participants adding context improved accuracy (p = 0.033). GPT-4 V is
   currently able to simultaneously analyze and integrate visual and
   textual data, and arrive at accurate clinical diagnoses in the majority
   of cases. Multimodal large language models like GPT-4 V have significant
   potential to advance both patient care and research in ophthalmology.
TC 2
ZA 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 2
DA 2025-02-17
UT WOS:001418722300017
PM 39930078
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Liu, Jonathan
   Segal, Kathryn
   Daher, Mohammad
   Ozolin, Jordan
   Binder, William
   Bergen, Michael
   McDonald, Christopher L.
   Owens, Brett
   Antoci, Valentin
TI Artificial intelligence versus orthopedic surgeons as an orthopedic
   consultant in the emergency department
SO INJURY-INTERNATIONAL JOURNAL OF THE CARE OF THE INJURED
VL 56
IS 4
AR 112297
DI 10.1016/j.injury.2025.112297
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB Introduction: ChatGPT, a widely accessible AI program, has demonstrated
   potential in various healthcare applications, including emergency
   department (ED) triage, differential diagnosis, and patient education.
   However, its potential in providing recommendations to emergency
   department providers with orthopedic consultations has not been
   evaluated yet. Methods: This study compared the performance of four
   board certified orthopedic surgeons, two attendings and two trauma
   fellows who take independent call at the same institution and ChatGPT-4
   in responding to clinical scenarios commonly encountered in emergency
   departments. Five common orthopedic ED scenarios were developed (lateral
   malleolar ankle fractures, distal radius fractures, septic arthritis of
   the knee, shoulder dislocations, and Achilles tendon ruptures), each
   with four questions related to diagnosis, management, surgical
   indication, and patient counseling, totaling 20 questions. Responses
   were anonymized, coded, and evaluated by independent reviewers including
   emergency medicine physicians using a five-point Likert scale across
   five criteria: accuracy, completeness, helpfulness, specificity, and
   overall quality. Results: When comparing the ratings of AI answers to
   non-AI responders, the AI answers were shown to be superior in
   completeness, helpfulness, specificity, and overall quality with no
   difference in regards to accuracy (p < 0.05). When considering question
   subtypes including diagnosis, management, treatment, and patient
   counseling, AI was shown to have superior scores in helpfulness, and
   specificity in diagnostic questions(p < 0.05). In addition, AI responses
   were superior in all the assessed categories when looking at the patient
   counseling questions (p < 0.05). When considering different clinical
   scenarios, AI outperformed non-AI groups in completeness in the distal
   radius fracture scenario. Furthermore, AI outperformed non-AI groups in
   helpfulness in the lateral malleolus fracture scenario. In the shoulder
   dislocation scenario, AI responses were more complete, helpful, and had
   a better overall quality. AI responses were non-inferior in the
   remaining categories of the different scenarios. Conclusion: Artificial
   intelligence exhibited non-inferior and often superior performance in
   common orthopedic-ED consultations compared to board certified
   orthopedic surgeons While current AI models are limited in their ability
   to integrate specific images and patient scenarios, our findings suggest
   AI can provide high quality recommendations for generic orthopedic
   consultations and with further development, will likely have an
   increasing role in the future.
ZA 0
TC 0
ZS 0
ZB 0
ZR 0
Z8 0
Z9 0
DA 2025-05-21
UT WOS:001489449700001
PM 40147063
ER

PT J
AU Ying, Lingwen
   Li, Sichen
   Chen, Chunyang
   Yang, Fan
   Li, Xin
   Chen, Yao
   Ding, Yu
   Chang, Guoying
   Li, Juan
   Wang, Xiumin
TI Screening/diagnosis of pediatric endocrine disorders through the
   artificial intelligence model in different language settings
SO EUROPEAN JOURNAL OF PEDIATRICS
VL 183
IS 6
BP 2655
EP 2661
DI 10.1007/s00431-024-05527-1
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB This study is aimed at examining the impact of ChatGPT on pediatric
   endocrine and metabolic conditions, particularly in the areas of
   screening and diagnosis, in both Chinese and English modes. A
   40-question questionnaire covering the four most common pediatric
   endocrine and metabolic conditions was posed to ChatGPT in both Chinese
   and English three times each. Six pediatric endocrinologists evaluated
   the responses. ChatGPT performed better when responding to questions in
   English, with an unreliable rate of 7.5% compared to 27.5% for Chinese
   questions, indicating a more consistent response pattern in English.
   Among the reliable questions, the answers were more comprehensive and
   satisfactory in the English mode. We also found disparities in ChatGPT's
   performance when interacting with different target groups and diseases,
   with improved performance for questions posed by clinicians in English
   and better performance for questions related to diabetes and
   overweight/obesity in Chinese for both clinicians and patients. Language
   comprehension, providing incomprehensive answers, and errors in key data
   were the main contributors to the low scores, according to reviewer
   feedback.Conclusion: Despite these limitations, as ChatGPT continues to
   evolve and expand its network, it has significant potential as a
   practical and effective tool for clinical diagnosis and treatment. What
   is Known:center dot The deep learning-based large-language model ChatGPT
   holds great promise for improving clinical practice for both physicians
   and patients and has the potential to increase the speed and accuracy of
   disease screening and diagnosis, as well as enhance the overall
   efficiency of the medical process. However, the reliability and
   appropriateness of AI model responses in specific field remains
   unclear.center dot This study focused on the reliability and
   appropriateness of AI model responses to straightforward and fundamental
   questions related to the four most prevalent pediatric endocrine and
   metabolic disorders, for both healthcare providers and patients, in
   different language scenarios.What is New:center dot The AI model
   performed better when responding to questions in English, with more
   consistent, as well as more comprehensive and satisfactory responses. In
   addition, we also found disparities in ChatGPT's performance when
   interacting with different target groups and different diseases.center
   dot Despite these limitations, as ChatGPT continues to evolve and expand
   its network, it has significant potential as a practical and effective
   tool for clinical diagnosis and treatment.
Z8 0
ZS 0
ZB 0
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-04-01
UT WOS:001187459700002
PM 38502320
ER

PT J
AU Pan, Jie
   Lee, Seungwon
   Cheligeer, Cheligeer
   Martin, Elliot A
   Riazi, Kiarash
   Quan, Hude
   Li, Na
TI Integrating large language models with human expertise for disease
   detection in electronic health records.
SO Computers in biology and medicine
VL 191
BP 110161
EP 110161
DI 10.1016/j.compbiomed.2025.110161
DT Journal Article
PD 2025-Jun
PY 2025
AB OBJECTIVE: Electronic health records (EHR) are widely available to
   complement administrative data-based disease surveillance and healthcare
   performance evaluation. Defining conditions from EHR is labour-intensive
   and requires extensive manual labelling of disease outcomes. This study
   developed an efficient strategy based on advanced large language models
   to identify multiple conditions from EHR clinical notes.
   METHODS: We linked a cardiac registry cohort in 2015 with an EHR system
   in Alberta, Canada. We developed a pipeline that leveraged a generative
   large language model (LLM) to analyze, understand, and interpret EHR
   notes by prompts based on specific diagnosis, treatment management, and
   clinical guidelines. The pipeline was applied to detect acute myocardial
   infarction (AMI), diabetes, and hypertension. The performance was
   compared against clinician-validated diagnoses as the reference standard
   and widely adopted International Classification of Diseases (ICD)
   codes-based methods.
   RESULTS: The study cohort accounted for 3088 patients and 551,095
   clinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI,
   diabetes, and hypertension, respectively. The performance of the
   LLM-based pipeline for detecting conditions varied: AMI had 88%
   sensitivity, 63% specificity, and 77% positive predictive value (PPV);
   diabetes had 91% sensitivity, 86% specificity, and 71% PPV; and
   hypertension had 94% sensitivity, 32% specificity, and 72% PPV. Compared
   with ICD codes, the LLM-based method demonstrated improved sensitivity
   and negative predictive value across all conditions. The monthly
   percentage trends from the detected cases by LLM and reference standard
   showed consistent patterns.
   CONCLUSION: The proposed LLM-based pipeline demonstrated reasonable
   accuracy and high efficiency in disease detection for multiple
   conditions. Human expert knowledge can be integrated into the pipeline
   to guide EHR note analysis without manually curated labels. The method
   could enable comprehensive real-time disease surveillance using EHRs.
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-04-11
UT MEDLINE:40198990
PM 40198990
ER

PT J
AU Seifen, Christopher
   Bahr-Hamm, Katharina
   Gouveris, Haralampos
   Pordzik, Johannes
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Simulation-Based Evaluation of Large Language Models for Comorbidity
   Detection in Sleep Medicine - a Pilot Study on ChatGPT o1 Preview
SO NATURE AND SCIENCE OF SLEEP
VL 17
BP 677
EP 688
DI 10.2147/NSS.S510254
DT Article
PD 2025
PY 2025
AB Purpose: Timely identification of comorbidities is critical in sleep
   medicine, where large language models (LLMs) like ChatGPT are currently
   emerging as transformative tools. Here, we investigate whether the novel
   LLM ChatGPT o1 preview can identify individual health risks or
   potentially existing comorbidities from the medical data of fictitious
   sleep medicine patients. Methods: We conducted a simulation-based study
   using 30 fictitious patients, designed to represent realistic variations
   in demographic and clinical parameters commonly seen in sleep medicine.
   Each profile included personal data (eg, body mass index, smoking
   status, drinking habits), blood pressure, and routine blood test
   results, along with a predefined sleep medicine diagnosis. Each patient
   profile was evaluated independently by the LLM and a sleep medicine
   specialist (SMS) for identification of potential comorbidities or
   individual health risks. Their recommendations were compared for
   concordance across lifestyle changes and further medical measures.
   Results: The LLM achieved high concordance with the SMS for lifestyle
   modification recommendations, including 100% concordance on smoking
   cessation (kappa = 1; p < 0.001), 97% on alcohol reduction (kappa =
   0.92; p < 0.001) and endocrinological examination (kappa = 0.92; p <
   0.001) or 93% on weight loss (kappa = 0.86; p < 0.001). However, it
   exhibited a tendency to over-recommend further medical measures
   (particularly 57% concordance for cardiological examination (kappa =
   0.08; p = 0.28) and 33% for gastrointestinal examination (kappa = 0.1; p
   = 0.22)) compared to the SMS. Conclusion: Despite the obvious limitation
   of using fictitious data, the findings suggest that LLMs like ChatGPT
   have the potential to complement clinical workflows in sleep medicine by
   identifying individual health risks and comorbidities. As LLMs continue
   to evolve, their integration into healthcare could redefine the approach
   to patient evaluation and risk stratification. Future research should
   contextualize the findings within broader clinical applications ideally
   testing locally run LLMs meeting data protection requirements.
ZA 0
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-05-10
UT WOS:001480706400001
PM 40321662
ER

PT J
AU Schwartz, Ilan S.
   Link, Katherine E.
   Daneshjou, Roxana
   Cortes-Penfield, Nicolas
TI Black Box Warning: Large Language Models and the Future of Infectious
   Diseases Consultation
SO CLINICAL INFECTIOUS DISEASES
VL 78
IS 4
BP 860
EP 866
DI 10.1093/cid/ciad633
EA NOV 2023
DT Article
PD APR 10 2024
PY 2024
AB Large language models (LLMs) are artificial intelligence systems trained
   by deep learning algorithms to process natural language and generate
   text responses to user prompts. Some approach physician performance on a
   range of medical challenges, leading some proponents to advocate for
   their potential use in clinical consultation and prompting some
   consternation about the future of cognitive specialties. However, LLMs
   currently have limitations that preclude safe clinical deployment in
   performing specialist consultations, including frequent confabulations,
   lack of contextual awareness crucial for nuanced diagnostic and
   treatment plans, inscrutable and unexplainable training data and
   methods, and propensity to recapitulate biases. Nonetheless, considering
   the rapid improvement in this technology, growing calls for clinical
   integration, and healthcare systems that chronically undervalue
   cognitive specialties, it is critical that infectious diseases
   clinicians engage with LLMs to enable informed advocacy for how they
   should-and shouldn't-be used to augment specialist care.
   Large language models (LLMs), advanced artificial intelligence systems
   capable of generating natural language, could revolutionize healthcare,
   including current models of specialist consultation. Infectious diseases
   clinicians must urgently engage with and understand limitations of LLMs
   to advocate for their responsible integration.
   Graphical Abstract
   https://tidbitapp.io/tidbits/black-box-warning-large-language-models-and
   -clinical-consultation-in-infectious-disease
ZB 10
ZR 0
TC 50
Z8 1
ZS 0
ZA 0
Z9 51
DA 2023-11-30
UT WOS:001102860600001
PM 37971399
ER

PT J
AU Huang, Kexin
   Zhang, Serena
   Wang, Hanchen
   Qu, Yuanhao
   Lu, Yingzhou
   Roohani, Yusuf
   Li, Ryan
   Qiu, Lin
   Li, Gavin
   Zhang, Junze
   Yin, Di
   Marwaha, Shruti
   Carter, Jennefer N
   Zhou, Xin
   Wheeler, Matthew
   Bernstein, Jonathan A
   Wang, Mengdi
   He, Peng
   Zhou, Jingtian
   Snyder, Michael
   Cong, Le
   Regev, Aviv
   Leskovec, Jure
TI Biomni: A General-Purpose Biomedical AI Agent.
SO bioRxiv : the preprint server for biology
DI 10.1101/2025.05.30.656746
DT Journal Article; Preprint
PD 2025 Jun 02
PY 2025
AB Biomedical research underpins progress in our understanding of human
   health and disease, drug discovery, and clinical care. However, with the
   growth of complex lab experiments, large datasets, many analytical
   tools, and expansive literature, biomedical research is increasingly
   constrained by repetitive and fragmented workflows that slow discovery
   and limit innovation, underscoring the need for a fundamentally new way
   to scale scientific expertise. Here, we introduce Biomni, a
   general-purpose biomedical AI agent designed to autonomously execute a
   wide spectrum of research tasks across diverse biomedical subfields. To
   systematically map the biomedical action space, Biomni first employs an
   action discovery agent to create the first unified agentic environment -
   mining essential tools, databases, and protocols from tens of thousands
   of publications across 25 biomedical domains. Built on this foundation,
   Biomni features a generalist agentic architecture that integrates large
   language model (LLM) reasoning with retrieval-augmented planning and
   code-based execution, enabling it to dynamically compose and carry out
   complex biomedical workflows - entirely without relying on predefined
   templates or rigid task flows. Systematic benchmarking demonstrates that
   Biomni achieves strong generalization across heterogeneous biomedical
   tasks - including causal gene prioritization, drug repurposing, rare
   disease diagnosis, micro-biome analysis, and molecular cloning - without
   any task-specific prompt tuning. Real-world case studies further
   showcase Biomni's ability to interpret complex, multi-modal biomedical
   datasets and autonomously generate experimentally testable protocols.
   Biomni envisions a future where virtual AI biologists operate alongside
   and augment human scientists to dramatically enhance research
   productivity, clinical insight, and healthcare. Biomni is ready to use
   at https://biomni.stanford.edu , and we invite scientists to explore its
   capabilities, stress-test its limits, and co-create the next era of
   biomedical discoveries.
ZR 0
Z8 0
ZS 0
ZA 0
ZB 0
TC 0
Z9 0
DA 2025-06-14
UT MEDLINE:40501924
PM 40501924
ER

PT J
AU Shi, Michael
   Hanna, Jovana
   Clavell, Christine
   Eid, Kevin
   Eid, Alen
   Ghorayeb, Ghassan
   John Nguyen
TI Assessing Readability of Patient Education Materials: A Comparative
   Study of ASRS Resources and AI-Generated Content by Popular Large
   Language Models (ChatGPT 4.0 and Google Bard)
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 5646
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZS 0
ZR 0
ZB 0
Z8 0
TC 3
ZA 0
Z9 3
DA 2024-11-30
UT WOS:001313316206217
ER

PT J
AU Sabanayagam, Charumathi
   Banu, Riswana
   Lim, Cynthia
   Tham, Yih Chung
   Cheng, Ching-Yu
   Tan, Gavin
   Ekinci, Elif
   Sheng, Bin
   Mckay, Gareth
   Shaw, Jonathan E.
   Matsushita, Kunihiro
   Tangri, Navdeep
   Choo, Jason
   Wong, Tien Y.
TI Artificial intelligence in chronic kidney disease management: a scoping
   review
SO THERANOSTICS
VL 15
IS 10
BP 4566
EP 4578
DI 10.7150/thno.108552
DT Review
PD 2025
PY 2025
AB Rationale: Chronic kidney disease (CKD) is a major public health problem
   worldwide associated with cardiovascular disease, renal failure, and
   mortality. To effectively address this growing burden, innovative
   solutions to management are urgently required. We conducted a scoping
   review to identify key use cases in which artificial intelligence (AI)
   could be leveraged for improving management of CKD. Additionally, we
   examined the challenges faced by AI in CKD management, proposed
   potential solutions to overcome these barriers. Methods: We reviewed 41
   articles published between 2014-2024 which examined various AI
   techniques including machine learning (ML) and deep learning (DL),
   unsupervised clustering, digital twin, natural language processing (NLP)
   and large language models (LLMs) in CKD management. We focused on four
   areas: early detection, risk stratification and prediction, treatment
   recommendations and patient care and communication. Results: We
   identified 41 articles published between 2014-2024 that assessed
   image-based DL models for early detection (n = 6), ML models for risk
   stratification and prediction (n = 14) and treatment recommendations (n
   = 4), and NLP and LLMs for patient care and communication (n = 17). Key
   challenges in integrating AI models into healthcare include technical
   issues such as data quality and access, model accuracy, and
   interpretability, alongside adoption barriers like workflow integration,
   user training, and regulatory approval. Conclusions: There is tremendous
   potential of integrating AI into clinical care of CKD patients to enable
   early detection, prediction, and improved patient outcomes.
   Collaboration among healthcare providers, researchers, regulators, and
   industries is crucial to developing robust protocols that ensure
   compliance with legal standards, while minimizing risks and maintaining
   patient
Z8 0
ZA 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-05-02
UT WOS:001473295700018
PM 40225559
ER

PT J
AU Huppertz, Marc Sebastian
   Siepmann, Robert
   Topp, David
   Nikoubashman, Omid
   Yueksel, Can
   Kuhl, Christiane Katharina
   Truhn, Daniel
   Nebelung, Sven
TI Revolution or risk?-Assessing the potential and challenges of GPT-4V in
   radiologic image interpretation
SO EUROPEAN RADIOLOGY
VL 35
IS 3
BP 1111
EP 1121
DI 10.1007/s00330-024-11115-6
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB ObjectivesChatGPT-4 Vision (GPT-4V) is a state-of-the-art multimodal
   large language model (LLM) that may be queried using images. We aimed to
   evaluate the tool's diagnostic performance when autonomously assessing
   clinical imaging studies.Materials and methodsA total of 206 imaging
   studies (i.e., radiography (n = 60), CT (n = 60), MRI (n = 60), and
   angiography (n = 26)) with unequivocal findings and established
   reference diagnoses from the radiologic practice of a large university
   hospital were accessed. Readings were performed uncontextualized, with
   only the image provided, and contextualized, with additional clinical
   and demographic information. Responses were assessed along multiple
   diagnostic dimensions and analyzed using appropriate statistical
   tests.ResultsWith its pronounced propensity to favor context over image
   information, the tool's diagnostic accuracy improved from 8.3%
   (uncontextualized) to 29.1% (contextualized, first diagnosis correct)
   and 63.6% (contextualized, correct diagnosis among differential
   diagnoses) (p <= 0.001, Cochran's Q test). Diagnostic accuracy declined
   by up to 30% when 20 images were re-read after 30 and 90 days and seemed
   unrelated to the tool's self-reported confidence (Spearman's rho = 0.117
   (p = 0.776)). While the described imaging findings matched the suggested
   diagnoses in 92.7%, indicating valid diagnostic reasoning, the tool
   fabricated 258 imaging findings in 412 responses and misidentified
   imaging modalities or anatomic regions in 65 images.ConclusionGPT-4V, in
   its current form, cannot reliably interpret radiologic images. Its
   tendency to disregard the image, fabricate findings, and misidentify
   details, especially without clinical context, may misguide healthcare
   providers and put patients at risk.Key PointsQuestionCan Generative
   Pre-trained Transformer 4 Vision (GPT-4V) interpret radiologic
   images-with and without clinical context?FindingsGPT-4V performed
   poorly, demonstrating diagnostic accuracy rates of 8%
   (uncontextualized), 29% (contextualized, most likely diagnosis correct),
   and 64% (contextualized, correct diagnosis among differential
   diagnoses).Clinical relevanceThe utility of commercial multimodal large
   language models, such as GPT-4V, in radiologic practice is limited.
   Without clinical context, diagnostic errors and fabricated findings may
   compromise patient safety and misguide clinical decision-making. These
   models must be further refined to be beneficial.Key PointsQuestionCan
   Generative Pre-trained Transformer 4 Vision (GPT-4V) interpret
   radiologic images-with and without clinical context?FindingsGPT-4V
   performed poorly, demonstrating diagnostic accuracy rates of 8%
   (uncontextualized), 29% (contextualized, most likely diagnosis correct),
   and 64% (contextualized, correct diagnosis among differential
   diagnoses).Clinical relevanceThe utility of commercial multimodal large
   language models, such as GPT-4V, in radiologic practice is limited.
   Without clinical context, diagnostic errors and fabricated findings may
   compromise patient safety and misguide clinical decision-making. These
   models must be further refined to be beneficial.Key PointsQuestionCan
   Generative Pre-trained Transformer 4 Vision (GPT-4V) interpret
   radiologic images-with and without clinical context?FindingsGPT-4V
   performed poorly, demonstrating diagnostic accuracy rates of 8%
   (uncontextualized), 29% (contextualized, most likely diagnosis correct),
   and 64% (contextualized, correct diagnosis among differential
   diagnoses).
   Clinical relevanceThe utility of commercial multimodal large language
   models, such as GPT-4V, in radiologic practice is limited. Without
   clinical context, diagnostic errors and fabricated findings may
   compromise patient safety and misguide clinical decision-making. These
   models must be further refined to be beneficial.
ZA 0
Z8 0
ZR 0
TC 2
ZB 0
ZS 0
Z9 2
DA 2024-10-28
UT WOS:001339015800003
PM 39422726
ER

PT J
AU Abi-Rafeh, Jad
   Mroueh, Vanessa J.
   Bassiri-Tehrani, Brian
   Marks, Jacob
   Kazan, Roy
   Nahai, Foad
TI Complications Following Body Contouring: Performance Validation of Bard,
   a Novel AI Large Language Model, in Triaging and Managing Postoperative
   Patient Concerns
SO AESTHETIC PLASTIC SURGERY
VL 48
IS 5
BP 953
EP 976
DI 10.1007/s00266-023-03819-9
EA JAN 2024
DT Article
PD MAR 2024
PY 2024
AB Introduction Large language models (LLM) have revolutionized the way
   humans interact with artificial intelligence (AI) technology, with
   marked potential for applications in esthetic surgery. The present study
   evaluates the performance of Bard, a novel LLM, in identifying and
   managing postoperative patient concerns for complications following body
   contouring surgery.Methods The American Society of Plastic Surgeons'
   website was queried to identify and simulate all potential postoperative
   complications following body contouring across different acuities and
   severity. Bard's accuracy was assessed in providing a differential
   diagnosis, soliciting a history, suggesting a most-likely diagnosis,
   appropriate disposition, treatments/interventions to begin from home,
   and red-flag signs/symptoms indicating deterioration, or requiring
   urgent emergency department (ED) presentation.Results Twenty-two
   simulated body contouring complications were examined. Overall, Bard
   demonstrated a 59% accuracy in listing relevant diagnoses on its
   differentials, with a 52% incidence of incorrect or misleading
   diagnoses. Following history-taking, Bard demonstrated an overall
   accuracy of 44% in identifying the most-likely diagnosis, and a 55%
   accuracy in suggesting the indicated medical dispositions. Helpful
   treatments/interventions to begin from home were suggested with a 40%
   accuracy, whereas red-flag signs/symptoms, indicating deterioration,
   were shared with a 48% accuracy. A detailed analysis of performance,
   stratified according to latency of postoperative presentation (<48hours,
   48hours-1month, or >1month postoperatively), and according to acuity and
   indicated medical disposition, is presented herein.Conclusions Despite
   promising potential of LLMs and AI in healthcare-related applications,
   Bard's performance in the present study significantly falls short of
   accepted clinical standards, thus indicating a need for further research
   and development prior to adoption.Level of Evidence IV This journal
   requires that authors assign a level of evidence to each article. For a
   full description of these Evidence-Based Medicine ratings, please refer
   to the Table of Contents or the online Instructions to Authors
   www.springer.com/00266.
ZS 0
ZB 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-02-03
UT WOS:001150315000001
PM 38273152
ER

PT J
AU Barat, Maxime
   Crombe, Amandine
   Boeken, Tom
   Dacher, Jean-Nicolas
   Si-Mohamed, Salim
   Dohan, Anthony
   Chassagnon, Guillaume
   Lecler, Augustin
   Greffier, Joel
   Nougaret, Stephanie
   Soyer, Philippe
TI Imaging in France: 2024 Update
SO CANADIAN ASSOCIATION OF RADIOLOGISTS JOURNAL-JOURNAL DE L ASSOCIATION
   CANADIENNE DES RADIOLOGISTES
VL 76
IS 2
BP 221
EP 231
DI 10.1177/08465371241288425
DT Review
PD MAY 2025
PY 2025
AB Radiology in France has made major advances in recent years through
   innovations in research and clinical practice. French institutions have
   developed innovative imaging techniques and artificial intelligence
   applications in the field of diagnostic imaging and interventional
   radiology. These include, but are not limited to, a more precise
   diagnosis of cancer and other diseases, research in dual-energy and
   photon-counting computed tomography, new applications of artificial
   intelligence, and advanced treatments in the field of interventional
   radiology. This article aims to explore the major research initiatives
   and technological advances that are shaping the landscape of radiology
   in France. By highlighting key contributions in diagnostic imaging,
   artificial intelligence, and interventional radiology, we provide a
   comprehensive overview of how these innovations are improving patient
   outcomes, enhancing diagnostic accuracy, and expanding the possibilities
   for minimally invasive therapies. As the field continues to evolve,
   France's position at the forefront of radiological research ensures that
   these innovations will play a central role in addressing current
   healthcare challenges and improving patient care on a global scale.
   La radiologie en France a r & eacute;alis & eacute; des progr & egrave;s
   majeurs durant ces derni & egrave;res ann & eacute;es gr & acirc;ce &
   agrave; des innovations dans les domaines de la recherche et de la
   clinique. Les institutions m & eacute;dicales fran & ccedil;aises ont d
   & eacute;velopp & eacute; des techniques innovantes et des applications
   d'intelligence artificielle dans le domaine de l'imagerie diagnostique
   et de la radiologie interventionnelle. Celles-ci incluent, de mani &
   egrave;re non exhaustive, un diagnostic plus pr & eacute;cis du cancer
   et d'autres maladies, la recherche fondamentale et clinique en
   tomodensitom & eacute;trie & agrave; double & eacute;nergie et par
   comptage photonique, de nouvelles applications de l'intelligence
   artificielle et de nouveaux traitements dans le domaine de la radiologie
   interventionnelle. Cet article vise & agrave; rapporter les grandes
   initiatives de recherche et les avanc & eacute;es technologiques qui fa
   & ccedil;onnent le paysage de la radiologie en France. En mettant en &
   eacute;vidence les contributions cl & eacute;s en imagerie diagnostique,
   en intelligence artificielle et en radiologie interventionnelle, cet
   article donne un aper & ccedil;u complet de la mani & egrave;re dont ces
   innovations am & eacute;liorent les r & eacute;sultats pour les
   patients, am & eacute;liorent la pr & eacute;cision du diagnostic et &
   eacute;largissent les possibilit & eacute;s de th & eacute;rapies
   mini-invasives. La position de la France & agrave; l'avant-garde de la
   recherche radiologique garantit que ces innovations joueront un r &
   ocirc;le central pour relever les d & eacute;fis actuels en mati &
   egrave;re de sant & eacute; et am & eacute;liorer les soins des patients
   & agrave; l'& eacute;chelle mondiale.
ZS 0
TC 1
ZR 0
ZA 0
ZB 0
Z8 0
Z9 1
DA 2025-03-21
UT WOS:001442832300009
PM 39367786
ER

PT J
AU Wali, Tursun
   Bolatbekov, Almat
   Maimaitijiang, Ehesan
   Salman, Dilbar
   Mamatjan, Yasin
TI A novel recommender framework with chatbot to stratify heart attack
   risk.
SO Discover medicine
VL 1
IS 1
BP 161
EP 161
DI 10.1007/s44337-024-00174-9
DT Journal Article
PD 2024
PY 2024
AB Cardiovascular diseases are a major cause of mortality and morbidity.
   Fast detection of life-threatening emergency events and an earlier start
   of the therapy would save many lives and reduce successive disabilities.
   Understanding the specific risk factors associated with heart attack and
   the degree of association is crucial in the clinical diagnosis.
   Considering the potential benefits of intelligent models in healthcare,
   many researchers have developed a variety of machine learning (ML)-based
   models to identify patients at risk of a heart attack. However, the
   common problem of previous works that used ML concepts was the lack of
   transparency in black-box models, which makes it difficult to understand
   how the model made the prediction. In this study, an automated smart
   recommender system (Explainable Artificial Intelligence) for heart
   attack prediction and risk stratification was developed. For the
   purpose, the CatBoost classifier was applied as the initial step. Then,
   the SHAP (SHapley Additive exPlanation) explainable algorithm was
   employed to determine reasons behind high or low risk classification.
   The recommender system can provide insights into the reasoning behind
   the predictions, including group-based and patient-specific
   explanations. In the final step, we integrated a Large Language Model
   (LLM) called BioMistral for chatting functionally to talk to users based
   on the model output as a digital doctor for consultation. Our smart
   recommender system achieved high accuracy in predicting a patient risk
   level with an average AUC of 0.88 and can explain the results
   transparently. Moreover, a Django-based online application that uses
   patient data to update medical information about an individual's heart
   attack risk was created. The LLM chatbot component would answer user
   questions about heart attacks and serve as a virtual companion on the
   route to heart health, our system also can locate nearby hospitals by
   applying Google Maps API and alert the users. The recommender system
   could improve patient management and lower heart attack risk while
   timely therapy aids in avoiding subsequent disabilities.
ZB 0
ZS 0
ZR 0
TC 0
ZA 0
Z8 0
Z9 0
DA 2025-01-09
UT MEDLINE:39759423
PM 39759423
ER

PT J
AU Olszewski, Robert
   Watros, Klaudia
   Manczak, Malgorzata
   Owoc, Jakub
   Jeziorski, Krzysztof
   Brzezinski, Jakub
TI Assessing the response quality and readability of chatbots in
   cardiovascular health, oncology, and psoriasis: A comparative study
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 190
AR 105562
DI 10.1016/j.ijmedinf.2024.105562
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background: Chatbots using the Large Language Model (LLM) generate human
   responses to questions from all categories. Due to staff shortages in
   healthcare systems, patients waiting for an appointment increasingly use
   chatbots to get information about their condition. Given the number of
   chatbots currently available, assessing the responses they generate is
   essential. Methods: Five chatbots with free access were selected
   (Gemini, Microsoft Copilot, PiAI, ChatGPT, ChatSpot) and blinded using
   letters (A, B, C, D, E). Each chatbot was asked questions about
   cardiology, oncology, and psoriasis. Responses were compared to
   guidelines from the European Society of Cardiology, American Academy of
   Dermatology and American Society of Clinical Oncology. All answers were
   assessed using readability scales (Flesch Reading Scale, Gunning Fog
   Scale Level, Flesch-Kincaid Grade Level and Dale-Chall Score). Using a
   3point Likert scale, two independent medical professionals assessed the
   compliance of the responses with the guidelines. Results: A total of 45
   questions were asked of all chatbots. Chatbot C gave the shortest
   answers, 7.0 (6.0 - 8.0), and Chatbot A the longest 17.5 (13.0 - 24.5).
   The Flesch Reading Ease Scale ranged from 16.3 (12.2 - 21.9) (Chatbot D)
   to 39.8 (29.0 - 50.4) (Chatbot A). Flesch-Kincaid Grade Level ranged
   from 12.5 (10.6 - 14.6) (Chatbot A) to 15.9 (15.1 - 17.1) (Chatbot D).
   Gunning Fog Scale Level ranged from 15.77 (Chatbot A) to 19.73 (Chatbot
   D). Dale-Chall Score ranged from 10.3 (9.3 - 11.3) (Chatbot A) to 11.9
   (11.5 - 12.4) (Chatbot D). Conclusion: This study indicates that
   chatbots vary in length, quality, and readability. They answer each
   question in their own way, based on the data they have pulled from the
   web. Reliability of the responses generated by chatbots is high. This
   suggests that people who want information from a chatbot need to be
   careful and verify the answers they receive, particularly when they ask
   about medical and health aspects.
ZS 0
ZR 0
TC 3
Z8 1
ZB 0
ZA 0
Z9 4
DA 2024-08-07
UT WOS:001281403200001
PM 39059084
ER

PT J
AU Zhang, Junxiu
   Ma, Yao
   Zhang, Rong
   Chen, Yanhua
   Xu, Mengyao
   Su, Rina
   Ma, Ke
TI A comparative study of GPT-4o and human ophthalmologists in glaucoma
   diagnosis
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30385
DI 10.1038/s41598-024-80917-x
DT Article
PD DEC 5 2024
PY 2024
AB Artificial intelligence (AI), particularly large language models like
   GPT-4o, holds promise for enhancing diagnostic accuracy in healthcare.
   This study evaluates the diagnostic performance of GPT-4o compared to
   human ophthalmologists in glaucoma cases. A prospective, observational
   study was conducted at a tertiary care ophthalmology center. Twenty-six
   glaucoma cases, including both primary and secondary types, were
   selected from publicly available databases and institutional records.
   The cases were analyzed by GPT-4o and three ophthalmologists with
   varying levels of experience. The accuracy and completeness of primary
   and differential diagnoses were assessed using 10-point and 6-point
   Likert scales, respectively. Statistical analyses were performed using
   nonparametric methods, including the Kruskal-Wallis and Mann-Whitney U
   tests. GPT-4o was significantly less accurate in primary diagnosis
   compared to human ophthalmologists. Specifically, GPT-4o achieved a mean
   score of 5.500 (p < 0.001) compared to Doctor C, who had the highest
   score of 8.038 (p < 0.001). Completeness scores for GPT-4o 3.077 (p <
   0.001) were also lower than Doctor B, who had the lowest score of 3.615
   (p < 0.001) among human ophthalmologists. However, for differential
   diagnosis, GPT-4o (7.577) showed comparable accuracy to Doctor A (7.615)
   and Doctor C (7.673) (p < 0.0001) while achieving the highest
   completeness score (4.096), outperforming Doctor C (3.846), Doctor A
   (2.923), and Doctor B (2.808) (p < 0.0001). AI, including GPT-4o, is
   currently not an acceptable standalone method for diagnosing glaucoma
   due to its lower accuracy compared to human clinicians. These findings
   suggest that GPT-4o could serve as a valuable adjunct in clinical
   practice, particularly in complex cases, but should not replace human
   expertise, especially for initial diagnoses. Future improvements in AI
   models could enhance their utility in ophthalmology.
Z8 0
ZS 0
TC 1
ZA 0
ZR 0
ZB 0
Z9 1
DA 2024-12-21
UT WOS:001373816800044
PM 39639068
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT J
AU Zheng, Ce
   Ye, Hongfei
   Guo, Jinming
   Yang, Junrui
   Fei, Ping
   Yuan, Yuanzhi
   Huang, Danqing
   Huang, Yuqiang
   Peng, Jie
   Xie, Xiaoling
   Xie, Meng
   Zhao, Peiquan
   Chen, Li
   Zhang, Mingzhi
TI Development and evaluation of a large language model of ophthalmology in
   Chinese
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1390
EP 1397
DI 10.1136/bjo-2023-324526
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background Large language models (LLMs), such as ChatGPT, have
   considerable implications for various medical applications. However,
   ChatGPT's training primarily draws from English-centric internet data
   and is not tailored explicitly to the medical domain. Thus, an
   ophthalmic LLM in Chinese is clinically essential for both healthcare
   providers and patients in mainland China.
   Methods We developed an LLM of ophthalmology (MOPH) using Chinese
   corpora and evaluated its performance in three clinical scenarios:
   ophthalmic board exams in Chinese, answering evidence-based
   medicine-oriented ophthalmic questions and diagnostic accuracy for
   clinical vignettes. Additionally, we compared MOPH's performance to that
   of human doctors.
   Results In the ophthalmic exam, MOPH's average score closely aligned
   with the mean score of trainees (64.7 (range 62-68) vs 66.2 (range
   50-92), p=0.817), but achieving a score above 60 in all seven mock
   exams. In answering ophthalmic questions, MOPH demonstrated an adherence
   of 83.3% (25/30) of responses following Chinese guidelines (Likert scale
   4-5). Only 6.7% (2/30, Likert scale 1-2) and 10% (3/30, Likert scale 3)
   of responses were rated as 'poor or very poor' or 'potentially
   misinterpretable inaccuracies' by reviewers. In diagnostic accuracy,
   although the rate of correct diagnosis by ophthalmologists was superior
   to that by MOPH (96.1% vs 81.1%, p>0.05), the difference was not
   statistically significant.
   Conclusion This study demonstrated the promising performance of MOPH, a
   Chinese-specific ophthalmic LLM, in diverse clinical scenarios. MOPH has
   potential real-world applications in Chinese-language ophthalmology
   settings.
ZS 0
ZA 0
TC 4
ZR 0
Z8 0
ZB 0
Z9 4
DA 2024-07-29
UT WOS:001274616900001
PM 39019566
ER

PT J
AU Guo, Edward
   Gupta, Mehul
   Sinha, Sarthak
   Roessler, Karl
   Tatagiba, Marcos
   Akagami, Ryojo
   Al-Mefty, Ossama
   Sugiyama, Taku
   Stieg, Philip E.
   Pickett, Gwynedd E.
   de Lotbiniere-Bassett, Madeleine
   Singh, Rahul
   Lama, Sanju
   Sutherland, Garnette R.
TI neuroGPT-X: toward a clinic-ready large language model
SO JOURNAL OF NEUROSURGERY
VL 140
IS 4
BP 1041
EP 1053
DT Article
PD APR 2024
PY 2024
AB OBJECTIVE The objective was to assess the performance of a
   context-enriched large language model (LLM) compared with international
   neurosurgical experts on questions related to the management of
   vestibular schwannoma. Furthermore, another objective was to develop a
   chat-based platform incorporating in-text citations, references, and
   memory to enable accurate, relevant, and reliable information in real
   time. METHODS The analysis involved 1) creating a data set through web
   scraping, 2) developing a chat-based platform called neuroGPT-X, 3)
   enlisting 8 expert neurosurgeons across international centers to
   independently create questions (n = 1) and to answer (n = 4) and
   evaluate responses (n = 3) while blinded, and 4) analyzing the
   evaluation results on the management of vestibular schwannoma. In the
   blinded phase, all answers were assessed for accuracy, coherence,
   relevance, thoroughness, speed, and overall rating. All experts were
   unblinded and provided their thoughts on the utility and limitations of
   the tool. In the unblinded phase, all neurosurgeons provided answers to
   a Likert scale survey and longanswer questions regarding the clinical
   utility, likelihood of use, and limitations of the tool. The tool was
   then evaluated on the basis of a set of 103 consensus statements on
   vestibular schwannoma care from the 8th Quadrennial International
   Conference on Vestibular Schwannoma. RESULTS Responses from the naive
   and context-enriched Generative Pretrained Transformer (GPT) models were
   consistently rated not significantly different in terms of accuracy,
   coherence, relevance, thoroughness, and overall performance, and they
   were often rated significantly higher than expert responses. Both the
   naive and content-enriched GPT models provided faster responses to the
   standardized question set than expert neurosurgeon respondents (p <
   0.01). The context-enriched GPT model agreed with 98 of the 103 (95%)
   consensus statements. Of interest, all expert surgeons expressed
   concerns about the reliability of GPT in accurately addressing the
   nuances and controversies surrounding the management of vestibular
   schwannoma. Furthermore, the authors developed neuroGPT-X, a chat-based
   platform designed to provide point-of-care clinical support and mitigate
   the limitations of human memory. neuroGPT-X incorporates features such
   as in-text citations and references to enable accurate, relevant, and
   reliable information in real time. CONCLUSIONS The present study, with
   its subspecialist-level performance in generating written responses to
   complex neurosurgical problems for which evidence-based consensus for
   management is lacking, suggests that context-enriched LLMs show promise
   as a point-of-care medical resource. The authors anticipate that this
   work will be a springboard for expansion into more medical specialties,
   incorporating evidence-based clinical information and developing
   expert-level dialogue surrounding LLMs in healthcare.
ZB 2
ZS 0
Z8 1
ZR 0
TC 10
ZA 0
Z9 11
DA 2024-06-30
UT WOS:001251735100004
PM 38564804
ER

PT J
AU Cosma, Claudia
   Radi, Alessio
   Cattano, Rachele
   Zanobini, Patrizio
   Bonaccorsi, Guglielmo
   Lorini, Chiara
   Del Riccio, Marco
TI Exploring Chatbot contributions to enhancing vaccine literacy and
   uptake: A scoping review of the literature
SO VACCINE
VL 44
AR 126559
DI 10.1016/j.vaccine.2024.126559
EA NOV 2024
DT Review
PD JAN 12 2025
PY 2025
AB Background: The increasing integration of chatbots across various
   sectors marks a significant shift in digital communication, and their
   role in healthcare makes no exception. This scoping review aims to
   systematically examine the role of chatbots in the perspective of
   organizational vaccine literacy, particularly in enhancing vaccine
   literacy and facilitating the dissemination of vaccine-related
   information, evaluating the potential of chatbots to transform
   vaccination communication strategies and improve health education
   outcomes. Methods: This scoping review adhered to the Joanna Briggs
   Institute methodology and the PRISMA-ScR checklist. A systematic search
   of MEDLINE, Embase, Scopus, and PsycInfo was conducted from January 2020
   to October 30, 2024, using keywords related to "chatbots" and
   "vaccination." Study selection involved a two-stage screening process,
   focusing on studies reporting the use of chatbots to improve vaccine
   literacy and uptake. Data were thematically analyzed and presented in a
   narrative format. Results: Twenty-two studies were included in the
   review: these studies demonstrate the effectiveness of chatbots in
   enhancing vaccine literacy and acceptance, mainly focusing on COVID-19
   but also addressing HPV and childhood vaccinations. They highlight
   chatbots' role in improving the vaccine-literate environment through
   countering misinformation and improving communication with healthcare
   professionals, showcasing their potential to significantly influence
   public health outcomes and their adaptability to diverse populations and
   geographic regions. Conclusions: These digital assistants could provide
   personalized and up-to-date information, improving not only knowledge
   but also attitudes and intentions towards vaccinations.
ZB 0
Z8 0
ZS 0
TC 2
ZA 0
ZR 0
Z9 2
DA 2024-12-13
UT WOS:001371923900001
PM 39615346
ER

PT J
AU Fonseca, Angelo
   Ferreira, Axel
   Ribeiro, Luis
   Moreira, Sandra
   Duque, Cristina
TI Embracing the future-is artificial intelligence already better? A
   comparative study of artificial intelligence performance in diagnostic
   accuracy and decision-making
SO EUROPEAN JOURNAL OF NEUROLOGY
VL 31
IS 4
DI 10.1111/ene.16195
EA JAN 2024
DT Article
PD APR 2024
PY 2024
AB Background and purposeThe integration of artificial intelligence (AI) in
   healthcare has the potential to revolutionize patient care and clinical
   decision-making. This study aimed to explore the reliability of large
   language models in neurology by comparing the performance of an AI
   chatbot with neurologists in diagnostic accuracy and
   decision-making.MethodsA cross-sectional observational study was
   conducted. A pool of clinical cases from the American Academy of
   Neurology's Question of the Day application was used as the basis for
   the study. The AI chatbot used was ChatGPT, based on GPT-3.5. The
   results were then compared to neurology peers who also answered the
   questions-a mean of 1500 neurologists/neurology residents.ResultsThe
   study included 188 questions across 22 different categories. The AI
   chatbot demonstrated a mean success rate of 71.3% in providing correct
   answers, with varying levels of proficiency across different neurology
   categories. Compared to neurology peers, the AI chatbot performed at a
   similar level, with a mean success rate of 69.2% amongst peers.
   Additionally, the AI chatbot achieved a correct diagnosis in 85.0% of
   cases and it provided an adequate justification for its correct
   responses in 96.1%.ConclusionsThe study highlights the potential of AI,
   particularly large language models, in assisting with clinical reasoning
   and decision-making in neurology and emphasizes the importance of AI as
   a complementary tool to human expertise. Future advancements and
   refinements are needed to enhance the AI chatbot's performance and
   broaden its application across various medical specialties.
ZA 0
ZS 0
Z8 0
ZB 0
ZR 0
TC 7
Z9 7
DA 2024-01-24
UT WOS:001144093900001
PM 38235841
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT J
AU Kee, Xiang Lee Jamie
   Sng, Gerald Gui Ren
   Lim, Daniel Yan Zheng
   Tung, Joshua Yi Min
   Abdullah, Hairil Rizal
   Chowdury, Anupama Roy
TI Use of a large language model with instruction-tuning for reliable
   clinical frailty scoring
SO JOURNAL OF THE AMERICAN GERIATRICS SOCIETY
VL 72
IS 12
BP 3849
EP 3854
DI 10.1111/jgs.19114
EA AUG 2024
DT Article
PD DEC 2024
PY 2024
AB BackgroundFrailty is an important predictor of health outcomes,
   characterized by increased vulnerability due to physiological decline.
   The Clinical Frailty Scale (CFS) is commonly used for frailty assessment
   but may be influenced by rater bias. Use of artificial intelligence
   (AI), particularly Large Language Models (LLMs) offers a promising
   method for efficient and reliable frailty scoring.MethodsThe study
   utilized seven standardized patient scenarios to evaluate the
   consistency and reliability of CFS scoring by OpenAI's GPT-3.5-turbo
   model. Two methods were tested: a basic prompt and an instruction-tuned
   prompt incorporating CFS definition, a directive for accurate responses,
   and temperature control. The outputs were compared using the
   Mann-Whitney U test and Fleiss' Kappa for inter-rater reliability. The
   outputs were compared with historic human scores of the same
   scenarios.ResultsThe LLM's median scores were similar to human raters,
   with differences of no more than one point. Significant differences in
   score distributions were observed between the basic and
   instruction-tuned prompts in five out of seven scenarios. The
   instruction-tuned prompt showed high inter-rater reliability (Fleiss'
   Kappa of 0.887) and produced consistent responses in all scenarios.
   Difficulty in scoring was noted in scenarios with less explicit
   information on activities of daily living (ADLs).ConclusionsThis study
   demonstrates the potential of LLMs in consistently scoring clinical
   frailty with high reliability. It demonstrates that prompt engineering
   via instruction-tuning can be a simple but effective approach for
   optimizing LLMs in healthcare applications. The LLM may overestimate
   frailty scores when less information about ADLs is provided, possibly as
   it is less subject to implicit assumptions and extrapolation than
   humans. Future research could explore the integration of LLMs in
   clinical research and frailty-related outcome prediction.
TC 2
ZR 0
ZB 0
ZS 0
ZA 0
Z8 0
Z9 2
DA 2024-08-13
UT WOS:001285634000001
PM 39105505
ER

PT J
AU Guillen-Grima, Francisco
   Guillen-Aguinaga, Sara
   Guillen-Aguinaga, Laura
   Alas-Brun, Rosa
   Onambele, Luc
   Ortega, Wilfrido
   Montejo, Rocio
   Aguinaga-Ontoso, Enrique
   Barach, Paul
   Aguinaga-Ontoso, Ines
TI Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical
   Residency Entrance Examination (MIR): Promising Horizons for AI in
   Clinical Medicine
SO CLINICS AND PRACTICE
VL 13
IS 6
BP 1460
EP 1487
DI 10.3390/clinpract13060130
DT Article
PD DEC 2023
PY 2023
AB The rapid progress in artificial intelligence, machine learning, and
   natural language processing has led to increasingly sophisticated large
   language models (LLMs) for use in healthcare. This study assesses the
   performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the
   MIR medical examination for access to medical specialist training in
   Spain. Our objectives included gauging the model's overall performance,
   analyzing discrepancies across different medical specialties, discerning
   between theoretical and practical questions, estimating error
   proportions, and assessing the hypothetical severity of errors committed
   by a physician. Material and methods: We studied the 2022 Spanish MIR
   examination results after excluding those questions requiring image
   evaluations or having acknowledged errors. The remaining 182 questions
   were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English.
   Logistic regression models analyzed the relationships between question
   length, sequence, and performance. We also analyzed the 23 questions
   with images, using GPT-4's new image analysis capability. Results: GPT-4
   outperformed GPT-3.5, scoring 86.81% in Spanish (p < 0.001). English
   translations had a slightly enhanced performance. GPT-4 scored 26.1% of
   the questions with images in English. The results were worse when the
   questions were in Spanish, 13.0%, although the differences were not
   statistically significant (p = 0.250). Among medical specialties, GPT-4
   achieved a 100% correct response rate in several areas, and the
   Pharmacology, Critical Care, and Infectious Diseases specialties showed
   lower performance. The error analysis revealed that while a 13.2% error
   rate existed, the gravest categories, such as "error requiring
   intervention to sustain life" and "error resulting in death", had a 0%
   rate. Conclusions: GPT-4 performs robustly on the Spanish MIR
   examination, with varying capabilities to discriminate knowledge across
   specialties. While the model's high success rate is commendable,
   understanding the error severity is critical, especially when
   considering AI's potential role in real-world medical practice and its
   implications for patient safety.
ZA 0
TC 28
Z8 0
ZS 1
ZB 6
ZR 0
Z9 28
DA 2024-01-17
UT WOS:001132385500001
PM 37987431
ER

PT J
AU Zhang, YuNing
   Dong, Yijie
   Mei, Zihan
   Hou, Yiqing
   Wei, Minyan
   Yeung, Yat Hin
   Xu, Jiale
   Hua, Qing
   Lai, LiMei
   Li, Ning
   Xia, ShuJun
   Zhou, Chun
   Zhou, JianQiao
TI Performance of large language models on benign prostatic hyperplasia
   frequently asked questions
SO PROSTATE
VL 84
IS 9
BP 807
EP 813
DI 10.1002/pros.24699
EA APR 2024
DT Article
PD JUN 2024
PY 2024
AB Background: Benign prostatic hyperplasia (BPH) is a common condition,
   yet it is challenging for the average BPH patient to find credible and
   accurate information about BPH. Our goal is to evaluate and compare the
   accuracy and reproducibility of large language models (LLMs), including
   ChatGPT-3.5, ChatGPT-4, and the New Bing Chat in responding to a BPH
   frequently asked questions (FAQs) questionnaire. Methods: A total of 45
   questions related to BPH were categorized into basic and professional
   knowledge. Three LLM-ChatGPT-3.5, ChatGPT-4, and New Bing Chat-were
   utilized to generate responses to these questions. Responses were graded
   as comprehensive, correct but inadequate, mixed with incorrect/outdated
   data, or completely incorrect. Reproducibility was assessed by
   generating two responses for each question. All responses were reviewed
   and judged by experienced urologists. Results: All three LLMs exhibited
   high accuracy in generating responses to questions, with accuracy rates
   ranging from 86.7% to 100%. However, there was no statistically
   significant difference in response accuracy among the three (p > 0.017
   for all comparisons). Additionally, the accuracy of the LLMs' responses
   to the basic knowledge questions was roughly equivalent to that of the
   specialized knowledge questions, showing a difference of less than 3.5%
   (GPT-3.5: 90% vs. 86.7%; GPT-4: 96.7% vs. 95.6%; New Bing: 96.7% vs.
   93.3%). Furthermore, all three LLMs demonstrated high reproducibility,
   with rates ranging from 93.3% to 97.8%. Conclusions: ChatGPT-3.5,
   ChatGPT-4, and New Bing Chat offer accurate and reproducible responses
   to BPH-related questions, establishing them as valuable resources for
   enhancing health literacy and supporting BPH patients in conjunction
   with healthcare professionals.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 2
TC 8
Z9 8
DA 2024-04-04
UT WOS:001194679200001
PM 38558009
ER

PT J
AU Ostrovsky, Adam M.
TI Evaluating a large language model's accuracy in chest X-ray
   interpretation for acute thoracic conditions
SO AMERICAN JOURNAL OF EMERGENCY MEDICINE
VL 93
BP 99
EP 102
DI 10.1016/j.ajem.2025.03.060
EA APR 2025
DT Article
PD JUL 2025
PY 2025
AB Background: The rapid advancement of artificial intelligence (AI) has
   great ability to impact healthcare. Chest X-rays are essential for
   diagnosing acute thoracic conditions in the emergency department (ED),
   but interpretation delays due to radiologist availability can impact
   clinical decision-making. AI models, including deep learning algorithms,
   have been explored for diagnostic support, but the potential of large
   language models (LLMs) in emergency radiology remains largely
   unexamined. Methods: This study assessed ChatGPT's feasibility in
   interpreting chest X-rays for acute thoracic conditions commonly
   encountered in the ED. A subset of 1400 images from the NIH Chest X-ray
   dataset was analyzed, representing seven pathology categories:
   Atelectasis, Effusion, Emphysema, Pneumothorax, Pneumonia, Mass, and No
   Finding. ChatGPT 4.0, utilizing the "X-Ray Interpreter" add-on, was
   evaluated for its diagnostic performance across these categories .
   Results: ChatGPT demonstrated high performance in identifying normal
   chest X-rays, with a sensitivity of 98.9 %, specificity of 93.9 %, and
   accuracy of 94.7 %. However, the model's performance varied across
   pathologies. The best results were observed in diagnosing pneumonia
   (sensitivity 76.2 %, specificity 93.7 %) and pneumothorax (sensitivity
   77.4 %, specificity 89.1 %), while performance for atelectasis and
   emphysema was lower. Conclusion: ChatGPT demonstrates potential as a
   supplementary tool for differentiating normal from abnormal chest
   X-rays, with promising results for certain pathologies like pneumonia.
   However, its diagnostic accuracy for more subtle conditions requires
   improvement. Further research integrating ChatGPT with specialized image
   recognition models could enhance its performance, offering new
   possibilities in medical imaging and education. (c) 2025 The Author.
   Published by Elsevier Inc. This is an open access article under the CC
   BY license (http:// creativecommons.org/licenses/by/4.0/).
ZA 0
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-04-12
UT WOS:001461342300001
PM 40174466
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Amini, Maziar
   Chang, Patrick
   Nguyen, Denis
   Davis, Rio O.
   Dodge, Jennifer
   Phan, Jennifer
   Buxbaum, James L.
   Sahakian, Ara B.
TI COMPARING CHATGPT3.5 AND BARD IN RECOMMENDING COLONOSCOPY INTERVALS:
   BRIDGING THE GAP IN HEALTHCARE SETTINGS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Tu1991
BP S1482
EP S1482
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2024-10-30
UT WOS:001282837706089
ER

PT J
AU Song, Jintao
   Huang, Junjie
   Liu, Ruili
TI Integrating NLP and LLMs to discover biomarkers and mechanisms in
   Alzheimer's disease
SO SLAS TECHNOLOGY
VL 31
AR 100257
DI 10.1016/j.slast.2025.100257
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB Alzheimer's disease (AD) is a progressive neurological condition
   characterized by cognitive decline, memory loss, and aberrant behaviour.
   It affects millions of people globally and is one of the main causes of
   dementia. The neurodegenerative condition known as AD has intricate,
   multifaceted mechanisms that make it difficult to comprehend and
   identify in its early stages. Conventional diagnostic techniques
   frequently fail to detect the disease in its early stages. By combining
   Natural Language Processing (NLP) and Large Language Models (LLMs), this
   research suggests a novel approach for identifying potential biomarkers
   and underlying mechanisms of AD. Clinical data is gathered from publicly
   accessible databases and healthcare facilities, including genetic
   information, neuroimaging scans, and medical records. The pre-processing
   of unstructured clinical notes involves tokenization and genetic
   profiles and neuroimaging data are normalized by Z-score normalization
   for consistency. Multi-Input Convolutional Neural Networks (MI-CNN) are
   employed to efficiently fuse diverse data sources, allowing for a
   thorough analysis. Key biomarkers linked to AD are identified and
   categorized using the Genetic Algorithm combined with Bidirectional
   Encoder Representations from Transformers (BERT) (GenBERT). By
   fine-tuning BERT's hyperparameters using genetic optimization
   approaches, GenBERT enables the effective analysis of large medical
   datasets, such as patient histories, genetic data, and clinical notes.
   The combination strategy increases feature selection and the model's
   capacity to identify minute genomic and linguistic patterns suggestive
   of AD. The goal of this integrated strategy is to provide early
   diagnostic tools and new insights into the pathogenesis of the disease,
   which could transform methods for detecting and treating AD. As it
   concerns early AD prediction, the GenBERT model performs better than
   current techniques, obtaining the highest accuracy (98.30%) and F1-score
   (0.97), as well as greater precision (0.95) and recall (0.92).
   Additionally, it demonstrates its capacity to reliably identify both
   positive and negative AD cases with sensitivity (98.65%) and specificity
   (99.73%). Overall, GenBERT offers a trustworthy and useful tool for AD
   early diagnosis.
ZA 0
ZS 0
Z8 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-03-12
UT WOS:001438158000001
PM 39988114
ER

PT J
AU Bushuven, Stefan
   Bentele, Michael
   Bentele, Stefanie
   Gerber, Bianka
   Bansbach, Joachim
   Ganter, Julian
   Trifunovic-Koenig, Milena
   Ranisch, Robert
TI "ChatGPT, Can You Help Me Save My Child's Life?" - Diagnostic Accuracy
   and Supportive Capabilities to Lay Rescuers by ChatGPT in Prehospital
   Basic Life Support and Paediatric Advanced Life Support Cases - An
   In-silico Analysis
SO JOURNAL OF MEDICAL SYSTEMS
VL 47
IS 1
AR 123
DI 10.1007/s10916-023-02019-x
DT Article
PD NOV 21 2023
PY 2023
AB BackgroundPaediatric emergencies are challenging for healthcare workers,
   first aiders, and parents waiting for emergency medical services to
   arrive. With the expected rise of virtual assistants, people will likely
   seek help from such digital AI tools, especially in regions lacking
   emergency medical services. Large Language Models like ChatGPT proved
   effective in providing health-related information and are competent in
   medical exams but are questioned regarding patient safety. Currently,
   there is no information on ChatGPT's performance in supporting parents
   in paediatric emergencies requiring help from emergency medical
   services. This study aimed to test 20 paediatric and two basic life
   support case vignettes for ChatGPT and GPT-4 performance and safety in
   children.MethodsWe provided the cases three times each to two models,
   ChatGPT and GPT-4, and assessed the diagnostic accuracy, emergency call
   advice, and the validity of advice given to parents.ResultsBoth models
   recognized the emergency in the cases, except for septic shock and
   pulmonary embolism, and identified the correct diagnosis in 94%.
   However, ChatGPT/GPT-4 reliably advised to call emergency services only
   in 12 of 22 cases (54%), gave correct first aid instructions in 9 cases
   (45%) and incorrectly advised advanced life support techniques to
   parents in 3 of 22 cases (13.6%).ConclusionConsidering these results of
   the recent ChatGPT versions, the validity, reliability and thus safety
   of ChatGPT/GPT-4 as an emergency support tool is questionable. However,
   whether humans would perform better in the same situation is uncertain.
   Moreover, other studies have shown that human emergency call operators
   are also inaccurate, partly with worse performance than ChatGPT/GPT-4 in
   our study. However, one of the main limitations of the study is that we
   used prototypical cases, and the management may differ from urban to
   rural areas and between different countries, indicating the need for
   further evaluation of the context sensitivity and adaptability of the
   model. Nevertheless, ChatGPT and the new versions under development may
   be promising tools for assisting lay first responders, operators, and
   professionals in diagnosing a paediatric emergency.Trial registrationNot
   applicable.
ZS 0
ZB 2
TC 16
Z8 0
ZR 0
ZA 0
Z9 16
DA 2023-12-17
UT WOS:001105533600001
PM 37987870
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Rauniyar, Ashish
   Hagos, Desta Haileselassie
   Jha, Debesh
   Hakegard, Jan Erik
   Bagci, Ulas
   Rawat, Danda B.
   Vlassov, Vladimir
TI Federated Learning for Medical Applications: A Taxonomy, Current Trends,
   Challenges, and Future Research Directions
SO IEEE INTERNET OF THINGS JOURNAL
VL 11
IS 5
BP 7374
EP 7398
DI 10.1109/JIOT.2023.3329061
DT Article
PD MAR 1 2024
PY 2024
AB With the advent of the Internet of Things (IoT), artificial intelligence
   (AI), machine learning (ML), and deep learning (DL) algorithms, the
   landscape of data-driven medical applications has emerged as a promising
   avenue for designing robust and scalable diagnostic and prognostic
   models from medical data. This has gained a lot of attention from both
   academia and industry, leading to significant improvements in healthcare
   quality. However, the adoption of AI-driven medical applications still
   faces tough challenges, including meeting security, privacy, and
   Quality-of-Service (QoS) standards. Recent developments in federated
   learning (FL) have made it possible to train complex machine-learned
   models in a distributed manner and have become an active research
   domain, particularly processing the medical data at the edge of the
   network in a decentralized way to preserve privacy and address security
   concerns. To this end, in this article, we explore the present and
   future of FL technology in medical applications where data sharing is a
   significant challenge. We delve into the current research trends and
   their outcomes, unraveling the complexities of designing reliable and
   scalable FL models. This article outlines the fundamental statistical
   issues in FL, tackles device-related problems, addresses security
   challenges, and navigates the complexity of privacy concerns, all while
   highlighting its transformative potential in the medical field. Our
   study primarily focuses on medical applications of FL, particularly in
   the context of global cancer diagnosis. We highlight the potential of FL
   to enable computer-aided diagnosis tools that address this challenge
   with greater effectiveness than traditional data-driven methods. Recent
   literature has shown that FL models are robust and generalize well to
   new data, which is essential for medical applications. We hope that this
   comprehensive review will serve as a checkpoint for the field,
   summarizing the current state of the art and identifying open problems
   and future research directions.
ZR 0
ZA 0
ZB 1
Z8 1
TC 51
ZS 0
Z9 52
DA 2024-06-25
UT WOS:001203463700006
ER

PT J
AU Argymbay, Mariyam
   Khan, Shams
   Ahmad, Noman
   Salih, Mira
   Mamatjan, Yasin
TI A Smart Recommender System for Stroke Risk Assessment with an Integrated
   Strokebot
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
VL 44
IS 6
BP 799
EP 808
DI 10.1007/s40846-024-00922-3
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB PurposeWe present a machine learning-based online recommendation system
   for stroke risk assessments. With this tool, users will be able to take
   proactive steps in managing their health by predicting stroke risk based
   on diverse data input, providing transparent and reliable risk factor
   interpretations, and helping healthcare professionals make informed
   clinical decisions.MethodsThis study uses the publicly available Stroke
   Analysis dataset. To predict stroke risk, the CatBoost classifier is
   employed, while the XAI component incorporates SHAP explainer to provide
   insights into its reasoning. A Django-based web application allows users
   to upload risk factor data and receive personalized stroke risk
   predictions. Smartwatch integration allows continuous monitoring of
   dynamic risk factors. BioMistral 7B Large Language Models (LLM) is
   employed to create an intuitive AI medical assistant.ResultsThe
   developed automated online recommender system is highly accurate and
   robust for stroke risk assessment. The CatBoost classifier shows an
   average AUC of 0.98. In addition to the SHAP explainer, the recommender
   system also integrates Google Maps, Alert System, and Q/A chatbot based
   on LLMs.ConclusionAccording to the study, AI-driven systems can assist
   in stroke risk assessment and preventive care strategies. Developing a
   user-friendly online recommender system provides proof of principle for
   an efficient and user-friendly health management tool using machine
   learning, explainable AI, and LLM.
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001372713100001
ER

PT J
AU Panagoulias, Dimitrios P.
   Tsoureli-Nikita, Evridiki
   Virvou, Maria
   Tsihrintzis, George A.
TI Dermacen analytica: A novel methodology integrating multi-modal large
   language models with machine learning in dermatology
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 199
AR 105898
DI 10.1016/j.ijmedinf.2025.105898
EA MAR 2025
DT Article
PD JUL 2025
PY 2025
AB Objective: To design, implement, evaluate, and quantify a novel and
   adaptable Artificial Intelligence-empowered methodology aimed at
   supporting a dermatologist's workflow in assessing and diagnosing skin
   conditions, leveraging AI's deep image analytic power and reasoning.
   Skin presents diverse conditions that no single AI solution can
   comprehensively address, suggesting that mimicking a medical
   professional's diagnostic process and creating strategic AI
   interventions may enhance decision-making. Patients and Methods: We
   employ large language, transformer-based vision models for image
   analysis, sophisticated machine learning tools for guideline-based
   segmentation, and measuring tasks in our system. As no single technology
   is sufficient on its own for efficient use by dermatologists, we apply a
   sequential logic with agency to improve outcomes. Results: Using natural
   language processing methods and incorporating human expert evaluation,
   our system achieved a weighted accuracy of 87% on the dataset used,
   demonstrating its reasoning and diagnostic capabilities. Conclusions:
   This study serves as a proof of concept for the application of AI in
   dermatology, highlighting its potential to enhance the patient journey
   for which we approximate the value of such interventions in healthcare
   using graph theory with an associated cost-optimization objective
   function.
Z8 0
TC 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 0
DA 2025-04-08
UT WOS:001458155100001
PM 40153891
ER

PT J
AU Dhanasekaran, Renumathy
   Daugherty, Tami
   Kwo, Paul Yien
   Ghaziani, T. Tara
   Masuoka, Howard
   Elango, Vetri Venthan
TI DEVELOPING A HIGH-PERFORMING CUSTOMIZED AI TUMOR BOARD TOOL FOR HCC
   STAGING AND MANAGEMENT
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1965
BP S884
EP S884
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
TC 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837703466
ER

PT J
AU Ostrowska, Magdalena
   Kacala, Paulina
   Onolememen, Deborah
   Vaughan-Lane, Katie
   Sisily Joseph, Anitta
   Ostrowski, Adam
   Pietruszewska, Wioletta
   Banaszewski, Jacek
   Wrobel, Maciej J.
TI To trust or not to trust: evaluating the reliability and safety of AI
   responses to laryngeal cancer queries
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6069
EP 6081
DI 10.1007/s00405-024-08643-8
EA APR 2024
DT Article
PD NOV 2024
PY 2024
AB Purpose As online health information-seeking surges, concerns mount over
   the quality and safety of accessible content, potentially leading to
   patient harm through misinformation. On one hand, the emergence of
   Artificial Intelligence (AI) in healthcare could prevent it; on the
   other hand, questions raise regarding the quality and safety of the
   medical information provided. As laryngeal cancer is a prevalent head
   and neck malignancy, this study aims to evaluate the utility and safety
   of three large language models (LLMs) as sources of patient information
   about laryngeal cancer.Methods A cross-sectional study was conducted
   using three LLMs (ChatGPT 3.5, ChatGPT 4.0, and Bard). A questionnaire
   comprising 36 inquiries about laryngeal cancer was categorised into
   diagnosis (11 questions), treatment (9 questions), novelties and
   upcoming treatments (4 questions), controversies (8 questions), and
   sources of information (4 questions). The population of reviewers
   consisted of 3 groups, including ENT specialists, junior physicians, and
   non-medicals, who graded the responses. Each physician evaluated each
   question twice for each model, while non-medicals only once. Everyone
   was blinded to the model type, and the question order was shuffled.
   Outcome evaluations were based on a safety score (1-3) and a Global
   Quality Score (GQS, 1-5). Results were compared between LLMs. The study
   included iterative assessments and statistical validations.Results
   Analysis revealed that ChatGPT 3.5 scored highest in both safety (mean:
   2.70) and GQS (mean: 3.95). ChatGPT 4.0 and Bard had lower safety scores
   of 2.56 and 2.42, respectively, with corresponding quality scores of
   3.65 and 3.38. Inter-rater reliability was consistent, with less than 3%
   discrepancy. About 4.2% of responses fell into the lowest safety
   category (1), particularly in the novelty category. Non-medical
   reviewers' quality assessments correlated moderately (r = 0.67) with
   response length.Conclusions LLMs can be valuable resources for patients
   seeking information on laryngeal cancer. ChatGPT 3.5 provided the most
   reliable and safe responses among the models evaluated.
TC 11
ZS 1
ZB 1
ZR 0
ZA 0
Z8 0
Z9 10
DA 2024-04-27
UT WOS:001207064800002
PM 38652298
ER

PT J
AU Zhao, Fang-Fang
   He, Han-Jie
   Liang, Jia-Jian
   Cen, Jingyun
   Wang, Yun
   Lin, Hongjie
   Chen, Feifei
   Li, Tai-Ping
   Yang, Jian-Feng
   Chen, Lan
   Cen, Ling-Ping
TI Benchmarking the performance of large language models in uveitis: a
   comparative analysis of ChatGPT-3.5, ChatGPT-4.0, Google Gemini, and
   Anthropic Claude3
SO EYE
VL 39
IS 6
BP 1132
EP 1137
DI 10.1038/s41433-024-03545-9
EA DEC 2024
DT Article
PD APR 2025
PY 2025
AB Background/Objective This study aimed to evaluate the accuracy,
   comprehensiveness, and readability of responses generated by various
   Large Language Models (LLMs) (ChatGPT-3.5, Gemini, Claude 3, and
   GPT-4.0) in the clinical context of uveitis, utilizing a meticulous
   grading methodology. Methods Twenty-seven clinical uveitis questions
   were presented individually to four Large Language Models (LLMs):
   ChatGPT (versions GPT-3.5 and GPT-4.0), Google Gemini, and Claude. Three
   experienced uveitis specialists independently assessed the responses for
   accuracy using a three-point scale across three rounds with a 48-hour
   wash-out interval. The final accuracy rating for each LLM response
   ('Excellent', 'Marginal', or 'Deficient') was determined through a
   majority consensus approach. Comprehensiveness was evaluated using a
   three-point scale for responses rated 'Excellent' in the final accuracy
   assessment. Readability was determined using the Flesch-Kincaid Grade
   Level formula. Statistical analyses were conducted to discern
   significant differences among LLMs, employing a significance threshold
   of p < 0.05. Results Claude 3 and ChatGPT 4 demonstrated significantly
   higher accuracy compared to Gemini (p < 0.001). Claude 3 also showed the
   highest proportion of 'Excellent' ratings (96.3%), followed by ChatGPT 4
   (88.9%). ChatGPT 3.5, Claude 3, and ChatGPT 4 had no responses rated as
   'Deficient', unlike Gemini (14.8%) (p = 0.014). ChatGPT 4 exhibited
   greater comprehensiveness compared to Gemini (p = 0.008), and Claude 3
   showed higher comprehensiveness compared to Gemini (p = 0.042). Gemini
   showed significantly better readability compared to ChatGPT 3.5, Claude
   3, and ChatGPT 4 (p < 0.001). Gemini also had fewer words, letter
   characters, and sentences compared to ChatGPT 3.5 and Claude 3.
   Conclusions Our study highlights the outstanding performance of Claude 3
   and ChatGPT 4 in providing precise and thorough information regarding
   uveitis, surpassing Gemini. ChatGPT 4 and Claude 3 emerge as pivotal
   tools in improving patient understanding and involvement in their
   uveitis healthcare journey.
ZB 0
ZS 0
TC 6
ZR 0
ZA 0
Z8 0
Z9 6
DA 2024-12-25
UT WOS:001380600200001
PM 39690303
ER

PT J
AU D'Amico, Saverio
   Delleani, Mattia
   Sauta, Elisabetta
   Asti, Gianluca
   Zazzetti, Elena
   Campagna, Alessia
   Lanino, Luca
   Maggioni, Giulia
   Ubezio, Marta
   Todisco, Gabriele
   Russo, Antonio
   Tentori, Cristina Astrid
   Buizza, Alessandro
   Bicchieri, Marilena
   Zampini, Matteo
   Brindisi, Matteo
   Ficara, Francesca
   Riva, Elena
   Ventura, Denise
   Crisafulli, Laura
   Pinocchio, Nicole
   Jacobs, Flavia
   Zambelli, Alberto
   Savevski, Victor
   Santoro, Armando
   Sanavia, Tiziana
   Rollo, Cesare
   Sartori, Flavio
   Fariselli, Piero
   Sanz, Guillermo
   Santini, Valeria
   Sole, Francesc
   Platzbecker, Uwe
   Fenaux, Pierre
   Diez-Campelo, Maria
   Kordasti, Shahram
   Komrokji, Rami S.
   Garcia-Manero, Guillermo
   Haferlach, Torsten
   Zeidan, Amer M.
   Castellani, Gastone
   Della Porta, Matteo Giovanni
TI Generation of Multimodal Longitudinal Synthetic Data By Artificial
   Intelligence to Improve Personalized Medicine in Hematology
SO BLOOD
VL 144
BP 4981
EP 4983
DI 10.1182/blood-2024-209541
SU 1
DT Meeting Abstract
PD NOV 5 2024
PY 2024
CT 66th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 07-10, 2024
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZB 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2025-03-12
UT WOS:001414500000040
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

EF