FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Ren, Yaxuan
   Luo, Xufei
   Wang, Ye
   Li, Haodong
   Zhang, Hairong
   Li, Zeming
   Lai, Honghao
   Li, Xuanlin
   Ge, Long
   Estill, Janne
   Zhang, Lu
   Yang, Shu
   Chen, Yaolong
   Wen, Chengping
   Bian, Zhaoxiang
   ADVANCED Working Group
TI Large Language Models in Traditional Chinese Medicine: A Scoping Review
SO JOURNAL OF EVIDENCE BASED MEDICINE
VL 18
IS 1
DI 10.1111/jebm.12658
EA DEC 2024
DT Review
PD MAR 2025
PY 2025
AB BackgroundThe application of large language models (LLMs) in medicine
   has received increasing attention, showing significant potential in
   teaching, research, and clinical practice, especially in knowledge
   extraction, management, and understanding. However, the use of LLMs in
   Traditional Chinese Medicine (TCM) has not been thoroughly studied. This
   study aims to provide a comprehensive overview of the status and
   challenges of LLM applications in TCM.MethodsA systematic search of five
   electronic databases and Google Scholar was conducted between November
   2022 and April 2024, using the Arksey and O'Malley five-stage framework
   to identify relevant studies. Data from eligible studies were
   comprehensively extracted and organized to describe LLM applications in
   TCM and assess their performance accuracy.ResultsA total of 29 studies
   were identified: 24 peer-reviewed articles, 1 review, and 4 preprints.
   Two core application areas were found: the extraction, management, and
   understanding of TCM knowledge, and assisted diagnosis and treatment.
   LLMs developed specifically for TCM achieved 70% accuracy in the TCM
   Practitioner Exam, while general-purpose Chinese LLMs achieved 60%
   accuracy. Common international LLMs did not pass the exam. Models like
   EpidemicCHAT and MedChatZH, trained on customized TCM corpora,
   outperformed general LLMs in TCM consultation.ConclusionDespite their
   potential, LLMs in TCM face challenges such as data quality and security
   issues, the specificity and complexity of TCM data, and the
   nonquantitative nature of TCM diagnosis and treatment. Future efforts
   should focus on interdisciplinary talent cultivation, enhanced data
   standardization and protection, and exploring LLM potential in
   multimodal interaction and intelligent diagnosis and treatment.
ZR 0
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001373936900001
PM 39651543
ER

PT J
AU Lammert, Jacqueline
   Dreyer, Tobias
   Mathes, Sonja
   Kuligin, Leonid
   Borm, Kai J.
   Schatz, Ulrich A.
   Kiechle, Marion
   Loersch, Alisa M.
   Jung, Johannes
   Lange, Sebastian
   Pfarr, Nicole
   Durner, Anna
   Schwamborn, Kristina
   Winter, Christof
   Ferber, Dyke
   Kather, Jakob Nikolas
   Mogler, Carolin
   Illert, Anna L.
   Tschochohei, Maximilian
TI Expert-Guided Large Language Models for Clinical Decision Support in
   Precision Oncology
SO JCO PRECISION ONCOLOGY
VL 8
AR e2400478
DI 10.1200/PO-24-00478
DT Article
PD OCT 2024
PY 2024
AB PURPOSE Rapidly expanding medical literature challenges oncologists
   seeking targeted cancer therapies. General-purpose large language models
   (LLMs) lack domain-specific knowledge, limiting their clinical utility.
   This study introduces the LLM system Medical Evidence Retrieval and Data
   Integration for Tailored Healthcare (MEREDITH), designed to support
   treatment recommendations in precision oncology. Built on Google's
   Gemini Pro LLM, MEREDITH uses retrieval-augmented generation and chain
   of thought.
   METHODS We evaluated MEREDITH on 10 publicly available fictional
   oncology cases with iterative feedback from a molecular tumor board
   (MTB) at a major German cancer center. Initially limited to
   PubMed-indexed literature (draft system), MEREDITH was enhanced to
   incorporate clinical studies on drug response within the specific tumor
   type, trial databases, drug approval status, and oncologic guidelines.
   The MTB provided a benchmark with manually curated treatment
   recommendations and assessed the clinical relevance of LLM-generated
   options (qualitative assessment). We measured semantic cosine similarity
   between LLM suggestions and clinician responses (quantitative
   assessment).
   RESULTS MEREDITH identified a broader range of treatment options (median
   4) compared with MTB experts (median 2). These options included
   therapies on the basis of preclinical data and combination treatments,
   expanding the treatment possibilities for consideration by the MTB. This
   broader approach was achieved by incorporating a curated medical data
   set that contextualized molecular targetability. Mirroring the approach
   MTB experts use to evaluate MTB cases improved the LLM's ability to
   generate relevant suggestions. This is supported by high concordance
   between LLM suggestions and expert recommendations (94.7% for the
   enhanced system) and a significant increase in semantic similarity from
   the draft to the enhanced system (from 0.71 to 0.76, P = .01).
   CONCLUSION Expert feedback and domain-specific data augment LLM
   performance. Future research should investigate responsible LLM
   integration into real-world clinical workflows.
ZA 0
ZB 0
TC 4
Z8 0
ZS 0
ZR 0
Z9 4
DA 2025-01-13
UT WOS:001376907800001
PM 39475661
ER

PT J
AU Ho, Cindy N.
   Tian, Tiffany
   Ayers, Alessandra T.
   Aaron, Rachel E.
   Phillips, Vidith
   Wolf, Risa M.
   Mathioudakis, Nestoras
   Dai, Tinglong
   Klonoff, David C.
TI Qualitative metrics from the biomedical literature for evaluating large
   language models in clinical decision-making: a narrative review
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
VL 24
IS 1
AR 357
DI 10.1186/s12911-024-02757-z
DT Article
PD NOV 26 2024
PY 2024
AB BackgroundThe large language models (LLMs), most notably ChatGPT,
   released since November 30, 2022, have prompted shifting attention to
   their use in medicine, particularly for supporting clinical
   decision-making. However, there is little consensus in the medical
   community on how LLM performance in clinical contexts should be
   evaluated.MethodsWe performed a literature review of PubMed to identify
   publications between December 1, 2022, and April 1, 2024, that discussed
   assessments of LLM-generated diagnoses or treatment plans.ResultsWe
   selected 108 relevant articles from PubMed for analysis. The most
   frequently used LLMs were GPT-3.5, GPT-4, Bard, LLaMa/Alpaca-based
   models, and Bing Chat. The five most frequently used criteria for
   scoring LLM outputs were "accuracy", "completeness", "appropriateness",
   "insight", and "consistency".ConclusionsThe most frequently used
   criteria for defining high-quality LLMs have been consistently selected
   by researchers over the past 1.5 years. We identified a high degree of
   variation in how studies reported their findings and assessed LLM
   performance. Standardized reporting of qualitative evaluation metrics
   that assess the quality of LLM outputs can be developed to facilitate
   research studies on LLMs in healthcare.
ZS 0
TC 4
ZA 0
ZB 0
Z8 0
ZR 0
Z9 4
DA 2024-12-03
UT WOS:001364059400003
PM 39593074
ER

PT J
AU Kamgno, Joseph
   Nguipdop-Djomo, Patrick
   Gounoue, Raceline
   Tejiokem, Mathurin
   Kuesel, Annette C.
TI Effect of Two or Six Doses 800 mg of Albendazole Every Two Months on
   Loa loa Microfilaraemia: A Double Blind, Randomized,
   Placebo-Controlled Trial
SO PLOS NEGLECTED TROPICAL DISEASES
VL 10
IS 3
AR e0004492
DI 10.1371/journal.pntd.0004492
DT Article
PD MAR 2016
PY 2016
AB Background
   Loiasis is a parasitic infection endemic in the African rain forest
   caused by the filarial nematode Loa loa. Loiasis can be co-endemic with
   onchocerciasis and/or lymphatic filariasis. Ivermectin, the drug used in
   the control of these diseases, can induce serious adverse reactions in
   patients with high L loa microfilaraemia (LLM). A drug is needed which
   can lower LLM below the level that represents a risk so that ivermectin
   mass treatment to support onchocerciasis and lymphatic filariasis
   elimination can be implemented safely.
   Methodology
   Sixty men and women from a loiasis endemic area in Cameroon were
   randomized after stratification by screening LLM (<= 30000, 30001-50000,
   > 50000) to three treatment arms: two doses albendazole followed by 4
   doses matching placebo (n = 20), six doses albendazole (n = 20)
   albendazole or 6 doses matching placebo (n = 20) administered every two
   months. LLM was measured before each treatment and 14, 18, 21 and 24
   months after the first treatment. Monitoring for adverse events occurred
   three and seven days as well as 2 months after each treatment.
   Principal Findings
   None of the adverse events recorded were considered treatment related.
   The percentages of participants with >= 50% decrease in LLM from
   pre-treatment for >= 4 months were 53%, 17% and 11% in the 6-dose,
   2-dose and placebo treatment arms, respectively. The difference between
   the 6-dose and the placebo arm was significant (p = 0.01). The
   percentages of participants with LLM < 8100 mf/ml for >= 4 months were
   21%, 11% and 0% in the 6-dose, 2- dose and placebo treatment arms,
   respectively.
   Conclusions/Significance
   The 6-dose regimen reduced LLM significantly, but the reduction was
   insufficient to eliminate the risk of severe and/or serious adverse
   reactions during ivermectin mass drug administration in loiasis
   co-endemic areas.
TC 24
ZB 17
Z8 0
ZS 0
ZA 0
ZR 0
Z9 24
DA 2016-04-27
UT WOS:000373272500025
PM 26967331
ER

PT J
AU Wang, Xu
   Mao, April W.
   Pan, Sirui
   Wang, Dawei
   He, Lili
   Vogel, Hannes
   Mao, Jian-Hua
   Weiss, William
   Li, Tao
   Chang, Hang
TI Cellular morphometric biomarkers and large language model predict
   prognosis and treatment response in neuroblastoma patients: A
   retrospective and double-blind prospective single arm clinical study
SO EUROPEAN JOURNAL OF CANCER
VL 218
AR 115273
DI 10.1016/j.ejca.2025.115273
EA FEB 2025
DT Article
PD MAR 11 2025
PY 2025
AB Background: The heterogeneity of Neuroblastoma (NB) leads to variation
   in response to treatment , outcomes. The aim of the current study is to
   discover AI-empowered cellular morphometric biomarkers (CMBs), to
   establish the corresponding CMB risk score (CMBRS), CMB risk group
   (CMBRG), large language model driven CMB risk score (CMB-LLM-RS) , large
   language model driven CMB risk group (CMB-LLM-RG), and to investigate
   and validate their prognostic and predictive power in NB. Methods: In
   this study, the retrospective cohort enrolled 84 primary NBs between
   1/2020 and 12/2021, followed up through 11/22/2024; the prospective
   cohort enrolled 67 primary NBs between 1/2022 and 7/2023, followed up
   through 11/22/2024. Results: We identified 9 CMBs from a retrospective
   NB cohort, enabling the CMBRS, CMBRG, CMB-LLM-RS, and CMB-LLM-RG. Both
   CMBRG and CMB-LLM-RG are significantly associated with prognosis (p <
   0.0001) and treatment response (p < 0.0001). Furthermore, we
   double-blindly validated the predictive power of CMBRG and CMB-LLM-RG in
   a prospective NB cohort, which confirms their potential value in real
   clinical settings. Impor- tantly, CMBRG provides clinical value
   independent of the International Neuroblastoma Risk Group (INRG)
   classification system in both retrospective and prospective NB cohorts
   (p < 0.05); and the combination of CMBRG and INRG significantly
   increases prognostic and predictive performance for NB patients.
   Conclusions: These findings suggest that CMBRG and CMB-LLM-RG have
   prognostic and predictive value for NB and warrants evaluation in larger
   multicenter cohorts.
ZA 0
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-02-23
UT WOS:001423930700001
PM 39908653
ER

PT J
AU Huang, Andy S.
   Hirabayashi, Kyle
   Barna, Laura
   Parikh, Deep
   Pasquale, Louis R.
TI Assessment of a Large Language Model's Responses to Questions and Cases
   About Glaucoma and Retina Management
SO JAMA OPHTHALMOLOGY
VL 142
IS 4
BP 371
EP 375
DI 10.1001/jamaophthalmol.2023.6917
EA APR 2024
DT Article
PD APR 2024
PY 2024
AB Importance: Large language models (LLMs) are revolutionizing medical
   diagnosis and treatment, offering unprecedented accuracy and ease
   surpassing conventional search engines. Their integration into medical
   assistance programs will become pivotal for ophthalmologists as an
   adjunct for practicing evidence-based medicine. Therefore, the
   diagnostic and treatment accuracy of LLM-generated responses compared
   with fellowship-trained ophthalmologists can help assess their accuracy
   and validate their potential utility in ophthalmic subspecialties.
   Objective: To compare the diagnostic accuracy and comprehensiveness of
   responses from an LLM chatbot with those of fellowship-trained glaucoma
   and retina specialists on ophthalmological questions and real patient
   case management. Design, Setting, and Participants: This comparative
   cross-sectional study recruited 15 participants aged 31 to 67 years,
   including 12 attending physicians and 3 senior trainees, from eye
   clinics affiliated with the Department of Ophthalmology at Icahn School
   of Medicine at Mount Sinai, New York, New York. Glaucoma and retina
   questions (10 of each type) were randomly selected from the American
   Academy of Ophthalmology's Commonly Asked Questions. Deidentified
   glaucoma and retinal cases (10 of each type) were randomly selected from
   ophthalmology patients seen at Icahn School of Medicine at Mount
   Sinai-affiliated clinics. The LLM used was GPT-4 (version dated May 12,
   2023). Data were collected from June to August 2023. Main Outcomes and
   Measures: Responses were assessed via a Likert scale for medical
   accuracy and completeness. Statistical analysis involved the
   Mann-Whitney U test and the Kruskal-Wallis test, followed by pairwise
   comparison. Results: The combined question-case mean rank for accuracy
   was 506.2 for the LLM chatbot and 403.4 for glaucoma specialists (n =
   831; Mann-Whitney U = 27976.5; P < .001), and the mean rank for
   completeness was 528.3 and 398.7, respectively (n = 828; Mann-Whitney U
   = 25218.5; P < .001). The mean rank for accuracy was 235.3 for the LLM
   chatbot and 216.1 for retina specialists (n = 440; Mann-Whitney U =
   15518.0; P = .17), and the mean rank for completeness was 258.3 and
   208.7, respectively (n = 439; Mann-Whitney U = 13123.5; P = .005). The
   Dunn test revealed a significant difference between all pairwise
   comparisons, except specialist vs trainee in rating chatbot
   completeness. The overall pairwise comparisons showed that both trainees
   and specialists rated the chatbot's accuracy and completeness more
   favorably than those of their specialist counterparts, with specialists
   noting a significant difference in the chatbot's accuracy (z = 3.23; P =
   .007) and completeness (z = 5.86; P < .001). Conclusions and Relevance:
   This study accentuates the comparative proficiency of LLM chatbots in
   diagnostic accuracy and completeness compared with fellowship-trained
   ophthalmologists in various clinical scenarios. The LLM chatbot
   outperformed glaucoma specialists and matched retina specialists in
   diagnostic and treatment accuracy, substantiating its role as a
   promising diagnostic adjunct in ophthalmology.
Z8 1
ZS 0
ZR 0
ZA 0
TC 53
ZB 8
Z9 53
DA 2024-03-21
UT WOS:001174564400007
PM 38386351
ER

PT J
AU Su, L X
   Weng, L
   Li, W X
   Long, Y
TI [Applications and challenges of large language models in critical care
   medicine].
SO Zhonghua yi xue za zhi
VL 103
IS 31
BP 2361
EP 2364
DI 10.3760/cma.j.cn112137-20230524-00847
DT English Abstract; Journal Article
PD 2023-Aug-22
PY 2023
AB The rapid development of big data methods and technologies has provided
   more and more new ideas and methods for clinical diagnosis and
   treatment. The emergence of large language models (LLM) has made it
   possible for human-computer interactive dialogues and applications in
   complex medical scenarios. Critical care medicine is a process of
   continuous dynamic targeted treatment. The huge data generated in this
   process needs to be integrated and optimized through models for clinical
   application, interaction in teaching simulation, and assistance in
   scientific research. Using the LLM represented by generative pre-trained
   transformer ChatGPT can initially realize the application in the
   diagnosis of severe diseases, the prediction of death risk and the
   management of medical records. At the same time, the time and space
   limitations, illusions and ethical and moral issues of ChatGPT emerged
   as the times require. In the future, it is undeniable that it may play a
   huge role in the diagnosis and treatment of critical care medicine, but
   the current application should be combined with more clinical knowledge
   reserves of critical care medicine to carefully judge its conclusions.
AB 大数据方法和技术发展日新月异，给临床诊疗提供了越来越多的新的思路和方法。大语言模型的出现使得人机交互式的对话和复杂的医疗场景下的应用成为了可能。
   重症医学是一个连续动态目标性治疗的过程，这个过程中产生的庞大数据需要通过模型进行整合与优化并在临床应用，在教学模拟中互动，在科学研究中助力。使用
   以生成式预训练转换模型（ChatGPT）为代表的大语言模型可初步实现在重症疾病的诊断、死亡风险预测和病案管理方面的应用。同时ChatGPT的时空
   局限性、幻象和伦理道德问题应运而生。ChatGPT在未来的重症医学诊疗中可能会发挥巨大作用，但目前需要结合更多的重症医学临床知识储备并谨慎对待其
   作出的结论进行判断。.
ZR 0
TC 1
ZB 0
Z8 3
ZS 0
ZA 0
Z9 4
DA 2023-08-23
UT MEDLINE:37599212
PM 37599212
ER

PT C
AU Bandara, Eranga
   Foytik, Peter
   Shetty, Sachin
   Mukkamala, Ravi
   Rahman, Abdul
   Liang, Xueping
   Keon, Ng Wee
   De Zoysa, Kasun
GP IEEE
TI WedaGPT - Generative-AI (with Custom-Trained Meta's Llama2 LLM),
   Blockchain, Self Sovereign Identity, NFT and Model Card Enabled
   Indigenous Medicine Platform
SO 2024 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, ISCC 2024
SE IEEE Symposium on Computers and Communications ISCC
DI 10.1109/ISCC61673.2024.10733674
DT Proceedings Paper
PD 2024
PY 2024
AB Traditional and indigenous medicine, deeply rooted in ancient traditions
   and wisdom, plays a crucial role in global healthcare and cultural
   identity. These practices provide treatments for illnesses such as
   cancer and bone injuries, which often lack effective remedies in Western
   medicine. However, these valuable systems face challenges like potential
   knowledge loss, undervaluation of practitioners' expertise, and the risk
   of fraud due to the absence of credential verification mechanisms. In
   this research, we introduce "WedaGPT," a Generative AI-enabled platform
   that utilizes a custom-trained Meta's Llama2 Large Language Model (LLM),
   Blockchain, self-sovereign identity (SSI), Non-Fungible Tokens (NFTs),
   and model cards to share traditional medical knowledge and address these
   issues. WedaGPT creates a collaborative ecosystem connecting doctors,
   medicine providers, therapists, patients, and technology experts, all
   committed to preserving and advancing traditional healing practices.
   This platform enables secure and transparent contributions from all
   stakeholders to patient well-being. Ancient medical recipe books are
   translated into English and digitized into PDF formats to enrich the
   platform's knowledge base. These texts are used to fine-tune the Llama2
   LLM, which has been quantized and optimized with Qlora for performance
   on consumer-grade hardware. Through a chat-based interface in the
   SSI-enabled mobile wallet, users can interact with the LLM and access
   detailed information on treatments, recipes, prescriptions, and healing
   methods. Additionally, users can consult remotely with doctors who
   prescribe treatments through this wallet. A key feature of WedaGPT is
   transforming ancient medicinal recipes into NFT tokens for sale on NFT
   marketplaces, giving traditional knowledge digital authenticity and
   economic value. Revenue from these sales is distributed among platform
   contributors, promoting equitable ownership and recognition. Medical
   recipe data, including treatment histories and physician details, are
   encapsulated in Model Cards and securely stored on the blockchain. This
   system offers mechanisms to verify doctors and treatments in a
   privacy-preserving way, potentially reducing fraud and medication
   errors.
CT 29th IEEE Symposium on Computers and Communications (IEEE ISCC)
CY JUN 26-29, 2024
CL Paris, FRANCE
SP IEEE
Z8 0
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-01-03
UT WOS:001363176200111
ER

PT J
AU Truhn, Daniel
   Weber, Christian D.
   Braun, Benedikt J.
   Bressem, Keno
   Kather, Jakob N.
   Kuhl, Christiane
   Nebelung, Sven
TI A pilot study on the efficacy of GPT-4 in providing orthopedic treatment
   recommendations from MRI reports
SO SCIENTIFIC REPORTS
VL 13
IS 1
AR 20159
DI 10.1038/s41598-023-47500-2
DT Article
PD NOV 17 2023
PY 2023
AB Large language models (LLMs) have shown potential in various
   applications, including clinical practice. However, their accuracy and
   utility in providing treatment recommendations for orthopedic conditions
   remain to be investigated. Thus, this pilot study aims to evaluate the
   validity of treatment recommendations generated by GPT-4 for common knee
   and shoulder orthopedic conditions using anonymized clinical MRI
   reports. A retrospective analysis was conducted using 20 anonymized
   clinical MRI reports, with varying severity and complexity. Treatment
   recommendations were elicited from GPT-4 and evaluated by two
   board-certified specialty-trained senior orthopedic surgeons. Their
   evaluation focused on semiquantitative gradings of accuracy and clinical
   utility and potential limitations of the LLM-generated recommendations.
   GPT-4 provided treatment recommendations for 20 patients (mean age, 50
   years +/- 19 [standard deviation]; 12 men) with acute and chronic knee
   and shoulder conditions. The LLM produced largely accurate and
   clinically useful recommendations. However, limited awareness of a
   patient's overall situation, a tendency to incorrectly appreciate
   treatment urgency, and largely schematic and unspecific treatment
   recommendations were observed and may reduce its clinical usefulness. In
   conclusion, LLM-based treatment recommendations are largely adequate and
   not prone to 'hallucinations', yet inadequate in particular situations.
   Critical guidance by healthcare professionals is obligatory, and
   independent use by patients is discouraged, given the dependency on
   precise data input.
ZB 9
ZA 0
ZR 0
Z8 2
ZS 0
TC 33
Z9 33
DA 2024-04-05
UT WOS:001125371600058
PM 37978240
ER

PT J
AU Komatsu, K
   Yamaguchi, T
   Ohata, N
TI A new training device for rehabilitation of lateral mandibular
   movements: A pilot study
SO CRANIO-THE JOURNAL OF CRANIOMANDIBULAR & SLEEP PRACTICE
VL 20
IS 3
BP 198
EP 203
DI 10.1080/08869634.2002.11746211
DT Article
PD JUL 2002
PY 2002
AB Laterotrusive training is often used together with mouth-opening
   training in order to achieve adequate translation of the affected
   condyle in treatment of TMJ closed lock. This training is usually
   performed by voluntary laterotrusive movement (VLM) or by laterotrusive
   movement using only the fingers (FLM). However, satisfactory results are
   often not obtained by using these methods. To resolve this problem, we
   devised a new laterotrusive training device (LT device). In this paper,
   we describe the method of the training of laterotrusive movement using
   the LT device (LLM) and present a comparison of the results obtained by
   using LLM with those obtained by using VLM and FLM. The subjects were
   ten patients with TMJ closed lock. The following results were obtained:
   1. the range of LLM was significantly larger than those of VLM and FLM;
   and 2. all of the patients reported that LLM could be performed more
   easily than VLM and FILM. In conclusion, the LT device is thought to be
   useful for laterotrusive training in TMJ closed lock.
TC 6
Z8 0
ZR 0
ZA 0
ZB 1
ZS 0
Z9 7
DA 2002-07-01
UT WOS:000177084700011
PM 12150266
ER

PT J
AU Hua, Rui
   Dong, Xin
   Wei, Yu
   Shu, Zixin
   Yang, Pengcheng
   Hu, Yunhui
   Zhou, Shuiping
   Sun, He
   Yan, Kaijing
   Yan, Xijun
   Chang, Kai
   Li, Xiaodong
   Bai, Yuning
   Zhang, Runshun
   Wang, Wenjia
   Zhou, Xuezhong
TI Lingdan: enhancing encoding of traditional Chinese medicine knowledge
   for clinical reasoning tasks with large language models
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
DI 10.1093/jamia/ocae087
EA JUL 2024
DT Article; Early Access
PY 2024
AB Objective The recent surge in large language models (LLMs) across
   various fields has yet to be fully realized in traditional Chinese
   medicine (TCM). This study aims to bridge this gap by developing a large
   language model tailored to TCM knowledge, enhancing its performance and
   accuracy in clinical reasoning tasks such as diagnosis, treatment, and
   prescription recommendations.Materials and Methods This study harnessed
   a wide array of TCM data resources, including TCM ancient books,
   textbooks, and clinical data, to create 3 key datasets: the TCM
   Pre-trained Dataset, the Traditional Chinese Patent Medicine (TCPM)
   Question Answering Dataset, and the Spleen and Stomach Herbal
   Prescription Recommendation Dataset. These datasets underpinned the
   development of the Lingdan Pre-trained LLM and 2 specialized models: the
   Lingdan-TCPM-Chat Model, which uses a Chain-of-Thought process for
   symptom analysis and TCPM recommendation, and a Lingdan Prescription
   Recommendation model (Lingdan-PR) that proposes herbal prescriptions
   based on electronic medical records.Results The Lingdan-TCPM-Chat and
   the Lingdan-PR Model, fine-tuned on the Lingdan Pre-trained LLM,
   demonstrated state-of-the art performances for the tasks of TCM clinical
   knowledge answering and herbal prescription recommendation. Notably,
   Lingdan-PR outperformed all state-of-the-art baseline models, achieving
   an improvement of 18.39% in the Top@20 F1-score compared with the best
   baseline.Conclusion This study marks a pivotal step in merging advanced
   LLMs with TCM, showcasing the potential of artificial intelligence to
   help improve clinical decision-making of medical diagnostics and
   treatment strategies. The success of the Lingdan Pre-trained LLM and its
   derivative models, Lingdan-TCPM-Chat and Lingdan-PR, not only
   revolutionizes TCM practices but also opens new avenues for the
   application of artificial intelligence in other specialized medical
   fields. Our project is available at
   https://github.com/TCMAI-BJTU/LingdanLLM.
Z8 4
ZR 0
ZA 0
ZS 0
TC 7
ZB 0
Z9 11
DA 2024-07-28
UT WOS:001273695100001
PM 39038795
ER

PT J
AU Qin, Zheng
   Zhao, Junjie
   Li, Jiameng
   Yang, Qinbo
   Geng, Jiwen
   Liao, Ruoxi
   Su, Baihai
TI Low lean mass is associated with lower urinary tract symptoms in US men
   from the 2005-2006 national health and nutrition examination survey
   dataset
SO AGING-US
VL 13
IS 17
BP 21421
EP 21434
DT Article
PD SEP 15 2021
PY 2021
AB We investigated the relationship between low lean mass (LLM) and lower
   urinary tract symptoms (LUTS) using the 2005-2006 National Health and
   Nutrition Examination Survey (NHANES) dataset. We enrolled 959 men with
   an average age of 52.08 +/- 7.91 years and performed weighted multiple
   regression analysis to determine the independent relationship between
   exposure variables (LLM, alternate LLM) and outcomes variables (urinary
   hesitancy, incomplete emptying, urinary frequency, nocturia, daytime
   LUTS, clinical LUTS) after adjusting for confounding factors. The
   prevalence of urinary hesitancy (OR = 7.76, P < 0.0001), incomplete
   emptying (OR = 2.49, P = 0.0070), urinary frequency (OR = 3.28, P <
   0.0001), daytime LUTS (OR = 3.88, P < 0.0001) and clinical LUTS (OR =
   8.11, P < 0.0001) was significantly higher among men with LLM compared
   to men without LLM. Moreover, alternate LLM (ALLM) was positively
   associated with urinary hesitancy (OR = 17.97, P < 0.0001), incomplete
   emptying (OR = 4.68, P = 0.0003), daytime LUTS (OR = 2.47, P = 0.0136)
   and clinical LUTS (OR = 12.18, P < 0.0001). These findings demonstrate
   that both LLM and ALLM were associated with a higher risk of LUTS in men
   aged >= 40 years, which suggested that early management and treatment of
   lean mass loss may improve or alleviate LUTS.
ZA 0
ZR 0
ZS 0
ZB 13
Z8 0
TC 21
Z9 21
DA 2021-10-20
UT WOS:000704398100013
PM 34475271
ER

PT J
AU Benary, Manuela
   Wang, Xing David
   Schmidt, Max
   Soll, Dominik
   Hilfenhaus, Georg
   Nassir, Mani
   Sigler, Christian
   Knoedler, Maren
   Keller, Ulrich
   Beule, Dieter
   Keilholz, Ulrich
   Leser, Ulf
   Rieke, Damian T.
TI Leveraging Large Language Models for Decision Support in Personalized
   Oncology
SO JAMA NETWORK OPEN
VL 6
IS 11
AR e2343689
DI 10.1001/jamanetworkopen.2023.43689
DT Article
PD NOV 17 2023
PY 2023
AB Importance Clinical interpretation of complex biomarkers for precision
   oncology currently requires manual investigations of previous studies
   and databases. Conversational large language models (LLMs) might be
   beneficial as automated tools for assisting clinical
   decision-making.Objective To assess performance and define their role
   using 4 recent LLMs as support tools for precision oncology.Design,
   Setting, and Participants This diagnostic study examined 10 fictional
   cases of patients with advanced cancer with genetic alterations. Each
   case was submitted to 4 different LLMs (ChatGPT, Galactica, Perplexity,
   and BioMedLM) and 1 expert physician to identify personalized treatment
   options in 2023. Treatment options were masked and presented to a
   molecular tumor board (MTB), whose members rated the likelihood of a
   treatment option coming from an LLM on a scale from 0 to 10 (0,
   extremely unlikely; 10, extremely likely) and decided whether the
   treatment option was clinically useful.Main Outcomes and Measures Number
   of treatment options, precision, recall, F1 score of LLMs compared with
   human experts, recognizability, and usefulness of
   recommendations.Results For 10 fictional cancer patients (4 with lung
   cancer, 6 with other; median [IQR] 3.5 [3.0-4.8] molecular alterations
   per patient), a median (IQR) number of 4.0 (4.0-4.0) compared with 3.0
   (3.0-5.0), 7.5 (4.3-9.8), 11.5 (7.8-13.0), and 13.0 (11.3-21.5)
   treatment options each was identified by the human expert and 4 LLMs,
   respectively. When considering the expert as a criterion standard,
   LLM-proposed treatment options reached F1 scores of 0.04, 0.17, 0.14,
   and 0.19 across all patients combined. Combining treatment options from
   different LLMs allowed a precision of 0.29 and a recall of 0.29 for an
   F1 score of 0.29. LLM-generated treatment options were recognized as
   AI-generated with a median (IQR) 7.5 (5.3-9.0) points in contrast to 2.0
   (1.0-3.0) points for manually annotated cases. A crucial reason for
   identifying AI-generated treatment options was insufficient accompanying
   evidence. For each patient, at least 1 LLM generated a treatment option
   that was considered helpful by MTB members. Two unique useful treatment
   options (including 1 unique treatment strategy) were identified only by
   LLM.Conclusions and Relevance In this diagnostic study, treatment
   options of LLMs in precision oncology did not reach the quality and
   credibility of human experts; however, they generated helpful ideas that
   might have complemented established procedures. Considering
   technological progress, LLMs could play an increasingly important role
   in assisting with screening and selecting relevant biomedical literature
   to support evidence-based, personalized treatment decisions.
ZB 23
ZR 0
ZA 0
Z8 3
TC 91
ZS 0
Z9 95
DA 2024-01-11
UT WOS:001124127500011
PM 37976064
ER

PT J
AU Goh, Ethan
   Gallo, Robert J.
   Strong, Eric
   Weng, Yingjie
   Kerman, Hannah
   Freed, Jason A.
   Cool, Josephine A.
   Kanjee, Zahir
   Lane, Kathleen P.
   Parsons, Andrew S.
   Ahuja, Neera
   Horvitz, Eric
   Yang, Daniel
   Milstein, Arnold
   Olson, Andrew P. J.
   Hom, Jason
   Chen, Jonathan H.
   Rodman, Adam
TI GPT-4 assistance for improvement of physician performance on patient
   care tasks: a randomized controlled trial
SO NATURE MEDICINE
VL 31
IS 4
DI 10.1038/s41591-024-03456-y
EA FEB 2025
DT Article
PD APR 2025
PY 2025
AB While large language models (LLMs) have shown promise in diagnostic
   reasoning, their impact on management reasoning, which involves
   balancing treatment decisions and testing strategies while managing
   risk, is unknown. This prospective, randomized, controlled trial
   assessed whether LLM assistance improves physician performance on
   open-ended management reasoning tasks compared to conventional
   resources. From November 2023 to April 2024, 92 practicing physicians
   were randomized to use either GPT-4 plus conventional resources or
   conventional resources alone to answer five expert-developed clinical
   vignettes in a simulated setting. All cases were based on real,
   de-identified patient encounters, with information revealed sequentially
   to mirror the nature of clinical environments. The primary outcome was
   the difference in total score between groups on expert-developed scoring
   rubrics. Secondary outcomes included domain-specific scores and time
   spent per case. Physicians using the LLM scored significantly higher
   compared to those using conventional resources (mean difference = 6.5%,
   95% confidence interval (CI) = 2.7 to 10.2, P < 0.001). LLM users spent
   more time per case (mean difference = 119.3 s, 95% CI = 17.4 to 221.2, P
   = 0.02). There was no significant difference between LLM-augmented
   physicians and LLM alone (-0.9%, 95% CI = -9.0 to 7.2, P = 0.8). LLM
   assistance can improve physician management reasoning in complex
   clinical vignettes compared to conventional resources and should be
   validated in real clinical practice.
ZS 0
ZB 1
ZR 0
TC 8
Z8 0
ZA 0
Z9 8
DA 2025-02-14
UT WOS:001415955000001
PM 39910272
ER

PT J
AU Griewing, Sebastian
   Knitza, Johannes
   Boekhoff, Jelena
   Hillen, Christoph
   Lechner, Fabian
   Wagner, Uwe
   Wallwiener, Markus
   Kuhn, Sebastian
TI Evolution of publicly available large language models for complex
   decision-making in breast cancer care
SO ARCHIVES OF GYNECOLOGY AND OBSTETRICS
VL 310
IS 1
BP 537
EP 550
DI 10.1007/s00404-024-07565-4
EA MAY 2024
DT Article
PD JUL 2024
PY 2024
AB Purpose This study investigated the concordance of five different
   publicly available Large Language Models (LLM) with the recommendations
   of a multidisciplinary tumor board regarding treatment recommendations
   for complex breast cancer patient profiles.Methods Five LLM, including
   three versions of ChatGPT (version 4 and 3.5, with data access until
   September 3021 and January 2022), Llama2, and Bard were prompted to
   produce treatment recommendations for 20 complex breast cancer patient
   profiles. LLM recommendations were compared to the recommendations of a
   multidisciplinary tumor board (gold standard), including surgical,
   endocrine and systemic treatment, radiotherapy, and genetic testing
   therapy options.Results GPT4 demonstrated the highest concordance
   (70.6%) for invasive breast cancer patient profiles, followed by GPT3.5
   September 2021 (58.8%), GPT3.5 January 2022 (41.2%), Llama2 (35.3%) and
   Bard (23.5%). Including precancerous lesions of ductal carcinoma in
   situ, the identical ranking was reached with lower overall concordance
   for each LLM (GPT4 60.0%, GPT3.5 September 2021 50.0%, GPT3.5 January
   2022 35.0%, Llama2 30.0%, Bard 20.0%). GPT4 achieved full concordance
   (100%) for radiotherapy. Lowest alignment was reached in recommending
   genetic testing, demonstrating a varying concordance (55.0% for GPT3.5
   January 2022, Llama2 and Bard up to 85.0% for GPT4).Conclusion This
   early feasibility study is the first to compare different LLM in breast
   cancer care with regard to changes in accuracy over time, i.e., with
   access to more data or through technological upgrades. Methodological
   advancement, i.e., the optimization of prompting techniques, and
   technological development, i.e., enabling data input control and secure
   data processing, are necessary in the preparation of large-scale and
   multicenter studies to provide evidence on their safe and reliable
   clinical application. At present, safe and evidenced use of LLM in
   clinical breast cancer care is not yet feasible.
ZB 3
Z8 0
ZA 0
ZR 0
ZS 0
TC 14
Z9 14
DA 2024-06-04
UT WOS:001233695900001
PM 38806945
ER

PT J
AU Verda, Damiano
   Parodi, Stefano
   Ferrari, Enrico
   Muselli, Marco
TI Analyzing gene expression data for pediatric and adult cancer diagnosis
   using logic learning machine and standard supervised methods
SO BMC BIOINFORMATICS
VL 20
AR 390
DI 10.1186/s12859-019-2953-8
SU 9
DT Article
PD NOV 22 2019
PY 2019
AB Background: Logic Learning Machine (LLM) is an innovative method of
   supervised analysis capable of constructing models based on simple and
   intelligible rules.
   In this investigation the performance of LLM in classifying patients
   with cancer was evaluated using a set of eight publicly available gene
   expression databases for cancer diagnosis.
   LLM accuracy was assessed by summary ROC curve (sROC) analysis and
   estimated by the area under an sROC curve (sAUC). Its performance was
   compared in cross validation with that of standard supervised methods,
   namely: decision tree, artificial neural network, support vector machine
   (SVM) and k-nearest neighbor classifier.
   Results: LLM showed an excellent accuracy (sAUC = 0.99, 95%CI: 0.98-1.0)
   and outperformed any other method except SVM.
   Conclusions: LLM is a new powerful tool for the analysis of gene
   expression data for cancer diagnosis. Simple rules generated by LLM
   could contribute to a better understanding of cancer biology,
   potentially addressing therapeutic approaches.
ZR 0
Z8 0
TC 13
ZS 0
ZA 0
ZB 4
Z9 13
DA 2020-01-03
UT WOS:000503868200007
PM 31757200
ER

PT J
AU Chen, Chien-Hsin
   Hsieh, Mao-Chih
   Lao, Wilson T.
   Lin, En-Kwang
   Lu, Yen-Jung
   Wu, Szu-Yuan
TI Multidisciplinary team intervention associated with improved survival
   for patients with colorectal adenocarcinoma with liver or lung
   metastasis
SO AMERICAN JOURNAL OF CANCER RESEARCH
VL 8
IS 9
BP 1887
EP +
DT Article
PD 2018
PY 2018
AB Background and Objectives: To investigate whether multidisciplinary team
   (MDT) intervention is associated with improved survival for patients
   with colorectal adenocarcinoma with liver or lung metastasis (CRA-LLM).
   Methods: We enrolled 161 consecutive patients with histologically
   confirmed CRA-LLM at Taipei Medical UniversityWan Fang Hospital between
   January 2007 and December 2017. In total, 75 patients with CRA-LLM
   received MDT intervention, and 86 patients did not receive MDT
   intervention. To evaluate prognostic factors for overall death, we
   performed univariate and multivariate Cox regression analyses of the
   overall death rate in all patients. Overall survival rates were
   calculated using the Kaplan-Meier method, and Kaplan-Meier survival
   curves were compared using the log-rank test (P < .001). Results: A
   multivariate Cox regression analysis of the overall death rate in
   patients with CRA-LLM showed that age <= 65 years, systemic
   chemotherapy, curative-intent treatments, and MDT intervention are
   strong prognostic factors. The adjusted hazard ratio of death risk for
   age <= 65 years, systemic chemotherapy, curative-intent treatments, and
   MDT intervention were 0.60 (95% confidence interval [CI], 0.40-0.92; P
   =.019), 0.19 (95% CI, 0.12-0.32; P = .001), 0.25 (95% CI, 0.13-0.50; P =
   .001), and 0.40 (95% CI, 0.25-0.65; P =.001), respectively. The 3-year
   overall survival rates in patients with CRA-LLM receiving MDT
   intervention and not receiving MDT intervention were 48.75% and 24.21%,
   respectively. Conclusion: MDT intervention is associated with improved
   survival for patients with CRA-LLM.
ZR 0
ZB 6
TC 20
Z8 4
ZA 0
ZS 0
Z9 23
DA 2018-10-15
UT WOS:000445929700020
PM 30323980
ER

PT J
AU Chang, Munyoung
   Ahn, Junyong
   Kang, Bong Gyun
   Yoon, Sungroh
TI Cross-modal embedding integrator for disease-gene/protein association
   prediction using a multi-head attention mechanism
SO PHARMACOLOGY RESEARCH & PERSPECTIVES
VL 12
IS 6
AR e70034
DI 10.1002/prp2.70034
DT Article
PD DEC 2024
PY 2024
AB Knowledge graphs, powerful tools that explicitly transfer knowledge to
   machines, have significantly advanced new knowledge inferences.
   Discovering unknown relationships between diseases and genes/proteins in
   biomedical knowledge graphs can lead to the identification of disease
   development mechanisms and new treatment targets. Generating
   high-quality representations of biomedical entities is essential for
   successfully predicting disease-gene/protein associations. We developed
   a computational model that predicts disease-gene/protein associations
   using the Precision Medicine Knowledge Graph, a biomedical knowledge
   graph. Embeddings of biomedical entities were generated using two
   different methods-a large language model (LLM) and the knowledge graph
   embedding (KGE) algorithm. The LLM utilizes information obtained from
   massive amounts of text data, whereas the KGE algorithm relies on graph
   structures. We developed a disease-gene/protein association prediction
   model, "Cross-Modal Embedding Integrator (CMEI)," by integrating
   embeddings from different modalities using a multi-head attention
   mechanism. The area under the receiver operating characteristic curve of
   CMEI was 0.9662 (+/- 0.0002) in predicting disease-gene/protein
   associations. In conclusion, we developed a computational model that
   effectively predicts disease-gene/protein associations. CMEI may
   contribute to the identification of disease development mechanisms and
   new treatment targets.
Z8 0
ZB 0
ZA 0
ZS 0
ZR 0
TC 0
Z9 0
DA 2024-12-09
UT WOS:001368894600001
PM 39560053
ER

PT J
AU Sun, Virginia
   Heemelaar, Julius
   Hadzic, Ibrahim
   Raghu, Vineet
   Wu, Chia-Yun
   Zubiri, Leyre
   Ghamari, Azin
   Suero-Abreu, Giselle
   Wu, Jessica
   Hathaway, Nora
   Gilman, Hannah
   Villani, Alexandra-Chloe
   Ho, Sam
   Zlotoff, Daniel
   Blum, Steven
   Sullivan, Ryan
   Reynolds, Kerry
   Neilan, Tomas
TI Enhancing early detection of ICI myocarditis cases during
   hospitalization: A role for large language models
SO CIRCULATION
VL 150
MA 4119426
DI 10.1161/circ.150.suppl_1.4119426
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
TC 0
ZA 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
DA 2025-02-10
UT WOS:001398742700200
ER

PT J
AU Singh, Krishna B.
   Ji, Xinhua
   Singh, Shivendra V.
TI Therapeutic Potential of Leelamine, a Novel Inhibitor of Androgen
   Receptor and Castration-Resistant Prostate Cancer
SO MOLECULAR CANCER THERAPEUTICS
VL 17
IS 10
BP 2079
EP 2090
DI 10.1158/1535-7163.MCT-18-0117
DT Article
PD OCT 2018
PY 2018
AB Clinical management of castration-resistant prostate cancer (CRPC)
   resulting from androgen deprivation therapy remains challenging. CRPC is
   driven by aberrant activation of androgen receptor (AR) through
   mechanisms ranging from its amplification, mutation, post-translational
   modification, and expression of splice variants (e.g., AR-V7). Herein,
   we present experimental evidence for therapeutic vulnerability of CRPC
   to a novel phytochemical, leelamine (LLM), derived from pine tree bark.
   Exposure of human prostate cancer cell lines LNCaP (an
   androgen-responsive cell line with mutant AR), C4-2B (an
   androgen-insensitive variant of LNCaP), and 22Rv1 (a CRPC cell line with
   expression of AR-Vs), and a murine prostate cancer cell line Myc-CaP to
   plasma achievable concentrations of LLM resulted in ligand-dependent
   (LNCaP) and ligand-independent (22Rv1) growth inhibition in vitro that
   was accompanied by downregulation of mRNA and/or protein levels of
   full-length AR as well as its splice variants, including AR-V7. LLM
   treatment resulted in apoptosis induction in the absence and presence of
   R1881. In silico modeling followed by luciferase reporter assay revealed
   a critical role for noncovalent interaction of LLM with Y739 in AR
   activity inhibition. Substitution of the amine group with an
   isothiocyanate functional moiety abolished AR and cell viability
   inhibition by LLM. Administration of LLM resulted in 22Rv1 xenograft
   growth suppression that was statistically insignificant but was
   associated with a significant decrease in Ki-67 expression, mitotic
   activity, expression of fulllength AR and AR-V7 proteins, and secretion
   of PSA. This study identifies a novel chemical scaffold for the
   treatment of CRPC. (C) 2018 AACR.
Z8 0
ZS 0
TC 18
ZB 11
ZR 0
ZA 0
Z9 18
DA 2019-01-30
UT WOS:000456145700001
PM 30030299
ER

PT J
AU Savage, Thomas
   Wang, John
   Gallo, Robert
   Boukil, Abdessalem
   Patel, Vishwesh
   Safavi-Naini, Seyed Amir Ahmad
   Soroush, Ali
   Chen, Jonathan H.
TI Large language model uncertainty proxies: discrimination and calibration
   for medical diagnosis and treatment
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 32
IS 1
BP 139
EP 149
DI 10.1093/jamia/ocae254
EA OCT 2024
DT Article
PD OCT 12 2024
PY 2024
AB Introduction The inability of large language models (LLMs) to
   communicate uncertainty is a significant barrier to their use in
   medicine. Before LLMs can be integrated into patient care, the field
   must assess methods to estimate uncertainty in ways that are useful to
   physician-users.Objective Evaluate the ability for uncertainty proxies
   to quantify LLM confidence when performing diagnosis and treatment
   selection tasks by assessing the properties of discrimination and
   calibration.Methods We examined confidence elicitation (CE), token-level
   probability (TLP), and sample consistency (SC) proxies across GPT3.5,
   GPT4, Llama2, and Llama3. Uncertainty proxies were evaluated against 3
   datasets of open-ended patient scenarios.Results SC discrimination
   outperformed TLP and CE methods. SC by sentence embedding achieved the
   highest discriminative performance (ROC AUC 0.68-0.79), yet with poor
   calibration. SC by GPT annotation achieved the second-best
   discrimination (ROC AUC 0.66-0.74) with accurate calibration. Verbalized
   confidence (CE) was found to consistently overestimate model
   confidence.Discussion and Conclusions SC is the most effective method
   for estimating LLM uncertainty of the proxies evaluated. SC by sentence
   embedding can effectively estimate uncertainty if the user has a set of
   reference cases with which to re-calibrate their results, while SC by
   GPT annotation is the more effective method if the user does not have
   reference cases and requires accurate raw calibration. Our results
   confirm LLMs are consistently over-confident when verbalizing their
   confidence (CE).
ZS 0
ZA 0
ZB 2
TC 6
ZR 0
Z8 0
Z9 6
DA 2024-10-17
UT WOS:001330240100001
PM 39396184
ER

PT J
AU Rubins, HB
   Nelson, DB
   Noorbaloochi, S
   Nugent, S
TI Effectiveness of lipid-lowering medications in outpatients with coronary
   heart disease in the department of veterans affairs system
SO AMERICAN JOURNAL OF CARDIOLOGY
VL 92
IS 10
BP 1177
EP 1182
DI 10.1016/j.amjcard.2003.07.026
DT Article
PD NOV 15 2003
PY 2003
AB Lipid therapy aimed at reducing low-density lipoprotein cholesterol has
   been shown, in several large-scale randomized controlled trials, to
   reduce coronary heart disease (CHD) morbidity and mortality and
   all-cause mortality in patients with established CHD. However, lipid
   therapy's effectiveness in usual clinical settings has not been
   extensively studied. The purpose of this study was to determine the
   effect of prescription lipid-lowering medication (LLM) on all-cause
   mortality in a cohort of patients with known CHD. We conducted a
   retrospective cohort study using linked administrative and clinical
   databases. Sixteen thousand four hundred seventy patients with CHD who
   were outpatients at 1 of 5 Veterans Affairs medical facilities in the
   upper midwest between 1994 and 1996 were identified and then followed
   until death or the end of the study (December 31, 2000). Pharmacy
   databases were used to determine whether patients had been prescribed
   LLMs. Demographics, comorbid conditions, cardiac medications, and lipid
   levels were collected. Time-dependent Cox proportional hazards analyses,
   adjusted for confounding variables, and the propensity score for LLM use
   were performed to compare survival between those prescribed and those
   not prescribed LLM. During an average follow-up of 5.9 years, there were
   4,821 recorded deaths in patients not prescribed LLM (51%) and 1,245
   deaths in patients prescribed LLM (18%). On average, the treated cohort
   survived 15 months longer than the untreated group (p <0.0001). The
   age-adjusted hazards ratio associated with LLM use was 0.59 (95%
   confidence interval 0.55 to 0.63, p = 0.0001). After adjusting for
   propensity score, age, and previous use of LLM, the hazard ratio
   associated with prescription of LLM was 0.77 (95% confidence interval
   0.70 to 0.85, p <0.0001). This study confirms, in a standard clinical
   setting, the beneficial effects of LLM on total mortality in patients
   with established CHD. These, data suggest that the benefits of lipid
   therapy observed in highly controlled randomized trials are attainable
   in usual clinical settings. (C)2003 by Excerpta Medica, Inc.
TC 7
ZA 0
Z8 0
ZR 0
ZB 1
ZS 0
Z9 8
DA 2003-11-15
UT WOS:000186638600007
PM 14609592
ER

PT J
AU Ghorbian, Mohsen
   Ghobaei-Arani, Mostafa
   Ghorbian, Saied
TI Transforming breast cancer diagnosis and treatment with large language
   Models: A comprehensive survey
SO METHODS
VL 239
BP 85
EP 110
DI 10.1016/j.ymeth.2025.04.001
EA APR 2025
DT Article
PD JUL 2025
PY 2025
AB Breast cancer (BrCa), being one of the most prevalent forms of cancer in
   women, poses many challenges in the field of treatment and diagnosis due
   to its complex biological mechanisms. Early and accurate diagnosis plays
   a fundamental role in improving survival rates, but the limitations of
   existing imaging methods and clinical data interpretation often prevent
   optimal results. Large Language Models (LLMs), which are developed based
   on advanced architectures such as transformers, have brought about a
   significant revolution in data processing and medical decision-making.
   By analyzing a large volume of medical and clinical data, these models
   enable early diagnosis by identifying patterns in images and medical
   records and provide personalized treatment strategies by integrating
   genetic markers and clinical guidelines. Despite the transformative
   potential of these models, their use in BrCa management faces challenges
   such as data sensitivity, algorithm transparency, ethical
   considerations, and model compatibility with the details of medical
   applications that need to be addressed to achieve reliable results. This
   review systematically reviews the impact of LLMs on BrCa treatment and
   diagnosis. This study's objectives include analyzing the role of LLM
   technology in diagnosing and treating this disease. The findings
   indicate that the application of LLMs has resulted in significant
   improvements in various aspects of BrCa management, such as a 35%
   increase in the Efficiency of Diagnosis and BrCa Treatment (EDBC), a 30%
   enhancement in the System's Clinical Trust and Reliability (SCTR), and a
   20% improvement in the quality of patient education and information
   (IPEI). Ultimately, this study demonstrates the importance of LLMs in
   advancing precision medicine for BrCa and paves the way for effective
   patient-centered care solutions.
ZS 0
ZR 0
TC 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001466448900001
PM 40199412
ER

PT J
AU Agaronnik, Nicole D.
   Davis, Joshua
   Manz, Christopher R.
   Tulsky, James A.
   Lindvall, Charlotta
TI Large Language Models to Identify Advance Care Planning in Patients With
   Advanced Cancer
SO JOURNAL OF PAIN AND SYMPTOM MANAGEMENT
VL 69
IS 3
DI 10.1016/j.jpainsymman.2024.11.016
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
AB Context. Efficiently tracking Advance Care Planning (ACP) documentation
   in electronic heath records (EHRs) is essential for quality improvement
   and research efforts. The use of large language models (LLMs) offers a
   novel approach to this task. Objectives. To evaluate the ability of LLMs
   to identify ACP in EHRs for patients with advanced cancer and compare
   performance to gold-standard manual chart review and natural language
   processing (NLP). Methods. EHRs from patients with advanced cancer
   followed at seven Dana Farber Cancer Center (DFCI) clinics in June 2024.
   We utilized GPT-4o-2024-05-13 within DFCI's HIPAA-secure digital
   infrastructure. We designed LLM prompts to identify ACP domains: goals
   of care, limitation of life-sustaining treatment, hospice, and
   palliative care. We developed a novel hallucination index to measure
   production of factually-incorrect evidence by the LLM. Performance was
   compared to gold-standard manual chart review and NLP. Results. 60
   unique patients associated with 528 notes were used to construct the
   gold-standard data set. LLM prompts had sensitivity ranging from 0.85 to
   1.0, specificity ranging from 0.80 to 0.91, and accuracy ranging from
   0.81 to 0.91 across domains. The LLM had better sensitivity than NLP for
   identifying complex topics such as goals of care. Average hallucination
   index for notes identified by LLM was less than 0.5, indicating a low
   probability of hallucination. Despite lower precision compared to NLP,
   false positive documentation identified by LLMs was clinically-relevant
   and useful for guiding management. Conclusion. LLMs can capture ACP
   domains from EHRs, with sensitivity exceeding NLP methods for complex
   domains such as goals of care. Future studies should explore approaches
   for scaling this methodology. J Pain Symptom Manage 2025;69:243-250. (c)
   2024 American Academy of Hospice and Palliative Medicine. Published by
   Elsevier Inc. All rights are reserved, including those for text and data
   mining, AI training, and similar technologies.
Z8 0
ZR 0
ZB 0
ZA 0
TC 2
ZS 0
Z9 2
DA 2025-02-23
UT WOS:001422708600001
PM 39586429
ER

PT J
AU Wang, Jike
   Feng, Jianwen
   Kang, Yu
   Pan, Peichen
   Ge, Jingxuan
   Wang, Yan
   Wang, Mingyang
   Wu, Zhenxing
   Zhang, Xingcai
   Yu, Jiameng
   Zhang, Xujun
   Wang, Tianyue
   Wen, Lirong
   Yan, Guangning
   Deng, Yafeng
   Shi, Hui
   Hsieh, Chang-Yu
   Jiang, Zhihui
   Hou, Tingjun
TI Discovery of antimicrobial peptides with notable antibacterial potency
   by an LLM-based foundation model
SO SCIENCE ADVANCES
VL 11
IS 10
AR eads8932
DI 10.1126/sciadv.ads8932
DT Article
PD MAR 5 2025
PY 2025
AB Large language models (LLMs) have shown remarkable advancements in
   chemistry and biomedical research, acting as versatile foundation models
   for various tasks. We introduce AMP-Designer, an LLM-based approach, for
   swiftly designing antimicrobial peptides (AMPs) with desired properties.
   Within 11 days, AMP-Designer achieved the de novo design of 18 AMPs with
   broad-spectrum activity against Gram-negative bacteria. In vitro
   validation revealed a 94.4% success rate, with two candidates
   demonstrating exceptional antibacterial efficacy, minimal hemotoxicity,
   stability in human plasma, and low potential to induce resistance, as
   evidenced by significant bacterial load reduction in murine lung
   infection experiments. The entire process, from design to validation,
   concluded in 48 days. AMP-Designer excels in creating AMPs targeting
   specific strains despite limited data availability, with a top candidate
   displaying a minimum inhibitory concentration of 2.0 micrograms per
   milliliter against Propionibacterium acnes. Integrating advanced machine
   learning techniques, AMP-Designer demonstrates remarkable efficiency,
   paving the way for innovative solutions to antibiotic resistance.
TC 3
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
Z9 3
DA 2025-03-13
UT WOS:001438146100004
PM 40043127
ER

PT J
AU Ding, Sirui
   Ye, Jiancheng
   Hu, Xia
   Zou, Na
TI Distilling the knowledge from large-language model for health event
   prediction
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30675
DI 10.1038/s41598-024-75331-2
DT Article
PD DEC 28 2024
PY 2024
AB Health event prediction is empowered by the rapid and wide application
   of electronic health records (EHR). In the Intensive Care Unit (ICU),
   precisely predicting the health related events in advance is essential
   for providing treatment and intervention to improve the patients
   outcomes. EHR is a kind of multi-modal data containing clinical text,
   time series, structured data, etc. Most health event prediction works
   focus on a single modality, e.g., text or tabular EHR. How to
   effectively learn from the multi-modal EHR for health event prediction
   remains a challenge. Inspired by the strong capability in text
   processing of large language model (LLM), we propose the framework CKLE
   for health event prediction by distilling the knowledge from LLM and
   learning from multi-modal EHR. There are two challenges of applying LLM
   in the health event prediction, the first one is most LLM can only
   handle text data rather than other modalities, e.g., structured data.
   The second challenge is the privacy issue of health applications
   requires the LLM to be locally deployed, which may be limited by the
   computational resource. CKLE solves the challenges of LLM scalability
   and portability in the healthcare domain by distilling the
   cross-modality knowledge from LLM into the health event predictive
   model. To fully take advantage of the strong power of LLM, the raw
   clinical text is refined and augmented with prompt learning. The
   embedding of clinical text are generated by LLM. To effectively distill
   the knowledge of LLM into the predictive model, we design a
   cross-modality knowledge distillation (KD) method. A specially designed
   training objective will be used for the KD process with the
   consideration of multiple modality and patient similarity. The KD loss
   function consists of two parts. The first one is cross-modality
   contrastive loss function, which models the correlation of different
   modalities from the same patient. The second one is patient similarity
   learning loss function to model the correlations between similar
   patients. The cross-modality knowledge distillation can distill the rich
   information in clinical text and the knowledge of LLM into the
   predictive model on structured EHR data. To demonstrate the
   effectiveness of CKLE, we evaluate CKLE on two health event prediction
   tasks in the field of cardiology, heart failure prediction and
   hypertension prediction. We select the 7125 patients from MIMIC-III
   dataset and split them into train/validation/test sets. We can achieve a
   maximum 4.48% improvement in accuracy compared to state-of-the-art
   predictive model designed for health event prediction. The results
   demonstrate CKLE can surpass the baseline prediction models
   significantly on both normal and limited label settings. We also conduct
   the case study on cardiology disease analysis in the heart failure and
   hypertension prediction. Through the feature importance calculation, we
   analyse the salient features related to the cardiology disease which
   corresponds to the medical domain knowledge. The superior performance
   and interpretability of CKLE pave a promising way to leverage the power
   and knowledge of LLM in the health event prediction in real-world
   clinical settings.
Z8 0
ZA 0
TC 2
ZS 0
ZB 0
ZR 0
Z9 2
DA 2025-01-09
UT WOS:001386137300038
PM 39730390
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Bhayana, Rajesh
   Alwahbi, Omar
   Ladak, Aly Muhammad
   Deng, Yangqing
   Dias, Adriano Basso
   Elbanna, Khaled
   Gomez, Jorge Abreu
   Jajodia, Ankush
   Jhaveri, Kartik
   Johnson, Sarah
   Kajal, Dilkash
   Wang, David
   Soong, Christine
   Kielar, Ania
   Krishna, Satheesh
TI Leveraging Large Language Models to Generate Clinical Histories for
   Oncologic Imaging Requisitions
SO RADIOLOGY
VL 314
IS 2
AR e242134
DI 10.1148/radiol.242134
DT Article
PD FEB 2025
PY 2025
AB Background: Clinical information improves imaging interpretation, but
   physician-provided histories on requisitions for oncologic imaging often
   lack key details. Purpose: To evaluate large language models (LLMs) for
   automatically generating clinical histories for oncologic imaging
   requisitions from clinical notes and compare them with original
   requisition histories. Materials and Methods: In total, 207 patients
   with CT performed at a cancer center from January to November 2023 and
   with an electronic health record clinical note coinciding with ordering
   date were randomly selected. A multidisciplinary team informed selection
   of 10 parameters important for oncologic imaging history, including
   primary oncologic diagnosis, treatment history, and acute symptoms.
   Clinical notes were independently reviewed to establish the reference
   standard regarding presence of each parameter. After prompt engineering
   with seven patients, GPT-4 (version 0613; OpenAI) was prompted on April
   9, 2024, to automatically generate structured clinical histories for the
   200 remaining patients. Using the reference standard, LLM extraction
   performance was calculated (recall, precision, F1 score). LLM-generated
   and original requisition histories were compared for completeness
   (proportion including each parameter), and 10 radiologists performed
   pairwise comparison for quality, preference, and subjective likelihood
   of harm. Results: For the 200 LLM-generated histories, GPT-4 performed
   well, extracting oncologic parameters from clinical notes (F1 = 0.983).
   Compared with original requisition histories, LLM-generated histories
   more frequently included parameters critical for radiologist
   interpretation, including primary oncologic diagnosis (99.5% vs 89% [199
   and 178 of 200 histories, respectively]; P < .001), acute or worsening
   symptoms (15% vs 4% [29 and seven of 200]; P < .001), and relevant
   surgery (61% vs 12% [122 and 23 of 200]; P < .001). Radiologists
   preferred LLM-generated histories for imaging interpretation (89% vs 5%,
   7% equal; P < .001), indicating they would enable more complete
   interpretation (86% vs 0%, 15% equal; P < .001) and have a lower
   likelihood of harm (3% vs 55%, 42% neither; P < .001). Conclusion: An
   LLM enabled accurate automated clinical histories for oncologic imaging
   from clinical notes. Compared with original requisition histories,
   LLM-generated histories were more complete and were preferred by
   radiologists for imaging interpretation and perceived safety.
ZA 0
Z8 0
ZR 0
ZB 0
ZS 0
TC 1
Z9 1
DA 2025-03-08
UT WOS:001434851700023
PM 39903072
ER

PT J
AU Skoulakis, Charalambos E.
   Stavroulaki, Pelagia
   Moschotzopoulos, Panagiotis
   Paxinos, Mihalis
   Fericean, Angela
   Valagiannis, Dimitris E.
TI Laryngeal leiomyosarcoma: a case report and review of the literature
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 263
IS 10
BP 929
EP 934
DI 10.1007/s00405-006-0092-0
DT Article
PD OCT 2006
PY 2006
AB Laryngeal leiomyosarcoma (LLM) is a rare malignancy originating from the
   smooth muscles of blood vessels or from aberrant undifferentiated
   mesenchymal tissue. Histological diagnosis may be particularly difficult
   and correct diagnosis is based on immunohistochemical investigations and
   electron microscopy. A case report of a LLM in a 74-year-old man is
   presented. Direct laryngoscopy revealed a large glottic lesion causing
   airway compromise and an emergency tracheotomy was performed. Subsequent
   total laryngectomy confirmed the diagnosis of leiomyosarcoma. Lung
   metastases developed 8 months following treatment, despite the absence
   of local or regional recurrence, and the patient died 3 months later. A
   review of the English and French literature revealed 30 previous cases
   of LLM. Clinical presentation, histological diagnosis, and management of
   this rare malignancy are analyzed aiming to improve our knowledge
   regarding the best treatment modality.
Z8 0
TC 17
ZR 0
ZS 0
ZB 4
ZA 0
Z9 17
DA 2006-10-01
UT WOS:000240396200009
PM 16804717
ER

PT J
AU Duan, Yuchen
   Zhou, Qingqing
   Li, Yu
   Qin, Chi
   Wang, Ziyang
   Kan, Hongxing
   Hu, Jili
TI Research on a traditional Chinese medicine case-based question-answering
   system integrating large language models and knowledge graphs
SO FRONTIERS IN MEDICINE
VL 11
AR 1512329
DI 10.3389/fmed.2024.1512329
DT Article
PD JAN 7 2025
PY 2025
AB Introduction Traditional Chinese Medicine (TCM) case records encapsulate
   vast clinical experiences and theoretical insights, holding significant
   research and practical value. However, traditional case studies face
   challenges such as large data volumes, complex information, and
   difficulties in efficient retrieval and analysis. This study aimed to
   address these issues by leveraging modern data techniques to improve
   access and analysis of TCM case records.Methods A total of 679 case
   records from Wang Zhongqi, a renowned physician of Xin'an Medicine, a
   branch of TCM, covering 41 diseases, were selected. The study involved
   four stages: pattern layer construction, knowledge extraction,
   integration, and data storage and visualization. A large language model
   (LLM) was employed to automatically extract key entities, including
   symptoms, pathogenesis, treatment principles, and prescriptions. These
   were structured into a TCM case knowledge graph.Results The LLM
   successfully identified and extracted relevant entities, which were then
   organized into relational triples. A TCM case query system based on
   natural language input was developed. The system's performance,
   evaluated using the RAGAS framework, achieved high scores: 0.9375 in
   faithfulness, 0.9686 in answer relevancy, and 0.9500 in context recall;
   In human evaluations, the levels of safety and usability are
   significantly higher than those of LLMs without using RAG.Discussion The
   results demonstrate that integrating LLMs with a knowledge graph
   significantly enhances the efficiency and accuracy of retrieving TCM
   case information. This approach could play a crucial role in modernizing
   TCM research and improving access to clinical insights. Future research
   may explore expanding the dataset and refining the query system for
   broader applications.
ZR 0
TC 1
Z8 0
ZS 0
ZB 0
ZA 0
Z9 1
DA 2025-01-25
UT WOS:001400611400001
PM 39839612
ER

PT J
AU Franke, Georg-Nikolaus
   Maier, Jacqueline
   Wildenberger, Kathrin
   Guenther, Christine
   Cross, Michael
   Ernst, Thomas
   Fabisch, Christian
   Niederwieser, Dietger
   Hochhaus, Andreas
   Lange, Thoralf
TI Incidence of Low Level Mutations in Newly Diagnosed CML Patients: A
   Substudy of the German Tiger Trial
SO BLOOD
VL 130
MA 252
SU 1
DT Meeting Abstract
PD DEC 7 2017
PY 2017
CT 59th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2017
CL Atlanta, GA
ZR 0
Z8 0
ZA 0
ZS 0
TC 2
ZB 1
Z9 2
DA 2018-07-13
UT WOS:000432419400307
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Goldenholz, Daniel M.
   Goldenholz, Shira R.
   Habib, Sara
   Westover, M. Brandon
TI Inductive reasoning with large language models: A simulated randomized
   controlled trial for epilepsy
SO EPILEPSY RESEARCH
VL 211
AR 107532
DI 10.1016/j.eplepsyres.2025.107532
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
AB Introduction: To investigate the potential of using artificial
   intelligence (AI), specifically large language models (LLMs), for
   synthesizing information in a simulated randomized clinical trial (RCT)
   for an anti-seizure medication, cenobamate, demonstrating the
   feasibility of inductive reasoning via medical chart review. Methods: An
   LLM-generated simulated RCT was conducted, featuring a placebo arm and a
   full-strength drug arm with a cohort of 240 patients divided 1:1.
   Seizure counts were simulated using a realistic seizure diary simulator.
   The study utilized LLMs to generate clinical notes with four neurologist
   writing styles and random extraneous details. A secondary LLM pipeline
   synthesized data from these notes. The efficacy and safety of cenobamate
   in seizure control were evaluated by both an LLM-based pipeline and a
   human reader. Results: The AI analysis closely mirrored human analysis,
   demonstrating the drug's efficacy with marginal differences (<3 %) in
   identifying both drug efficacy and reported symptoms. The AI
   successfully identified the number of seizures, symptom reports, and
   treatment efficacy, with statistical analysis comparing the 50
   %responder rate and median percentage change between the placebo and
   drug arms, as well as side effect rates in each arm. Discussion: This
   study highlights the potential of AI to accurately analyze noisy
   clinical notes to inductively produce clinical knowledge. Here,
   treatment effect sizes and symptom frequencies derived from unstructured
   simulated notes were inferred despite many distractors. The findings
   emphasize the relevance of AI in future clinical research, offering a
   scalable and efficient alternative to traditional labor-intensive data
   mining.
TC 0
ZS 0
ZB 0
ZR 0
ZA 0
Z8 0
Z9 0
DA 2025-03-10
UT WOS:001437276700001
PM 40020525
ER

PT J
AU Kreimeyer, Kory
   Canzoniero, Jenna V
   Fatteh, Maria
   Anagnostou, Valsamo
   Botsis, Taxiarchis
TI Using Retrieval-Augmented Generation to Capture Molecularly-Driven
   Treatment Relationships for Precision Oncology.
SO Studies in health technology and informatics
VL 316
BP 983
EP 987
DI 10.3233/SHTI240575
DT Journal Article
PD 2024-Aug-22
PY 2024
AB Modern generative artificial intelligence techniques like
   retrieval-augmented generation (RAG) may be applied in support of
   precision oncology treatment discussions. Experts routinely review
   published literature for evidence and recommendations of treatments in a
   labor-intensive process. A RAG pipeline may help reduce this effort by
   providing chunks of text from these publications to an off-the-shelf
   large language model (LLM), allowing it to answer related questions
   without any fine-tuning. This potential application is demonstrated by
   retrieving treatment relationships from a trusted data source (OncoKB)
   and reproducing over 80% of them by asking simple questions to an
   untrained Llama 2 model with access to relevant abstracts.
ZA 0
ZB 1
ZR 0
Z8 0
TC 2
ZS 0
Z9 2
DA 2024-08-24
UT MEDLINE:39176956
PM 39176956
ER

PT J
AU Antiochos, P.
   Marques-Vidal, P.
   Waeber, G.
   Vollenweider, P.
TI Five year trends in dyslipidaemia prevalence and management in
   Switzerland: The CoLaus study
SO NUTRITION METABOLISM AND CARDIOVASCULAR DISEASES
VL 25
IS 11
BP 1007
EP 1015
DI 10.1016/j.numecd.2015.07.011
DT Article
PD NOV 2015
PY 2015
AB Background and aims: Data from prospective cohorts describing
   dyslipidaemia prevalence and treatment trends are lacking. Using data
   from the prospective CoLaus study, we aimed to examine changes in serum
   lipid levels, dyslipidaemia prevalence and management in a
   population-based sample of Swiss adults.
   Methods and results: Cardiovascular risk was assessed using PROCAM.
   Dyslipidaemia and lowdensity lipoprotein cholesterol (LDL-C) target
   levels were defined according to the Swiss Group for Lipids and
   Atherosclerosis. Complete baseline and follow up (FU) data were
   available for n = 4863 subjects during mean FU time of 5.6 years.
   Overall, 32.1% of participants were dyslipidaemic at baseline vs 46.3%
   at FU (p < 0.001). During this time, lipid lowering medication (LLM)
   rates among dyslipidaemic subjects increased from 34.0% to 39.2% (p <
   0.001). In secondary prevention, LLM rates were 42.7% at baseline and
   53.2% at FU (p = 0.004).
   In multivariate analysis, LLM use among dyslipidaemic subjects, between
   baseline and FU, was positively associated with personal history of CVD,
   older age, hypertension, higher BMI and diabetes, while negatively
   associated with higher educational level. Among treated subjects, LDL-C
   target achievement was positively associated with diabetes and
   negatively associated with personal history of CVD and higher BMI. Among
   subjects treated at baseline, LLM discontinuation was negatively
   associated with older age, male sex, smoking, hypertension and parental
   history of CVD.
   Conclusions: In Switzerland, the increase over time in dyslipidaemia
   prevalence was not paralleled by a similar increase in LLM. In a
   real-life setting, dyslipidaemia management remains far from optimal,
   both in primary and secondary prevention. (C) 2015 The Italian Society
   of Diabetology, the Italian Society for the Study of Atherosclerosis,
   the Italian Society of Human Nutrition, and the Department of Clinical
   Medicine and Surgery, Federico II University. Published by Elsevier B.V.
   All rights reserved.
ZA 0
Z8 0
ZS 0
ZB 8
TC 12
ZR 0
Z9 12
DA 2015-12-02
UT WOS:000364434000004
PM 26321470
ER

PT J
AU Capovilla, Giovanni
   Salvador, Renato
   Provenzano, Luca
   Voltarel, Guerrino
   Perazzolo, Anna
   Briscolini, Dario
   Nicoletti, Loredana
   Costantini, Andrea
   Merigliano, Stefano
   Costantini, Mario
TI EXTENDING MYOTOMY BOTH DOWNWARDS AND UPWARDS FOR MANOMETRIC PATTERN III
   ACHALASIA PATIENTS IMPROVES THE FINAL OUTCOME
SO GASTROENTEROLOGY
VL 154
IS 6
MA Su1153
BP S1301
EP S1301
SU 1
DT Meeting Abstract
PD MAY 2018
PY 2018
CT Annual Meeting of the American-Society-for-Gastrointestinal-Endoscopy /
   Digestive Disease Week
CY JUN 02-05, 2018
CL Washington, DC
SP Amer Soc Gastrointestinal Endoscopy
TC 0
ZB 0
ZR 0
ZS 0
Z8 0
ZA 0
Z9 0
DA 2018-12-07
UT WOS:000450011105183
ER

PT J
AU Li, Zhong-Liang
   Hu, Bao-Shan
   Liu, Yong-Kang
   Zheng, You-Bing
   He, Xu
   Li, Yong
   Lu, Li-Gong
TI Transhepatic arterial chemoembolizations with lobaplatin-eluting
   microspheres for the treatment of unresectable hepatocellular carcinoma
SO INTERNATIONAL JOURNAL OF CLINICAL AND EXPERIMENTAL MEDICINE
VL 11
IS 2
BP 1192
EP 1199
DT Article
PD 2018
PY 2018
AB Objective: To assess the clinical safety and efficacy of Transhepatic
   Arterial Chemoembolizations (TACE) with lobaplatin-eluting microspheres
   in treating unresectable hepatocellular carcinoma (HCC). Materials and
   Methods: A total of 70 patients with unresectable hepatocellular
   carcinoma and preserved liver function, who were treated with TACE using
   lobaplatin-eluting microspheres (Group-LEM, as experimental group) or
   using lobaplatin-lipiodol mixtures (Group-LLM, as control group), were
   evaluated retrospectively. Tumor response was determined with follow-up
   computed tomography after each chemoembolized procedure according to
   modified Response Evaluation Criteria in Solid Tumors (mRECIST). The
   side effects and complications were evaluated by the National Cancer
   Institute Common Terminology Criteria for Adverse Events (CTCAE) v4.0.
   Results: A database of 70 patients with advanced HCC admitted to
   Guangdong General Hospital between January 2016 and October 2016 was
   evaluated retrospectively. Four weeks after TACE procedure, radiological
   evaluation of tumour response was available in all patients, According
   to mRECIST, disease control rate (DCR) and objective response rate (ORR)
   differed significantly between Group-LEM and Group-LLM (60.00% vs
   31.43%, and 22.86% vs 2.86%). The most common adverse event was
   postembolization syndrome (PES), with 18 in Group-LEM and 24 in
   Group-LLM respectively. Liver dysfunction and thrombocytopenia also had
   significant difference through comparative analysis between Group-LEM
   and Group-LLM (8 vs 16, and 1 vs 8). There were neither periprocedural
   deaths nor adverse events (AEs) of grade 5 documented in all patients.
   Conclusion: TACE with lobaplatin-eluting microspheres is a safe and
   feasible treatment without major adverse events in treating unresectable
   hepatocellular carcinoma. However, the long-term effects of this
   treatment need further observation.
ZA 0
ZR 0
ZS 0
TC 0
ZB 0
Z8 0
Z9 0
DA 2018-04-02
UT WOS:000427417600101
ER

PT J
AU McClelland, Robyn L.
   Jorgensen, Neal W.
   Post, Wendy S.
   Szklo, Moyses
   Kronmal, Richard A.
TI Methods for estimation of disparities in medication use in an
   observational cohort study: results from the Multi-Ethnic Study of
   Atherosclerosis
SO PHARMACOEPIDEMIOLOGY AND DRUG SAFETY
VL 22
IS 5
BP 533
EP 541
DI 10.1002/pds.3406
DT Article
PD MAY 2013
PY 2013
AB Purpose Evaluating disparities in health care is an important aspect of
   understanding differences in disease risk. The purpose of this study is
   to describe the methodology for estimating such disparities, with
   application to a large multi-ethnic cohort study. Methods The
   Multi-Ethnic Study of Atherosclerosis includes 6814 participants aged
   4584years free of cardiovascular disease. Prevalence ratio (PR)
   regression was used to model baseline lipid lowering medication (LLM) or
   anti-hypertensive medication use at baseline as a function of gender,
   race, risk factors, and estimated pre-treatment biomarker values.
   Results Hispanics and African Americans had lower prevalence of
   medication use than did non-Hispanic whites, even at the same risk
   factor profile. This became non-significant after adjusting for
   socioeconomic status. Although gender did not influence the prevalence
   of LLM use (PR=1.09, 95%CI 0.951.25), there were differences in the
   association of diabetes and HDL with LLM use by gender. Men were
   significantly less likely to be on anti-hypertensive medications than
   women (PR=0.86, 95%CI 0.800.92, p<0.001), and this was not explained by
   risk factors or socioeconomic status. Lack of health insurance strongly
   influenced medication use, controlling for risk factors and other
   markers of socioeconomic status. Conclusions Disparities exist in the
   treatment of cholesterol and hypertension. Hispanics and African
   Americans had less use of LLM; men had less use of anti-hypertensives.
   Risk factors have differential associations with medication use
   depending on gender. Methods described in this paper can provide
   improved disparity estimation in observational cohort studies. Copyright
   (c) 2013 John Wiley & Sons, Ltd.
ZS 0
Z8 0
ZR 0
ZB 6
ZA 0
TC 9
Z9 11
DA 2013-06-05
UT WOS:000318439500011
PM 23382107
ER

PT J
AU Ye, Liu-Fang
   Ji, Xiao-Meng
   Ren, Chao
   Wang, Zhi-Qiang
   Lin, Chun-Ping
   Chen, Dong-Liang
   Cai, Yan-Qing
   Jin, Ying
   Qiu, Miao-Zhen
   Du, Zi-Ming
   Xi, Shao-Yan
   Zhang, Dong-Sheng
   Wang, Feng
   Wang, Feng-Hua
   Xu, Rui-Hua
   Li, Yu-Hong
   Wang, De-Shen
TI The Prognostic Value of Locoregional Interventions for BRAF V600E
   Metastatic Colorectal Cancer: A Retrospective Cohort Analysis
SO BIOMOLECULES
VL 11
IS 9
AR 1268
DI 10.3390/biom11091268
DT Article
PD SEP 2021
PY 2021
AB The prognostic heterogeneity in patients with BRAF V600E metastatic
   colorectal cancer (mCRC) remains poorly defined. Real-world data of 93
   BRAF V600E mCRC patients from Sun Yat-sen University Cancer Center were
   evaluated using the prognostic factors affecting overall survival (OS).
   Treatment of metastases served as an independent prognosticator, where
   curative locoregional interventions (LRIs) were associated with superior
   clinical outcomes (adjusted hazard ratio (HR): 0.46, 95% confidence
   interval (CI): 0.22-0.98; p = 0.044). The LRIs group showed an improved
   median OS of 49.4 months versus 18.3 months for the palliative
   treatments (PTs) group. The median OS of patients with colorectal liver
   metastasis (CRLM) was significantly prolonged after undergoing LRIs
   (42.4 vs. 23.7 months; HR: 0.11, 95% CI: 0.01-1.22; p = 0.030), and
   patients in the LRIs plus liver-limited or lung-limited metastasis (LLM)
   group benefited more than those in the LRIs plus non-LLM group when
   compared to the PTs group (LLM from LRIs vs. PTs, HR: 0.16, 95% CI:
   0.04-0.68; p = 0.006. Non-LLM from LRIs vs. PTs, HR: 0.47, 95% CI:
   0.21-1.05; p = 0.074). In conclusion, we confirmed the positive
   prognostic value of LRIs in BRAF V600E mCRC, particularly in patients
   with CRLM or LLM.
ZS 0
ZA 0
ZB 1
Z8 0
TC 4
ZR 0
Z9 4
DA 2021-10-02
UT WOS:000699229600001
PM 34572480
ER

PT J
AU Wallach-Kildemoes, Helle
   Hansen, Ebba Holme
TI Sociodemographic and diagnostic characteristics of prescribing a
   second-line lipid-lowering medication: ezetimibe used as initial
   medication, switch from statins, or add-on medication
SO EUROPEAN JOURNAL OF CLINICAL PHARMACOLOGY
VL 71
IS 10
BP 1245
EP 1254
DI 10.1007/s00228-015-1907-y
DT Article
PD OCT 2015
PY 2015
AB Objective Ezetimibe is used as a second-line lipid-lowering medication
   (LLM) if statin therapy is not tolerated or cholesterol targets are not
   reached by statins alone. We aimed to investigate the impact of
   sociodemographic factors on ezetimibe initiation as (a) incident LLM
   therapy, (b) add-on therapy, and (c) switch from statins.
   Methods All individuals aged 30+ who had filled at least one
   prescription for either statins (N = 581.074) or ezetimibe (N = 7.932)
   in 2011 were followed in the nationwide Danish registries to explore LLM
   prescribing patterns from 1 January 2011 to end 2012. Using logistic
   regression analyses, the odds ratio (OR) with 95 % confidence intervals
   (CIs) was calculated for (a) incident ezetimibe use among LLM initiators
   (N = 77,472), (b) ezetimibe switching by discontinuing statin users (N =
   37,509), and (c) ezetimibe as add-on by non-discontinuing statin users
   (N = 442,672).
   Results Women had higher odds for initiating ezetimibe than men (switch
   OR = 1.55; 95 % CI = 1.32-1.82). While prior use of newer high-potency
   statins was the strongest predictor (add-on (5.56; 4.95-6.24), income
   was the strongest socioeconomic predictor for incident LLM use (1.33;
   1.14-1.56) and switching (1.64; 1.27-2.13). Both income and education
   were predictors for add-on therapy, with the educational effect mediated
   by prior use of high-potency statins. Odds for ezetimibe prescribing
   were highest in myocardial infarction patients.
   Conclusions While higher income is a predictor for switching to
   ezetimibe, both higher education and income are weak predictors for
   using ezetimibe as add-on therapy. Women and individuals with myocardial
   infarction are more likely to be prescribed ezetimibe than others,
   despite lack of evidence of ezetimibe lowering the risk of
   cardiovascular events.
ZB 2
ZR 0
Z8 0
ZS 1
ZA 0
TC 4
Z9 5
DA 2015-10-01
UT WOS:000360996300010
PM 26227068
ER

PT J
AU Suharjono
   Sunoto
   Boediarso, A
   Sutoto
   Dadi, E M
TI Low lactose milk (LLM) on refeeding of infantile diarrhoea.
SO Paediatrica Indonesiana
VL 15
IS 9-10
BP 247
EP 54
DT Case Reports; Journal Article
PD 1975 Sep-Oct
PY 1975
Z8 0
ZS 0
ZA 0
ZB 0
ZR 0
TC 1
Z9 1
DA 1975-09-01
UT MEDLINE:1243776
PM 1243776
ER

PT J
AU Ge, Jin
   Sun, Steve
   Owens, Joseph
   Galvez, Victor
   Gologorskaya, Oksana
   Lai, Jennifer C
   Pletcher, Mark J
   Lai, Ki
TI Development of a Liver Disease-Specific Large Language Model Chat
   Interface using Retrieval Augmented Generation.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2023.11.10.23298364
DT Preprint
PD 2023 Nov 10
PY 2023
AB Background: Large language models (LLMs) have significant capabilities
   in clinical information processing tasks. Commercially available LLMs,
   however, are not optimized for clinical uses and are prone to generating
   incorrect or hallucinatory information. Retrieval-augmented generation
   (RAG) is an enterprise architecture that allows embedding of customized
   data into LLMs. This approach "specializes" the LLMs and is thought to
   reduce hallucinations.
   Methods: We developed "LiVersa," a liver disease-specific LLM, by using
   our institution's protected health information (PHI)-complaint text
   embedding and LLM platform, "Versa." We conducted RAG on 30 publicly
   available American Association for the Study of Liver Diseases (AASLD)
   guidelines and guidance documents to be incorporated into LiVersa. We
   evaluated LiVersa's performance by comparing its responses versus those
   of trainees from a previously published knowledge assessment study
   regarding hepatitis B (HBV) treatment and hepatocellular carcinoma (HCC)
   surveillance.
   Results: LiVersa answered all 10 questions correctly when forced to
   provide a "yes" or "no" answer. Full detailed responses with
   justifications and rationales, however, were not completely correct for
   three of the questions.
   Discussions: In this study, we demonstrated the ability to build
   disease-specific and PHI-compliant LLMs using RAG. While our LLM,
   LiVersa, demonstrated more specificity in answering questions related to
   clinical hepatology - there were some knowledge deficiencies due to
   limitations set by the number and types of documents used for RAG. The
   LiVersa prototype, however, is a proof of concept for utilizing RAG to
   customize LLMs for clinical uses and a potential strategy to realize
   personalized medicine in the future.
ZR 0
ZA 0
ZB 2
TC 5
Z8 0
ZS 0
Z9 5
DA 2023-11-22
UT MEDLINE:37986764
PM 37986764
ER

PT J
AU Zhuang, Yi
   Yu, Lingkai
   Jiang, Nan
   Ge, Yujia
TI TCM-KLLaMA: Intelligent generation model for Traditional Chinese
   Medicine Prescriptions based on knowledge graph and large language
   model.
SO Computers in biology and medicine
VL 189
BP 109887
EP 109887
DI 10.1016/j.compbiomed.2025.109887
DT Journal Article
PD 2025-May
PY 2025
AB Traditional Chinese medicine (TCM) prescriptions are a basic component
   of TCM treatment, developed by assessing patient symptoms and
   prescribing a mix of herbs. Accurate prescription generation is critical
   for enhancing treatment outcomes and maintaining patient safety.
   However, conventional methods based on Large Language Models (LLMs)
   focus mainly on symptom information, neglecting other TCM diagnostic
   expertise, such as tongue and pulse diagnosis, and are prone to
   hallucination, which is unacceptable in medical applications. To address
   these challenges, the paper proposes an effective prescription
   generation model enriched by a TCM knowledge graph (KG) called the
   TCM-KLLaMA model. In this model, the Chinese-LLaMA2-7B model is provided
   with a new output layer and loss function to suppress hallucinations and
   increase recommendation accuracy. A TCM KG including symptoms, tongue
   diagnosis, and pulse diagnosis was developed, and the model was
   fine-tuned utilizing the suggested synonym and matching knowledge
   injection (SMKI) mechanism. Extensive experiments demonstrate that the
   TCM- KLLaMA outperforms baseline models in both Precision and F1 Score,
   proving its superior performance in prescription generation tasks.
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-03-11
UT MEDLINE:40056842
PM 40056842
ER

PT J
AU Mora, J.
   Chen, S.
   Mak, R. H.
   Bitterman, D. S.
TI Cancer Treatment Information Differences by Bilingual Prompting in Large
   Language Model Chatbots
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3415
BP E645
EP E646
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001325892302096
ER

PT J
AU Pordzik, Johannes
   Bahr-Hamm, Katharina
   Huppertz, Tilman
   Gouveris, Haralampos
   Seifen, Christopher
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Eckrich, Jonas
   Buhr, Christoph R.
TI Patient Support in Obstructive Sleep Apnoea by a Large Language Model -
   ChatGPT 4o on Answering Frequently Asked Questions on First Line
   Positive Airway Pressure and Second Line Hypoglossal Nerve Stimulation
   Therapy: A Pilot Study
SO NATURE AND SCIENCE OF SLEEP
VL 16
BP 2269
EP 2277
DI 10.2147/NSS.S495654
DT Article
PD 2024
PY 2024
AB Purpose: Obstructive sleep apnoea (OSA) is a common disease that
   benefits from early treatment and patient support in order to prevent
   secondary illnesses. This study assesses the capability of the large
   language model (LLM) ChatGPT-4o to offer patient support regarding first
   line positive airway pressure (PAP) and second line hypoglossal nerve
   stimulation (HGNS) therapy. Methods: Seventeen questions, each regarding
   PAP and HGNS therapy, were posed to ChatGPT-4o. Answers were rated by
   experienced experts in sleep medicine on a 6-point Likert scale in the
   categories of medical adequacy, conciseness, coherence, and
   comprehensibility. Completeness of medical information and potential
   hazard for patients were rated using a binary system. Results: Overall,
   ChatGPT-4o achieved reasonably high ratings in all categories. In
   medical adequacy, it performed significantly better on PAP questions
   (mean 4.9) compared to those on HGNS (mean 4.6) (p < 0.05). Scores for
   coherence, comprehensibility and conciseness showed similar results for
   both HGNS and PAP answers. Raters confirmed completeness of responses in
   45 of 51 ratings (88.24%) for PAP answers and 28 of 51 ratings (54.9%)
   for HGNS answers. Potential hazards for patients were stated in 2 of 52
   ratings (0.04%) for PAP answers and none for HGNS answers. Conclusion:
   ChatGPT-4o has potential as a valuable patient-oriented support tool in
   sleep medicine therapy that can enhance subsequent face-to-face
   consultations with a sleep specialist. However, some substantial flaws
   regarding second line HGNS therapy are most likely due to recent
   advances in HGNS therapy and the consequent limited information
   available in LLM training data.
ZS 0
ZR 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
DA 2025-01-03
UT WOS:001385851000001
PM 39741798
ER

PT J
AU Agrawal, Anjali
TI Fairness in AI-Driven Oncology: Investigating Racial and Gender Biases
   in Large Language Models
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 9
AR e69541
DI 10.7759/cureus.69541
DT Article
PD SEP 16 2024
PY 2024
AB Introduction: Large language model (LLM) chatbots have many applications
   in medical settings. However, these tools can potentially perpetuate
   racial and gender biases through their responses, worsening disparities
   in healthcare. With the ongoing discussion of LLM chatbots in oncology
   and the widespread goal of addressing cancer disparities, this study
   focuses on biases propagated by LLM chatbots in oncology. Methods: Chat
   Generative Pre-trained Transformer (Chat GPT; OpenAI, San Francisco, CA,
   USA) was asked to determine what occupation a generic description of
   "assesses cancer patients" would correspond to for different
   demographics. Chat GPT, Gemini (Alphabet Inc., Mountain View, CA, USA),
   and Bing Chat (Microsoft Corp., Redmond, WA, USA) were prompted to
   provide oncologist recommendations in the top U.S. cities and
   demographic information (race, gender) of recommendations was compared
   against national distributions. Chat GPT was also asked to generate a
   job description for oncologists with different demographic backgrounds.
   Finally, Chat GPT, Gemini, and Bing Chat were asked to generate
   hypothetical cancer patients with race, smoking, and drinking histories.
   Results: LLM chatbots are about two times more likely to predict Blacks
   and Native Americans as oncology nurses than oncologists, compared to
   Asians (p < 0.01 and < 0.001, respectively). Similarly, they are also
   significantly more likely to predict females than males as oncology
   nurses (p < 0.001). Chat GPT's real-world oncologist recommendations
   overrepresent Asians by almost double and underrepresent Blacks by
   double and Hispanics by seven times. Chatbots also generate different
   job descriptions based on demographics, including cultural competency
   and advocacy and excluding treatment administration for underrepresented
   backgrounds. AI-generated cancer cases are not fully representative of
   real-world demographic distributions and encode stereotypes on substance
   abuse, such as Hispanics having a greater proportion of smokers than
   Whites by about 20% in Chat GPT breast cancer cases. Conclusion: To our
   knowledge, this is the first study of its kind to investigate racial and
   gender biases of such a diverse set of AI chatbots, and that too, within
   oncology. The methodology presented in this study provides a framework
   for targeted bias evaluation of LLMs in various fields across medicine.
ZB 0
Z8 0
ZA 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2024-09-29
UT WOS:001318056600011
PM 39416584
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Assessing the use of the novel tool Claude 3 in comparison to ChatGPT
   4.0 as an artificial intelligence tool in the diagnosis and therapy of
   primary head and neck cancer cases
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6099
EP 6109
DI 10.1007/s00405-024-08828-1
EA AUG 2024
DT Article
PD NOV 2024
PY 2024
AB ObjectivesHead and neck squamous cell carcinoma (HNSCC) is a complex
   malignancy that requires a multidisciplinary tumor board approach for
   individual treatment planning. In recent years, artificial intelligence
   tools have emerged to assist healthcare professionals in making informed
   treatment decisions. This study investigates the application of the
   newly published LLM Claude 3 Opus compared to the currently most
   advanced LLM ChatGPT 4.0 for the diagnosis and therapy planning of
   primary HNSCC. The results were compared to that of a conventional
   multidisciplinary tumor board; (2) Materials and Methods: We conducted a
   study in March 2024 on 50 consecutive primary head and neck cancer
   cases. The diagnostics and MDT recommendations were compared to the
   Claude 3 Opus and ChatGPT 4.0 recommendations for each patient and rated
   by two independent reviewers for the following parameters: clinical
   recommendation, explanation, and summarization in addition to the
   Artificial Intelligence Performance Instrument (AIPI); (3) Results: In
   this study, Claude 3 achieved better scores for the diagnostic workup of
   patients than ChatGPT 4.0 and provided treatment recommendations
   involving surgery, chemotherapy, and radiation therapy. In terms of
   clinical recommendations, explanation and summarization Claude 3 scored
   similar to ChatGPT 4.0, listing treatment recommendations which were
   congruent with the MDT, but failed to cite the source of the
   information; (4) Conclusion: This study is the first analysis of Claude
   3 for primary head and neck cancer cases and demonstrates a superior
   performance in the diagnosis of HNSCC than ChatGPT 4.0 and similar
   results for therapy recommendations. This marks the advent of a newly
   launched advanced AI model that may be superior to ChatGPT 4.0 for the
   assessment of primary head and neck cancer cases and may assist in the
   clinical diagnostic and MDT setting.
   Claude 3 OpusHNSCCMultidisciplinary TumorboardArtificial IntelligenceLLM
ZA 0
ZS 0
ZB 4
TC 17
Z8 0
ZR 0
Z9 17
DA 2024-08-13
UT WOS:001285919100001
PM 39112556
ER

PT J
AU Ihara, Keiko
   Dumkrieger, Gina
   Zhang, Pengfei
   Takizawa, Tsubasa
   Schwedt, Todd J.
   Chiang, Chia-Chun
TI Application of Artificial Intelligence in the Headache Field
SO CURRENT PAIN AND HEADACHE REPORTS
VL 28
IS 10
BP 1049
EP 1057
DI 10.1007/s11916-024-01297-5
EA JUL 2024
DT Review
PD OCT 2024
PY 2024
AB Purpose of ReviewHeadache disorders are highly prevalent worldwide.
   Rapidly advancing capabilities in artificial intelligence (AI) have
   expanded headache-related research with the potential to solve unmet
   needs in the headache field. We provide an overview of AI in headache
   research in this article.Recent FindingsWe briefly introduce machine
   learning models and commonly used evaluation metrics. We then review
   studies that have utilized AI in the field to advance diagnostic
   accuracy and classification, predict treatment responses, gather
   insights from various data sources, and forecast migraine attacks.
   Furthermore, given the emergence of ChatGPT, a type of large language
   model (LLM), and the popularity it has gained, we also discuss how LLMs
   could be used to advance the field. Finally, we discuss the potential
   pitfalls, bias, and future directions of employing AI in headache
   medicine.SummaryMany recent studies on headache medicine incorporated
   machine learning, generative AI and LLMs. A comprehensive understanding
   of potential pitfalls and biases is crucial to using these novel
   techniques with minimum harm. When used appropriately, AI has the
   potential to revolutionize headache medicine.
ZA 0
ZR 0
TC 2
ZB 0
Z8 0
ZS 0
Z9 2
DA 2024-07-18
UT WOS:001264634300002
PM 38976174
ER

PT J
AU Zhu, Libing
   Rong, Yi
   Mcgee, Lisa A.
   Rwigema, Jean-Claude M.
   Patel, Samir H.
TI Testing and Validation of a Custom Retrained Large Language Model for
   the Supportive Care of HN Patients with External Knowledge Base
SO CANCERS
VL 16
IS 13
AR 2311
DI 10.3390/cancers16132311
DT Article
PD JUL 2024
PY 2024
AB Simple Summary Cancer patients, especially long-distance patients, often
   struggle to receive timely and precise medical information and support
   for their symptom management and survivorship care. ChatGPT-4's
   responses to queries concerning head and neck (HN) cancer remain
   questionable. The purpose of this study was to develop and validate a
   retrained large language model (LLM) for HN cancer patients. In this
   cross-sectional study, the presented LLM was retrained with a
   high-quality user-defined knowledge base. The responses from the LLM to
   patients' questions were validated against human responses, and the
   model showed a superior performance, with average scores of 4.25 for
   accuracy, 4.35 for clarity, 4.22 for completeness, and 4.32 for
   relevance, on a 5-point scale. The confined-trained LLM with a
   high-quality user-defined knowledge base demonstrates high accuracy,
   clarity, completeness, and relevance in offering evidence-based
   information and guidance on the symptom management and survivorship care
   for head and neck cancer patients.Abstract Purpose: This study aimed to
   develop a retrained large language model (LLM) tailored to the needs of
   HN cancer patients treated with radiotherapy, with emphasis on symptom
   management and survivorship care. Methods: A comprehensive external
   database was curated for training ChatGPT-4, integrating
   expert-identified consensus guidelines on supportive care for HN
   patients and correspondences from physicians and nurses within our
   institution's electronic medical records for 90 HN patients. The
   performance of our model was evaluated using 20 patient post-treatment
   inquiries that were then assessed by three Board certified radiation
   oncologists (RadOncs). The rating of the model was assessed on a scale
   of 1 (strongly disagree) to 5 (strongly agree) based on accuracy,
   clarity of response, completeness s, and relevance. Results: The average
   scores for the 20 tested questions were 4.25 for accuracy, 4.35 for
   clarity, 4.22 for completeness, and 4.32 for relevance, on a 5-point
   scale. Overall, 91.67% (220 out of 240) of assessments received scores
   of 3 or higher, and 83.33% (200 out of 240) received scores of 4 or
   higher. Conclusion: The custom-trained model demonstrates high accuracy
   in providing support to HN patients offering evidence-based information
   and guidance on their symptom management and survivorship care.
ZA 0
ZS 0
Z8 0
ZR 0
TC 1
ZB 1
Z9 1
DA 2024-07-22
UT WOS:001269842700001
PM 39001375
ER

PT J
AU Blaum, Christopher
   Brunner, Fabian J.
   Gossling, Alina
   Kroeger, Friederike
   Bay, Benjamin
   Lorenz, Thiess
   Graef, Annika
   Zeller, Tanja
   Schnabel, Renate
   Clemmensen, Peter
   Westermann, Dirk
   Blankenberg, Stefan
   Seiffert, Moritz
   Waldeyer, Christoph
TI Target Populations and Treatment Cost for Bempedoic Acid and PCSK9
   Inhibitors: A Simulation Study in a Contemporary CAD Cohort
SO CLINICAL THERAPEUTICS
VL 43
IS 9
BP 1583
EP +
DI 10.1016/j.clinthera.2021.07.019
EA NOV 2021
DT Article
PD SEP 2021
PY 2021
AB Purpose: The lowered LDL-C treatment goal of the 2019 European Society
   of Cardiology dyslipidemia guidelines results in a significant increase
   in the projected need for cost-intensive proprotein convertase
   subtilisin/kexin type 9 (PCSK9) inhibitors. Addition of bempedoic acid
   (BA) to established oral lipid lowering medication (LLM) has the
   potential to enable affordable LDL-C goal attainment, particularly in
   patients with statin intolerance (SI). The goal of this study was to
   quantify the target populations for BA and PCSK9 inhibitors as well as
   the related treatment costs to achieve the LDL-C goal of < 55 mg/dL and
   a >50% reduction assuming the addition of BA to LLM. Methods: This study
   included 1922 patients with coronary artery disease (CAD) from the
   contemporary observational cohort study INTERCATH. A Monte Carlo
   simulation incorporating an algorithm adding sequentially a statin,
   ezetimibe, optionally BA, and a PCSK9 inhibitor was applied to achieve
   the LDLC treatment goal, with consideration of both partial and total
   SI. Two scenarios were simulated for both a moderate (2% full and 10%
   partial) and a high (12% full) rate of SI: (1) without BA; and (2) with
   BA. Findings: Patients' mean age was 69.3 years, and the median baseline
   LDL-C level was 86.0 mg/dL. The need for a PCSK9 inhibitor would be
   41.4% for a moderate rate of SI and 46.1% for a high rate of SI.
   Addition of BA would: (1) reduce the need for a PCSK9 inhibitor to 25.3%
   and 29.4%, thus lowering the annual overall treatment cost incurred
   through PCSK9 inhibitor +/- BA per 1 million patients with CAD by 13.3%
   and 10.5%; (2) lower the cost per prevented event in the entire cohort
   (-5.0% and -6.3%), although at the price of fewer prevented events
   (-8.7% and -4.5%); and (3) reduce the cost per prevented event (-6.8%
   for both rates of SI) while preventing more events (7.6% and 6.9%) in
   the subpopulation of patients with full SI. Implications: Use of BA is
   projected to reduce the need for PCSK9 inhibitors as well as the
   treatment cost for add-on LLM. The subpopulation of patients with full
   SI might profit particularly. (Clin Ther. 2021;43:1583-1594.) (c) 2021
   Elsevier Inc.
ZR 0
ZS 0
Z8 0
ZB 8
ZA 0
TC 16
Z9 16
DA 2021-12-02
UT WOS:000718006700016
PM 34462126
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT J
AU Scaff, Simone P. S.
   Reis, Felipe J. J.
   Ferreira, Giovanni E.
   Jacob, Maria Fernanda
   Saragiotto, Bruno T.
TI Assessing the performance of AI chatbots in answering patients' common
   questions about low back pain
SO ANNALS OF THE RHEUMATIC DISEASES
VL 84
IS 1
BP 143
EP 149
DI 10.1136/ard-2024-226202
EA SEP 2024
DT Article
PD JAN 2025
PY 2025
AB Objectives: The aim of this study was to assess the accuracy and
   readability of the answers generated by large language model
   (LLM)-chatbots to common patient questions about low back pain (LBP).
   Methods: This cross-sectional study analysed responses to 30 LBP-related
   questions, covering self-management, risk factors and treatment. The
   questions were developed by experienced clinicians and researchers and
   were piloted with a group of consumer representatives with lived
   experience of LBP. The inquiries were inputted in prompt form into
   ChatGPT 3.5, Bing, Bard (Gemini) and ChatGPT 4.0. Responses were
   evaluated in relation to their accuracy, readability and presence of
   disclaimers about health advice. The accuracy was assessed by comparing
   the recommendations generated with the main guidelines for LBP. The
   responses were analysed by two independent reviewers and classified as
   accurate, inaccurate or unclear. Readability was measured with the
   Flesch Reading Ease Score (FRES). Results: Out of 120 responses yielding
   1069 recommendations, 55.8% were accurate, 42.1% inaccurate and 1.9%
   unclear. Treatment and self-management domains showed the highest
   accuracy while risk factors had the most inaccuracies. Overall,
   LLM-chatbots provided answers that were 'reasonably difficult' to read,
   with a mean (SD) FRES score of 50.94 (3.06). Disclaimer about health
   advice was present around 70%-100% of the responses produced.
   Conclusions: The use of LLM-chatbots as tools for patient education and
   counselling in LBP shows promising but variable results. These chatbots
   generally provide moderately accurate recommendations. However, the
   accuracy may vary depending on the topic of each question. The
   reliability level of the answers was inadequate, potentially affecting
   the patient's ability to comprehend the information.
Z8 0
TC 5
ZB 1
ZR 0
ZS 0
ZA 0
Z9 5
DA 2024-09-30
UT WOS:001319686500001
PM 39874229
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT J
AU Gencer, Gulcan
   Gencer, Kerem
TI Large Language Models in Healthcare: A Bibliometric Analysis and
   Examination of Research Trends
SO JOURNAL OF MULTIDISCIPLINARY HEALTHCARE
VL 18
BP 223
EP 238
DI 10.2147/JMDH.S502351
DT Article
PD 2025
PY 2025
AB Background: The integration of large language models (LLMs) in
   healthcare has generated significant interest due to their potential to
   improve diagnostic accuracy, personalization of treatment, and patient
   care efficiency. Objective: This study aims to conduct a comprehensive
   bibliometric analysis to identify current research trends, main themes
   and future directions regarding applications in the healthcare sector.
   Methods: A systematic scan of publications until 08.05.2024 was carried
   out from an important database such as Web of Science.Using bibliometric
   tools such as VOSviewer and CiteSpace, we analyzed data covering
   publication counts, citation analysis, co-authorship, co- occurrence of
   keywords and thematic development to map the intellectual landscape and
   collaborative networks in this field. Results: The analysis included
   more than 500 articles published between 2021 and 2024. The United
   States, Germany and the United Kingdom were the top contributors to this
   field. The study highlights that neural network applications in
   diagnostic imaging, natural language processing for clinical
   documentation, and patient data in the field of general internal
   medicine, radiology, medical informatics, health care services, surgery,
   oncology, ophthalmology, neurology, orthopedics and psychiatry have seen
   significant growth in publications over the past two years. Keyword
   trend analysis revealed emerging sub-themes such as clinical research,
   artificial intelligence, ChatGPT, education, natural language
   processing, clinical management, virtual reality, chatbot, indicating a
   shift towards addressing the broader implications of LLM application in
   healthcare. Conclusion: The use of LLM in healthcare is an expanding
   field with significant academic and clinical interest. This bibliometric
   analysis not only maps the current state of the research, but also
   identifies important areas that require further research and
   development. Continued advances in this field are expected to
   significantly impact future healthcare applications, with a focus on
   increasing the accuracy and personalization of patient care through
   advanced data analytics.
ZR 0
Z8 0
ZS 0
ZA 0
TC 3
ZB 0
Z9 3
DA 2025-01-25
UT WOS:001400829200001
PM 39844924
ER

PT J
AU Sezgin, Emre
   Jackson, Daniel I.
   Kocaballi, A. Baki
   Bibart, Mindy
   Zupanec, Sue
   Landier, Wendy
   Audino, Anthony
   Ranalli, Mark
   Skeens, Micah
TI Can Large Language Models Aid Caregivers of Pediatric Cancer Patients in
   Information Seeking? A Cross-Sectional Investigation
SO CANCER MEDICINE
VL 14
IS 1
AR e70554
DI 10.1002/cam4.70554
DT Article
PD JAN 2025
PY 2025
AB PurposeCaregivers in pediatric oncology need accurate and understandable
   information about their child's condition, treatment, and side effects.
   This study assesses the performance of publicly accessible large
   language model (LLM)-supported tools in providing valuable and reliable
   information to caregivers of children with cancer. MethodsIn this
   cross-sectional study, we evaluated the performance of the four
   LLM-supported tools-ChatGPT (GPT-4), Google Bard (Gemini Pro), Microsoft
   Bing Chat, and Google SGE-against a set of frequently asked questions
   (FAQs) derived from the Children's Oncology Group Family Handbook and
   expert input (In total, 26 FAQs and 104 generated responses). Five
   pediatric oncology experts assessed the generated LLM responses using
   measures including accuracy, clarity, inclusivity, completeness,
   clinical utility, and overall rating. Additionally, the content quality
   was evaluated including readability, AI disclosure, source credibility,
   resource matching, and content originality. We used descriptive analysis
   and statistical tests including Shapiro-Wilk, Levene's, Kruskal-Wallis
   H-tests, and Dunn's post hoc tests for pairwise comparisons.
   ResultsChatGPT shows high overall performance when evaluated by the
   experts. Bard also performed well, especially in accuracy and clarity of
   the responses, whereas Bing Chat and Google SGE had lower overall
   scores. Regarding the disclosure of responses being generated by AI, it
   was observed less frequently in ChatGPT responses, which may have
   affected the clarity of responses, whereas Bard maintained a balance
   between AI disclosure and response clarity. Google SGE generated the
   most readable responses whereas ChatGPT answered with the most
   complexity. LLM tools varied significantly (p < 0.001) across all expert
   evaluations except inclusivity. Through our thematic analysis of expert
   free-text comments, emotional tone and empathy emerged as a unique theme
   with mixed feedback on expectations from AI to be empathetic.
   ConclusionLLM-supported tools can enhance caregivers' knowledge of
   pediatric oncology. Each model has unique strengths and areas for
   improvement, indicating the need for careful selection based on specific
   clinical contexts. Further research is required to explore their
   application in other medical specialties and patient demographics,
   assessing broader applicability and long-term impacts.
ZA 0
TC 2
Z8 0
ZS 0
ZB 1
ZR 0
Z9 2
DA 2025-01-13
UT WOS:001391811100001
PM 39776222
ER

PT J
AU Hooshangnejad, Hamed
   Huang, Gaofeng
   Kelly, Katelyn
   Feng, Xue
   Luo, Yi
   Zhang, Rui
   Xu, Ziyue
   Chen, Quan
   Ding, Kai
TI EXACT-Net: Framework for EHR-Guided Lung Tumor Auto-Segmentation for
   Non-Small Cell Lung Cancer Radiotherapy
SO CANCERS
VL 16
IS 23
AR 4097
DI 10.3390/cancers16234097
DT Article
PD DEC 2024
PY 2024
AB Background/Objectives: Lung cancer is a devastating disease with the
   highest mortality rate among cancer types. Over 60% of non-small cell
   lung cancer (NSCLC) patients, accounting for 87% of lung cancer
   diagnoses, require radiation therapy. Rapid treatment initiation
   significantly increases the patient's survival rate and reduces the
   mortality rate. Accurate tumor segmentation is a critical step in
   diagnosing and treating NSCLC. Manual segmentation is time- and
   labor-consuming and causes delays in treatment initiation. Although many
   lung nodule detection methods, including deep learning-based models,
   have been proposed. Most of these methods still have a long-standing
   problem of high false positives (FPs). Methods: Here, we developed an
   electronic health record (EHR)-guided lung tumor auto-segmentation
   called EXACT-Net (EHR-enhanced eXACtitude in Tumor segmentation), where
   the extracted information from EHRs using a pre-trained large language
   model (LLM) was used to remove the FPs and keep the TP nodules only.
   Results: The auto-segmentation model was trained on NSCLC patients'
   computed tomography (CT), and the pre-trained LLM was used with the
   zero-shot learning approach. Our approach resulted in a 250% boost in
   successful nodule detection using the data from ten NSCLC patients
   treated in our institution. Conclusions: We demonstrated that combining
   vision-language information in EXACT-Net multi-modal AI framework
   greatly enhances the performance of vision only models, paving the road
   to multimodal AI framework for medical image processing.
ZS 0
ZA 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2024-12-19
UT WOS:001376131100001
PM 39682283
ER

PT J
AU Roumie, Christianne L.
   Huizinga, Mary Margaret
   Liu, Xulei
   Greevy, Robert A.
   Grijalva, Carlos G.
   Murff, Harvey J.
   Hung, Adriana M.
   Griffin, Marie R.
TI The effect of incident antidiabetic regimens on lipid profiles in
   veterans with type 2 diabetes: a retrospective cohort
SO PHARMACOEPIDEMIOLOGY AND DRUG SAFETY
VL 20
IS 1
BP 36
EP 44
DI 10.1002/pds.2029
DT Article
PD JAN 2011
PY 2011
AB Objective Effects of oral antidiabetic drugs (OADs) on lipids may
   influence cardiovascular outcomes. Our aim was to compare time to
   initiation of lipid lowering medication (LLM) and 12-month lipid
   profiles among new OAD users.
   Methods We identified a retrospective cohort of 17 774 veterans who
   received care at Veterans Administration (VA) Mid-South Network with a
   first OAD from 1 January 2000 to 31 December 2007. There were 6917
   patients (38.9%) not on a LLM at baseline, and 3871 (56%) had complete
   covariates. Incident users of sulfonylurea and combination
   metformin+sulfonylurea were compared to metformin users for time to LLM
   initiation. Incident users of these OADs and thiazolidendiones were
   included in comparison of 12-month low-density lipoprotein (LDL),
   high-density lipoprotein (HDL), triglycerides (TGs), and total
   cholesterol. All analyses adjusted for demographics, lipids, HbA1C,
   healthcare utilization, and cardiovascular disease at baseline.
   Results The median time to starting LLM was 2.35 years (interquartile
   range 0.96, 4.6) following metformin initiation and not statistically
   different for users of sulfonylureas, or combination OADs. Compared to
   metformin users, 12-month HDL was 1.35 mg/dl (95%CI: -2.01, -0.72) lower
   and TGs were 5.7% higher (95%CI: 1.5%, 10.0%) for sulfonylurea users;
   TGs were 24.8% (95%CI: 0.7%, 54.5%) higher for thiazolidinedione users.
   Statin users had LDL and total cholesterol 16.7 mg/dl (95%CI: -19.9,
   -13.5) and 18.6 mg/dl (95%CI: -22.1, -15.1) lower than non-statin users,
   respectively.
   Conclusions Time to LLM initiation was similar between OADs. Metformin
   use resulted in more favorable lipids at 12 months compared to
   sulfonylureas or thiazolidinediones. Copyright (C) 2010 John Wiley &
   Sons, Ltd.
ZS 0
ZR 0
ZB 7
Z8 0
ZA 0
TC 11
Z9 11
DA 2011-01-01
UT WOS:000286071700005
PM 21182152
ER

PT J
AU John, Annette
   Alhajj, Reda
   Rokne, Jon
TI A systematic review of AI as a digital twin for prostate cancer care
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 268
AR 108804
DI 10.1016/j.cmpb.2025.108804
EA MAY 2025
DT Review
PD AUG 2025
PY 2025
AB Artificial Intelligence (AI) and Digital Twin (DT) technologies are
   rapidly transforming healthcare, offering the potential for
   personalized, accurate, and efficient medical care. This systematic
   review focuses on the intersection of AI-based digital twins and their
   applications in prostate cancer pathology. A digital twin, when applied
   to healthcare, creates a dynamic, data-driven virtual model that
   simulates a patient's biological systems in real-time. By incorporating
   AI techniques such as Machine Learning (ML) and Deep Learning (DL),
   these systems enhance predictive accuracy, enable early diagnosis, and
   facilitate individualized treatment strategies for prostate cancer. This
   review systematically examines recent advances (2020-2025) in AI-driven
   digital twins for prostate cancer, highlighting key methodologies,
   algorithms, and data integration strategies. The literature analysis
   also reveals substantial progress in image processing, predictive
   modeling, and clinical decision support systems, which are the basic
   tools used when implementing digital twins for prostate cancer care. Our
   survey also critically evaluates the strengths and limitations of
   current approaches, identifying gaps such as the need for real-time data
   integration, improved explainability in AI models, and more robust
   clinical validation. It concludes with a discussion of future research
   directions, emphasizing the importance of integrating multi-modal data
   with Large Language Models (LLMs) and Vision-Language Models (VLMs),
   scalability, and ethical considerations in advancing AI-driven digital
   twins for prostate cancer diagnosis and treatment. This paper provides a
   comprehensive resource for researchers and clinicians, offering insights
   into how AI-based digital twins can enhance precision medicine and
   improve patient outcomes in prostate cancer care.
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
DA 2025-05-23
UT WOS:001490802200002
PM 40347618
ER

PT J
AU Samaranayake, Lakshman
   Tuygunov, Nozimjon
   Schwendicke, Falk
   Osathanon, Thanaphum
   Khurshid, Zohaib
   Boymuradov, Shukhrat A.
   Cahyanto, Arief
TI The Transformative Role of Artificial Intelligence in Dentistry: A
   Comprehensive Overview. Part 1: Fundamentals of AI, and its Contemporary
   Applications in Dentistry
SO INTERNATIONAL DENTAL JOURNAL
VL 75
IS 2
BP 383
EP 396
DI 10.1016/j.identj.2025.02.005
EA MAR 2025
DT Review
PD APR 2025
PY 2025
AB Artificial intelligence (AI) holds immense promise in revolutionising
   dentistry, spanning, diagnostics, treatment planning and educational
   realms. This narrative review, in two parts, explores the fundamentals
   and the multifaceted potential of AI in dentistry. The current article
   explores the profound impact of AI in dentistry, encompassing diagnostic
   tools, treatment planning, and patient care. The Part 2 of the article
   delves into the potential of AI in patient education, ethics and the FDI
   communique on AI in dentistry. The review begins by elucidating the
   historical context of AI, outlining its recent widespread use in various
   sectors, including medicine and dentistry. The narrative delves into the
   fundamental concepts of AI, which entails developing machines capable of
   executing tasks that typically necessitate human intellect. In the
   biomedical realm, AI has evolved from exploring computational models to
   constructing systems for clinical data processing and interpretation,
   aiming to enhance medical/dental decision-making. The discussion delves
   into the pivotal role of AI models in dentistry, such as Large Language
   Models (LLM), Large Vision Models (LVM), and Multimodality Models (MM),
   revolutionizing processes from clinical documentation to treatment
   planning. The narrative extends to the applications of AI in dental
   specialties such as periodontics, endodontics, oral medicine and
   pathology, restorative dentistry, prosthodontics, paediatric dentistry,
   forensic odontology, oral and maxillofacial surgery, orthodontics, and
   orofacial pain management. AI's role in improving treatment outcomes,
   diagnostic accuracy, and decision-making processes is evident across
   these specialties, showcasing its potential in transforming dental care.
   The review concludes by highlighting the need for continued validation,
   interdisciplinary collaboration, and regulatory
TC 6
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
Z9 6
DA 2025-04-25
UT WOS:001468197900001
PM 40074616
ER

PT J
AU Claure-Del Granado, Rolando
   Moya-Mamani, Juan C.
   Malhotra, Rakesh
   Dasgupta, Subhasis
TI Performance of an Artificial Intelligence-Generated Risk Score for AKI
   Prediction
SO JOURNAL OF THE AMERICAN SOCIETY OF NEPHROLOGY
VL 35
IS 10
MA FR-PO036
DI 10.1681/ASN.202482byjb75
SU S
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Kidney Week
CY OCT 24-27, 2024
CL San Diego, CA
Z8 0
TC 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 0
DA 2025-03-21
UT WOS:001405917800150
ER

PT J
AU Buhr, Christoph Raphael
   Ernst, Benjamin Philipp
   Blaikie, Andrew
   Smith, Harry
   Kelsey, Tom
   Matthias, Christoph
   Fleischmann, Maximilian
   Jungmann, Florian
   Alt, Juergen
   Brandts, Christian
   Kaemmerer, Peer W.
   Foersch, Sebastian
   Kuhn, Sebastian
   Eckrich, Jonas
TI Assessment of decision-making with locally run and web-based large
   language models versus human board recommendations in
   otorhinolaryngology, head and neck surgery
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1593
EP 1607
DI 10.1007/s00405-024-09153-3
EA JAN 2025
DT Article
PD MAR 2025
PY 2025
AB IntroductionTumor boards are a cornerstone of modern cancer treatment.
   Given their advanced capabilities, the role of Large Language Models
   (LLMs) in generating tumor board decisions for otorhinolaryngology (ORL)
   head and neck surgery is gaining increasing attention. However, concerns
   over data protection and the use of confidential patient information in
   web-based LLMs have restricted their widespread adoption and hindered
   the exploration of their full potential. In this first study of its kind
   we compared standard human multidisciplinary tumor board recommendations
   (MDT) against a web-based LLM (ChatGPT-4o) and a locally run LLM (Llama
   3) addressing data protection concerns.Material and methodsTwenty-five
   simulated tumor board cases were presented to an MDT composed of
   specialists from otorhinolaryngology, craniomaxillofacial surgery,
   medical oncology, radiology, radiation oncology, and pathology. This
   multidisciplinary team provided a comprehensive analysis of the cases.
   The same cases were input into ChatGPT-4o and Llama 3 using structured
   prompts, and the concordance between the LLMs' and MDT's recommendations
   was assessed. Four MDT members evaluated the LLMs' recommendations in
   terms of medical adequacy (using a six-point Likert scale) and whether
   the information provided could have influenced the MDT's original
   recommendations.ResultsChatGPT-4o showed 84% concordance (21 out of 25
   cases) and Llama 3 demonstrated 92% concordance (23 out of 25 cases)
   with the MDT in distinguishing between curative and palliative treatment
   strategies. In 64% of cases (16/25) ChatGPT-4o and in 60% of cases
   (15/25) Llama, identified all first-line therapy options considered by
   the MDT, though with varying priority. ChatGPT-4o presented all the
   MDT's first-line therapies in 52% of cases (13/25), while Llama 3
   offered a homologous treatment strategy in 48% of cases (12/25).
   Additionally, both models proposed at least one of the MDT's first-line
   therapies as their top recommendation in 28% of cases (7/25). The
   ratings for medical adequacy yielded a mean score of 4.7 (IQR: 4-6) for
   ChatGPT-4o and 4.3 (IQR: 3-5) for Llama 3. In 17% of the assessments
   (33/200), MDT members indicated that the LLM recommendations could
   potentially enhance the MDT's decisions.DiscussionThis study
   demonstrates the capability of both LLMs to provide viable therapeutic
   recommendations in ORL head and neck surgery. Llama 3, operating
   locally, bypasses many data protection issues and shows promise as a
   clinical tool to support MDT decisions. However at present, LLMs should
   augment rather than replace human decision-making.
TC 0
ZA 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
DA 2025-01-19
UT WOS:001394124400001
PM 39792200
ER

PT J
AU Ra, Sinyoung
   Kim, Jonghun
   Na, Inye
   Ko, Eun Sook
   Park, Hyunjin
TI Enhancing radiomics features via a large language model for classifying
   benign and malignant breast tumors in mammography
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 265
AR 108765
DI 10.1016/j.cmpb.2025.108765
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Background and Objectives: Radiomics is widely used to assist in
   clinical decision-making, disease diagnosis, and treatment planning for
   various target organs, including the breast. Recent advances in large
   language models (LLMs) have helped enhance radiomics analysis. Materials
   and Methods: Herein, we sought to improve radiomics analysis by
   incorporating LLM-learned clinical knowledge, to classify benign and
   malignant tumors in breast mammography. We extracted radiomics features
   from the mammograms based on the region of interest and retained the
   features related to the target task. Using prompt engineering, we
   devised an input sequence that reflected the selected features and the
   target task. The input sequence was fed to the chosen LLM (LLaMA
   variant), which was fine-tuned using low-rank adaptation to enhance
   radiomics features. This was then evaluated on two mammogram datasets
   (VinDr-Mammo and INbreast) against conventional baselines. Results: The
   enhanced radiomics-based method performed better than baselines using
   conventional radiomics features tested on two mammogram datasets,
   achieving accuracies of 0.671 for the VinDr-Mammo dataset and 0.839 for
   the INbreast dataset. Conventional radiomics models require retraining
   from scratch for an unseen dataset using a new set of features. In
   contrast, the model developed in this study effectively reused the
   common features between the training and unseen datasets by explicitly
   linking feature names with feature values, leading to extensible
   learning across datasets. Our method performed better than the baseline
   method in this retraining setting using an unseen dataset. Conclusions:
   Our method, one of the first to incorporate LLM into radiomics, has the
   potential to improve radiomics analysis.
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
ZB 0
Z9 0
DA 2025-04-21
UT WOS:001466026900001
PM 40203779
ER

PT J
AU Huo, Bright
   Boyle, Amy
   Marfo, Nana
   Tangamornsuksan, Wimonchat
   Steen, Jeremy P.
   Mckechnie, Tyler
   Lee, Yung
   Mayol, Julio
   Antoniou, Stavros A.
   Thirunavukarasu, Arun James
   Sanger, Stephanie
   Ramji, Karim
   Guyatt, Gordon
TI Large Language Models for Chatbot Health Advice Studies: A Systematic
   Review
SO JAMA NETWORK OPEN
VL 8
IS 2
AR e2457879
DI 10.1001/jamanetworkopen.2024.57879
DT Article
PD FEB 4 2025
PY 2025
AB Importance There is much interest in the clinical integration of large
   language models (LLMs) in health care. Many studies have assessed the
   ability of LLMs to provide health advice, but the quality of their
   reporting is uncertain. Objective To perform a systematic review to
   examine the reporting variability among peer-reviewed studies evaluating
   the performance of generative artificial intelligence (AI)-driven
   chatbots for summarizing evidence and providing health advice to inform
   the development of the Chatbot Assessment Reporting Tool (CHART).
   Evidence Review A search of MEDLINE via Ovid, Embase via Elsevier, and
   Web of Science from inception to October 27, 2023, was conducted with
   the help of a health sciences librarian to yield 7752 articles. Two
   reviewers screened articles by title and abstract followed by full-text
   review to identify primary studies evaluating the clinical accuracy of
   generative AI-driven chatbots in providing health advice (chatbot health
   advice studies). Two reviewers then performed data extraction for 137
   eligible studies. Findings A total of 137 studies were included. Studies
   examined topics in surgery (55 [40.1%]), medicine (51 [37.2%]), and
   primary care (13 [9.5%]). Many studies focused on treatment (91
   [66.4%]), diagnosis (60 [43.8%]), or disease prevention (29 [21.2%]).
   Most studies (136 [99.3%]) evaluated inaccessible, closed-source LLMs
   and did not provide enough information to identify the version of the
   LLM under evaluation. All studies lacked a sufficient description of LLM
   characteristics, including temperature, token length, fine-tuning
   availability, layers, and other details. Most studies (136 [99.3%]) did
   not describe a prompt engineering phase in their study. The date of LLM
   querying was reported in 54 (39.4%) studies. Most studies (89 [65.0%])
   used subjective means to define the successful performance of the
   chatbot, while less than one-third addressed the ethical, regulatory,
   and patient safety implications of the clinical integration of LLMs.
   Conclusions and Relevance In this systematic review of 137 chatbot
   health advice studies, the reporting quality was heterogeneous and may
   inform the development of the CHART reporting standards. Ethical,
   regulatory, and patient safety considerations are crucial as interest
   grows in the clinical integration of LLMs.
TC 5
Z8 0
ZS 0
ZB 0
ZR 0
ZA 0
Z9 5
DA 2025-02-14
UT WOS:001416067000009
PM 39903463
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT J
AU Franke, Georg-Nikolaus
   Maier, Jacqueline
   Schubert, Karoline
   Cross, Michael
   Leiblein, Sabine
   Wildenberger, Kathrin
   Giles, Frank
   Hochhaus, Andreas
   Frank, Oliver
   Niederwieser, Dietger
   Lange, Thoralf
TI Low Level BCR-ABL Mutations and Response to Treatment: A Substudy of the
   ENEST1st Trial
SO BLOOD
VL 124
IS 21
DT Meeting Abstract
PD DEC 6 2014
PY 2014
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2015-03-25
UT WOS:000349242700194
ER

PT J
AU Franc, Jeffrey Micheal
   Med, Dip Sport
   Hertelendy, Attila Julius
   Cheng, Lenard
   Hata, Ryan
   Verde, Manuela
TI Accuracy of a Commercial Large Language Model (ChatGPT) toPerform
   Disaster Triage of Simulated Patients Using the SimpleTriage and Rapid
   Treatment (START) Protocol:Gage Repeatabilityand Reproducibility Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 26
AR e55648
DI 10.2196/55648
DT Article
PD SEP 30 2024
PY 2024
AB Background: The release of ChatGPT (OpenAI) in November 2022 drastically
   reduced the barrier to using artificial intelligence by allowing a
   simple web-based text interface to a large language model (LLM). One use
   case where ChatGPT could be useful is in triaging patients at the site
   of a disaster using the Simple Triage and Rapid Treatment (START)
   protocol. However, LLMs experience several common errors including
   hallucinations (also called confabulations) and prompt dependency.
   Objective: This study addresses the research problem: "Can ChatGPT
   adequately triage simulated disaster patients using the START protocol?"
   by measuring three outcomes: repeatability, reproducibility, and
   accuracy. Methods: Nine prompts were developed by 5 disaster medicine
   physicians. A Python script queried ChatGPT Version 4 for each prompt
   combined with 391 validated simulated patient vignettes. Ten repetitions
   of each combination were performed for a total of 35,190 simulated
   triages. A reference standard START triage code for each simulated case
   was assigned by 2 disaster medicine specialists (JMF and MV), with a
   third specialist (LC) added if the first two did not agree. Results were
   evaluated using a gage repeatability and reproducibility study (gage R
   and R). Repeatability was defined as variation due to repeated use of
   the same prompt. Reproducibility was defined as variation due to the use
   of different prompts on the same patient vignette. Accuracy was defined
   as agreement with the reference standard. Results: Although 35,102
   (99.7%) queries returned a valid START score, there was considerable
   variability. Repeatability (use of the same prompt repeatedly) was 14%
   of the overall variation. Reproducibility (use of different prompts) was
   4.1% of the overall variation. The accuracy of ChatGPT for START was
   63.9% with a 32.9% overtriage rate and a 3.1% undertriage rate. Accuracy
   varied by prompt with a maximum of 71.8% and a minimum of 46.7%.
   Conclusions: This study indicates that ChatGPT version 4 is insufficient
   to triage simulated disaster patients via the START protocol. It
   demonstrated suboptimal repeatability and reproducibility. The overall
   accuracy of triage was only 63.9%. Health care professionals are advised
   to exercise caution while using commercial LLMs for vital medical
   determinations, given that these tools may commonly produce inaccurate
   data, colloquially referred to as hallucinations or confabulations.
   Artificial intelligence-guided tools should undergo rigorous statistical
   evaluation-using methods such as gage R and R-before implementation into
   clinical settings.
ZS 0
TC 2
ZA 0
ZR 0
ZB 0
Z8 0
Z9 2
DA 2024-10-24
UT WOS:001334857400004
PM 39348189
ER

PT J
AU Griewing, Sebastian
   Lechner, Fabian
   Gremke, Niklas
   Lukac, Stefan
   Janni, Wolfgang
   Wallwiener, Markus
   Wagner, Uwe
   Hirsch, Martin
   Kuhn, Sebastian
TI Proof-of-concept study of a small language model chatbot for breast
   cancer decision support - a transparent, source-controlled, explainable
   and data-secure approach
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 10
AR 451
DI 10.1007/s00432-024-05964-3
DT Article
PD OCT 9 2024
PY 2024
AB Purpose Large language models (LLM) show potential for decision support
   in breast cancer care. Their use in clinical care is currently
   prohibited by lack of control over sources used for decision-making,
   explainability of the decision-making process and health data security
   issues. Recent development of Small Language Models (SLM) is discussed
   to address these challenges. This preclinical proof-of-concept study
   tailors an open-source SLM to the German breast cancer guideline
   (BC-SLM) to evaluate initial clinical accuracy and technical
   functionality in a preclinical simulation. Methods A multidisciplinary
   tumor board (MTB) is used as the gold-standard to assess the initial
   clinical accuracy in terms of concordance of the BC-SLM with MTB and
   comparing it to two publicly available LLM, ChatGPT3.5 and 4. The study
   includes 20 fictional patient profiles and recommendations for 5
   treatment modalities, resulting in 100 binary treatment recommendations
   (recommended or not recommended). Statistical evaluation includes
   concordance with MTB in % including Cohen's Kappa statistic (kappa).
   Technical functionality is assessed qualitatively in terms of local
   hosting, adherence to the guideline and information retrieval. Results
   The overall concordance amounts to 86% for BC-SLM (kappa = 0.721, p <
   0.001), 90% for ChatGPT4 (kappa = 0.820, p < 0.001) and 83% for
   ChatGPT3.5 (kappa = 0.661, p < 0.001). Specific concordance for each
   treatment modality ranges from 65 to 100% for BC-SLM, 85-100% for
   ChatGPT4, and 55-95% for ChatGPT3.5. The BC-SLM is locally functional,
   adheres to the standards of the German breast cancer guideline and
   provides referenced sections for its decision-making. Conclusion The
   tailored BC-SLM shows initial clinical accuracy and technical
   functionality, with concordance to the MTB that is comparable to
   publicly-available LLMs like ChatGPT4 and 3.5. This serves as a
   proof-of-concept for adapting a SLM to an oncological disease and its
   guideline to address prevailing issues with LLM by ensuring decision
   transparency, explainability, source control, and data security, which
   represents a necessary step towards clinical validation and safe use of
   language models in clinical oncology.
ZR 0
ZA 0
Z8 0
TC 1
ZB 1
ZS 0
Z9 1
DA 2024-10-24
UT WOS:001335902900001
PM 39382778
ER

PT J
AU SORENSEN, KL
   MEERSOHN, MV
   SONNE, J
   LARSEN, L
   EDELSTEN, D
   GUDMANDHOYER, E
TI A NEW TYPE OF LOW-LACTOSE MILK - TOLERANCE BY LACTOSE MALABSORBERS AND
   EVALUATION OF PROTEIN NUTRITIONAL-VALUE
SO SCANDINAVIAN JOURNAL OF GASTROENTEROLOGY
VL 18
IS 8
BP 1063
EP 1068
DI 10.3109/00365528309181841
DT Article
PD 1983
PY 1983
AB By ultrafiltration of skim milk a new low-lactose milk powder was
   developed whose lactose content was reduced by 86%. The lactose was
   replaced by malto-dextrin. In contrast to lactose-hydrolyzed milk
   powder, no protein-destroying processes (Maillard reactions) could be
   demonstrated during production or after storage at standard conditions.
   Tolerance of the new low-lactose milk vs. regular skim milk was tested
   in 35 well-nourished, adult Latin Americans with lactose malabsorption.
   The ingestion of 500 ml of the low-lactose milk gave rise to
   significantly (P < 0.05) fewer symptoms than regular skim milk. After
   the intake of 250 ml there was a tendency to fewer symptoms after the
   low-lactose milk, although the difference was not significant (0.05 < P
   < 0.1). The new milk may be of potential usefulness in the treatment of
   protein calories malnutrition in the developing countries, where lactose
   malabsorption is highly prevalent.
ZR 0
ZB 3
ZA 0
Z8 0
TC 11
ZS 0
Z9 11
DA 1983-01-01
UT WOS:A1983RU71700011
PM 6424228
ER

PT J
AU Koidou, Vasiliki P
   Chatzopoulos, Georgios S
   Tsalikis, Lazaros
   Kaklamanos, Eleutherios G
TI Large Language Models in peri-implant disease: How well do they perform?
SO The Journal of prosthetic dentistry
DI 10.1016/j.prosdent.2025.02.008
DT Journal Article
PD 2025-Mar-06
PY 2025
AB STATEMENT OF PROBLEM: Artificial intelligence (AI) has gained
   significant recent attention and several AI applications, such as the
   Large Language Models (LLMs) are promising for use in clinical medicine
   and dentistry. Nevertheless, assessing the performance of LLMs is
   essential to identify potential inaccuracies or even prevent harmful
   outcomes.
   PURPOSE: The purpose of this study was to evaluate and compare the
   evidence-based potential of answers provided by 4 LLMs to clinical
   questions in the field of implant dentistry.
   MATERIAL AND METHODS: A total of 10 open-ended questions pertinent to
   prevention and treatment of peri-implant disease were posed to 4
   distinct LLMs including ChatGPT 4.0, Google Gemini, Google Gemini
   Advanced, and Microsoft Copilot. The answers were evaluated
   independently by 2 periodontists against scientific evidence for
   comprehensiveness, scientific accuracy, clarity, and relevance. The LLMs
   responses received scores ranging from 0 (minimum) to 10 (maximum)
   points. To assess the intra-evaluator reliability, a re-evaluation of
   the LLM responses was performed after 2 weeks and Cronbach alpha and
   interclass correlation coefficient (ICC) was used (alpha=.05).
   RESULTS: The scores assigned by the examiners on the 2 occasions were
   not statistically different and each LLM received an average score.
   Google Gemini Advanced ranked higher than the rest of the LLMs, while
   Google Gemini scored worst. The difference between Google Gemini
   Advanced and Google Gemini was statistically significantly different
   (P=.005).
   CONCLUSIONS: Dental professionals need to be cautious when using LLMs to
   access content related to peri-implant diseases. LLMs cannot currently
   replace dental professionals and caution should be exercised when used
   in patient care.
Z8 0
ZR 0
ZA 0
ZB 0
TC 0
ZS 0
Z9 0
DA 2025-03-12
UT MEDLINE:40055086
PM 40055086
ER

PT J
AU Del Buono, Milan
   Wu, Gloria
   Lee, David A.
   Wong, Adrial
   Zhao, Weichen
TI Do AI models provide medically accurate guidance for glaucoma patients?
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1642
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZS 0
TC 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 0
DA 2024-12-01
UT WOS:001312227704270
ER

PT J
AU Desolneux, Gregoire
   Maziere, Camille
   Vara, Jeremy
   Brouste, Veronique
   Fonck, Marianne
   Bechade, Dominique
   Becouarn, Yves
   Evrard, Serge
TI Cytoreductive Surgery of Colorectal Peritoneal Metastases: Outcomes
   after Complete Cytoreductive Surgery and Systemic Chemotherapy Only
SO PLOS ONE
VL 10
IS 3
AR e0122816
DI 10.1371/journal.pone.0122816
DT Article
PD MAR 31 2015
PY 2015
AB Background
   Cytoreductive peritoneal surgery (CRS) associated with hyperthermic
   peritoneal chemotherapy (HIPEC) has long been considered the standard
   treatment for colorectal peritoneal metastases (CPM). However, although
   efficacy of surgery has been demonstrated, evidence supporting HIPEC's
   role is less certain.
   Method
   Overall survival (OS), progression-free survival (PFS) and morbidity
   were analysed retrospectively for fifty consecutively included patients
   treated for colorectal CPM with complete CRS and systemic chemotherapy
   only.
   Results
   Median peritoneal cancer index (PCI) was 8 (range 1-24). 23 patients had
   liver or lung metastases (LLM). 22 patients had synchronous CPM. 27
   complications occurred (12 Grade 1/2, 14 Grade 3, 1 Grade 4a, 0 Grade
   5). Median follow-up was 62.5 months (95 % CI 45.481.3), median survival
   32.4 months (21.5-41.7). Three-and 5-year OS were 45.5% (0.31-0.59) and
   29.64% (0.17-0.44) respectively. Presence of LLMs associated with
   peritoneal carcinomatosis was significantly associated with poorer
   prognosis, with survival at 5 years of 13.95% (95 % CI 2.9-33.6) vs.
   43.87% (22.2-63.7) when no metastases were present (P=0.018). Median PFS
   was 9.5 months (95 % CI 6.2-11.1).
   Conclusion
   With an equivalent PCI range and despite one of the highest rates of LLM
   in the literature, our survival data of CRS + systemic chemotherapy only
   compare well with results reported after additional HIPEC. Tolerance was
   better with acceptable morbidity without any mortality. Extra-hepatic
   metastasis (LLM) is a strong factor of poor prognosis. Awaiting the
   results of the randomized PRODIGE trial, these results indicate that CRS
   + systemic chemotherapy only is a robust hypothesis to treat colorectal
   CPM.
ZR 0
ZA 0
ZB 5
Z8 1
ZS 0
TC 42
Z9 43
DA 2015-03-31
UT WOS:000352084800094
PM 25825874
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT C
AU Balakrishna, Chinnala
   Yadav, Ankit
   Singh, Jagendra
   Saba, Masarath
   Shashikant
   Shrivastava, Vineet
GP IEEE
TI Smart Drug Delivery Systems using Large Language Models for Real-Time
   Treatment Personalization
SO 2024 2ND WORLD CONFERENCE ON COMMUNICATION & COMPUTING, WCONF 2024
AR 2593
DI 10.1109/WCONF61366.2024.10692060
DT Proceedings Paper
PD 2024
PY 2024
AB This research explores the use of large language models, such as BERT
   and GPT, in developing a smart drug delivery system utilizing real-time
   personalized treatments. The research aims to utilize large datasets
   with advanced natural language processing to recommend the appropriate
   drug for a patient based on their health record with enhanced accuracy
   and efficiency. The research, which evaluates and compares BERT and GPT,
   achieves the goal of predicting a drug with high accuracy, and GPT
   delivers the best results compared to BERT. Specifically, GPT achieved
   an accuracy of 97.95%, while BERT's accuracy was 95.50%. Additionally,
   the research emphasizes the essential aspect of a model's time response
   since these are real-time clinical decision systems. GPT took 110
   milliseconds to predict the drug while the BERT took 120 milliseconds.
   It is clear from the results of this work that LLM has the potential of
   changing personalized medicine's approach by recommending drugs in
   real-time and according to the patient's health record within no time.
   The proposed system for smart drug delivery is promising to improve
   healthcare services, patient outcomes, and reduce drug administration
   errors. Apart from predicting the drug, these research findings can be
   simulated to the health sectors and integrated with AI technologies to
   improve decision support systems.
CT 2nd IEEE World Conference on Communication and Computing (WCONF)
CY JUL 12-14, 2024
CL Kalinga Univ, Raipur, INDIA
HO Kalinga Univ
SP IEEE; Govt India, Dept Sci & Technol, Sci & Engn Res Board; IEEE Tech
   Comm; IEEE MP Sect
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
ZA 0
Z9 0
DA 2025-02-14
UT WOS:001339364000090
ER

PT J
AU Zakka, Cyril
   Shad, Rohan
   Chaurasia, Akash
   Dalal, Alex R
   Kim, Jennifer L
   Moor, Michael
   Fong, Robyn
   Phillips, Curran
   Alexander, Kevin
   Ashley, Euan
   Boyd, Jack
   Boyd, Kathleen
   Hirsch, Karen
   Langlotz, Curt
   Lee, Rita
   Melia, Joanna
   Nelson, Joanna
   Sallam, Karim
   Tullis, Stacey
   Vogelsong, Melissa Ann
   Cunningham, John Patrick
   Hiesinger, William
TI Almanac - Retrieval-Augmented Language Models for Clinical Medicine.
SO NEJM AI
VL 1
IS 2
DI 10.1056/aioa2300068
DT Journal Article
PD 2024-Feb
PY 2024
AB BACKGROUND: Large language models (LLMs) have recently shown impressive
   zero-shot capabilities, whereby they can use auxiliary data, without the
   availability of task-specific training examples, to complete a variety
   of natural language tasks, such as summarization, dialogue generation,
   and question answering. However, despite many promising applications of
   LLMs in clinical medicine, adoption of these models has been limited by
   their tendency to generate incorrect and sometimes even harmful
   statements.
   METHODS: We tasked a panel of eight board-certified clinicians and two
   health care practitioners with evaluating Almanac, an LLM framework
   augmented with retrieval capabilities from curated medical resources for
   medical guideline and treatment recommendations. The panel compared
   responses from Almanac and standard LLMs (ChatGPT-4, Bing, and Bard)
   versus a novel data set of 314 clinical questions spanning nine medical
   specialties.
   RESULTS: Almanac showed a significant improvement in performance
   compared with the standard LLMs across axes of factuality, completeness,
   user preference, and adversarial safety.
   CONCLUSIONS: Our results show the potential for LLMs with access to
   domain-specific corpora to be effective in clinical decision-making. The
   findings also underscore the importance of carefully testing LLMs before
   deployment to mitigate their shortcomings. (Funded by the National
   Institutes of Health, National Heart, Lung, and Blood Institute.).
ZS 0
ZR 0
TC 103
ZB 15
Z8 1
ZA 0
Z9 103
DA 2024-02-14
UT MEDLINE:38343631
PM 38343631
ER

PT J
AU Liu, Xiaohong
   Liu, Hao
   Yang, Guoxing
   Jiang, Zeyu
   Cui, Shuguang
   Zhang, Zhaoze
   Wang, Huan
   Tao, Liyuan
   Sun, Yongchang
   Song, Zhu
   Hong, Tianpei
   Yang, Jin
   Gao, Tianrun
   Zhang, Jiangjiang
   Li, Xiaohu
   Zhang, Jing
   Sang, Ye
   Yang, Zhao
   Xue, Kanmin
   Wu, Song
   Zhang, Ping
   Yang, Jian
   Song, Chunli
   Wang, Guangyu
TI A generalist medical language model for disease diagnosis assistance
SO NATURE MEDICINE
VL 31
IS 3
DI 10.1038/s41591-024-03416-6
EA JAN 2025
DT Article
PD MAR 2025
PY 2025
AB The delivery of accurate diagnoses is crucial in healthcare and
   represents the gateway to appropriate and timely treatment. Although
   recent large language models (LLMs) have demonstrated impressive
   capabilities in few-shot or zero-shot learning, their effectiveness in
   clinical diagnosis remains unproven. Here we present MedFound, a
   generalist medical language model with 176 billion parameters,
   pre-trained on a large-scale corpus derived from diverse medical text
   and real-world clinical records. We further fine-tuned MedFound to learn
   physicians' inferential diagnosis with a self-bootstrapping
   strategy-based chain-of-thought approach and introduced a unified
   preference alignment framework to align it with standard clinical
   practice. Extensive experiments demonstrate that our medical LLM
   outperforms other baseline LLMs and specialized models in
   in-distribution (common diseases), out-of-distribution (external
   validation) and long-tailed distribution (rare diseases) scenarios
   across eight specialties. Further ablation studies indicate the
   effectiveness of key components in our medical LLM training approach. We
   conducted a comprehensive evaluation of the clinical applicability of
   LLMs for diagnosis involving artificial intelligence (AI) versus
   physician comparison, AI-assistance study and human evaluation
   framework. Our proposed framework incorporates eight clinical evaluation
   metrics, covering capabilities such as medical record summarization,
   diagnostic reasoning and risk management. Our findings demonstrate the
   model's feasibility in assisting physicians with disease diagnosis as
   part of the clinical workflow.
Z8 0
ZB 0
ZA 0
ZS 0
TC 3
ZR 0
Z9 3
DA 2025-01-13
UT WOS:001391696700001
PM 39779927
ER

PT J
AU Patel, Anshum
   Cheung, Joseph
TI Artificial intelligence in sleep medicine: assessing the diagnostic
   precision of ChatGPT-4.
SO Journal of clinical sleep medicine : JCSM : official publication of the
   American Academy of Sleep Medicine
DI 10.5664/jcsm.11732
DT Journal Article
PD 2025-Apr-23
PY 2025
AB STUDY OBJECTIVES: Large language models (LLMs) like ChatGPT-4 are
   emerging in medicine, including sleep medicine, where artificial
   intelligence (AI) is used to analyze sleep data and predict treatment
   outcomes. Effectiveness of LLM in accurately diagnosing sleep disorders
   based on clinical history has not yet been studied. This study evaluates
   ChatGPT-4's diagnostic performance using clinical vignettes.
   METHODS: Nineteen clinical vignettes containing patient history,
   physical examination findings, and diagnostic tests from the Case Book
   of Sleep Medicine (3rd ed., 2019, AASM) were presented to ChatGPT-4. Its
   differential and final diagnoses were compared to reference diagnoses,
   with accuracy assessed by (1) the percentage of correct differentials
   and (2) three-tier scoring system (no match, partial match, full match)
   for final diagnoses.
   RESULTS: The mean accuracy for differential diagnoses was 63.27% ±
   15.61% (SD), ranging from 33.33% to 100%. The mean number of
   AI-generated differential diagnoses matching the AASM case differential
   diagnoses was 2.79 ± 0.71 (SD). For final diagnoses, ChatGPT-4 scored
   total of 30 out of a possible 38, resulting in an overall accuracy of
   78.95%. The model achieved a mean score was 1.58 ± 0.61 (SD) out of 2,
   with 68.42% of cases achieving a full match. Performance was higher in
   cases with fewer differential diagnoses, whereas accuracy decreased in
   complex cases.
   CONCLUSIONS: ChatGPT-4 demonstrates promising diagnostic potential in
   sleep medicine, with moderate to high accuracy in identifying
   differential and final diagnoses. Although its variability in more
   complex cases calls for refinement and clinical validation.
TC 0
ZA 0
ZB 0
ZR 0
ZS 0
Z8 0
Z9 0
DA 2025-04-25
UT MEDLINE:40265240
PM 40265240
ER

PT J
AU Zalikha, Abdul K
   Hong, Thomas S
   Small, Easton A
   Constant, Michael
   Harris, Alex H S
   Giori, Nicholas J
TI Can a Large Language Model Interpret Data in the Electronic Health
   Record to Infer Minimum Clinically Important Difference Achievement of
   Knee Osteoarthritis Outcome Score-Joint Replacement Score Following
   Total Knee Arthroplasty?
SO The Journal of arthroplasty
VL 40
IS 7S1
BP S153
EP S157
DI 10.1016/j.arth.2025.03.049
DT Journal Article
PD 2025-Jul
PY 2025
AB BACKGROUND: Obtaining total knee arthroplasty patient-reported outcomes
   for quality assessment is costly and difficult. We asked whether a large
   language model (LLM) could interpret electronic health record notes to
   differentiate patients attaining a 1-year minimum clinically important
   difference (MCID) for the Knee Osteoarthritis Outcome Score-Joint
   Replacement (KOOS-JR) from those who did not. We also investigated
   whether sufficient information to infer MCID achievement exists in the
   chart by having a blinded orthopaedic surgeon make the same
   determination.
   METHODS: In this retrospective case-control study, we selected 40 total
   knee arthroplasty patients who achieved 1-year KOOS-JR MCID and 40 who
   did not. Orthopaedic, emergency medicine, and primary care notes from
   zero to six months preoperatively and nine to 15 months postoperatively
   were deidentified. ChatGPT 3.5 (ChatGPT) interpreted these notes to
   determine whether the patient improved after surgery. A blinded
   orthopaedic surgeon classified these patients using all chart
   information. The sensitivity, specificity, and accuracy of ChatGPT and
   the surgeon's responses were calculated.
   RESULTS: ChatGPT classified 78 of 80 cases with 97% sensitivity, but
   only 33% specificity. The surgeon's assessment had 90% sensitivity and
   63% specificity. Given the equal distribution of patients meeting or not
   meeting MCID, Chat GPT's accuracy was 65%. The surgeon's was 76%.
   CONCLUSIONS: ChatGPT's assessment of KOOS-JR MCID attainment had 97%
   sensitivity, but only 33% specificity. False positives were commonly due
   to the LLM not having access to, or not properly interpreting, signs of
   problems in the chart. This was an initial evaluation of the current
   ability of a general-purpose LLM to evaluate patient outcomes based on
   information in chart notes. An orthopaedic surgeon's assessment of the
   full chart suggests an opportunity to improve on this baseline
   performance, possibly enabling quality monitoring and identification of
   best practices across a large health care system. Additional work is
   needed to optimize model performance and confirm the utility of this
   approach.
Z8 0
ZB 0
ZS 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2025-03-30
UT MEDLINE:40139476
PM 40139476
ER

PT J
AU Busch, Felix
   Hoffmann, Lena
   Rueger, Christopher
   van Dijk, Elon H. C.
   Kader, Rawen
   Ortiz-Prado, Esteban
   Makowski, Marcus R.
   Saba, Luca
   Hadamitzky, Martin
   Kather, Jakob Nikolas
   Truhn, Daniel
   Cuocolo, Renato
   Adams, Lisa C.
   Bressem, Keno K.
TI Current applications and challenges in large language models for patient
   care: a systematic review
SO COMMUNICATIONS MEDICINE
VL 5
IS 1
AR 26
DI 10.1038/s43856-024-00717-2
DT Article
PD JAN 21 2025
PY 2025
AB BackgroundThe introduction of large language models (LLMs) into clinical
   practice promises to improve patient education and empowerment, thereby
   personalizing medical care and broadening access to medical knowledge.
   Despite the popularity of LLMs, there is a significant gap in
   systematized information on their use in patient care. Therefore, this
   systematic review aims to synthesize current applications and
   limitations of LLMs in patient care.MethodsWe systematically searched 5
   databases for qualitative, quantitative, and mixed methods articles on
   LLMs in patient care published between 2022 and 2023. From 4349 initial
   records, 89 studies across 29 medical specialties were included. Quality
   assessment was performed using the Mixed Methods Appraisal Tool 2018. A
   data-driven convergent synthesis approach was applied for thematic
   syntheses of LLM applications and limitations using free line-by-line
   coding in Dedoose.ResultsWe show that most studies investigate
   Generative Pre-trained Transformers (GPT)-3.5 (53.2%, n = 66 of 124
   different LLMs examined) and GPT-4 (26.6%, n = 33/124) in answering
   medical questions, followed by patient information generation, including
   medical text summarization or translation, and clinical documentation.
   Our analysis delineates two primary domains of LLM limitations: design
   and output. Design limitations include 6 second-order and 12 third-order
   codes, such as lack of medical domain optimization, data transparency,
   and accessibility issues, while output limitations include 9
   second-order and 32 third-order codes, for example, non-reproducibility,
   non-comprehensiveness, incorrectness, unsafety, and bias.ConclusionsThis
   review systematically maps LLM applications and limitations in patient
   care, providing a foundational framework and taxonomy for their
   implementation and evaluation in healthcare settings.
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 8
Z9 8
DA 2025-01-29
UT WOS:001402540700001
PM 39838160
ER

PT J
AU Albagieh, Hamad
   Alzeer, Zaid O.
   Alasmari, Osama N.
   Alkadhi, Abdullah A.
   Naitah, Abdulaziz N.
   Almasaad, Khaled F.
   Alshahrani, Turki S.
   Alshahrani, Khalid S.
   Almahmoud, Mohammed I.
TI Comparing Artificial Intelligence and Senior Residents in Oral Lesion
   Diagnosis: A Comparative Study
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 1
AR e51584
DI 10.7759/cureus.51584
DT Article
PD JAN 3 2024
PY 2024
AB Introduction: Artificial intelligence (AI) is a field of computer
   science that seeks to build intelligent machines that can carry out
   tasks that usually necessitate human intelligence. AI may help dentists
   with a variety of dental tasks, including clinical diagnosis and
   treatment planning. This study aims to compare the performance of AI and
   oral medicine residents in diagnosing different cases, providing
   treatment, and determining if it is reliable to assist them in their
   field of work. Methods: The study conducted a comparative analysis of
   the responses from third-and fourth-year residents trained in Oral
   Medicine and Pathology at King Saud University, College of Dentistry.
   The residents were given a closed multiple-choice test consisting of 19
   questions with four response options labeled A-D and one question with
   five response options labeled A-E. The test was administered via Google
   Forms, and each resident's response was stored electronically in an
   Excel sheet (Microsoft (R) Corp., Redmond, WA). The residents' answers
   were then compared to the responses generated by three major language
   models: OpenAI, Stablediffusion, and PopAI. The questions were inputted
   into the language models in the same format as the original test, and
   prior to each question, an artificial intelligence chat session was
   created to eliminate memory retention bias. The input was done on
   November 19, 2023, the same day the official multiple-choice test was
   administered. The study had a sample size of 20 residents trained in
   Oral Medicine and Pathology at King Saud University, College of
   Dentistry, consisting of both third-year and fourth-year residents.
   Result: The responses of three large language models (LLM), including
   OpenAI, Stablediffusion, and PopAI, as well as the responses of 20
   senior residents for 20 clinical cases about oral lesion diagnosis.
   There were no significant variations observed for the remaining
   questions in the responses to only two questions (10%). For the
   remaining questions, there were no significant differences. The median
   (IQR) score of LLMs was 50.0 (45.0 to 60.0), with a minimum of 40 (for
   stable diffusion) and a maximum of 70 (for OpenAI). The median (IQR)
   score of senior residents was 65.0 (55.0-75.0). The highest and lowest
   scores of residents were 40 and 90, respectively. There was no
   significant difference in the percent scores of residents and LLMs (p =
   0.211). The agreement level was measured using the Kappa value. The
   agreement among senior dental residents was observed to be weak, with a
   Kappa value of 0.396. In contrast, the agreement among LLMs demonstrated
   a moderate level, with a Kappa value of 0.622, suggesting a more
   cohesive alignment in responses among the artificial intelligence
   models. When comparing residents' responses with those generated by
   different OpenAI models, including OpenAI, Stablediffusion, and PopAI,
   the agreement levels were consistently categorized as weak, with Kappa
   values of 0.402, 0.381, and 0.392, respectively. Conclusion: What the
   current study reveals is that when comparing the response score, there
   is no significant difference, in contrast to the agreement analysis
   among the residents, which was low compared to the LLMs, in which it was
   high. Dentists should consider that AI is very beneficial in providing
   diagnosis and treatment and use it to assist them.
ZA 0
ZR 0
TC 6
ZB 1
ZS 0
Z8 0
Z9 6
DA 2024-03-17
UT WOS:001165530200012
PM 38173951
ER

PT J
AU Chen, Zikang
   Wang, Qinchuan
   Sun, Yaoqian
   Cai, Hailing
   Lu, Xudong
TI Chat-ePRO: Development and pilot study of an electronic patient-reported
   outcomes system based on ChatGPT
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 154
AR 104651
DI 10.1016/j.jbi.2024.104651
EA MAY 2024
DT Article
PD JUN 2024
PY 2024
AB Objective: Chatbots have the potential to improve user compliance in
   electronic Patient-Reported Outcome (ePRO) system. Compared to
   rule-based chatbots, Large Language Model (LLM) offers advantages such
   as simplifying the development process and increasing conversational
   flexibility. However, there is currently a lack of practical
   applications of LLMs in ePRO systems. Therefore, this study utilized
   ChatGPT to develop the ChatePRO system and designed a pilot study to
   explore the feasibility of building an ePRO system based on LLM.
   Materials and Methods: This study employed prompt engineering and
   offline knowledge distillation to design a dialogue algorithm and built
   the Chat-ePRO system on the WeChat Mini Program platform. In order to
   compare Chat-ePRO with the form-based ePRO and rule-based chatbot ePRO
   used in previous studies, we conducted a pilot study applying the three
   ePRO systems sequentially at the Sir Run Run Shaw Hospital to collect
   patients' PRO data. Result: Chat-ePRO is capable of correctly generating
   conversation based on PRO forms (success rate: 95.7 %) and accurately
   extracting the PRO data instantaneously from conversation (Macro-F1:
   0.95). The majority of subjective evaluations from doctors (>70 %)
   suggest that Chat-ePRO is able to comprehend questions and consistently
   generate responses. Pilot study shows that Chat-ePRO demonstrates higher
   response rate (9/10, 90 %) and longer interaction time (10.86 s/turn)
   compared to the other two methods. Conclusion: Our study demonstrated
   the feasibility of utilizing algorithms such as prompt engineering to
   drive LLM in completing ePRO data collection tasks, and validated that
   the Chat-ePRO system can effectively enhance patient compliance.
Z8 0
ZA 0
ZR 0
ZS 0
TC 1
ZB 0
Z9 1
DA 2024-06-17
UT WOS:001243033900001
PM 38703936
ER

PT J
AU Delleani, Mattia
   D'Amico, Saverio
   Sauta, Elisabetta
   Asti, Gianluca
   Zazzetti, Elena
   Campagna, Alessia
   Lanino, Luca
   Maggioni, Giulia
   Grondelli, Maria Chiara
   Barrero, Alessandro Forcina
   Morandini, Pierandrea
   Ubezio, Marta
   Todisco, Gabriele
   Russo, Antonio
   Tentori, Cristina Astrid
   Buizza, Alessandro
   Bonometti, Arturo
   Lancellotti, Cesare
   Di Tommaso, Luca
   Rahal, Daoud
   Bicchieri, Marilena
   Savevski, Victor
   Santoro, Armando
   Santini, Valeria
   Sole, Francesc
   Platzbecker, Uwe
   Fenaux, Pierre
   Diez-Campelo, Maria
   Komrokji, Rami S.
   Garcia-Manero, Guillermo
   Haferlach, Torsten
   Kordasti, Shahram
   Zeidan, Amer M.
   Castellani, Gastone
   Della Porta, Matteo Giovanni
TI The "David Vs Goliath" Study: Application of Large
   Language Models (LLM) for Automatic Medical Information Retrieval from
   Multiple Data Sources to Accelerate Clinical and Translational Research
   in Hematology
SO BLOOD
VL 144
BP 3597
EP 3599
DI 10.1182/blood-2024-205621
SU 1
DT Meeting Abstract
PD NOV 5 2024
PY 2024
ZR 0
ZA 0
Z8 0
ZB 0
TC 0
ZS 0
Z9 0
DA 2025-02-20
UT WOS:001412307500014
ER

PT J
AU Abdel-Rehim, Abbi
   Zenil, Hector
   Orhobor, Oghenejokpeme
   Fisher, Marie
   Collins, Ross J.
   Bourne, Elizabeth
   Fearnley, Gareth W.
   Tate, Emma
   Smith, Holly X.
   Soldatova, Larisa N.
   King, Ross
TI Scientific hypothesis generation by large language models: laboratory
   validation in breast cancer treatment
SO JOURNAL OF THE ROYAL SOCIETY INTERFACE
VL 22
IS 227
AR 20240674
DI 10.1098/rsif.2024.0674
DT Article
PD JUN 4 2025
PY 2025
AB Large language models (LLMs) have transformed artificial intelligence
   (AI) and achieved breakthrough performance on a wide range of tasks. In
   science, the most interesting application of LLMs is for hypothesis
   formation. A feature of LLMs, which results from their probabilistic
   structure, is that the output text is not necessarily a valid inference
   from the training text. These are termed 'hallucinations', and are
   harmful in many applications. In science, some hallucinations may be
   useful: novel hypotheses whose validity may be tested by laboratory
   experiments. Here, we experimentally test the application of LLMs as a
   source of scientific hypotheses using the domain of breast cancer
   treatment. We applied the LLM GPT4 to hypothesize novel synergistic
   pairs of US Food and Drug Administration (FDA)-approved non-cancer drugs
   that target the MCF7 breast cancer cell line relative to the
   non-tumorigenic breast cell line MCF10A. In the first round of
   laboratory experiments, GPT4 succeeded in discovering three drug
   combinations (out of 12 tested) with synergy scores above the positive
   controls. GPT4 then generated new combinations based on its initial
   results, this generated three more combinations with positive synergy
   scores (out of four tested). We conclude that LLMs are a valuable source
   of scientific hypotheses.
ZA 0
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
Z9 0
DA 2025-06-08
UT WOS:001501540900001
PM 40462712
ER

PT J
AU Nabieva, Naiba
   Brucker, Sara Y.
   Gmeiner, Benjamin
TI ChatGPT's Agreement with the Recommendations from the 18th St. Gallen
   International Consensus Conference on the Treatment of Early Breast
   Cancer
SO CANCERS
VL 16
IS 24
AR 4163
DI 10.3390/cancers16244163
DT Article
PD DEC 2024
PY 2024
AB Introduction: Organizations like the European Society for Medical
   Oncology and the St. Gallen Oncology Conference panel regularly review
   the latest research data to align on common recommendations for the
   treatment of breast cancer patients. In the era of artificial
   intelligence (AI), the question arises whether AI can enhance scientific
   debates by providing potential recommendations for expert discussions.
   Methods: We focused on the St. Gallen International Breast Cancer
   Conference (SGBCC) in 2023, where 71 experts from 27 countries answered
   127 questions across 17 topics related to early breast cancer. OpenAI's
   ChatGPT version 4.0 was employed to respond to the same set of
   questions. We simulated response variability and mitigated potential
   memory effects using several question-rounds in new chat sessions.
   Results: ChatGPT answered 71 questions (55.91%) in accordance with the
   most common answer voted by the SGBCC panel and showed a moderate
   overall agreement. In these cases, AI voted with an average reliability
   of 98.31%, compared to the panel's average majority of 65.39% for the
   most common answer. A very high agreement could be observed in questions
   on "Genetics", "Pathology", "Oligometastatic disease", "Ductal carcinoma
   in situ" and "Well-being for breast cancer survivors". A very low
   agreement was seen in the topics "BRCA associated", "Adjuvant endocrine
   therapy", "HER2 positive", "Local/regional recurrence" and
   "Bone-modifying therapy". Conclusions: Our study demonstrates that
   ChatGPT shows potential in the development of breast cancer treatment
   recommendations, particularly in areas where high agreement with expert
   panel responses was observed. However, significant improvements are
   necessary before AI can be considered a reliable tool to support human
   expertise.
ZS 0
Z8 0
ZR 0
ZB 1
ZA 0
TC 2
Z9 2
DA 2024-12-31
UT WOS:001383770000001
PM 39766061
ER

PT J
AU Chen, Xi
   Wang, Li
   You, Mingke
   Liu, Weizhi
   Fu, Yu
   Xu, Jie
   Zhang, Shaoting
   Chen, Gang
   Li, Kang
   Li, Jian
TI Evaluating and Enhancing Large Language Models'Performancein
   Domain-Specific Medicine:Development and Usability StudyWith DocOA
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 26
AR e58158
DI 10.2196
DT Article
PD JUL 24 2024
PY 2024
AB Background: The efficacy of large language models (LLMs) in
   domain-specific medicine, particularly for managing complex diseases
   such as osteoarthritis (OA), remains largely unexplored. Objective: This
   study focused on evaluating and enhancing the clinical capabilities and
   explain ability of LLMs in specific domains, using OA management as a
   case study. Methods: A domain-specific benchmark framework was developed
   to evaluate LLMs across a spectrum from domain-specific knowledge to
   clinical applications in real-world clinical scenarios. DocOA, a
   specialized LLM designed for OA management integrating
   retrieval-augmented generation and instructional prompts, was developed.
   It can identify the clinical evidence upon which its answers are based
   through retrieval-augmented generation, thereby demonstrating the
   explain ability of those answers. The study compared the performance of
   GPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and
   human evaluations. Results: Results showed that general LLMs such as
   GPT-3.5 and GPT-4 were less effective in the specialized domain of OA
   management, particularly in providing personalized treatment
   recommendations. However, DocOA showed significant improvements.
   Conclusions: This study introduces a novel benchmark framework that
   assesses the domain-specific abilities of LLMs in multiple aspects,
   highlights the limitations of generalized LLMs in clinical contexts, and
   demonstrates the potential of tailored approaches for developing
   domain-specific medical LLMs
TC 4
ZR 0
Z8 1
ZS 0
ZA 0
ZB 1
Z9 4
DA 2024-09-15
UT WOS:001297028800003
PM 38833165
ER

PT J
AU Luedtke, Nando F.
   Shung, Dennis
TI AUTOMATED EXTRACTION OF RANDOMIZED CONTROLLED TRIAL DATA USING LARGE
   LANGUAGE MODELS: A PILOT STUDY WITH VEDOLIZUMAB META-ANALYSIS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Mo1181
BP S967
EP S967
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
Z8 0
ZA 0
TC 0
ZR 0
ZS 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837704056
ER

PT J
AU Li, Shusheng
   Tan, Wenjun
   Zhang, Changshuai
   Li, Jiale
   Ren, Haiyan
   Guo, Yanliang
   Jia, Jing
   Liu, Yangyang
   Pan, Xingfang
   Guo, Jing
   Meng, Wei
   He, Zhaoshui
TI Taming large language models to implement diagnosis and evaluating the
   generation of LLMs at the semantic similarity level in acupuncture and
   moxibustion
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 264
AR 125920
DI 10.1016/j.eswa.2024.125920
EA DEC 2024
DT Article
PD MAR 10 2025
PY 2025
AB With the rapid advancement of artificial intelligence and deep learning
   technologies, large language models (LLMs) such as ChatGPT and GPT-4
   have made significant progress in comprehending and responding to human
   instructions. Acupuncture and moxibustion, therapeutic modalities in
   Traditional Chinese Medicine (TCM), possess extensive knowledge
   beneficial for patient treatment. Currently, acupuncture diagnosis
   relies on the experience and skills of individual acupuncturists,
   emphasizing the need for research to improve diagnostic accuracy through
   objective methods. Therefore, the integration of LLMs into the field of
   acupuncture can facilitate the recommendation of personalized
   acupuncture treatment programs. However, the application of general LLMs
   to the field of acupuncture diagnosis often yields suboptimal results.
   In addition, most LLM evaluation metrics depend solely on literal
   overlap and fail to capture semantic similarity. To address these
   challenges, this paper introduces AcupunctureGPT, a specialized large
   language model for acupuncture diagnosis, aimed at exploring the
   potential application of LLMs in this field. Patient Diagnostic
   Acupuncture Data is constructed to enhance the diagnostic capabilities
   of AcupunctureGPT in acupuncture. The Generated Knowledge Filter
   Prompting approach is proposed to improve the accuracy of LLMs in
   identifying similar diseases through the development and filtering of
   knowledge statements. The Sentence Similarity Evaluation Module (SSEM)
   is employed to assess the generation quality of LLMs at the semantic
   level. The Sentence Adaptive Enhancement Fusion Module (SAEFM), proposed
   within SSEM, enhances the adaptive fusion of output features at various
   levels. Experimental results demonstrate that AcupunctureGPT outperforms
   other large language models in diagnosing diseases and devising
   reasonable treatment plans. Furthermore, the evaluation metrics proposed
   in this paper have been validated for effectiveness.
TC 0
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
Z9 0
DA 2024-12-13
UT WOS:001372992400001
ER

PT J
AU Musacchio, Nicoletta
   Zilich, Rita
   Masi, Davide
   Baccetti, Fabio
   Nreu, Besmir
   Giorda, Carlo Bruno
   Guaita, Giacomo
   Morviducci, Lelio
   Muselli, Marco
   Ozzello, Alessandro
   Pisani, Federico
   Ponzani, Paola
   Rossi, Antonio
   Santin, Pierluigi
   Verda, Damiano
   Di Cianni, Graziano
   Candido, Riccardo
TI A transparent machine learning algorithm uncovers HbA1c patterns
   associated with therapeutic inertia in patients with type 2 diabetes and
   failure of metformin monotherapy
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 190
AR 105550
DI 10.1016/j.ijmedinf.2024.105550
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Aims: This study aimed to identify and categorize the determinants
   influencing the intensification of therapy in Type 2 Diabetes (T2D)
   patients with suboptimal blood glucose control despite metformin
   monotherapy. Methods: Employing the Logic Learning Machine (LLM), an
   advanced artificial intelligence system, we scrutinized electronic
   health records of 1.5 million patients treated in 271 diabetes clinics
   affiliated with the Italian Association of Medical Diabetologists from
   2005 to 2019. Inclusion criteria comprised patients on metformin
   monotherapy with two consecutive mean HbA1c levels exceeding 7.0%. The
   cohort was divided into "inertia-NO" (20,067 patients with prompt
   intensification) and "inertia-YES" (13,029 patients without timely
   intensification). Results: The LLM model demonstrated robust
   discriminatory ability among the two groups (ROC-AUC = 0.81, accuracy =
   0.71, precision = 0.80, recall = 0.71, F1 score = 0.75). The main
   novelty of our results is indeed the identification of two main distinct
   subtypes of therapeutic inertia. The first exhibited a gradual but
   steady HbA1c increase, while the second featured a moderate, non-uniform
   rise with substantial fluctuations. Conclusions: Our analysis sheds
   light on the significant impact of HbA1c levels over time on therapeutic
   inertia in patients with T2D, emphasizing the importance of early
   intervention in the presence of specific HbA1c patterns.
ZB 0
ZS 0
TC 1
Z8 0
ZR 0
ZA 0
Z9 1
DA 2024-08-08
UT WOS:001282126000001
PM 39059083
ER

PT J
AU Keat, Karl
   Venkatesh, Rasika
   Huang, Yidi
   Kumar, Rachit
   Tuteja, Sony
   Sangkuhl, Katrin
   Li, Binglan
   Gong, Li
   Whirl-Carrillo, Michelle
   Klein, Teri E
   Ritchie, Marylyn D
   Kim, Dokyoon
TI PGxQA: A Resource for Evaluating LLM Performance for Pharmacogenomic QA
   Tasks.
SO Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
VL 30
BP 229
EP 246
DI 10.1142/9789819807024_0017
DT Journal Article
PD 2025
PY 2025
AB Pharmacogenetics represents one of the most promising areas of precision
   medicine, with several guidelines for genetics-guided treatment ready
   for clinical use. Despite this, implementation has been slow, with few
   health systems incorporating the technology into their standard of care.
   One major barrier to uptake is the lack of education and awareness of
   pharmacogenetics among clinicians and patients. The introduction of
   large language models (LLMs) like GPT-4 has raised the possibility of
   medical chatbots that deliver timely information to clinicians,
   patients, and researchers with a simple interface. Although
   state-of-the-art LLMs have shown impressive performance at advanced
   tasks like medical licensing exams, in practice they still often provide
   false information, which is particularly hazardous in a clinical
   context. To quantify the extent of this issue, we developed a series of
   automated and expert-scored tests to evaluate the performance of
   chatbots in answering pharmacogenetics questions from the perspective of
   clinicians, patients, and researchers. We applied this benchmark to
   state-of-the-art LLMs and found that newer models like GPT-4o greatly
   outperform their predecessors, but still fall short of the standards
   required for clinical use. Our benchmark will be a valuable public
   resource for subsequent developments in this space as we work towards
   better clinical AI for pharmacogenetics.
ZB 0
ZS 0
ZA 0
Z8 0
TC 0
ZR 0
Z9 0
DA 2025-05-17
UT MEDLINE:39670373
PM 39670373
ER

PT J
AU Hueso, Miguel
   Alvarez, Rafael
   Mari, David
   Ribas-Ripoll, Vicent
   Lekadir, Karim
   Vellido, Alfredo
TI IS GENERATIVE ARTIFICIAL INTELLIGENCE THE NEXT STEP TOWARD A
   PERSONALIZED HEMODIALYSIS?
SO REVISTA DE INVESTIGACION CLINICA-CLINICAL AND TRANSLATIONAL
   INVESTIGATION
VL 75
IS 6
BP 309
EP 317
DI 10.24875/RIC.23000162
EA JUL 2023
DT Review
PD NOV-DEC 2023
PY 2023
AB Artificial intelligence (AI) generative models driven by the integration
   of AI and natural language processing technologies, such as OpenAI's
   chatbot generative pre-trained transformer large language model (LLM),
   are receiving much public attention and have the potential to transform
   personalized medicine. Dialysis patients are highly dependent on
   technology and their treatment generates a challenging large volume of
   data that has to be analyzed for knowledge extraction. We argue that, by
   integrating the data acquired from hemodialysis treatments with the
   powerful conversational capabilities of LLMs, nephrologists could
   personalize treatments adapted to patients' lifestyles and preferences.
   We also argue that this new conversational AI integrated with a
   personalized patient-computer interface will enhance patients'
   engagement and self-care by providing them with a more personalized
   experience. However, generative AI models require continuous and
   accurate updates of data, and expert supervision and must address
   potential biases and limitations. Dialysis patients can also benefit
   from other new emerging technologies such as Digital Twins with which
   patients' care can also be addressed from a personalized medicine
   perspective. In this paper, we will revise LLMs potential strengths in
   terms of their contribution to personalized medicine, and, in
   particular, their potential impact, and limitations in nephrology.
   Nephrologists' collaboration with AI academia and companies, to develop
   algorithms and models that are more transparent, understandable, and
   trustworthy, will be crucial for the next generation of dialysis
   patients. The combination of technology, patient-specific data, and AI
   should contribute to create a more personalized and interactive dialysis
   process, improving patients' quality of life.
Z8 0
ZS 0
ZB 1
ZR 0
ZA 0
TC 5
Z9 5
DA 2023-10-16
UT WOS:001072108900001
PM 37734067
ER

PT J
AU Raal, Frederick J.
   Rosenson, Robert S.
   Reeskamp, Laurens F.
   Hovingh, G. Kees
   Kastelein, John J.
   Rubba, Paolo
   Ali, Shazia
   Banerjee, Poulabi
   Chan, Kuo-Chen
   Khilla, Nagwa
   McGinniss, Jennifer
   Pordy, Robert
   Zhang, Yi
   Gaudet, Daniel
TI Evinacumab Lowers LDL-C in Patients With Homozygous Familial
   Hypercholesterolemia Irrespective of Background Lipid-lowering
   Medication
SO CIRCULATION
VL 142
MA A14267
SU 3
DT Meeting Abstract
PD NOV 17 2020
PY 2020
ZA 0
ZS 0
Z8 0
ZR 0
ZB 2
TC 6
Z9 6
DA 2021-02-19
UT WOS:000607190401389
ER

PT J
AU Xu, Peng
TI Multi-layered data framework for enhancing postoperative outcomes and
   anaesthesia management through natural language processing
SO SLAS TECHNOLOGY
VL 32
AR 100294
DI 10.1016/j.slast.2025.100294
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Anaesthesia management is a critical aspect of perioperative care,
   directly influencing postoperative recovery, pain management, and
   patient outcomes. Despite advancements in anaesthesia techniques,
   variability in patient responses and unexpected postoperative
   complications remain significant challenges. The research proposes a
   multi-layered architecture named Anaesthesia CareNet for analyzing data
   from diverse sources to enhance personalized anaesthesia management and
   postoperative outcome prediction. The architecture is structured into
   two primary layers: Data processing and Predictive Modeling. In the Data
   processing layer, advanced Natural Language Processing (NLP) techniques
   such as Named Entity Recognition (NER), normalization, lemmatization,
   and stemming are applied to clean and standardize the unstructured
   clinical data. Generative Pre-trained Transformer 3 (GPT-3), a Large
   Language Model (LLM) is employed as a feature extraction method,
   allowing the system to process and analyze complex clinical narratives
   and unstructured textual data from patient records. This enables more
   precise and personalized predictions, not only improving anaesthesia
   management but also laying the groundwork for broader applications in
   life sciences. The extracted data is passed into the predictive modeling
   layer, where the Intelligent Golden Eagle Fine-Tuned Logistic Regression
   (IGE-LR) model is applied. By analyzing correlations between patient
   characteristics, surgical details, and postoperative recovery patterns,
   IGELR enables the prediction of complications, pain management
   requirements, and recovery trajectories beyond anaesthesia; the
   methodology has potential applications in diverse areas such as
   diagnostics, drug discovery, and personalized medicine, where
   large-scale data analysis, predictive modeling, and real-time
   adaptability are crucial for improving patient outcomes. The proposed
   IGE-LR method achieves higher performance with 91.7 % accuracy, 90.6 %
   specificity, and 90 % AUC, with a recall of 91.3 %, precision of 90.1 %,
   and an F1-Score of 90.4 %. By leveraging advanced NLP and predictive
   analytics, Anaesthesia CareNet exemplifies how AI-driven frameworks can
   transform life sciences, advancing personalized healthcare and creating
   a more precise, efficient, and dynamic approach to treatment management.
ZR 0
ZS 0
TC 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-10
UT WOS:001479823100001
PM 40252977
ER

PT J
AU Sinha, Rooma
   Raina, Rohit
   Bag, Moumita
   Rupa, Bana
TI Empowering gynaecologists with Artificial Intelligence: Tailoring
   surgical solutions for fibroids
SO EUROPEAN JOURNAL OF OBSTETRICS & GYNECOLOGY AND REPRODUCTIVE BIOLOGY
VL 299
BP 72
EP 77
DI 10.1016/j.ejogrb.2024.06.001
EA JUN 2024
DT Article
PD AUG 2024
PY 2024
AB Background: In recent years, the integration of Artificial intelligence
   (AI) into various fields of medicine including Gynaecology, has shown
   promising potential. Surgical treatment of fibroid is myomectomy if
   uterine preservation and fertility are the primary aims. AI usage begins
   with the involvement of LLM (Large Language Model) from the point when a
   patient visits a gynecologist, from identifying signs and symptoms to
   reaching a diagnosis, providing treatment plans, and patient counseling.
   Objective: Use of AI (ChatGPT versus Google Bard) in the surgical
   management of fibroid. Study design: Identifying the patient's problems
   using LLMs like ChatGPT and Google Bard and giving a treatment option in
   8 clinical scenarios of fibroid. Data entry was done using M.S. Excel
   and was statistically analyzed using Statistical Package for Social
   Sciences (SPSS Version 26) for M.S. Windows 2010. All results were
   presented in tabular form. Data were analyzed using nonparametric tests
   Chi-square tests or Fisher exact test. p values < 0.05 were considered
   statistically significant. The sensitivity of both techniques was
   calculated. We have used Cohen's Kappa to know the degree of agreement.
   Results: We found that on the first attempt, ChatGPT gave general
   answers in 62.5 % of cases and specific answers in 37.5 % of cases.
   ChatGPT showed improved sensitivity on successive prompts 37.5 % to 62.5
   % on the third prompt. Google Bard could not identify the clinical
   question in 50 % of cases and gave incorrect answers in 12.5 % of cases
   (p = 0.04). Google Bard showed the same sensitivity of 25 % on all
   prompts. Conclusion: AI helps to reduce the time to diagnose and plan a
   treatment strategy for fibroid and acts as a powerful tool in the hands
   of a gynecologist. However, the usage of AI by patients for
   self-treatment is to be avoided and should be used only for education
   and counseling about fibroids.
ZS 0
ZR 0
ZB 0
ZA 0
Z8 0
TC 2
Z9 2
DA 2024-06-29
UT WOS:001251789000001
PM 38838389
ER

PT J
AU Warren, Christopher J.
   Payne, Nicolette G.
   Edmonds, Victoria S.
   Voleti, Sandeep S.
   Choudry, Mouneeb M.
   Punjani, Nahid
   Abdul-Muhsin, Haider M.
   Humphreys, Mitchell R.
TI Quality of Chatbot Information Related to Benign Prostatic Hyperplasia
SO PROSTATE
VL 85
IS 2
BP 175
EP 180
DI 10.1002/pros.24814
EA NOV 2024
DT Article
PD FEB 2025
PY 2025
AB Background: Large language model (LLM) chatbots, a form of artificial
   intelligence (AI) that excels at prompt-based interactions and mimics
   human conversation, have emerged as a tool for providing patients with
   information about urologic conditions. We aimed to examine the quality
   of information related to benign prostatic hyperplasia surgery from four
   chatbots and how they would respond to sample patient messages. Methods:
   We identified the top three queries in Google Trends related to
   "treatment for enlarged prostate." These were entered into ChatGPT
   (OpenAI), Bard (Google), Bing AI (Microsoft), and Doximity GPT
   (Doximity), both unprompted and prompted for specific criteria
   (optimized). The chatbot-provided answers to each query were evaluated
   for overall quality by three urologists using the DISCERN instrument.
   Readability was measured with the built-in Flesch-Kincaid reading level
   tool in Microsoft Word. To assess the ability of chatbots to answer
   patient questions, we prompted the chatbots with a clinical scenario
   related to holmium laser enucleation of the prostate, followed by 10
   questions that the National Institutes of Health recommends patients ask
   before surgery. Accuracy and completeness of responses were graded with
   Likert scales. Results: Without prompting, the quality of information
   was moderate across all chatbots but improved significantly with
   prompting (mean [SD], 3.3 [1.2] vs. 4.4 [0.7] out of 5; p < 0.001). When
   answering simulated patient messages, the chatbots were accurate (mean
   [SD], 5.6 [0.4] out of 6) and complete (mean [SD], 2.8 [0.3] out of 3).
   Additionally, 98% (39/40) had a median score of 5 or higher for
   accuracy, which corresponds to "nearly all correct." The readability was
   poor, with a mean (SD) Flesch-Kincaid reading level grade of 12.1 (1.3)
   (unprompted). Conclusions: LLM chatbots hold promise for patient
   education, but their effectiveness is limited by the need for careful
   prompting from the user and by responding at a reading level higher than
   that of most Americans (grade 8). Educating patients and physicians on
   optimal LLM interaction is crucial to unlock the full potential of
   chatbots.
ZB 0
ZA 0
ZR 0
ZS 0
TC 3
Z8 0
Z9 3
DA 2024-11-23
UT WOS:001355317000001
PM 39513562
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   Pugliese, Nicola
   You, Kisung
   Shung, Dennis L.
TI Optimizing large language models in digestive disease: strategies and
   challenges to improve clinical outcomes
SO LIVER INTERNATIONAL
VL 44
IS 9
BP 2114
EP 2124
DI 10.1111/liv.15974
EA MAY 2024
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs) are transformer-based neural networks with
   billions of parameters trained on very large text corpora from diverse
   sources. LLMs have the potential to improve healthcare due to their
   capability to parse complex concepts and generate context-based
   responses. The interest in LLMs has not spared digestive disease
   academics, who have mainly investigated foundational LLM accuracy, which
   ranges from 25% to 90% and is influenced by the lack of standardized
   rules to report methodologies and results for LLM-oriented research. In
   addition, a critical issue is the absence of a universally accepted
   definition of accuracy, varying from binary to scalar interpretations,
   often tied to grader expertise without reference to clinical guidelines.
   We address strategies and challenges to increase accuracy. In
   particular, LLMs can be infused with domain knowledge using Retrieval
   Augmented Generation (RAG) or Supervised Fine-Tuning (SFT) with
   reinforcement learning from human feedback (RLHF). RAG faces challenges
   with in-context window limits and accurate information retrieval from
   the provided context. SFT, a deeper adaptation method, is
   computationally demanding and requires specialized knowledge. LLMs may
   increase patient quality of care across the field of digestive diseases,
   where physicians are often engaged in screening, treatment and
   surveillance for a broad range of pathologies for which in-context
   learning or SFT with RLHF could improve clinical decision-making and
   patient outcomes. However, despite their potential, the safe deployment
   of LLMs in healthcare still needs to overcome hurdles in accuracy,
   suggesting a need for strategies that integrate human feedback with
   advanced model training.
ZR 0
TC 16
ZA 0
Z8 2
ZS 0
ZB 3
Z9 16
DA 2024-06-06
UT WOS:001235783300001
PM 38819632
ER

PT J
AU Fan, K
   Li, GQ
   Yang, SH
   An, X
   Ma, GY
   Roufogalis, BD
   Joshua, DE
   Sze, D
TI Dual roles of T/NK immunomodulatory and anti-tumor properties for
   selected herbal medicines in multiple myeloma therapy.
SO BLOOD
VL 106
IS 11
MA 5097
BP 356B
EP 356B
PN 2
DT Meeting Abstract
PD NOV 16 2005
PY 2005
CT 47th Annual Meeting of the American-Society-of-Hematology
CY DEC 10-13, 2005
CL Atlanta, GA
SP Amer Soc Hematol
ZA 0
ZB 0
Z8 0
ZS 0
TC 0
ZR 0
Z9 0
DA 2005-11-16
UT WOS:000233426102199
ER

PT J
AU Wenz, Frederik
   Ebener, Stefan
TI Artificial intelligence applications in oncology: opportunities,
   feasibility, and regulatory challenges
SO ONKOLOGIE
VL 30
IS 5
SI SI
BP 339
EP 346
DI 10.1007/s00761-023-01428-4
EA NOV 2023
DT Review
PD MAY 2024
PY 2024
AB The integration of artificial intelligence (AI) into oncology promises a
   revolution in diagnosis, treatment, and research. Various applications
   are considered, with a focus on stress and burnout experienced by
   oncologists. The potentials are comprehensively discussed, starting from
   prevention through wearables and AI-assisted analysis of health data to
   personalized treatment planning and accelerated drug development. One
   area of focus is AlphaFold, an AI application for protein folding. The
   management of patient data and the creation of medical reports are
   optimized by AI, with search engines and large language models (LLM)
   playing a prominent role. The increasing specialization of LLMs,
   particularly in medical text generation, underscores their growing
   importance. The feasibility of AI applications is emphasized, addressing
   the need for resources and training for medical personnel. Commercial
   organizations, such as DeepMind, play a crucial role in implementing AI
   in clinical practice. Regulatory challenges are discussed, including
   data privacy, quality control, liability, and ethical aspects. The
   European Health Data Space (EHDS) is a promising initiative for
   promoting secure data exchange within the European Union. Overall, AI
   can facilitate significant advancements in oncology. However, regulatory
   challenges require careful attention to ensure an ethically responsible
   and safe implementation. AI applications have the potential to improve
   cancer care, revolutionize patient management, and reduce the workload
   for medical personnel.
TC 0
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
Z9 0
DA 2024-04-02
UT WOS:001193607500001
ER

PT J
AU Li, Ang
   Wang, Yunxin
   Chen, Hongxu
TI AI driven cardiovascular risk prediction using NLP and Large Language
   Models for personalized medicine in athletes
SO SLAS TECHNOLOGY
VL 32
AR 100286
DI 10.1016/j.slast.2025.100286
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB The performance and long-term health of athletes are significantly
   influenced by their cardiovascular resilience and associated risk
   factors. This study explores the innovative applications of Natural
   Language Processing (NLP) and Large Language Models (LLMs) in biomedical
   diagnostics, particularly for AI-driven arrhythmia detection,
   hypertrophic cardiomyopathy (HCM) in athletes, and personalized
   medicine. The complexity of analysing diverse biomedical datasets, such
   as electrocardiograms (ECG), clinical records, genetic screening
   reports, and imaging results, poses challenges in obtaining precise
   early diagnoses. To address these issues, we introduce a hybrid machine
   learning (ML) framework that integrates the Wolf Pack Search Algorithm
   Dynamic Random Forest (WPSA-DRF) with a RoBERTa-based LLM to enhance the
   accuracy of cardiovascular disease predictions. Using advanced NLP
   techniques, including biomedical text mining, entity recognition, and
   feature extraction, the system processes structured and unstructured
   clinical data to detect abnormalities associated with sudden cardiac
   arrest (SCA), arrhythmias, and genetic cardiomyopathies. The proposed
   system achieves a diagnostic accuracy of 92.5 %, precision of 92.7 %,
   recall of 99.23 %, and F1-score of 95.6 %, outperforming traditional
   diagnostic methodologies. Furthermore, the research underscores the role
   of LLMs in personalized medicine, identifying patient-specific risk
   factors and optimizing treatment pathways for cardiac patients. This
   work highlights how NLP-driven AI solutions are transforming biomedical
   research, accelerating early disease detection, and improving clinical
   decision-making for both athletes and the general population.
ZR 0
TC 0
ZA 0
ZS 0
Z8 0
ZB 0
Z9 0
DA 2025-05-08
UT WOS:001478484900001
PM 40216258
ER

PT J
AU Wong, Matthew
   Lim, Zhi Wei
   Pushpanathan, Krithi
   Cheung, Carol Y.
   Wang, Ya Xing
   Chen, David
   Tham, Yih Chung
TI Review of emerging trends and projection of future developments in large
   language models research in ophthalmology
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1362
EP 1370
DI 10.1136/bjo-2023-324734
EA DEC 2023
DT Review
PD OCT 2024
PY 2024
AB Background Large language models (LLMs) are fast emerging as potent
   tools in healthcare, including ophthalmology. This systematic review
   offers a twofold contribution: it summarises current trends in
   ophthalmology-related LLM research and projects future directions for
   this burgeoning field.
   Methods We systematically searched across various databases (PubMed,
   Europe PMC, Scopus and Web of Science) for articles related to LLM use
   in ophthalmology, published between 1 January 2022 and 31 July 2023.
   Selected articles were summarised, and categorised by type (editorial,
   commentary, original research, etc) and their research focus (eg,
   evaluating ChatGPT's performance in ophthalmology examinations or
   clinical tasks).
   Findings We identified 32 articles meeting our criteria, published
   between January and July 2023, with a peak in June (n=12). Most were
   original research evaluating LLMs' proficiency in clinically related
   tasks (n=9). Studies demonstrated that ChatGPT-4.0 outperformed its
   predecessor, ChatGPT-3.5, in ophthalmology exams. Furthermore, ChatGPT
   excelled in constructing discharge notes (n=2), evaluating diagnoses
   (n=2) and answering general medical queries (n=6). However, it struggled
   with generating scientific articles or abstracts (n=3) and answering
   specific subdomain questions, especially those regarding specific
   treatment options (n=2). ChatGPT's performance relative to other LLMs
   (Google's Bard, Microsoft's Bing) varied by study design. Ethical
   concerns such as data hallucination (n=27), authorship (n=5) and data
   privacy (n=2) were frequently cited.
   Interpretation While LLMs hold transformative potential for healthcare
   and ophthalmology, concerns over accountability, accuracy and data
   security remain. Future research should focus on application programming
   interface integration, comparative assessments of popular LLMs, their
   ability to interpret image-based data and the establishment of
   standardised evaluation frameworks.
ZB 2
ZA 0
ZS 0
TC 14
Z8 0
ZR 0
Z9 14
DA 2024-01-06
UT WOS:001129050700001
PM 38164563
ER

PT J
AU Nwachukwu, Benedict U.
   Varady, Nathan H.
   Allen, Answorth A.
   Dines, Joshua S.
   Altchek, David W.
   Williams III, Riley J.
   Kunze, Kyle N.
TI Currently Available Large Language Models Do Not Provide Musculoskeletal
   Treatment Recommendations That Are Concordant With Evidence-Based
   Clinical Practice Guidelines
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 2
DI 10.1016/j.arthro.2024.07.040
EA JAN 2025
DT Article
PD FEB 2025
PY 2025
AB Purpose: To determine whether several leading, commercially available
   large language models (LLMs) provide treatment recommendations
   concordant with evidence-based clinical practice guidelines (CPGs)
   developed by the American Academy of Orthopaedic Surgeons (AAOS).
   Methods: All CPGs concerning the management of rotator cuff tears (n =
   33) and anterior cruciate ligament injuries (n = 15) were extracted from
   the AAOS. Treatment recommendations from ChatGenerative Pretrained
   Transformer version 4 (ChatGPT-4), Gemini, Mistral-7B, and Claude-3 were
   graded by 2 blinded physicians as being concordant, discordant, or
   indeterminate (i.e., neutral response without definitive recommendation)
   with respect to AAOS CPGs. The overall concordance between LLM and AAOS
   recommendations was quantified, and the comparative overall concordance
   of recommendations among the 4 LLMs was evaluated through the Fisher
   exact test. Results: Overall, 135 responses (70.3%) were concordant, 43
   (22.4%) were indeterminate, and 14 (7.3%) were discordant. Inter-rater
   reliability for concordance classification was excellent (K = 0.92).
   Concordance with AAOS CPGs was most frequently observed with ChatGPT-4
   (n = 38, 79.2%) and least frequently observed with Mistral-7B (n = 28,
   58.3%). Indeterminate recommendations were most frequently observed with
   Mistral-7B (n = 17, 35.4%) and least frequently observed with Claude-3
   (n = 8, 6.7%). Discordant recommendations were most frequently observed
   with Gemini (n = 6, 12.5%) and least frequently observed with ChatGPT-4
   (n = 1, 2.1%). Overall, no statistically significant difference in
   concordant recommendations was observed across LLMs (P = .12). Of all
   recommendations, only 20 (10.4%) were transparent and provided
   references with full bibliographic details or links to specific
   peer-reviewed content to support recommendations. Conclusions: Among
   leading commercially available LLMs, more than 1-in-4 recommendations
   concerning the evaluation and management of rotator cuff and anterior
   cruciate ligament injuries do not reflect current evidence-based CPGs.
   Although ChatGPT-4 showed the highest performance, clinically
   significant rates of recommendations without concordance or supporting
   evidence were observed. Only 10% of responses by LLMs were transparent,
   precluding users from fully interpreting the sources from which
   recommendations were provided. Clinical Relevance: Although leading LLMs
   generally provide recommendations concordant with CPGs, a substantial
   error rate exists, and the proportion of recommendations that do not
   align with these CPGs suggests that LLMs are not trustworthy clinical
   support tools at this time. Each off-the-shelf, closed-source LLM has
   strengths and weaknesses. Future research should evaluate and compare
   multiple LLMs to avoid bias associated with narrow evaluation of few
   models as observed in the current literature.
TC 14
ZS 0
ZA 0
ZR 0
ZB 2
Z8 0
Z9 14
DA 2025-02-05
UT WOS:001407460300001
PM 39173690
ER

PT J
AU Wang, Xueqi
   Ye, Haiyan
   Zhang, Sumian
   Yang, Mei
   Wang, Xuebin
TI Evaluation of the Performance of Three Large Language Models in Clinical
   Decision Support: A Comparative Study Based on Actual Cases
SO JOURNAL OF MEDICAL SYSTEMS
VL 49
IS 1
AR 23
DI 10.1007/s10916-025-02152-9
DT Article
PD FEB 14 2025
PY 2025
AB Background Generative large language models (LLMs) are increasingly
   integrated into the medical field. However, their actual efficacy in
   clinical decision-making remains partially unexplored. This study aimed
   to assess the performance of the three LLMs, ChatGPT-4, Gemini, and
   Med-Go, in the domain of professional medicine when confronted with
   actual clinical cases. Methods This study involved 134 clinical cases
   spanning nine medical disciplines. Each LLM was required to provide
   suggestions for diagnosis, diagnostic criteria, differential diagnosis,
   examination and treatment for every case. Responses were scored by two
   experts using a predefined rubric. Results In overall performance among
   the models, Med-Go achieved the highest median score (37.5, IQR
   31.9-41.5), while Gemini recorded the lowest (33.0, IQR 25.5-36.6),
   showing significant statistical difference among the three LLMs (p <
   0.001). Analysis revealed that responses related to differential
   diagnosis were the weakest, while those pertaining to treatment
   recommendations were the strongest. Med-Go displayed notable performance
   advantages in gastroenterology, nephrology, and neurology. Conclusions
   The findings show that all three LLMs achieved over 60% of the maximum
   possible score, indicating their potential applicability in clinical
   practice. However, inaccuracies that could lead to adverse decisions
   underscore the need for caution in their application. Med-Go's superior
   performance highlights the benefits of incorporating specialized medical
   knowledge into LLMs training. It is anticipated that further development
   and refinement of medical LLMs will enhance their precision and safety
   in clinical use.
Z8 0
TC 2
ZR 0
ZA 0
ZB 0
ZS 0
Z9 2
DA 2025-02-20
UT WOS:001421570100001
PM 39948214
ER

PT J
AU Zhu, L.
   Anand, A.
   Gevorkyan, G.
   Mcgee, L. A.
   Rwigema, J. C.
   Rong, Y.
   Patel, S. H.
TI Testing and Validation of a Custom Trained Large Language Model for HN
   Patients with Guardrails
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 118
IS 5
MA 182
BP E52
EP E53
DT Meeting Abstract
PD APR 1 2024
PY 2024
CT Multidisciplinary Head and Neck Cancers Symposium
CY FEB 29-MAR 02, 2024
CL Phoenix, AZ
TC 1
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
Z9 1
DA 2024-10-18
UT WOS:001300212900102
ER

PT J
AU Sun, Di
   Hadjiiski, Lubomir
   Gormley, John
   Chan, Heang-Ping
   Caoili, Elaine
   Cohan, Richard
   Alva, Ajjai
   Bruno, Grace
   Mihalcea, Rada
   Zhou, Chuan
   Gulani, Vikas
TI Outcome Prediction Using Multi-Modal Information: Integrating Large
   Language Model-Extracted Clinical Information and Image Analysis
SO CANCERS
VL 16
IS 13
AR 2402
DI 10.3390/cancers16132402
DT Article
PD JUL 2024
PY 2024
AB Simple Summary: Predicting the survival of bladder cancer patients
   following cystectomy can offer valuable information for treatment
   planning, decision-making, patient counseling, and resource allocation.
   Our aim was to develop large language model (LLM)-aided multi-modal
   predictive models, based on clinical information and CT images. These
   models achieved performances comparable to those of multi-modal
   predictive models that rely on manually extracted clinical information.
   This study demonstrates the potential of employing LLMs to process
   medical data, and of integrating LLM-processed data into modeling for
   prognosis.
   Survival prediction post-cystectomy is essential for the follow-up care
   of bladder cancer patients. This study aimed to evaluate artificial
   intelligence (AI)-large language models (LLMs) for extracting clinical
   information and improving image analysis, with an initial application
   involving predicting five-year survival rates of patients after radical
   cystectomy for bladder cancer. Data were retrospectively collected from
   medical records and CT urograms (CTUs) of bladder cancer patients
   between 2001 and 2020. Of 781 patients, 163 underwent chemotherapy, had
   pre- and post-chemotherapy CTUs, underwent radical cystectomy, and had
   an available post-surgery five-year survival follow-up. Five AI-LLMs
   (Dolly-v2, Vicuna-13b, Llama-2.0-13b, GPT-3.5, and GPT-4.0) were used to
   extract clinical descriptors from each patient's medical records. As a
   reference standard, clinical descriptors were also extracted manually.
   Radiomics and deep learning descriptors were extracted from CTU images.
   The developed multi-modal predictive model, CRD, was based on the
   clinical (C), radiomics (R), and deep learning (D) descriptors. The LLM
   retrieval accuracy was assessed. The performances of the survival
   predictive models were evaluated using AUC and Kaplan-Meier analysis.
   For the 163 patients (mean age 64 +/- 9 years; M:F 131:32), the LLMs
   achieved extraction accuracies of 74%similar to 87% (Dolly), 76%similar
   to 83% (Vicuna), 82%similar to 93% (Llama), 85%similar to 91% (GPT-3.5),
   and 94%similar to 97% (GPT-4.0). For a test dataset of 64 patients, the
   CRD model achieved AUCs of 0.89 +/- 0.04 (manually extracted
   information), 0.87 +/- 0.05 (Dolly), 0.83 +/- 0.06 similar to 0.84 +/-
   0.05 (Vicuna), 0.81 +/- 0.06 similar to 0.86 +/- 0.05 (Llama), 0.85 +/-
   0.05 similar to 0.88 +/- 0.05 (GPT-3.5), and 0.87 +/- 0.05 similar to
   0.88 +/- 0.05 (GPT-4.0). This study demonstrates the use of LLM
   model-extracted clinical information, in conjunction with imaging
   analysis, to improve the prediction of clinical outcomes, with bladder
   cancer as an initial example.
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
TC 4
Z9 4
DA 2024-07-24
UT WOS:001270395100001
PM 39001463
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU Kaarre, Janina
   Feldt, Robert
   Keeling, Laura E.
   Dadoo, Sahil
   Zsidai, Balint
   Hughes, Jonathan D.
   Samuelsson, Kristian
   Musahl, Volker
TI Exploring the potential of ChatGPT as a supplementary tool for providing
   orthopaedic information
SO KNEE SURGERY SPORTS TRAUMATOLOGY ARTHROSCOPY
VL 31
IS 11
BP 5190
EP 5198
DI 10.1007/s00167-023-07529-2
EA AUG 2023
DT Article
PD NOV 2023
PY 2023
AB PurposeTo investigate the potential use of large language models (LLMs)
   in orthopaedics by presenting queries pertinent to anterior cruciate
   ligament (ACL) surgery to generative pre-trained transformer (ChatGPT,
   specifically using its GPT-4 model of March 14th 2023). Additionally,
   this study aimed to evaluate the depth of the LLM's knowledge and
   investigate its adaptability to different user groups. It was
   hypothesized that the ChatGPT would be able to adapt to different target
   groups due to its strong language understanding and processing
   capabilities.MethodsChatGPT was presented with 20 questions and response
   was requested for two distinct target audiences: patients and
   non-orthopaedic medical doctors. Two board-certified orthopaedic sports
   medicine surgeons and two expert orthopaedic sports medicine surgeons
   independently evaluated the responses generated by ChatGPT. Mean
   correctness, completeness, and adaptability to the target audiences
   (patients and non-orthopaedic medical doctors) were determined. A
   three-point response scale facilitated nuanced assessment.ResultsChatGPT
   exhibited fair accuracy, with average correctness scores of 1.69 and
   1.66 (on a scale from 0, incorrect, 1, partially correct, to 2, correct)
   for patients and medical doctors, respectively. Three of the 20
   questions (15.0%) were deemed incorrect by any of the four orthopaedic
   sports medicine surgeon assessors. Moreover, overall completeness was
   calculated to be 1.51 and 1.64 for patients and medical doctors,
   respectively, while overall adaptiveness was determined to be 1.75 and
   1.73 for patients and doctors, respectively.ConclusionOverall, ChatGPT
   was successful in generating correct responses in approximately 65% of
   the cases related to ACL surgery. The findings of this study imply that
   LLMs offer potential as a supplementary tool for acquiring orthopaedic
   knowledge. However, although ChatGPT can provide guidance and
   effectively adapt to diverse target audiences, it cannot supplant the
   expertise of orthopaedic sports medicine surgeons in diagnostic and
   treatment planning endeavours due to its limited understanding of
   orthopaedic domains and its potential for erroneous responses.
ZS 0
ZB 6
TC 56
ZR 0
Z8 2
ZA 0
Z9 58
DA 2023-08-23
UT WOS:001044338600003
PM 37553552
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik Y.
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on the Ocular Hypertension Treatment Study
   Dataset Using Chat Generative Pre-Trained Transformer as a Large
   Language Model
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100599
DI 10.1016/j.xops.2024.100599
EA SEP 2024
DT Article
PD JAN-FEB 2025
PY 2025
AB Purpose: To evaluate the capabilities of Chat Generative Pre-Trained
   Transformer (ChatGPT), as a large language model (LLM), for diagnosing
   glaucoma using the Ocular Hypertension Treatment Study (OHTS) dataset,
   and comparing the diagnostic capability of ChatGPT 3.5 and ChatGPT 4.0.
   Design: Prospective data collection study. Participants: A total of 3170
   eyes of 1585 subjects from the OHTS were included in this study.
   Methods: We selected demographic, clinical, ocular, visual field, optic
   nerve head photo, and history of disease parameters of each participant
   and developed case reports by converting tabular data into textual
   format based on information from both eyes of all subjects. We then
   developed a procedure using the application programming interface of
   ChatGPT, a LLM-based chatbot, to automatically input prompts into a chat
   box. This was followed by querying 2 different generations of ChatGPT
   (versions 3.5 and 4.0) regarding the underlying diagnosis of each
   subject. We then evaluated the output responses based on several
   objective metrics. Main Outcome Measures: Area under the receiver
   operating characteristic curve (AUC), accuracy, specificity,
   sensitivity, and F1 score. Results: Chat Generative Pre-Trained
   Transformer 3.5 achieved AUC of 0.74, accuracy of 66%, specificity of
   64%, sensitivity of 85%, and F1 score of 0.72. Chat Generative
   Pre-Trained Transformer 4.0 obtained AUC of 0.76, accuracy of 87%,
   specificity of 90%, sensitivity of 61%, and F1 score of 0.92.
   Conclusions: The accuracy of ChatGPT 4.0 in diagnosing glaucoma based on
   input data from OHTS was promising. The overall accuracy of ChatGPT 4.0
   was higher than ChatGPT 3.5. However, ChatGPT 3.5 was found to be more
   sensitive than ChatGPT 4.0. In its current forms, ChatGPT may serve as a
   useful tool in exploring disease status of ocular hypertensive eyes when
   specific data are available for analysis. In the future, leveraging LLMs
   with multimodal capabilities, allowing for integration of imaging and
   diagnostic testing as part of the analyses, could further enhance
   diagnostic capabilities and enhance diagnostic accuracy. Financial
   Disclosures: Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100599 (c) 2024 by the American Academy of Ophthalmology.
   This is an open access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-ncnd/4.0/).
ZR 0
ZB 0
ZA 0
Z8 0
TC 3
ZS 0
Z9 3
DA 2024-10-16
UT WOS:001330416200001
PM 39346574
ER

PT J
AU Nazar, Wojciech
   Nazar, Grzegorz
   Kaminska, Aleksandra
   Danilowicz-Szymanowicz, Ludmila
TI How to Design, Create, and Evaluate an Instruction-Tuning Dataset for
   Large Language Model Training in Health Care: Tutorial From a Clinical
   Perspective
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e70481
DI 10.2196/70481
DT Article
PD MAR 18 2025
PY 2025
AB High-quality data are critical in health care, forming the cornerstone
   for accurate diagnoses, effective treatment plans, and reliable
   conclusions. Similarly, high-quality datasets underpin the development
   and performance of large language models (LLMs). Among these,
   instruction-tuning datasets (ITDs) used for instruction fine-tuning have
   been pivotal in enhancing LLM performance and generalization
   capabilities across diverse tasks. This tutorial provides a
   comprehensive guide to designing, creating, and evaluating ITDs for
   health care applications. Written from a clinical perspective, it aims
   to make the concepts accessible to a broad audience, especially medical
   practitioners. Key topics include identifying useful data sources,
   defining the characteristics of well-designed datasets, and crafting
   high-quality instruction-input-output examples. We explore practical
   approaches to dataset construction, examining the advantages and
   limitations of 3 primary methods: fully manual preparation by expert
   annotators, fully synthetic generation using artificial intelligence
   (AI), and an innovative hybrid approach in which experts draft the
   initial dataset and AI generates additional data. Moreover, we discuss
   strategies for metadata selection and human evaluation to ensure the
   quality and effectiveness of ITDs. By integrating these elements, this
   tutorial provides a structured framework for establishing ITDs. It
   bridges technical and clinical domains, supporting the continued
   interdisciplinary advancement of AI in medicine. Additionally, we
   address the limitations of current practices and propose future
   directions, emphasizing the need for a global, unified frameworkfor
   ITDs. We also arguethat artificial general intelligence (AGI), if
   realized, will not replace empirical research in medicine. AGI will
   depend on human-curated datasets to process and apply medical knowledge.
   At the same time, ITDs will likely remain the most effective method of
   supplying this knowledge to AGI, positioning them as a critical tool in
   AI-driven health care.
ZA 0
Z8 0
ZB 0
ZS 0
TC 0
ZR 0
Z9 0
DA 2025-04-27
UT WOS:001469527400010
PM 40100270
ER

PT J
AU Cangelosi, Davide
   Blengio, Fabiola
   Versteeg, Rogier
   Eggert, Angelika
   Garaventa, Alberto
   Gambini, Claudio
   Conte, Massimo
   Eva, Alessandra
   Muselli, Marco
   Varesio, Luigi
TI Logic Learning Machine creates explicit and stable rules stratifying
   neuroblastoma patients
SO BMC BIOINFORMATICS
VL 14
AR S12
DI 10.1186/1471-2105-14-S7-S12
SU 7
DT Article
PD APR 22 2013
PY 2013
AB Background: Neuroblastoma is the most common pediatric solid tumor.
   About fifty percent of high risk patients die despite treatment making
   the exploration of new and more effective strategies for improving
   stratification mandatory. Hypoxia is a condition of low oxygen tension
   occurring in poorly vascularized areas of the tumor associated with poor
   prognosis. We had previously defined a robust gene expression signature
   measuring the hypoxic component of neuroblastoma tumors (NB-hypo) which
   is a molecular risk factor. We wanted to develop a prognostic classifier
   of neuroblastoma patients' outcome blending existing knowledge on
   clinical and molecular risk factors with the prognostic NB-hypo
   signature. Furthermore, we were interested in classifiers outputting
   explicit rules that could be easily translated into the clinical
   setting.
   Results: Shadow Clustering (SC) technique, which leads to final models
   called Logic Learning Machine (LLM), exhibits a good accuracy and
   promises to fulfill the aims of the work. We utilized this algorithm to
   classify NB-patients on the bases of the following risk factors: Age at
   diagnosis, INSS stage, MYCN amplification and NB-hypo. The algorithm
   generated explicit classification rules in good agreement with existing
   clinical knowledge. Through an iterative procedure we identified and
   removed from the dataset those examples which caused instability in the
   rules. This workflow generated a stable classifier very accurate in
   predicting good and poor outcome patients. The good performance of the
   classifier was validated in an independent dataset. NB-hypo was an
   important component of the rules with a strength similar to that of
   tumor staging.
   Conclusions: The novelty of our work is to identify stability, explicit
   rules and blending of molecular and clinical risk factors as the key
   features to generate classification rules for NB patients to be conveyed
   to the clinic and to be used to design new therapies. We derived,
   through LLM, a set of four stable rules identifying a new class of poor
   outcome patients that could benefit from new therapies potentially
   targeting tumor hypoxia or its consequences.
ZR 0
ZB 8
TC 24
ZS 0
ZA 0
Z8 1
Z9 25
DA 2013-04-22
UT WOS:000318869400012
PM 23815266
ER

PT J
AU McCoy, Thomas H.
   Castro, Victor M.
   Perlis, Roy H.
TI Estimating depression severity in narrative clinical notes using large
   language models
SO JOURNAL OF AFFECTIVE DISORDERS
VL 381
BP 270
EP 274
DI 10.1016/j.jad.2025.04.014
EA APR 2025
DT Article
PD JUL 15 2025
PY 2025
AB Background: Depression treatment guidelines emphasize measurement-based
   care using patient-reported outcome measures, yet their impact on
   narrative documentation quality remains underexplored. Methods: We
   sampled 15,000 narrative clinical outpatient notes from the electronic
   health record of a large academic medical center, reflecting visits
   between January 2, 2019 and January 30, 2024, for which a 9-item Patient
   Health Questionnaire (PHQ-9) was completed at the same time. After
   censoring PHQ-9 scores from notes, we estimated severity of depressive
   symptoms with a foundational large language model (gpt4o-08-06) in a
   HIPAA-compliant enclave. We estimated correlation between true PHQ-9 and
   model-estimated score and examined the predictive performance of the
   model for moderate or greater depressive symptoms. Results: Mean age was
   46.3 years (SD 14.9); 9083 (60.6 %) identified as female. 925 (6.2 %)
   identified as Asian, 638 (4.3 %) as Black, 853 (5.7 %) as another race,
   and 12,187 (81.2 %) as White. A total of 1044 (7.0 %) identified as
   Hispanic ethnicity, while 12,699 (84.7 %) were non-Hispanic. Mean
   measured PHQ-9 score was 1.23 (SD 3.45); 721 (4.8 %) met criteria for
   moderate or greater depressive symptoms. LLM-predicted PHQ-9 scores were
   modestly correlated with actual scores (r2 = 0.264 (95 % CI
   0.252-0.276)); PPV for moderate or greater depression was 0.309 (95 % CI
   0.302-0.317). Performance was consistent across demographic subgroups,
   with modest differences identified by race, ethnicity, and sex.
   Conclusion: A foundational LLM performed poorly but consistently across
   subgroups in imputing PHQ-9 scores from notes when actual PHQ-9
   reporting was ablated. This result suggests the extent to which
   inclusion of PROMs may impoverish documentation of psychiatric symptoms.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-04-26
UT WOS:001469145100001
PM 40187432
ER

PT J
AU Wang, Li
   Chen, Xi
   Deng, Xiangwen
   Wen, Hao
   You, Mingke
   Liu, Weizhi
   Li, Qi
   Li, Jian
TI Prompt engineering in consistency and reliability with the
   evidence-based guideline for LLMs
SO NPJ DIGITAL MEDICINE
VL 7
IS 1
AR 41
DI 10.1038/s41746-024-01029-4
DT Article
PD FEB 20 2024
PY 2024
AB The use of large language models (LLMs) in clinical medicine is
   currently thriving. Effectively transferring LLMs' pertinent theoretical
   knowledge from computer science to their application in clinical
   medicine is crucial. Prompt engineering has shown potential as an
   effective method in this regard. To explore the application of prompt
   engineering in LLMs and to examine the reliability of LLMs, different
   styles of prompts were designed and used to ask different LLMs about
   their agreement with the American Academy of Orthopedic Surgeons (AAOS)
   osteoarthritis (OA) evidence-based guidelines. Each question was asked 5
   times. We compared the consistency of the findings with guidelines
   across different evidence levels for different prompts and assessed the
   reliability of different prompts by asking the same question 5 times.
   gpt-4-Web with ROT prompting had the highest overall consistency (62.9%)
   and a significant performance for strong recommendations, with a total
   consistency of 77.5%. The reliability of the different LLMs for
   different prompts was not stable (Fleiss kappa ranged from -0.002 to
   0.984). This study revealed that different prompts had variable effects
   across various models, and the gpt-4-Web with ROT prompt was the most
   consistent. An appropriate prompt could improve the accuracy of
   responses to professional medical questions.
TC 87
Z8 0
ZA 0
ZS 0
ZB 11
ZR 0
Z9 88
DA 2024-03-09
UT WOS:001169095300001
PM 38378899
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Schmidt, Kurt W.
   Lechner, Fabian
TI ChatGPT: aid to medical ethics decision making?
SO ANAESTHESIOLOGIE
VL 73
IS 3
SI SI
BP 177
EP 185
DI 10.1007/s00101-024-01385-6
DT Review
PD MAR 2024
PY 2024
AB Background: Physicians have to make countless decisions every day. The
   medical, ethical and legal aspects are often intertwined and subject to
   change over time. Involving an ethics committee or arranging an ethical
   consultation are examples of potential aids to decision making. Whether
   and how artificial intelligence (AI) and the large language model (LLM)
   of the company OpenAI (San Francisco, CA, USA), known under the name
   ChatGPT, can also help and support ethical decision making is
   increasingly becoming a matter of controversial debate. Material and
   methods: Based on a case example, in which a female physician is
   confronted with ethical and legal issues and presents these to ChatGPT
   to come up with answers, the first indications of the strengths and
   weaknesses are ascertained. Conclusion: Due to the rapid technical
   development and access to ever increasing quantities of data, the
   utilization should be closely observed and evaluated.
TC 1
ZA 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 1
DA 2024-10-27
UT WOS:001230024600003
PM 38315183
ER

PT J
AU Bellamkonda, Nikhil
   Farlow, Janice L.
   Haring, Catherine T.
   Sim, Michael W.
   Seim, Nolan B.
   Cannon, Richard B.
   Monroe, Marcus M.
   Agrawal, Amit
   Rocco, James W.
   McCrary, Hilary C.
TI Evaluating the Accuracy of ChatGPT in Common Patient Questions Regarding
   HPV plus Oropharyngeal Carcinoma
SO ANNALS OF OTOLOGY RHINOLOGY AND LARYNGOLOGY
VL 133
IS 9
BP 814
EP 819
DI 10.1177/00034894241259137
EA JUL 2024
DT Article
PD SEP 2024
PY 2024
AB Objectives: Large language model (LLM)-based chatbots such as ChatGPT
   have been publicly available and increasingly utilized by the general
   public since late 2022. This study sought to investigate ChatGPT
   responses to common patient questions regarding Human Papilloma Virus
   (HPV) positive oropharyngeal cancer (OPC). Methods: This was a
   prospective, multi-institutional study, with data collected from high
   volume institutions that perform >50 transoral robotic surgery cases per
   year. The 100 most recent discussion threads including the term "HPV" on
   the American Cancer Society's Cancer Survivors Network's Head and Neck
   Cancer public discussion board were reviewed. The 11 most common
   questions were serially queried to ChatGPT 3.5; answers were recorded. A
   survey was distributed to fellowship trained head and neck oncologic
   surgeons at 3 institutions to evaluate the responses. Results: A total
   of 8 surgeons participated in the study. For questions regarding HPV
   contraction and transmission, ChatGPT answers were scored as clinically
   accurate and aligned with consensus in the head and neck surgical
   oncology community 84.4% and 90.6% of the time, respectively. For
   questions involving treatment of HPV+ OPC, ChatGPT was clinically
   accurate and aligned with consensus 87.5% and 91.7% of the time,
   respectively. For questions regarding the HPV vaccine, ChatGPT was
   clinically accurate and aligned with consensus 62.5% and 75% of the
   time, respectively. When asked about circulating tumor DNA testing, only
   12.5% of surgeons thought responses were accurate or consistent with
   consensus. Conclusion: ChatGPT 3.5 performed poorly with questions
   involving evolving therapies and diagnostics-thus, caution should be
   used when using a platform like ChatGPT 3.5 to assess use of advanced
   technology. Patients should be counseled on the importance of consulting
   their surgeons to receive accurate and up to date recommendations, and
   use LLM's to augment their understanding of these important
   health-related topics.
ZB 0
Z8 0
ZR 0
ZA 0
TC 1
ZS 0
Z9 1
DA 2024-08-06
UT WOS:001280661600001
PM 39075853
ER

PT J
AU Vrdoljak, Josip
   Boban, Zvonimir
   Vilovic, Marino
   Kumric, Marko
   Bozic, Josko
TI A Review of Large Language Models in Medical Education, Clinical
   Decision Support, and Healthcare Administration
SO HEALTHCARE
VL 13
IS 6
AR 603
DI 10.3390/healthcare13060603
DT Review
PD MAR 10 2025
PY 2025
AB Background/Objectives: Large language models (LLMs) have shown
   significant potential to transform various aspects of healthcare. This
   review aims to explore the current applications, challenges, and future
   prospects of LLMs in medical education, clinical decision support, and
   healthcare administration. Methods: A comprehensive literature review
   was conducted, examining the applications of LLMs across the three key
   domains. The analysis included their performance, challenges, and
   advancements, with a focus on techniques like retrieval-augmented
   generation (RAG). Results: In medical education, LLMs show promise as
   virtual patients, personalized tutors, and tools for generating study
   materials. Some models have outperformed junior trainees in specific
   medical knowledge assessments. Concerning clinical decision support,
   LLMs exhibit potential in diagnostic assistance, treatment
   recommendations, and medical knowledge retrieval, though performance
   varies across specialties and tasks. In healthcare administration, LLMs
   effectively automate tasks like clinical note summarization, data
   extraction, and report generation, potentially reducing administrative
   burdens on healthcare professionals. Despite their promise, challenges
   persist, including hallucination mitigation, addressing biases, and
   ensuring patient privacy and data security. Conclusions: LLMs have
   transformative potential in medicine but require careful integration
   into healthcare settings. Ethical considerations, regulatory challenges,
   and interdisciplinary collaboration between AI developers and healthcare
   professionals are essential. Future advancements in LLM performance and
   reliability through techniques such as RAG, fine-tuning, and
   reinforcement learning will be critical to ensuring patient safety and
   improving healthcare delivery.
TC 1
ZA 0
ZS 0
ZR 0
ZB 0
Z8 0
Z9 1
DA 2025-03-31
UT WOS:001452063500001
PM 40150453
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on a Large Language Model Chatbot
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1636
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
TC 0
ZB 0
Z8 0
ZA 0
ZS 0
Z9 0
DA 2024-12-01
UT WOS:001312227704264
ER

PT J
AU Wang, Ling
   Li, Jinglin
   Zhuang, Boyang
   Huang, Shasha
   Fang, Meilin
   Wang, Cunze
   Li, Wen
   Zhang, Mohan
   Gong, Shurong
TI Accuracy of Large Language Models When Answering Clinical Research
   Questions: Systematic Review and Network Meta-Analysis
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e64486
DI 10.2196/64486
DT Review
PD APR 30 2025
PY 2025
AB Background: Large language models (LLMs) have flourished and gradually
   become an important research and application direction in the medical
   field. However, due to the high degree of specialization, complexity,
   and specificity of medicine, which results in extremely high accuracy
   requirements, controversy remains about whether LLMscan be used in the
   medical field. More studies have evaluated the performance of various
   types of LLMs in medicine, but the conclusions are inconsistent.
   Objective: This study uses a network meta-analysis (NMA) to assess the
   accuracy of LLMs when answering clinical research questions to provide
   high-level evidence-based evidence for its future development and
   application in the medical field. Methods: In this systematic review and
   NMA, we searched PubMed, Embase, Web of Science, and Scopus from
   inception until October 14, 2024. Studies on the accuracy of LLMs when
   answering clinical research questions were included and screened by
   reading published reports. The systematic review and NMA were conducted
   to compare the accuracy of different LLMs when answering clinical
   research questions, including objective questions, open-ended questions,
   top 1 diagnosis, top 3 diagnosis, top 5 diagnosis, and triage and
   classification. The NMA was performed using Bayesian frequency theory
   methods. Indirect intercomparisons between programs were performed using
   a grading scale. A larger surface under the cumulative ranking curve
   (SUCRA) value indicates a higher ranking of the corresponding LLM
   accuracy. Results: The systematic review and NMA examined 168 articles
   encompassing 35,896 questions and 3063 clinical cases. Of the 168
   studies, 40 (23.8%) were considered to have a low risk of bias, 128
   (76.2%) had a moderate risk, and none were rated as having a high risk.
   ChatGPT-4o (SUCRA=0.9207) demonstrated strong performance in terms of
   accuracy for objective questions, followed by Aeyeconsult (SUCRA=0.9187)
   and ChatGPT-4 (SUCRA=0.8087). ChatGPT-4 (SUCRA=0.8708) excelled at
   answering open-ended questions. In terms of accuracy for top 1 diagnosis
   and top 3 diagnosis of clinical cases, human experts (SUCRA=0.9001 and
   SUCRA=0.7126, respectively) rankedthehighest, whileClaude3 Opus
   (SUCRA=0.9672) performed well at the top 5 diagnosis. Gemini
   (SUCRA=0.9649) had the highest rated SUCRA value for accuracy in the
   area of triage and classification. Conclusions: Our study indicates that
   ChatGPT-4o has an advantage when answering objective questions. For
   open-ended questions, ChatGPT-4 may be more credible. Humans are more
   accurate at the top 1 diagnosis and top 3 diagnosis. Claude 3 Opus
   performs better atthetop5diagnosis, whilefortriage and classification,
   Gemini is more advantageous. This analysis offers valuable insights for
   clinicians and medical practitioners, empowering them to effectively
   leverage LLMs for improved decision-making in learning, diagnosis, and
   management of various clinical scenarios.
ZB 0
ZA 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-05-30
UT WOS:001495307800003
PM 40305085
ER

PT J
AU Huang, Thomas
   Safranek, Conrad
   Socrates, Vimig
   Chartash, David
   Wright, Donald
   Dilip, Monisha
   Sangal, Rohit B.
   Taylor, Richard Andrew
TI Patient-Representing Population's Perceptions of GPT-GeneratedVersus
   Standard Emergency Department Discharge Instructions:Randomized Blind
   Survey Assessment
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 26
AR e60336
DI 10.2196/60336
DT Article
PD AUG 2 2024
PY 2024
AB Background: Discharge instructions are a key form of documentation and
   patient communication in the time of transition fromthe emergency
   department (ED) to home. Discharge instructions are time-consuming and
   often underprioritized, especially inthe ED, leading to discharge delays
   and possibly impersonal patient instructions. Generative artificial
   intelligence and largelanguage models (LLMs) offer promising methods of
   creating high-quality and personalized discharge instructions;
   however,there exists a gap in understanding patient perspectives of
   LLM-generated discharge instructions. Objective: We aimed to assess the
   use of LLMs such as ChatGPT in synthesizing accurate and
   patient-accessible dischargeinstructions in the ED. Methods: We
   synthesized 5 unique, fictional ED encounters to emulate real ED
   encounters that included a diverse set of clinicianhistory, physical
   notes, and nursing notes. These were passed to GPT-4 in Azure OpenAI
   Service (Microsoft) to generateLLM-generated discharge instructions.
   Standard discharge instructions were also generated for each of the 5
   unique ED encounters.All GPT-generated and standard discharge
   instructions were then formatted into standardized after-visit summary
   documents.These after-visit summaries containing either GPT-generated or
   standard discharge instructions were randomly and blindlyadministered to
   Amazon MTurk respondents representing patient populations through Amazon
   MTurk Survey Distribution.Discharge instructions were assessed based on
   metrics of interpretability of significance, understandability, and
   satisfaction. Results: Our findings revealed that survey
   respondents'perspectives regarding GPT-generated and standard discharge
   instructionswere significantly (P=.01) more favorable toward
   GPT-generated return precautions, and all other sections were
   considerednoninferior to standard discharge instructions. Of the 156
   survey respondents, GPT-generated discharge instructions were
   assignedfavorable ratings, "agree" and "strongly agree," more frequently
   along the metric of interpretability of significancein
   dischargeinstruction subsections regarding diagnosis, procedures,
   treatment, post-ED medications or any changes to medications, andreturn
   precautions. Survey respondents found GPT-generated instructions to be
   more understandablewhen rating procedures,treatment, post-ED medications
   or medication changes, post-ED follow-up, and return precautions.
   Satisfactionwith GPT-generateddischarge instruction subsections was the
   most favorable in procedures, treatment, post-ED medications or
   medication changes,and return precautions. Wilcoxon rank-sum test of
   Likert responses revealed significant differences (P=.01) in the
   interpretabilityof significantreturn precautions in GPT-generated
   discharge instructions compared to standard discharge instructions but
   not forother evaluation metrics and discharge instruction subsections
   Conclusions: This study demonstrates the potential for LLMs such as
   ChatGPT to act as a method of augmenting currentdocumentation workflows
   in the ED to reduce the documentation burden of physicians. The ability
   of LLMs to provide tailoredinstructions for patients by improving
   readability and making instructions more applicable to patients could
   improve upon themethods of communication that currently exist
ZB 1
ZS 0
ZR 0
TC 5
Z8 0
ZA 0
Z9 5
DA 2024-09-13
UT WOS:001304413300003
PM 39094112
ER

PT J
AU Tong, Linjian
   Zhang, Chaoyang
   Liu, Rui
   Yang, Jia
   Sun, Zhiming
TI Comparative performance analysis of large language models: ChatGPT-3.5,
   ChatGPT-4 and Google Gemini in glucocorticoid-induced osteoporosis
SO JOURNAL OF ORTHOPAEDIC SURGERY AND RESEARCH
VL 19
IS 1
AR 574
DI 10.1186/s13018-024-04996-2
DT Article
PD SEP 18 2024
PY 2024
AB Backgrounds The use of large language models (LLMs) in medicine can help
   physicians improve the quality and effectiveness of health care by
   increasing the efficiency of medical information management, patient
   care, medical research, and clinical decision-making. Methods We
   collected 34 frequently asked questions about glucocorticoid-induced
   osteoporosis (GIOP), covering topics related to the disease's clinical
   manifestations, pathogenesis, diagnosis, treatment, prevention, and risk
   factors. We also generated 25 questions based on the 2022 American
   College of Rheumatology Guideline for the Prevention and Treatment of
   Glucocorticoid-Induced Osteoporosis (2022 ACR-GIOP Guideline). Each
   question was posed to the LLM (ChatGPT-3.5, ChatGPT-4, and Google
   Gemini), and three senior orthopedic surgeons independently rated the
   responses generated by the LLMs. Three senior orthopedic surgeons
   independently rated the answers based on responses ranging between 1 and
   4 points. A total score (TS) > 9 indicated 'good' responses, 6 <= TS <=
   9 indicated 'moderate' responses, and TS < 6 indicated 'poor' responses.
   Results In response to the general questions related to GIOP and the
   2022 ACR-GIOP Guidelines, Google Gemini provided more concise answers
   than the other LLMs. In terms of pathogenesis, ChatGPT-4 had
   significantly higher total scores (TSs) than ChatGPT-3.5. The TSs for
   answering questions related to the 2022 ACR-GIOP Guideline by ChatGPT-4
   were significantly higher than those for Google Gemini. ChatGPT-3.5 and
   ChatGPT-4 had significantly higher self-corrected TSs than pre-corrected
   TSs, while Google Gemini self-corrected for responses that were not
   significantly different than before. Conclusions Our study showed that
   Google Gemini provides more concise and intuitive responses than
   ChatGPT-3.5 and ChatGPT-4. ChatGPT-4 performed significantly better than
   ChatGPT3.5 and Google Gemini in terms of answering general questions
   about GIOP and the 2022 ACR-GIOP Guidelines. ChatGPT3.5 and ChatGPT-4
   self-corrected better than Google Gemini.
ZA 0
Z8 0
TC 1
ZB 0
ZR 0
ZS 0
Z9 1
DA 2024-09-23
UT WOS:001314945200001
PM 39289734
ER

PT J
AU Zhang, Chi
   Yang, Hao
   Liu, Xingyun
   Wu, Rongrong
   Zong, Hui
   Wu, Erman
   Zhou, Yi
   Li, Jiakun
   Shen, Bairong
TI A Knowledge-Enhanced Platform (MetaSepsisKnowHub) for Retrieval
   Augmented Generation-Based Sepsis Heterogeneity and Personalized
   Management: Development Study.
SO Journal of medical Internet research
VL 27
BP e67201
EP e67201
DI 10.2196/67201
DT Journal Article
PD 2025 Jun 06
PY 2025
AB BACKGROUND: Sepsis is a severe syndrome of organ dysfunction caused by
   infection; it has high heterogeneity and high in-hospital mortality,
   representing a grim clinical challenge for precision medicine in
   critical care.
   OBJECTIVE: We aimed to extract reported sepsis biomarkers to provide
   users with comprehensive biomedical information and integrate retrieval
   augmented generation (RAG) and prompt engineering to enhance the
   accuracy, stability, and interpretability of clinical decisions
   recommended by large language models (LLMs).
   METHODS: To address the challenge, we established and updated the first
   knowledge-enhanced platform, MetaSepsisKnowHub, comprising 427 sepsis
   biomarkers and 423 studies, aiming to systematically collect and
   annotate sepsis biomarkers to guide personalized clinical
   decision-making in the diagnosis and treatment of human sepsis. We
   curated a tailored LLM framework incorporating RAG and prompt
   engineering and incorporated 2 performance evaluation scales: the System
   Usability Scale and the Net Promoter Score.
   RESULTS: The overall quantitative ratings of expert-reviewed clinical
   recommendations based on RAG surpassed baseline responses generated by 4
   LLMs and showed a statistically significant improvement in textual
   questions (GPT-4: mean 75.79, SD 7.11 vs mean 81.59, SD 9.87; P=.02;
   GPT-4o: mean 70.36, SD 7.63 vs mean 77.98, SD 13.26; P=.02;
   Qwen2.5-instruct: mean 77.08 SD 3.75 vs mean 85.46, SD 7.27; P<.001; and
   DeepSeek-R1: mean 77.67, SD 3.66 vs mean 86.42, SD 8.56; P<.001), but no
   significant statistical differences could be measured in clinical
   scenarios. The RAG assessment score comparing RAG-based responses and
   expert-provided benchmark answers illustrated prominent factual
   correctness, accuracy, and knowledge recall compared to the baseline
   responses. After use, the average the System Usability Scale score was
   82.20 (SD 14.17) and the Net Promoter Score was 72, demonstrating high
   user satisfaction and loyalty.
   CONCLUSIONS: We highlight the pioneering MetaSepsisKnowHub platform, and
   we show that combining MetaSepsisKnowHub with RAG can minimize
   limitations on precision and maximize the breadth of LLMs to shorten the
   bench-to-bedside distance, serving as a knowledge-enhanced paradigm for
   future application of artificial intelligence in critical care medicine.
ZS 0
ZR 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
DA 2025-06-08
UT MEDLINE:40478618
PM 40478618
ER

PT J
AU McLean, Aaron Lawson
   Wu, Yonghui
   McLean, Anna C. Lawson
   Hristidis, Vagelis
TI Large language models as decision aids in neuro-oncology: a review of
   shared decision-making applications
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 3
AR 139
DI 10.1007/s00432-024-05673-x
DT Review
PD MAR 19 2024
PY 2024
AB Shared decision-making (SDM) is crucial in neuro-oncology, fostering
   collaborations between patients and healthcare professionals to navigate
   treatment options. However, the complexity of neuro-oncological
   conditions and the cognitive and emotional burdens on patients present
   significant barriers to achieving effective SDM. This discussion
   explores the potential of large language models (LLMs) such as OpenAI's
   ChatGPT and Google's Bard to overcome these barriers, offering a means
   to enhance patient understanding and engagement in their care. LLMs, by
   providing accessible, personalized information, could support but not
   supplant the critical insights of healthcare professionals. The
   hypothesis suggests that patients, better informed through LLMs, may
   participate more actively in their treatment choices. Integrating LLMs
   into neuro-oncology requires navigating ethical considerations,
   including safeguarding patient data and ensuring informed consent,
   alongside the judicious use of AI technologies. Future efforts should
   focus on establishing ethical guidelines, adapting healthcare workflows,
   promoting patient-oriented research, and developing training programs
   for clinicians on the use of LLMs. Continuous evaluation of LLM
   applications will be vital to maintain their effectiveness and alignment
   with patient needs. Ultimately, this exploration contends that the
   thoughtful integration of LLMs into SDM processes could significantly
   enhance patient involvement and strengthen the patient-physician
   relationship in neuro-oncology care.
ZR 0
ZB 1
ZA 0
ZS 0
TC 8
Z8 1
Z9 8
DA 2024-04-01
UT WOS:001187667700003
PM 38503921
ER

PT J
AU Dai, Jiayi
   Kim, Mi-Young
   Sutton, Reed T.
   Mitchell, Joseph R.
   Goebel, Randolph G.
   Baumgart, Daniel C.
TI DEVELOPMENT OF IBDBERT - NATURAL LANGUAGE PROCESSING ANALYSIS OF CROHN'S
   DISEASE COMPUTED TOMOGRAPHY ENTEROGRAPHY (CTE) REPORTS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Sa2032
BP S612
EP S612
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZR 0
TC 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837702379
ER

PT J
AU Beattie, J.
   Neufeld, S.
   Yang, D. X.
   Chukwuma, C.
   Desai, N. B.
   Dohopolski, M.
   Jiang, S. B.
TI Using Large Language Models to Create Patient Centered Consent Forms
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3342
BP E612
EP E612
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
Z8 0
ZR 0
ZB 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302026
ER

PT J
AU Nielsen, Jacob P. S.
   Gronhoj, Christian
   Skov, Lone
   Gyldenlove, Mette
TI Usefulness of the large language model ChatGPT (GPT-4) as a diagnostic
   tool and information source in dermatology
SO JEADV CLINICAL PRACTICE
VL 3
IS 5
BP 1570
EP 1575
DI 10.1002/jvc2.459
EA JUN 2024
DT Article
PD DEC 2024
PY 2024
AB BackgroundThe field of artificial intelligence is rapidly evolving. As
   an easily accessible platform with vast user engagement, the Chat
   Generative Pre-Trained Transformer (ChatGPT) holds great promise in
   medicine, with the latest version, GPT-4, capable of analyzing clinical
   images.ObjectivesTo evaluate ChatGPT as a diagnostic tool and
   information source in clinical dermatology.MethodsA total of 15 clinical
   images were selected from the Danish web atlas, Danderm, depicting
   various common and rare skin conditions. The images were uploaded to
   ChatGPT version GPT-4, which was prompted with 'Please provide a
   description, a potential diagnosis, and treatment options for the
   following dermatological condition'. The generated responses were
   assessed by senior registrars in dermatology and consultant
   dermatologists in terms of accuracy, relevance, and depth (scale 1-5),
   and in addition, the image quality was rated (scale 0-10). Demographic
   and professional information about the respondents was
   registered.ResultsA total of 23 physicians participated in the study.
   The majority of the respondents were consultant dermatologists (83%),
   and 48% had more than 10 years of training. The overall image quality
   had a median rating of 10 out of 10 [interquartile range (IQR): 9-10].
   The overall median rating of the ChatGPT generated responses was 2 (IQR:
   1-4), while overall median ratings in terms of relevance, accuracy, and
   depth were 2 (IQR: 1-4), 3 (IQR: 2-4) and 2 (IQR: 1-3),
   respectively.ConclusionsDespite the advancements in ChatGPT, including
   newly added image processing capabilities, the chatbot demonstrated
   significant limitations in providing reliable and clinically useful
   responses to illustrative images of various dermatological conditions.
ZA 0
TC 1
ZR 0
ZB 0
Z8 0
ZS 0
Z9 1
DA 2024-06-08
UT WOS:001237597700001
ER

PT J
AU Silverman, Anna L.
   Sushil, Madhumita
   Bhasuran, Balu
   Ludwig, Dana
   Buchanan, James
   Racz, Rebecca
   Parakala, Mahalakshmi
   El-Kamary, Samer
   Ahima, Ohenewaa
   Belov, Artur
   Choi, Lauren
   Billings, Monisha
   Li, Yan
   Habal, Nadia
   Liu, Qi
   Tiwari, Jawahar
   Butte, Atul J.
   Rudrapatna, Vivek A.
TI Algorithmic Identification of Treatment-Emergent Adverse Events From
   Clinical Notes Using Large Language Models: A Pilot Study in
   Inflammatory Bowel Disease
SO CLINICAL PHARMACOLOGY & THERAPEUTICS
VL 115
IS 6
BP 1391
EP 1399
DI 10.1002/cpt.3226
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB Outpatient clinical notes are a rich source of information regarding
   drug safety. However, data in these notes are currently underutilized
   for pharmacovigilance due to methodological limitations in text mining.
   Large language models (LLMs) like Bidirectional Encoder Representations
   from Transformers (BERT) have shown progress in a range of natural
   language processing tasks but have not yet been evaluated on adverse
   event (AE) detection. We adapted a new clinical LLM, University of
   California - San Francisco (UCSF)-BERT, to identify serious AEs (SAEs)
   occurring after treatment with a non-steroid immunosuppressant for
   inflammatory bowel disease (IBD). We compared this model to other
   language models that have previously been applied to AE detection. We
   annotated 928 outpatient IBD notes corresponding to 928 individual
   patients with IBD for all SAE-associated hospitalizations occurring
   after treatment with a non-steroid immunosuppressant. These notes
   contained 703 SAEs in total, the most common of which was failure of
   intended efficacy. Out of eight candidate models, UCSF-BERT achieved the
   highest numerical performance on identifying drug-SAE pairs from this
   corpus (accuracy 88-92%, macro F1 61-68%), with 5-10% greater accuracy
   than previously published models. UCSF-BERT was significantly superior
   at identifying hospitalization events emergent to medication use (P <
   0.01). LLMs like UCSF-BERT achieve numerically superior accuracy on the
   challenging task of SAE detection from clinical notes compared with
   prior methods. Future work is needed to adapt this methodology to
   improve model performance and evaluation using multicenter data and
   newer architectures like Generative pre-trained transformer (GPT). Our
   findings support the potential value of using large language models to
   enhance pharmacovigilance.
Z8 0
ZB 0
ZR 0
ZA 0
ZS 0
TC 6
Z9 6
DA 2024-03-28
UT WOS:001181392200001
PM 38459719
ER

PT J
AU Cohen, Natalie D.
   Ho, Milan
   Mcintire, Donald
   Smith, Katherine
   Kho, Kimberly A.
TI A comparative analysis of generative artificial intelligence responses
   from leading chatbots to questions about endometriosis
SO AJOG GLOBAL REPORTS
VL 5
IS 1
AR 100405
DI 10.1016/j.xagr.2024.100405
EA DEC 2024
DT Article
PD FEB 2025
PY 2025
AB INTRODUCTION: The use of generative artificial intelligence (AI) has
   begun to permeate most industries, including medicine, and patients will
   inevitably start using these large language model (LLM) chatbots as a
   modality for education. As healthcare information technology evolves, it
   is imperative to evaluate chatbots and the accuracy of the information
   they provide to patients and to determine if there is variability
   between them. OBJECTIVE: This study aimed to evaluate the accuracy and
   comprehensiveness of three chatbots in addressing questions related to
   endometriosis and determine the level of variability between them. STUDY
   DESIGN: Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic),
   and Bard (Google) were asked to generate answers to 10 commonly asked
   questions about endometriosis. The responses were qualitatively compared
   to current guidelines and expert opinion on endometriosis and rated on a
   scale by nine gynecologists. The grading scale included the following:
   (1) Completely incorrect, (2) mostly incorrect and some correct, (3)
   mostly correct and some incorrect, (4) correct but inadequate, (5)
   correct and comprehensive. Final scores were averaged between the nine
   reviewers. Kendall's Wand the related chi-square test were used to
   evaluate the reviewers' strength of agreement in ranking the LLMs'
   responses for each item. RESULTS: Average scores for the 10 answers
   amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7,
   respectively. Two questions showed significant disagreement between the
   nine reviewers. There were no questions the models could answer
   comprehensively or correctly across the reviewers. The model most
   associated with comprehensive and correct responses was ChatGPT.
   Chatbots showed an improved ability to accurately answer questions about
   symptoms and pathophysiology over treatment and risk of recurrence.
   CONCLUSION: The analysis of LLMs revealed that, on average, they mainly
   provided correct but inadequate responses to commonly asked patient
   questions about endometriosis. While chatbot responses can serve as
   valuable supplements to information provided by licensed medical
   professionals, it is crucial to maintain a thorough ongoing evaluation
   process for outputs to provide the most comprehensive and accurate
   information to patients. Further research into this technology and its
   role in patient education and treatment is crucial as generative AI
   becomes more embedded in the medical field.
ZA 0
Z8 0
TC 1
ZS 0
ZB 0
ZR 0
Z9 1
DA 2025-05-06
UT WOS:001476609200001
PM 39810943
ER

PT J
AU Zhang, Yapei
   Shi, Min
   Liebman, Daniel L.
   Barna, Laura
   Pasquale, Louis R.
   Elze, Tobias
   Friedman, David S.
   Boland, Michael V.
   Shen, Lucy Q.
   Wang, Mengyu
TI Evaluation of the accuracy of AIgenerated clinical summaries from
   Glaucoma outpatient visits.
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1641
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
DA 2024-12-01
UT WOS:001312227704269
ER

PT J
AU Li, Yiming
   Zhao, Jeff
   Li, Manqi
   Dang, Yifang
   Yu, Evan
   Li, Jianfu
   Sun, Zenan
   Hussein, Usama
   Wen, Jianguo
   Abdelhameed, Ahmed M.
   Mai, Junhua
   Li, Shenduo
   Yu, Yue
   Hu, Xinyue
   Yang, Daowei
   Feng, Jingna
   Li, Zehan
   He, Jianping
   Tao, Wei
   Duan, Tiehang
   Lou, Yanyan
   Li, Fang
   Tao, Cui
TI RefAI: a GPT-powered retrieval-augmented generative tool for biomedical
   literature recommendation and summarization
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 9
BP 2030
EP 2039
DI 10.1093/jamia/ocae129
EA JUN 2024
DT Article
PD JUN 10 2024
PY 2024
AB Objectives: Precise literature recommendation and summarization are
   crucial for biomedical professionals. While the latest iteration of
   generative pretrained transformer (GPT) incorporates 2 distinct
   modes-real-time search and pretrained model utilization-it encounters
   challenges in dealing with these tasks. Specifically, the real-time
   search can pinpoint some relevant articles but occasionally provides
   fabricated papers, whereas the pretrained model excels in generating
   well-structured summaries but struggles to cite specific sources. In
   response, this study introduces RefAI, an innovative retrieval-augmented
   generative tool designed to synergize the strengths of large language
   models (LLMs) while overcoming their limitations. Materials and Methods:
   RefAI utilized PubMed for systematic literature retrieval, employed a
   novel multivariable algorithm for article recommendation, and leveraged
   GPT-4 turbo for summarization. Ten queries under 2 prevalent topics
   ("cancer immunotherapy and target therapy" and "LLMs in medicine") were
   chosen as use cases and 3 established counterparts (ChatGPT-4,
   ScholarAI, and Gemini) as our baselines. The evaluation was conducted by
   10 domain experts through standard statistical analyses for performance
   comparison. Results: The overall performance of RefAI surpassed that of
   the baselines across 5 evaluated dimensions-relevance and quality for
   literature recommendation, accuracy, comprehensiveness, and reference
   integration for summarization, with the majority exhibiting
   statistically significant improvements (P-values <.05). Discussion:
   RefAI demonstrated substantial improvements in literature recommendation
   and summarization over existing tools, addressing issues like fabricated
   papers, metadata inaccuracies, restricted recommendations, and poor
   reference integration. Conclusion: By augmenting LLM with external
   resources and a novel ranking algorithm, RefAI is uniquely capable of
   recommending high-quality literature and generating well-structured
   summaries, holding the potential to meet the critical needs of
   biomedical professionals in navigating and synthesizing vast amounts of
   scientific literature.
Z8 1
ZA 0
ZS 0
ZR 0
ZB 3
TC 13
Z9 14
DA 2024-06-17
UT WOS:001243328800001
PM 38857454
ER

PT J
AU Han, B.
   Chen, Y.
   Buyyounouski, M. K.
   Gensheimer, M. F.
   Xing, L.
TI RadAlonc: Enhancing Decision-Making in Radiation Oncology with a
   GPT-4-Based Prompt-Driven Large Language Model
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 2297
BP E134
EP E134
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892300029
ER

PT J
AU Fu, Sidney W.
   Tang, Cong
   Tan, Xiaohui
   Srivastava, Sudhir
TI Liquid biopsy for early cancer detection: technological revolutions and
   clinical dilemma
SO EXPERT REVIEW OF MOLECULAR DIAGNOSTICS
VL 24
IS 10
BP 937
EP 955
DI 10.1080/14737159.2024.2408744
EA OCT 2024
DT Review
PD OCT 2 2024
PY 2024
AB IntroductionLiquid biopsy is an innovative advancement in oncology,
   offering a noninvasive method for early cancer detection and monitoring
   by analyzing circulating tumor cells, DNA, RNA, and other biomarkers in
   bodily fluids. This technique has the potential to revolutionize
   precision oncology by providing real-time analysis of tumor dynamics,
   enabling early detection, monitoring treatment responses, and tailoring
   personalized therapies based on the molecular profiles of individual
   patients.Areas coveredIn this review, the authors discuss current
   methodologies, technological challenges, and clinical applications of
   liquid biopsy. This includes advancements in detecting minimal residual
   disease, tracking tumor evolution, and combining liquid biopsy with
   other diagnostic modalities for precision oncology. Key areas explored
   are the sensitivity, specificity, and integration of multi-omics, AI,
   ML, and LLM technologies.Expert opinionLiquid biopsy holds great
   potential to revolutionize cancer care through early detection and
   personalized treatment strategies. However, its success depends on
   overcoming technological and clinical hurdles, such as ensuring high
   sensitivity and specificity, interpreting results amidst tumor
   heterogeneity, and making tests accessible and affordable. Continued
   innovation and collaboration are crucial to fully realize the potential
   of liquid biopsy in improving early cancer detection, treatment, and
   monitoring.
ZR 0
ZA 0
Z8 0
ZB 2
TC 6
ZS 0
Z9 6
DA 2024-10-09
UT WOS:001325602700001
PM 39360748
ER

PT J
AU Bentzen, S. M.
TI Artificial Intelligence in Health Care: A Rallying Cry for Critical
   Clinical Research and Ethical Thinking
SO CLINICAL ONCOLOGY
VL 41
AR 103798
DI 10.1016/j.clon.2025.103798
EA APR 2025
DT Article
PD MAY 2025
PY 2025
AB Artificial intelligence (AI) will impact a large proportion of jobs in
   the short to medium term, especially in the developed countries. The
   consequences will be felt across many sectors including health care, a
   critical sector for implementation of AI tools because glitches in
   algorithms or biases in training datasets may lead to suboptimal
   treatment that may negatively affect the health of an individual. The
   stakes are obviously higher in case of potentially life-threatening
   diseases such as cancer and therapies with a potential for causing
   severe or even fatal adverse events. Over the last two decades, much of
   the research on AI in health care has focussed on diagnostic radiology
   and digital pathology, but a solid body of research is emerging on AI
   tools in the radiation oncology workflow. Many of these applications are
   relatively uncontroversial, although there is still a lack of evidence
   regarding effectiveness rather than efficiency, and-the ultimate
   bar-evidence of clinical utility. Proponents of AI will argue that these
   algorithms should be implemented with robust human supervision. One
   challenge here is the deskilling effect associated with new
   technologies. We will become increasingly dependent on the AI tools over
   time, and we will become less capable of assessing the quality of the AI
   output. Much of this research appears almost old-fashioned in view of
   the rapid advances in Generative artificial intelligence (GenAI). GenAI
   can draw from multiple types of data and produce output that is
   personalised and appears relevant in the given context. Especially the
   rapid progress in large language models (LLMs) has opened a wide field
   of potential applications that were out of bounds just a few years ago.
   One LLM, Generative Pre-trained Transformer 4 (GPT-4), has been made
   widely accessible to end-users as ChatGPT-4, which passed a rigorous
   Turing test in a recent study. In this viewpoint, I argue for the
   necessity of independent academic research to establish evidence-based
   applications of AI in medicine. Algorithmic medicine is an intervention
   similar to a new drug or a new medical device. We should be especially
   concerned about under-represented minorities and rare/atypical clinical
   cases that may drown in the petabyte-sized training sets. A huge
   educational push is needed to ensure that the end-users of AI in health
   care understand the strengths and weaknesses of algorithmic medicine.
   Finally, we need to address the ethical boundaries for where and when
   GenAI can replace humans in the relation between patients and healthcare
   providers. (c) 2025 The Royal College of Radiologists. Published by
   Elsevier Ltd. All rights are reserved, including those for text and data
   mining, AI training, and similar technologies.
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2025-04-17
UT WOS:001463027500001
PM 40184826
ER

PT J
AU Li, Xue
   Yuan, Ye
   Yang, Yang
   Guan, Yi
   Wang, Haotian
   Jiang, Jingchi
   Shi, Huaizhang
   Liu, Xiguang
TI Quality-Controllable automatic construction method of Chinese knowledge
   graph for medical decision-making applications
SO INFORMATION PROCESSING & MANAGEMENT
VL 62
IS 4
AR 104148
DI 10.1016/j.ipm.2025.104148
EA MAR 2025
DT Article
PD JUL 2025
PY 2025
AB Medical Knowledge Graphs (KGs) store complex medical knowledge in a
   structured manner, increasingly becoming the foundation of medical
   artificial intelligence. They provide interpretable evidence for disease
   diagnosis and treatment, and enhance the accuracy and interpretability
   of medical information in large language models (LLMs), thus mitigating
   the hallucination issues. However, existing medical KGs lack diverse
   knowledge types, sufficient coverage, fine granularity, and high
   quality, resulting in low utilization rates. To address these issues,
   this paper, under the guidance of medical professionals, proposes
   guidelines and automated methods for constructing a Chinese medical KG,
   drawing from existing experience in building KGs and the requirements of
   medical decision systems. The construction principles include (1)
   universality and personalization, (2) comprehensiveness and granularity,
   (3) knowledge quality control. Furthermore, the automated construction
   method integrates a chain of thought-based knowledge mining approach and
   an axiom logic-based quality control module, which improves the
   scalability of mining and the quality of the knowledge. Based on these,
   a Chinese medical KG named WiMedKG has been developed. It meets the
   established construction guidelines by: (1) including both commonsense
   and experiential medical knowledge, (2) comprehensively covering 111
   departments with content ranging from clinical practice to preventive
   medicine and rehabilitation treatments. The granularity of the knowledge
   is detailed, featuring 29 entity types, 128 refined relationship types,
   and 40 attribute types, comprising a total of 367,108 entities,
   3,176,389 relational triples, and 1,021,966 attribute triples. (3) The
   knowledge has been validated and completed, receiving an evaluation
   score of 90.66% from medical professionals, which demonstrates the
   reliability of the quality-controlled automatic KG construction method.
   Finally, we constructed medical LLM WiMedLLM enhanced by WiMedKG.
   Experimental results on the medical test dataset show an average
   performance improvement of 1.51% after KG enhancement, demonstrating the
   necessity of KG construction and the effectiveness of the automatic
   construction method. The data and system resources can be found on our
   page: https://github.com/lx-hit/WiMedKG.
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-04-06
UT WOS:001455489300001
ER

PT J
AU Shaheen, Abdulla
   Afflitto, Gabriele Gallo
   Swaminathan, Swarup S.
TI ChatGPT-Assisted Classification fi cation of Postoperative Bleeding
   Following Microinvasive Glaucoma Surgery Using Electronic Health Record
   Data
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100602
DI 10.1016/j.xops.2024.100602
EA SEP 2024
DT Article
PD FEB 2025
PY 2025
AB Purpose: To evaluate the performance of a large language model (LLM) in
   classifying electronic health record (EHR) text, and to use this
   classification to evaluate the type and resolution of hemorrhagic events
   (HEs) after microinvasive glaucoma surgery (MIGS). Design: Retrospective
   cohort study. Participants: Eyes from the Bascom Palmer Glaucoma
   Repository. Methods: Eyes that underwent MIGS between July 1, 2014 and
   February 1, 2022 were analyzed. Chat Generative Pre-trained Transformer
   (ChatGPT) was used to classify deidentified EHR anterior chamber
   examination text into HE categories (no hyphema, microhyphema, clot, and
   hyphema). Agreement between classifications by ChatGPT and a glaucoma
   specialist was evaluated using Cohen's Kappa and precision-recall (PR)
   curve. Time to resolution of HEs was assessed using Cox
   proportional-hazards models. Goniotomy HE resolution was evaluated by
   degree of angle treatment (90 degrees-179 degrees,180 degrees-269
   degrees, 270 degrees-360 degrees). degrees-360 degrees ). Logistic
   regression was used to identify HE risk factors. Main Outcome Measures:
   Accuracy of ChatGPT HE classification and incidence and resolution of
   HEs. Results: The study included 434 goniotomy eyes (368 patients) and
   528 Schlemm's canal stent (SCS) eyes (390 patients). Chat Generative
   Pre-trained Transformer facilitated excellent HE classification (Cohen's
   kappa 0.93, area under PR curve 0.968). Using ChatGPT classifications,
   at postoperative day 1, HEs occurred in 67.8% of goniotomy and 25.2% of
   SCS eyes (P < 0.001). The 270 degrees degrees to 360 degrees degrees
   goniotomy group had the highest HE rate (84.0%, P < 0.001). At
   postoperative week 1, HEs were observed in 43.4% and 11.3% of goniotomy
   and SCS eyes, respectively (P < 0.001). By postoperative month 1, HE
   rates were 13.3% and 1.3% among goniotomy and SCS eyes, respectively (P
   < 0.001). Time to HE resolution differed between the goniotomy angle
   groups (log-rank P = 0.034); median time to resolution was 10, 10, and
   15 days for the 90 degrees degrees to 179 degrees, 180 degrees to 269
   degrees, and 270 degrees to 360 degrees groups, respectively. Risk
   factor analysis demonstrated greater goniotomy angle was the only
   significant predictor of HEs (odds ratio for 270 degrees-360 degrees:
   360 degrees : 4.08, P < 0.001). Conclusions: Large language models can
   be effectively used to classify longitudinal EHR free-text examination
   data with high accuracy, highlighting a promising direction for future
   LLM-assisted research and clinical decision support. Hemorrhagic events
   are relatively common self-resolving complications that occur more often
   in goniotomy cases and with larger goniotomy treatments. Time to HE
   resolution differs significantly between goniotomy groups. Financial
   Disclosure(s):Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100602<feminine ordinal indicator>2024 by the American
   Academy of Ophthalmology. This is an open access article under the CC
   BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
DA 2024-10-05
UT WOS:001321792000001
PM 39380881
ER

PT J
AU Arnesen, Kjell-Erik
   Phung, Ann Vinh
   Randsborg, Karoline
   Mork, Irene
   Thorvall, Marlene
   Langslet, Gisle
   Svilaas, Arne
   Wium, Cecilie
   Ose, Leiv
   Retterstol, Kjetil
TI Risk of Recurrent Coronary Events in Patients With Familial
   Hypercholesterolemia; A 10-Years Prospective Study
SO FRONTIERS IN PHARMACOLOGY
VL 11
AR 560958
DI 10.3389/fphar.2020.560958
DT Article
PD MAR 2 2021
PY 2021
AB Background and Aim: Real world evidence on long term treatment of
   patients with familial hypercholesterolemia (FH) is important. We
   studied the effects of intensive lipid lowering medication (LLM) and
   optimized lifestyle in the study TTTFH-Treat To Target FH.
   Materials and Methods: Adults with a first known total cholesterol of
   mean (95% CI) 9.8 mmol/L (9.5, 10.1) were included consecutively in
   their routine consultation during 2006. Of the patients 86.4% had a
   pathogenic FH-mutation and the remaining were clinically diagnosed. We
   included 357 patients and 279 met for follow-up after median 10.0 (min
   8.1, max 12.8) years.
   Results: Mean (95% CI) low density lipoprotein (LDL-C) was reduced from
   3.9 (3.8, 4.1) to 3.0 (2.9, 3.2). More men than women used high
   intensity statin treatment, 85.2 and 60.8%, respectively. Women (n =
   129) had higher LDL-C; 3.3 mmol/L (3.0, 3.5), than men; (n = 144) 2.8
   mmol/L (2.6, 3.0), p = 0.004. Add-on PCSK9 inhibitors (n = 25) reduced
   mean LDL-C to 2.0 (1.4, 2.6) mmol/L. At enrollment 57 patients (20.4%)
   had established atherosclerotic cardiovascular disease (ASCVD), and 46
   (80.4%) of them experienced a new event during the study period.
   Similarly, 222 (79.6%) patients had no detectable ASCVD at enrollment,
   and 29 of them (13.1%) experienced a first-time event during the study
   period.
   Conclusion: A mean LDL-C of 3.0 mmol/L was achievable in FH, treated
   intensively at a specialized clinic with few users of PCSK9 inhibitors.
   LDL-C was higher (0.5 mmol/L) in women than in men. In patients with
   ASCVD at enrollment, most (80.7%) experienced a new ASCVD event in the
   study period. The FH patients in primary prevention had more moderate CV
   risk, 13% in ten years.
Z8 0
ZA 0
ZB 2
ZR 0
TC 3
ZS 0
Z9 3
DA 2021-03-21
UT WOS:000629245000001
PM 33737874
ER

PT J
AU Gasparovic, Michal
   Jungova, Petra
   Tomasik, Juraj
   Mrinakova, Bela
   Hirjak, Dusan
   Timkova, Silvia
   Danisovic, Lubos
   Janek, Marian
   Baca, Lubos
   Peciar, Peter
   Thurzo, Andrej
TI Evolving Strategies and Materials for Scaffold Development in
   Regenerative Dentistry
SO APPLIED SCIENCES-BASEL
VL 14
IS 6
AR 2270
DI 10.3390/app14062270
DT Review
PD MAR 2024
PY 2024
AB Regenerative dentistry has experienced remarkable advancement in recent
   years. The interdisciplinary discoveries in stem cell applications and
   scaffold design and fabrication, including novel techniques and
   biomaterials, have demonstrated immense potential in the field of tissue
   engineering and regenerative therapy. Scaffolds play a pivotal role in
   regenerative dentistry by facilitating tissue regeneration and restoring
   damaged or missing dental structures. These biocompatible and biomimetic
   structures serve as a temporary framework for cells to adhere,
   proliferate, and differentiate into functional tissues. This review
   provides a concise overview of the evolution of scaffold strategies in
   regenerative dentistry, along with a novel analysis (Bard v2.0 based on
   the Gemini neural network architecture) of the most commonly employed
   materials used for scaffold fabrication during the last 10 years.
   Additionally, it delves into bioprinting, stem cell colonization
   techniques and procedures, and outlines the prospects of regenerating a
   whole tooth in the future. Moreover, it discusses the optimal conditions
   for maximizing mesenchymal stem cell utilization and optimizing scaffold
   design and personalization through precise 3D bioprinting. This review
   highlights the recent advancements in scaffold development, particularly
   with the advent of 3D bioprinting technologies, and is based on a
   comprehensive literature search of the most influential recent
   publications in this field.
TC 16
Z8 0
ZB 1
ZR 0
ZA 0
ZS 0
Z9 16
DA 2024-04-03
UT WOS:001191807800001
ER

PT J
AU Rajabian, Arezoo
   McCloskey, Alice P.
   Jamialahmadi, Tannaz
   Moallem, Seyed Adel
   Sahebkar, Amirhossein
TI A review on the efficacy and safety of lipid-lowering drugs in
   neurodegenerative disease
SO REVIEWS IN THE NEUROSCIENCES
VL 34
IS 7
BP 801
EP 824
DI 10.1515/revneuro-2023-0005
EA APR 2023
DT Review
PD OCT 26 2023
PY 2023
AB There is a train of thought that lipid therapies may delay or limit the
   impact of neuronal loss and poor patient outcomes of neurodegenerative
   diseases (NDDs). A variety of medicines including lipid lowering
   modifiers (LLMs) are prescribed in NDDs. This paper summarizes the
   findings of clinical and observational trials including systematic
   reviews and meta-analyses relating to LLM use in NDDs published in the
   last 15 years thus providing an up-to-date evidence pool. Three
   databases were searched PubMed, CINAHL, and Web of Science using key
   terms relating to the review question. The findings confirm the benefit
   of LLMs in hyperlipidemic patients with or without cardiovascular risk
   factors due to their pleotropic effects. In NDDs LLMs are proposed to
   delay disease onset and slow the rate of progression. Clinical
   observations show that LLMs protect neurons from a-synuclein, tau, and
   Ab toxicity, activation of inflammatory processes, and ultimately
   oxidative injury. Moreover, current meta-analyses and clinical trials
   indicated low rates of adverse events with LLMs when used as
   monotherapy. LLMs appear to have favorable safety and tolerability
   profiles with few patients stopping treatment due to severe adverse
   effects. Our collated evidence thus concludes that LLMs have a role in
   NDDs but further work is needed to understand the exact mechanism of
   action and reach more robust conclusions on where and when it is
   appropriate to use LLMs in NDDs in the clinic.
ZR 0
TC 2
ZB 1
Z8 0
ZA 0
ZS 0
Z9 2
DA 2023-05-04
UT WOS:000967648400001
PM 37036894
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT J
AU Feng, Jia-Li
   Qin, Xiwen
TI Lipid-lowering medication use and cancer-specific survival among
   endometrial or lung cancer patients: an Australian nationwide cohort
   study
SO EUROPEAN JOURNAL OF CLINICAL PHARMACOLOGY
VL 77
IS 3
BP 399
EP 407
DI 10.1007/s00228-020-03009-5
EA OCT 2020
DT Article
PD MAR 2021
PY 2021
AB Purpose Inconsistent results of lipid-lowering medications (LLMs) on
   improved cancer survival need more investigations. We tested the
   hypothesis that adherence to the drug would be associated with a lower
   cancer-specific mortality in a homogeneous population who has ever used
   the drug. Methods Utilising data from the Australian Cancer database,
   linked to the Pharmaceutical Benefits Scheme data and the National Death
   Index, we identified two separate cohorts of 4519 and 3083 women
   patients with newly diagnosed endometrial and lung cancer respectively
   between 2003 and 2013. Adherence to this drug was calculated by
   proportion of days covered. Cox regression models with time-varying
   covariates were used to estimate the multivariable-adjusted
   cause-specific hazard ratios (HRs) and 95% confidence intervals (CIs)
   for the association of adherence to LLMs, statins, lipophilic and
   hydrophilic statins, and cancer-specific mortality. Results Each 10%
   increase in 1-year adherence to LLMs reduced cancer-specific mortality
   among women with endometrial cancer (adjusted HR=0.93, 95% CI 0.90-0.96)
   or lung cancer (adjusted HR=0.95, 95% CI 0.93-0.97). The inverse
   associations remained unchanged in different subgroup analyses. The
   reductions in lung cancer mortality were not apparent for women who
   adhered to lipophilic statins albeit better endometrial cancer survival
   appeared in the lipophilic statin group and borderline statistical
   improvement in the hydrophilic statin group. Conclusions Among LLM
   users, adherence to this drug is inversely associated with reduced
   cancer-specific mortality. Together with previous evidence, randomised
   controlled trials are called for to confirm whether LLMs could be
   considered as an adjuvant treatment to improve prognosis.
TC 2
ZR 0
Z8 1
ZA 0
ZS 0
ZB 0
Z9 3
DA 2020-10-27
UT WOS:000577981300001
PM 33030570
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Yang, Z.
   Kazemimoghadam, M.
   Wang, L.
   Szalkowski, G. A.
   Chuang, C. F.
   Liu, L.
   Soltys, S. G.
   Pollom, E.
   Rahimy, E.
   Jiang, H.
   Park, D.
   Persad, A.
   Hori, Y.
   Fu, J.
   Romero, I. O.
   Zalavari, L.
   Chen, M.
   Lu, W.
   Gu, X.
TI A Deep Learning-Driven Framework for Large Language Model -Assisted
   Automatic Target Volume Localization and Delineation for Enhancing
   Spinal Metastases Stereotactic Body Radiotherapy Workflow
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 195
BP S61
EP S62
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302564
ER

PT J
AU Ozkan, Ecem
   Tekin, Aysun
   Ozkan, Mahmut Can
   Cabrera, Daniel
   Niven, Alexander
   Dong, Yue
TI Global Health care Professionals' Perceptions of Large Language Model
   Use In Practice: Cross-Sectional Survey Study
SO JMIR MEDICAL EDUCATION
VL 11
AR e58801
DI 10.2196/58801
DT Article
PD 2025
PY 2025
AB Background: ChatGPT is a large language model-based chatbot developed by
   OpenAI. ChatGPT has many potential applications to health care,
   including enhanced diagnostic accuracy and efficiency, improved
   treatment planning, and better patient outcomes. However, health care
   professionals' perceptions of ChatGPT and similar artificial
   intelligence tools are not well known. Understanding these attitudes is
   important to inform the best approaches to exploring their use in
   medicine. Objective: Our aim was to evaluate the health care
   professionals' awareness and perceptions regarding potential
   applications of ChatGPT in the medical field, including potential
   benefits and challenges of adoption. Methods: We designed a 33-question
   online survey that was distributed among health care professionals via
   targeted emails and professional Twitter and LinkedIn accounts. The
   survey included a range of questions to define respondents' demographic
   characteristics, familiarity with ChatGPT, perceptions of this tool's
   usefulness and reliability, and opinions on its potential to improve
   patient care, research, and education efforts. Results: One hundred and
   fifteen health care professionals from 21 countries responded to the
   survey, including physicians, nurses, researchers, and educators. Of
   these, 101 (87.8%) had heard of ChatGPT, mainly from peers, social
   media, and news, and 77 (76.2%) had used ChatGPT at least once.
   Participants found ChatGPT to be helpful for writing manuscripts (n=31,
   45.6%), emails (n=25, 36.8%), and grants (n=12, 17.6%); accessing the
   latest research and evidence-based guidelines (n=21, 30.9%); providing
   suggestions on diagnosis or treatment (n=15, 22.1%); and improving
   patient communication (n=12, 17.6%). Respondents also felt that the
   ability of ChatGPT to access and summarize research articles (n=22,
   46.8%), provide quick answers to clinical questions (n=15, 31.9%), and
   generate patient education materials (n=10, 21.3%) was helpful. However,
   there are concerns regarding the use of ChatGPT, for example, the
   accuracy of responses (n=14, 29.8%), limited applicability in specific
   practices (n=18, 38.3%), and legal and ethical considerations (n=6,
   12.8%), mainly related to plagiarism or copyright violations.
   Participants stated that safety protocols such as data encryption (n=63,
   62.4%) and access control (n=52, 51.5%) could assist in ensuring patient
   privacy and data security. Conclusions: Our findings show that ChatGPT
   use is widespread among health care professionals in daily clinical,
   research, and educational activities. The majority of our participants
   found ChatGPT to be useful; however, there are concerns about patient
   privacy, data security, and its legal and ethical issues as well as the
   accuracy of its information. Further studies are required to understand
   the impact of ChatGPT and other large language models on clinical,
   educational, and research outcomes, and the concerns regarding its use
   must be addressed systematically and through appropriate methods.
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-23
UT WOS:001490640700001
PM 40354644
ER

PT J
AU Simsek, Cem
   Tinaz, Berk
   Erol, Hasan S.
   Demir, Hikmet
   Atay, Beyza
   Yazarkan, Yigit
   Aydinli, Hakan
   Bozdogan, Ali B.
   Toruner, Merih D.
   Schuster, Kimberly F.
   Ryou, Marvin
   Jirapinyo, Pichamol
   Thompson, Christopher C.
TI GASTROENTEROLOGY SPECIFIC AI MODEL OUTPERFORMS ATTENDING PHYSICIAN
   CLINICAL NOTES IN A REAL-WORLD DATA EVALUATION
SO GASTROENTEROLOGY
VL 166
IS 5
MA 315
BP S68
EP S69
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
Z8 0
TC 1
ZR 0
ZB 0
ZS 0
ZA 0
Z9 1
DA 2024-10-30
UT WOS:001282837700178
ER

PT J
AU Rasool, Abdur
   Aslam, Saba
   Hussain, Naeem
   Imtiaz, Sharjeel
   Riaz, Waqar
TI nBERT: Harnessing NLP for Emotion Recognition in Psychotherapy to
   Transform Mental Health Care
SO INFORMATION
VL 16
IS 4
AR 301
DI 10.3390/info16040301
DT Article
PD APR 9 2025
PY 2025
AB The rising prevalence of mental health disorders, particularly
   depression, highlights the need for improved approaches in therapeutic
   interventions. Traditional psychotherapy relies on subjective
   assessments, which can vary across therapists and sessions, making it
   challenging to track emotional progression and therapy effectiveness
   objectively. Leveraging the advancements in Natural Language Processing
   (NLP) and domain-specific Large Language Models (LLMs), this study
   introduces nBERT, a fine-tuned Bidirectional Encoder Representations
   from the Transformers (BERT) model integrated with the NRC Emotion
   Lexicon, to elevate emotion recognition in psychotherapy transcripts.
   The goal of this study is to provide a computational framework that aids
   in identifying emotional patterns, tracking patient-therapist emotional
   alignment, and assessing therapy outcomes. Addressing the challenge of
   emotion classification in text-based therapy sessions, where non-verbal
   cues are absent, nBERT demonstrates its ability to extract nuanced
   emotional insights from unstructured textual data, providing a
   data-driven approach to enhance mental health assessments. Trained on a
   dataset of 2021 psychotherapy transcripts, the model achieves an average
   precision of 91.53%, significantly outperforming baseline models. This
   capability not only improves diagnostic accuracy but also supports the
   customization of therapeutic strategies. By automating the
   interpretation of complex emotional dynamics in psychotherapy, nBERT
   exemplifies the transformative potential of NLP and LLMs in
   revolutionizing mental health care. Beyond psychotherapy, the framework
   enables broader LLM applications in the life sciences, including
   personalized medicine and precision healthcare.
TC 0
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
Z9 0
DA 2025-05-04
UT WOS:001475220100001
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Jinia, A. J.
   Chapman, K. L.
   Liu, S.
   Della Biancia, C.
   Li, A.
   Moran, J. M.
TI Challenges in Developing an Al -Based Analysis System for Incident
   Learning
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3198
BP E542
EP E542
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
ZS 0
Z8 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2024-12-16
UT WOS:001325892301523
ER

PT J
AU Jang, B. S.
   Alcorn, S. R.
   McNutt, T. R.
   Ehsan, U.
TI Hype or Reality: Utility of Large Language Models in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3382
BP E629
EP E630
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
Z8 0
ZR 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302063
ER

PT J
AU TOKEDE, OLUWABUNMI 
TI FullMouth: Enhancing Dental Clinical Data and Reducing Disparities
   through Innovative ML Approaches.
DT Awarded Grant
PD Sep 01 2024
PY 2024
AB Project Abstract/SummaryThe vast amount of health data created in the
   United States may hold the key to understanding disease,improving
   quality, and lowering healthcare costs. Electronic health records
   (EHRs), digital collections of patienthealthcare events and
   observations, are now ubiquitous in medicine and critical to healthcare
   delivery,operations, and research. EHR data is often classified as
   structured or unstructured. Structured EHR datainclude standardized
   diagnoses, medications, and laboratory values in fixed numerical or
   categorical fields. Forstructured data, challenges such as missing,
   incomplete, and inconsistent data are very prevalent.Unstructured data,
   in contrast, refer to free-form text written by healthcare providers,
   such as clinical notes anddischarge summaries. Dental care providers
   often write detailed findings, diagnoses, treatment plans andprognostic
   factors in free-text format for clinical care purposes. While this
   information is easily accessible duringpatient care, extracting it for
   generating meaningful insights for secondary analysis can be
   challenging. Utilizingthese records requires manual review by domain
   experts, which can be time-consuming and costly, particularlywhen
   dealing with a large number of patient records. Unstructured data
   represents about 60% of total EHR data.Recently, Large Language Models
   (LLMs) and newer deep learning approaches to Natural Language
   Processing(NLP) have made considerable advances, outperforming
   traditional statistical and rule-based systems on avariety of tasks.To
   fully realize the promise of health information technology in dentistry,
   it is important to address datamissingness and disparity in missingness.
   Through a periodontal use-case, this proposal will tackle the
   challengeof missing structured, and ‘technically’ inaccessible,
   unstructured clinical data. Periodontal (advanced gumdisease) problems
   are very pervasive, and unlike caries (whose prevalence has steadily
   declined over the pastfour decades), disease burden and tooth loss
   secondary to periodontal disease remain intractable. In preliminarywork
   at two dental institutions, we observed that most patients seen for a
   comprehensive oral evaluation hadmissing or incomplete documentation
   with respect to clinical periodontal indices/diagnosis, demographic,
   andhealth-related behavior information – all of which are critical in
   diagnosing and treating periodontal disease. Thissignificantly limits
   our ability to learn and improve. Aim 1 will focus on using LLM-based
   NLP approaches for theconversion of unstructured note entries into
   structured and machine-readable information. In Aim 2, we will
   useimputation techniques to fill in missing structured clinical data
   entries. Aim 3 will then evaluate the impact ofreduction in clinical
   data missingness for both clinical and research applications. This work
   builds on our priorwork in developing the BigMouth Dental Data
   Repository (which contains regularly updated structured data on4.6
   million patients). We will be supported by the collective strength of
   the 11 core BigMouth, and other allieddental institutions that currently
   share and/or contribute data to the repository.
TC 0
ZA 0
Z8 0
ZR 0
ZS 0
ZB 0
Z9 0
G1 11137246; 1R56DE034086-01; R56DE034086
DA 2024-09-29
UT GRANTS:17810133
ER

PT J
AU Toiv, Avi
   Saleh, Zachary
   Alsheik, Eva
   Venkat, Deepak
   Nandi, Neilanjan
   Zuchelli, Tobias
TI STARTING THE CONVERSATION: THE RELIABILITY OF ARTIFICIAL INTELLIGENCE
   GENERATED MEDICAL INFORMATION IN GASTROENTEROLOGY
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1972
BP S887
EP S887
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZR 0
ZB 0
ZS 0
ZA 0
Z8 0
TC 0
Z9 0
DA 2024-10-30
UT WOS:001282837703473
ER

PT J
AU Giannuzzi, Federico
   Carla, Matteo Mario
   Hu, Lorenzo
   Cestrone, Valentina
   Caputo, Carmela Grazia
   Sammarco, Maria Grazia
   Savino, Gustavo
   Rizzo, Stanislao
   Blasi, Maria Antonietta
   Pagliara, Monica Maria
TI Artificial intelligence with ChatGPT 4: a large language model in
   support of ocular oncology cases
SO INTERNATIONAL OPHTHALMOLOGY
VL 45
IS 1
AR 59
DI 10.1007/s10792-024-03399-w
DT Article
PD FEB 7 2025
PY 2025
AB PurposeTo evaluate ChatGPT's ability to analyze comprehensive case
   descriptions of patients with uveal melanoma and provide recommendations
   for the most appropriate management.DesignRetrospective analysis of
   ocular oncology patients' medical records.Subjects.Forty patients
   treated for uveal melanoma between May 2019 and October
   2023.DesignRetrospective analysis of ocular oncology patients' medical
   records.Subjects.Forty patients treated for uveal melanoma between May
   2019 and October 2023.DesignRetrospective analysis of ocular oncology
   patients' medical records.Subjects.Forty patients treated for uveal
   melanoma between May 2019 and October 2023.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.MethodsWe uploaded each case description into the ChatGPT
   interface (version 4.0) and asked the model to provide realistic
   treatment options by asking the question, "What type of treatment do you
   recommend?" The accuracy of decisions produced by ChatGPT was compared
   to those recorded in patients' files and the treatment recommendations
   provided by three ocular oncologists, each with more than 10 years of
   experience.Main outcome measures.The primary objective of this research
   was to assess the accuracy of ChatGPT replies in ocular oncology cases,
   analyzing its competence in both straightforward and intricate
   situations. Our secondary purpose was to assess the concordance between
   the responses of ChatGPT and those of ocular oncology specialists when
   faced with analogous clinical scenarios.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.ResultsChatGPT's surgical choices matched those in patients'
   files in 55% of cases (22 out of 40). ChatGPT options were agreed upon
   by 50%, 55%, and 57% of the three ocular oncology specialists. The
   investigation revealed significant differences between ChatGPT's
   responses and those of the three cancer specialists when compared to
   patients' files (p = 0.003, p = 0.001, and p = 0.001). ChatGPT's
   surgical responses matched with patient data in 18 out of 24 cases
   (75%), excluding enucleation cases.
   The decisions matched with the three ocular oncology specialists in
   17/24, 18/24, and 18/24 cases, reflecting agreements of 70%, 75%, and
   75%, respectively. The decisions made by ChatGPT were not significantly
   different from those of the three professionals in this cohort (p =
   0.50, p = 0.36, and p = 0.36 for ChatGPT compared to specialists 1, 2,
   and 3).ConclusionChatGPT exhibited a level of proficiency that was
   comparable to that of trained ocular oncology specialists. However, it
   exhibited its limitations when evaluating more complex scenarios, such
   as extrascleral extension or infiltration of the optic nerve, when a
   comprehensive evaluation of the patient is therefore necessary.
ZS 0
Z8 0
ZB 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-04-25
UT WOS:001468330700001
PM 39918656
ER

PT J
AU De Paiva, CS
   Chen, Z
   Koch, DD
   Hamill, MB
   Manuel, FK
   Hassan, SS
   Wilhelmus, KR
   Pflugfelder, SC
TI The incidence and risk factors for developing dry eye after myopic LASIK
SO AMERICAN JOURNAL OF OPHTHALMOLOGY
VL 141
IS 3
BP 438
EP 445
DI 10.1016/j.ajo.2005.10.006
DT Article; Proceedings Paper
PD MAR 2006
PY 2006
AB PURPOSE: To determine the incidence of dry eye and its risk factors
   after myopic laser-assisted in situ keratomileusis (LASIK).
   DESIGN: Single-center, prospective randomized clinical trial of 35 adult
   patients, aged 24 to 54 years, with myopia undergoing LASIK.
   METHODS: SETTING AND STUDY POPULATION: Participants were randomized to
   undergo LASIK with a superior or a nasal hinge flap. They were evaluated
   at 1 week and 1, 3, and 6 months after surgery.
   INTERVENTION: Bilateral LASIK with either a superior,hinge Hansatome
   microkeratome (n = 17) or a nasal-hinge Amadeus microkeratome (n = 18).
   MAIN OUTCOME MEASURES: The criterion for dry eye was a total corneal
   fluorescein staining score >= 3. Visual acuity, ocular surface
   parameters, and corneal sensitivity were also analyzed. Cox
   proportional-hazard regression was used to assess rate ratios (RRs) with
   95% confidence intervals.
   RESULTS: The incidence of dry eye in the nasal, and superior-hinge group
   was eight (47-06%) of 17 and nine (52.94%) of 17 at 1 week, seven
   (38.89%) of 18 and seven (41-18%) of 17 at I month, four (25%) of 16 and
   three (17.65%) of 17 at 3 months, and two (12.50%) of 16 and six
   (35.29%) of 17 at 6 months, respectively. Dry eye was associated with
   level of preoperative myopia (RR 0.88/each diopter, P =.04),
   laser-calculated ablation depth (RR 1.01/lLm, P = 0.01), and combined
   ablation depth and flap thickness (RR 1.01/mu m, P = 0.01).
   CONCLUSIONS: Dry eye occurs commonly after LASIK surgery in patients
   with no history of dry eye. The risk of developing dry eye is correlated
   with the degree of preoperative myopia and the depth of laser treatment.
CT Annual Meeting of the
   American-Society-of-Cataract-and-Refractive-Surgery
CY MAY 02-04, 2004
CL San Diego, CA
SP Amer Soc Cataract & Refract Surg
ZB 53
Z8 2
TC 162
ZA 0
ZR 0
ZS 1
Z9 170
DA 2006-03-01
UT WOS:000236057900002
PM 16490488
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

PT J
AU Wilhelm, Theresa Isabelle
   Roos, Jonas
   Kaczmarczyk, Robert
TI Large Language Models for Therapy Recommendations Across 3 Clinical
   Specialties: Comparative Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 25
AR e49324
DI 10.2196/49324
DT Article
PD OCT 30 2023
PY 2023
AB Background: As advancements in artificial intelligence (AI) continue,
   large language models (LLMs) have emerged as promising tools for
   generating medical information. Their rapid adaptation and potential
   benefits in health care require rigorous assessment in terms of the
   quality, accuracy, and safety of the generated information across
   diverse medical specialties.
   Objective: This study aimed to evaluate the performance of 4 prominent
   LLMs, namely, Claude-instant-v1.0, GPT-3.5-Turbo,
   Command-xlarge-nightly, and Bloomz, in generating medical content
   spanning the clinical specialties of ophthalmology, orthopedics, and
   dermatology.
   Methods: Three domain-specific physicians evaluated the AI-generated
   therapeutic recommendations for a diverse set of 60 diseases. The
   evaluation criteria involved the mDISCERN score, correctness, and
   potential harmfulness of the recommendations. ANOVA and pairwise t tests
   were used to explore discrepancies in content quality and safety across
   models and specialties. Additionally, using the capabilities of OpenAI's
   most advanced model, GPT-4, an automated evaluation of each model's
   responses to the diseases was performed using the same criteria and
   compared to the physicians' assessments through Pearson correlation
   analysis.
   Results: Claude-instant-v1.0 emerged with the highest mean mDISCERN
   score (3.35, 95% CI 3.23-3.46). In contrast, Bloomz lagged with the
   lowest score (1.07, 95% CI 1.03-1.10). Our analysis revealed significant
   differences among the models in terms of quality (P<.001). Evaluating
   their reliability, the models displayed strong contrasts in their
   falseness ratings, with variations both across models (P<.001) and
   specialties (P<.001). Distinct error patterns emerged, such as confusing
   diagnoses; providing vague, ambiguous advice; or omitting critical
   treatments, such as antibiotics for infectious diseases. Regarding
   potential harm, GPT-3.5-Turbo was found to be the safest, with the
   lowest harmfulness rating. All models lagged in detailing the risks
   associated with treatment procedures, explaining the effects of
   therapies on quality of life, and offering additional sources of
   information. Pearson correlation analysis underscored a substantial
   alignment between physician assessments and GPT-4's evaluations across
   all established criteria (P<.01).
   Conclusions: This study, while comprehensive, was limited by the
   involvement of a select number of specialties and physician evaluators.
   The straightforward prompting strategy ("How to treat...") and the
   assessment benchmarks, initially conceptualized for human-authored
   content, might have potential gaps in capturing the nuances of AI-driven
   information. The LLMs evaluated showed a notable capability in
   generating valuable medical content; however, evident lapses in content
   quality and potential harm the need for further refinements. Given the
   of this the need for regular and methodical assessments, oversight, and
   fine-tuning of these AI tools to ensure they produce consistently
   trustworthy and clinically safe medical advice. Notably, the
   introduction of an auto-evaluation mechanism using GPT-4, as detailed in
   this study, provides a scalable, transferable method for domain-agnostic
   evaluations, extending beyond therapy recommendation assessments.
ZA 0
ZB 12
ZR 0
ZS 0
TC 57
Z8 0
Z9 57
DA 2024-01-07
UT WOS:001106812100007
PM 37902826
ER

PT J
AU Morcilla, Jericho
   Cao, Jessica Anning
   Fan, Kenneth
   Rahman, Effie
   Khang Ngo
   Patel, Sagar
   Chaudhary, Varun
   Wykoff, Charles Clifton
TI A Potential Role for AI: Evaluating ChatGPT's Efficacy in Prioritizing
   Medical Waiting Lists
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 5668
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZB 0
ZS 0
Z8 0
ZA 0
TC 0
ZR 0
Z9 0
DA 2024-11-30
UT WOS:001313316206237
ER

PT J
AU Fennig, Uriel
   Yom-Tov, Elad
   Savitsky, Leehe
   Nissan, Johnatan
   Altman, Keren
   Loebenstein, Roni
   Boxer, Marina
   Weinberg, Nitai
   Gofrit, Shany Guly
   Maggio, Nicola
TI Bridging the conversational gap in epilepsy: Using large language models
   to reveal insights into patient behavior and concerns from online
   discussions
SO EPILEPSIA
VL 66
IS 3
BP 686
EP 699
DI 10.1111/epi.18226
EA DEC 2024
DT Article
PD MAR 2025
PY 2025
AB ObjectiveThis study was undertaken to explore the experiences and
   concerns of people living with epilepsy by analyzing discussions in an
   online epilepsy community, using large language models (LLMs) to
   identify themes, demographic patterns, and associations with emotional
   distress, substance use, and suicidal ideation.MethodsWe analyzed 56 970
   posts and responses to them from 21 906 users on the epilepsy forum
   (subreddit) of Reddit and 768 504 posts from the same users in other
   subreddits, between 2010 and 2023. LLMs, validated against human
   labeling, were used to identify 23 recurring themes, assess demographic
   differences, and examine cross-posting to depression- and
   suicide-related subreddits. Hazard ratios (HRs) were calculated to
   assess the association between specific themes and activity in mental
   health forums.ResultsProminent topics included seizure descriptions,
   medication management, stigma, drug and alcohol use, and emotional
   well-being. The posts on topics less likely to be discussed in clinical
   settings had the highest engagement. Younger users focused on stigma and
   emotional issues, whereas older users discussed medical treatments.
   Posts about emotional distress (HR = 1.3), postictal state (HR = 1.4),
   surgical treatment (HR = .7), and work challenges (HR = 1.6) predicted
   activity in a subreddit associated with suicidal ideation, whereas
   emotional distress (HR = 1.5), surgical treatment (HR = .6), and stigma
   (HR = 1.3) predicted activity in the depression subreddit. Substance use
   discussions showed a temporal pattern of association with seizure
   descriptions, implying possible opportunities for
   intervention.SignificanceLLM analysis of online epilepsy communities
   provides novel insights into patient concerns often overlooked in
   clinical settings. These findings may improve patient-provider
   communication, inform personalized interventions, and support the
   development of patient-reported outcome measures. Additionally, hazard
   models can help identify at-risk individuals, offering opportunities for
   early mental health interventions.
ZB 0
ZA 0
Z8 0
TC 1
ZS 0
ZR 0
Z9 1
DA 2024-12-16
UT WOS:001373700400001
PM 39655574
ER

PT J
AU Johnston, Carolyn
Z2  
TI Divergence in healthcare decision-making: seeking a consensus on the
   meaning and application of 'best interests'
DT Dissertation/Thesis
PD Jan 01 2011
PY 2011
ZR 0
TC 0
ZA 0
Z8 0
ZB 0
ZS 0
Z9 0
UT PQDT:67862891
ER

PT J
AU Schwieger, Arne
   Angst, Katrin
   de Bardeci, Mateo
   Burrer, Achim
   Cathomas, Flurin
   Ferrea, Stefano
   Gratz, Franziska
   Knorr, Marius
   Kronenberg, Golo
   Spiller, Tobias
   Troi, David
   Seifritz, Erich
   Weber, Samantha
   Olbrich, Sebastian
TI Large language models can support generation of standardized discharge
   summaries - A retrospective study utilizing ChatGPT-4 and electronic
   health records
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 192
AR 105654
DI 10.1016/j.ijmedinf.2024.105654
EA OCT 2024
DT Article
PD DEC 2024
PY 2024
AB Objective: To evaluate whether psychiatric discharge summaries (DS)
   generated with ChatGPT-4 from electronic health records (EHR) can match
   the quality of DS written by psychiatric residents. Methods: At a
   psychiatric primary care hospital, we compared 20 inpatient DS, written
   by residents, to those written with ChatGPT-4 from pseudonymized
   residents' notes of the patients' EHRs and a standardized prompt. 8
   blinded psychiatry specialists rated both versions on a custom Likert
   scale from 1 to 5 across 15 quality subcategories. The primary outcome
   was the overall rating difference between the two groups. The secondary
   outcomes were the rating differences at the level of individual
   question, case, and rater. Results: Human-written DS were rated
   significantly higher than AI (mean ratings: human 3.78, AI 3.12, p <
   0.05). They surpassed AI significantly in 12/15 questions and 16/20
   cases and were favored significantly by 7/8 raters. For "low expected
   correction effort", human DS were rated as 67 % favorable, 19 % neutral,
   and 14 % unfavorable, whereas AI-DS were rated as 22 % favorable, 33 %
   neutral, and 45 % unfavorable. Hallucinations were present in 40 % of
   AI-DS, with 37.5 % deemed highly clinically relevant. Minor content
   mistakes were found in 30 % of AI and 10 % of human DS. Raters correctly
   identified AI-DS with 81 % sensitivity and 75 % specificity. Discussion:
   Overall, AI-DS did not match the quality of resident-written DS but
   performed similarly in 20% of cases and were rated as favorable for "low
   expected correction effort" in 22% of cases. AI-DS lacked most in
   content specificity, ability to distill key case information, and
   coherence but performed adequately in conciseness, adherence to
   formalities, relevance of included content, and form. Conclusion:
   LLM-written DS show potential as templates for physicians to finalize,
   potentially saving time in the future.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 1
TC 5
Z9 5
DA 2024-11-07
UT WOS:001343302900001
PM 39437512
ER

PT B
AU Asly, Amneh
Z2  
TI Developing Objective Chronic Pain Assessment Based on Linguistic
   Characteristics of Patients' Narratives
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
TC 0
ZA 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
UT PQDT:119375393
ER

EF