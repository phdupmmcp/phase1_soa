FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Qiu, Jianing
   Lam, Kyle
   Li, Guohao
   Acharya, Amish
   Wong, Tien Yin
   Darzi, Ara
   Yuan, Wu
   Topol, Eric J.
TI LLM-based agentic systems in medicine and healthcare
SO NATURE MACHINE INTELLIGENCE
VL 6
IS 12
BP 1418
EP 1420
DI 10.1038/s42256-024-00944-1
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB Large language model-based agentic systems can process input
   information, plan and decide, recall and reflect, interact and
   collaborate, leverage various tools and act. This opens up a wealth of
   opportunities within medicine and healthcare, ranging from clinical
   workflow automation to multi-agent-aided diagnosis.
ZS 0
Z8 0
TC 6
ZR 0
ZA 0
ZB 1
Z9 6
DA 2024-12-11
UT WOS:001370695300001
ER

PT J
AU Verda, Damiano
   Parodi, Stefano
   Ferrari, Enrico
   Muselli, Marco
TI Analyzing gene expression data for pediatric and adult cancer diagnosis
   using logic learning machine and standard supervised methods
SO BMC BIOINFORMATICS
VL 20
AR 390
DI 10.1186/s12859-019-2953-8
SU 9
DT Article
PD NOV 22 2019
PY 2019
AB Background: Logic Learning Machine (LLM) is an innovative method of
   supervised analysis capable of constructing models based on simple and
   intelligible rules.
   In this investigation the performance of LLM in classifying patients
   with cancer was evaluated using a set of eight publicly available gene
   expression databases for cancer diagnosis.
   LLM accuracy was assessed by summary ROC curve (sROC) analysis and
   estimated by the area under an sROC curve (sAUC). Its performance was
   compared in cross validation with that of standard supervised methods,
   namely: decision tree, artificial neural network, support vector machine
   (SVM) and k-nearest neighbor classifier.
   Results: LLM showed an excellent accuracy (sAUC = 0.99, 95%CI: 0.98-1.0)
   and outperformed any other method except SVM.
   Conclusions: LLM is a new powerful tool for the analysis of gene
   expression data for cancer diagnosis. Simple rules generated by LLM
   could contribute to a better understanding of cancer biology,
   potentially addressing therapeutic approaches.
ZR 0
Z8 0
TC 13
ZS 0
ZA 0
ZB 4
Z9 13
DA 2020-01-03
UT WOS:000503868200007
PM 31757200
ER

PT J
AU Ren, Yaxuan
   Luo, Xufei
   Wang, Ye
   Li, Haodong
   Zhang, Hairong
   Li, Zeming
   Lai, Honghao
   Li, Xuanlin
   Ge, Long
   Estill, Janne
   Zhang, Lu
   Yang, Shu
   Chen, Yaolong
   Wen, Chengping
   Bian, Zhaoxiang
   ADVANCED Working Group
TI Large Language Models in Traditional Chinese Medicine: A Scoping Review
SO JOURNAL OF EVIDENCE BASED MEDICINE
VL 18
IS 1
DI 10.1111/jebm.12658
EA DEC 2024
DT Review
PD MAR 2025
PY 2025
AB BackgroundThe application of large language models (LLMs) in medicine
   has received increasing attention, showing significant potential in
   teaching, research, and clinical practice, especially in knowledge
   extraction, management, and understanding. However, the use of LLMs in
   Traditional Chinese Medicine (TCM) has not been thoroughly studied. This
   study aims to provide a comprehensive overview of the status and
   challenges of LLM applications in TCM.MethodsA systematic search of five
   electronic databases and Google Scholar was conducted between November
   2022 and April 2024, using the Arksey and O'Malley five-stage framework
   to identify relevant studies. Data from eligible studies were
   comprehensively extracted and organized to describe LLM applications in
   TCM and assess their performance accuracy.ResultsA total of 29 studies
   were identified: 24 peer-reviewed articles, 1 review, and 4 preprints.
   Two core application areas were found: the extraction, management, and
   understanding of TCM knowledge, and assisted diagnosis and treatment.
   LLMs developed specifically for TCM achieved 70% accuracy in the TCM
   Practitioner Exam, while general-purpose Chinese LLMs achieved 60%
   accuracy. Common international LLMs did not pass the exam. Models like
   EpidemicCHAT and MedChatZH, trained on customized TCM corpora,
   outperformed general LLMs in TCM consultation.ConclusionDespite their
   potential, LLMs in TCM face challenges such as data quality and security
   issues, the specificity and complexity of TCM data, and the
   nonquantitative nature of TCM diagnosis and treatment. Future efforts
   should focus on interdisciplinary talent cultivation, enhanced data
   standardization and protection, and exploring LLM potential in
   multimodal interaction and intelligent diagnosis and treatment.
ZR 0
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001373936900001
PM 39651543
ER

PT J
AU Goh, Ethan
   Gallo, Robert
   Hom, Jason
   Strong, Eric
   Weng, Yingjie
   Kerman, Hannah
   Cool, Josephine A.
   Kanjee, Zahir
   Parsons, Andrew S.
   Ahuja, Neera
   Horvitz, Eric
   Yang, Daniel
   Milstein, Arnold
   Olson, Andrew P. J.
   Rodman, Adam
   Chen, Jonathan H.
TI Large Language Model Influence on Diagnostic Reasoning A Randomized
   Clinical Trial
SO JAMA NETWORK OPEN
VL 7
IS 10
AR e2440969
DI 10.1001/jamanetworkopen.2024.40969
DT Article
PD OCT 28 2024
PY 2024
AB IMPORTANCE Large language models (LLMs) have shown promise in their
   performance on both multiple-choice and open-ended medical reasoning
   examinations, but it remains unknown whether the use of such tools
   improves physician diagnostic reasoning. OBJECTIVE To assess the effect
   of an LLM on physicians' diagnostic reasoning compared with conventional
   resources. DESIGN, SETTING, AND PARTICIPANTS A single-blind randomized
   clinical trial was conducted from November 29 to December 29, 2023.
   Using remote video conferencing and in-person participation across
   multiple academic medical institutions, physicians with training in
   family medicine, internal medicine, or emergency medicine were
   recruited. INTERVENTION Participants were randomized to either access
   the LLM in addition to conventional diagnostic resources or conventional
   resources only, stratified by career stage. Participants were allocated
   60 minutes to review up to 6 clinical vignettes. MAIN OUTCOMES AND
   MEASURES The primary outcome was performance on a standardized rubric of
   diagnostic performance based on differential diagnosis accuracy,
   appropriateness of supporting and opposing factors, and next diagnostic
   evaluation steps, validated and graded via blinded expert consensus.
   Secondary outcomes included time spent per case (in seconds) and final
   diagnosis accuracy. All analyses followed the intention-to-treat
   principle. A secondary exploratory analysis evaluated the standalone
   performance of the LLM by comparing the primary outcomes between the LLM
   alone group and the conventional resource group. RESULTS Fifty
   physicians (26 attendings, 24 residents; median years in practice, 3
   [IQR, 2-8]) participated virtually as well as at 1 in-person site. The
   median diagnostic reasoning score per case was 76% (IQR, 66%-87%) for
   the LLM group and 74% (IQR, 63%-84%) for the conventional resources-only
   group, with an adjusted difference of 2 percentage points (95% CI, -4 to
   8 percentage points; P = .60). The median time spent per case for the
   LLM group was 519 (IQR, 371-668) seconds, compared with 565 (IQR,
   456-788) seconds for the conventional resources group, with a time
   difference of -82 (95% CI, -195 to 31; P = .20) seconds. The LLM alone
   scored 16 percentage points (95% CI, 2-30 percentage points; P = .03)
   higher than the conventional resources group. CONCLUSIONS AND RELEVANCE
   In this trial, the availability of an LLM to physicians as a diagnostic
   aid did not significantly improve clinical reasoning compared with
   conventional resources. The LLM alone demonstrated higher performance
   than both physician groups, indicating the need for technology and
   workforce development to realize the potential of physician-artificial
   intelligence collaboration in clinical practice.
ZB 9
Z8 0
ZS 0
ZA 0
TC 81
ZR 0
Z9 81
DA 2024-11-11
UT WOS:001346416900001
PM 39466245
ER

PT J
AU Kainz, Jakob
   Seisl, Philipp
   Grob, Moritz
   Hauptfeld, Leonhard
   Wahringer, Jonas
   Rappelsberger, Andrea
   Adlassnig, Klaus-Peter
TI Fine-Tuning an Existing Large Language Model with Knowledge from the
   Medical Expert System Hepaxpert.
SO Studies in health technology and informatics
VL 327
BP 143
EP 147
DI 10.3233/SHTI250290
DT Journal Article
PD 2025-May-15
PY 2025
AB The analysis and individual interpretation of hepatitis serology test
   results is a complex task in laboratory medicine, requiring either
   experienced physicians or specialized expert systems. This study
   explores fine-tuning a large language model (LLM) for hepatitis serology
   interpretation using a single graphics processing unit (GPU). A custom
   dataset based on the Hepaxpert expert system was used to train the LLM.
   Fine-tuning was performed on an Nvidia RTX 6000 Ada GPU via torchtune.
   The fine-tuned LLM showed significant performance improvements over the
   base model when compared to Hepaxpert using the METEOR algorithm. The
   findings highlight the potential of LLMs in enhancing medical expert
   systems as well as the significance of domain-specific fine-tuning.
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
ZA 0
Z9 0
DA 2025-05-20
UT MEDLINE:40380402
PM 40380402
ER

PT J
AU Parodi, Stefano
   Filiberti, Rosa
   Marroni, Paola
   Libener, Roberta
   Ivaldi, Giovanni Paolo
   Mussap, Michele
   Ferrari, Enrico
   Manneschi, Chiara
   Montani, Erika
   Muselli, Marco
TI Differential diagnosis of pleural mesothelioma using Logic Learning
   Machine
SO BMC BIOINFORMATICS
VL 16
AR S3
DI 10.1186/1471-2105-16-S9-S3
SU 9
DT Article; Proceedings Paper
PD JUN 1 2015
PY 2015
AB Background: Tumour markers are standard tools for the differential
   diagnosis of cancer. However, the occurrence of nonspecific symptoms and
   different malignancies involving the same cancer site may lead to a high
   proportion of misclassifications.
   Classification accuracy can be improved by combining information from
   different markers using standard data mining techniques, like Decision
   Tree (DT), Artificial Neural Network (ANN), and k-Nearest Neighbour
   (KNN) classifier. Unfortunately, each method suffers from some
   unavoidable limitations. DT, in general, tends to show a low
   classification performance, whereas ANN and KNN produce a "black-box"
   classification that does not provide biological information useful for
   clinical purposes.
   Methods: Logic Learning Machine (LLM) is an innovative method of
   supervised data analysis capable of building classifiers described by a
   set of intelligible rules including simple conditions in their
   antecedent part. It is essentially an efficient implementation of the
   Switching Neural Network model and reaches excellent classification
   accuracy while keeping low the computational demand.
   LLM was applied to data from a consecutive cohort of 169 patients
   admitted for diagnosis to two pulmonary departments in Northern Italy
   from 2009 to 2011. Patients included 52 malignant pleural mesotheliomas
   (MPM), 62 pleural metastases (MTX) from other tumours and 55 benign
   diseases (BD) associated with pleurisies. Concentration of three tumour
   markers (CEA, CYFRA 21-1 and SMRP) was measured in the pleural fluid of
   each patient and a cytological examination was also carried out.
   The performance of LLM and that of three competing methods (DT, KNN and
   ANN) was assessed by leave-one-out cross-validation.
   Results: LLM outperformed all other considered methods. Global accuracy
   was 77.5% for LLM, 72.8% for DT, 54.4% for KNN, and 63.9% for ANN,
   respectively. In more details, LLM correctly classified 79% of MPM, 66%
   of MTX and 89% of BD. The corresponding figures for DT were: MPM = 83%,
   MTX = 55% and BD = 84%; for KNN: MPM = 58%, MTX = 45%, BD = 62%; for
   ANN: MPM = 71%, MTX = 47%, BD = 76%.
   Finally, LLM provided classification rules in a very good agreement with
   a priori knowledge about the biological role of the considered tumour
   markers.
   Conclusions: LLM is a new flexible tool potentially useful for the
   differential diagnosis of pleural mesothelioma.
CT 11th Annual Meeting of the Bioinformatics-Italian-Society (BITS)
CY FEB 26-28, 2014
CL Rome, ITALY
SP Bioinformat Italian Soc
TC 21
Z8 1
ZR 0
ZA 0
ZB 9
ZS 0
Z9 22
DA 2016-01-27
UT WOS:000367875300003
PM 26051106
ER

PT J
AU Su, L X
   Weng, L
   Li, W X
   Long, Y
TI [Applications and challenges of large language models in critical care
   medicine].
SO Zhonghua yi xue za zhi
VL 103
IS 31
BP 2361
EP 2364
DI 10.3760/cma.j.cn112137-20230524-00847
DT English Abstract; Journal Article
PD 2023-Aug-22
PY 2023
AB The rapid development of big data methods and technologies has provided
   more and more new ideas and methods for clinical diagnosis and
   treatment. The emergence of large language models (LLM) has made it
   possible for human-computer interactive dialogues and applications in
   complex medical scenarios. Critical care medicine is a process of
   continuous dynamic targeted treatment. The huge data generated in this
   process needs to be integrated and optimized through models for clinical
   application, interaction in teaching simulation, and assistance in
   scientific research. Using the LLM represented by generative pre-trained
   transformer ChatGPT can initially realize the application in the
   diagnosis of severe diseases, the prediction of death risk and the
   management of medical records. At the same time, the time and space
   limitations, illusions and ethical and moral issues of ChatGPT emerged
   as the times require. In the future, it is undeniable that it may play a
   huge role in the diagnosis and treatment of critical care medicine, but
   the current application should be combined with more clinical knowledge
   reserves of critical care medicine to carefully judge its conclusions.
AB 大数据方法和技术发展日新月异，给临床诊疗提供了越来越多的新的思路和方法。大语言模型的出现使得人机交互式的对话和复杂的医疗场景下的应用成为了可能。
   重症医学是一个连续动态目标性治疗的过程，这个过程中产生的庞大数据需要通过模型进行整合与优化并在临床应用，在教学模拟中互动，在科学研究中助力。使用
   以生成式预训练转换模型（ChatGPT）为代表的大语言模型可初步实现在重症疾病的诊断、死亡风险预测和病案管理方面的应用。同时ChatGPT的时空
   局限性、幻象和伦理道德问题应运而生。ChatGPT在未来的重症医学诊疗中可能会发挥巨大作用，但目前需要结合更多的重症医学临床知识储备并谨慎对待其
   作出的结论进行判断。.
ZR 0
TC 1
ZB 0
Z8 3
ZS 0
ZA 0
Z9 4
DA 2023-08-23
UT MEDLINE:37599212
PM 37599212
ER

PT J
AU Schaye, Verity
   Ditullio, David
   Guzman, Benedict Vincent
   Vennemeyer, Scott
   Shih, Hanniel
   Reinstein, Ilan
   Weber, Danielle E.
   Goodman, Abbie
   Wu, Danny T. Y.
   Sartori, Daniel J.
   Santen, Sally A.
   Gruppen, Larry
   Aphinyanaphongs, Yindalon
   Burk-Rafel, Jesse
TI Large Language Model-Based Assessment of Clinical Reasoning
   Documentation in the Electronic Health Record Across Two Institutions:
   Development and Validation Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e67967
DI 10.2196/67967
DT Article
PD MAR 21 2025
PY 2025
AB Background: Clinical reasoning (CR) is an essential skill; yet,
   physicians often receive limited feedback. Artificial intelligence holds
   promise to fill this gap. Objective: We report the development of named
   entity recognition (NER), logic-based and large language model
   (LLM)-based assessments of CR documentation in the electronic health
   record across 2 institutions (New York University Grossman School of
   Medicine[NYU] and University of Cincinnati Collegeof Medicine[UC]).
   Methods: The note corpus consisted of internal medicine resident
   admission notes (retrospective set: July 2020-December 2021, n=700 NYU
   and 450 UC notes and prospective validation set: July 2023-December
   2023, n=155 NYU and 92 UC notes). Clinicians rated CR documentation
   quality in each note using a previously validated tool (Revised-IDEA),
   on 3-point scales across 2 domains: differential diagnosis (D0, D1, and
   D2) and explanation of reasoning, (EA0, EA1, and EA2). At NYU, the
   retrospective set was annotated for NER for 5 entities (diagnosis,
   diagnostic category, prioritization of diagnosis language, data, and
   linkage terms). Models were developed using different artificial
   intelligence approaches, including NER, logic-based model: a large word
   vector model (scispaCy en_core_sci_lg) with model weights adjusted with
   backpropagation from annotations, developed at NYU with external
   validation at UC, NYUTron LLM: an NYU internal 110 million parameter LLM
   pretrained on 7.25 million clinical notes, only validated at NYU, and
   GatorTron LLM: an open source 345 million parameter LLM pretrained on 82
   billion words of clinical text, fined tuned on NYU retrospective sets,
   then externally validated and further fine-tuned at UC. Model
   performance was assessed in the prospective sets with F1-scores for the
   NER, logic-based model and area under the receiver operating
   characteristic curve (AUROC) and area under the precision-recall curve
   (AUPRC) for the LLMs. Results: At NYU, the NYUTron LLM performed best:
   the D0 and D2 models had AUROC/AUPRC 0.87/0.79 and 0.89/0.86,
   respectively. The D1, EA0, and EA1 models had insufficient performance
   for implementation (AUROC range 0.57-0.80, AUPRC range 0.33-0.63). For
   the D1 classification, the approach pivoted to a stepwise approach
   taking advantage of the more performant D0 and D2 models. For the EA
   model, the approach pivoted to a binary EA2 model (ie, EA2 vs not EA2)
   with excellent performance, AUROC/AUPRC 0.85/ 0.80. At UC, the NER,
   D-logic-based model was the best performing D model (F1-scores 0.80,
   0.74, and 0.80 for D0, D1, D2, respectively. The GatorTron LLM performed
   best for EA2 scores AUROC/AUPRC 0.75/ 0.69. Conclusions:This is the
   first multi-institutional study to apply LLMs for assessing CR
   documentation in the electronic health record. Such tools can enhance
   feedback on CR. Lessons learned by implementing these models at distinct
   institutions support the generalizability of this approach.
ZR 0
TC 0
Z8 0
ZA 0
ZB 0
ZS 0
Z9 0
DA 2025-04-27
UT WOS:001469544100003
PM 40117575
ER

PT J
AU Wang, JY
   Kuo, PH
   Jan, IS
   Lee, LN
   Yang, PC
TI Serial analysis of fat-containing macrophages in bronchoalveolar lavage
   fluid in a patient with fat embolism syndrome
SO JOURNAL OF THE FORMOSAN MEDICAL ASSOCIATION
VL 100
IS 8
BP 557
EP 560
DT Article
PD AUG 2001
PY 2001
AB Recent studies suggest that an increase in fat-containing macrophages in
   bronchoalveolar lavage (BAL) fluid may be helpful in the diagnosis of
   fat embolism syndrome (FES). Nevertheless, none of these studies have
   explored the sequential findings of BAL fluid. We report the case of a
   19-year-old man admitted to our intensive care unit because of dyspnea
   with radiographic evidence of bilateral alveolar infiltrate after
   traumatic fracture. Analysis of BAL fluid on the third hospital day
   revealed 8.3% fat-containing macrophages and a lipid-laden macrophages
   (LLM) index of 23. Pathologic examination of lung biopsy showed numerous
   fat globules within arterioles. For comparison, the BAL fluid from four
   other patients with acute respiratory distress syndrome (ARDS) but
   without FES was also analyzed. The underlying diseases leading to ARDS
   included Wegener's granulomatosis in one case, pneumonia in two cases,
   and alveolar proteinosis in one case. The percentages of fat-containing
   macrophages in these specimens were 1.3%, 52%, 2.3%, and 74%,
   respectively. The LLM indexes were 1, 133, 3, and 243, respectively. As
   the patients condition improved, the percentage of fat-containing
   macrophages in the BAL fluid decreased to 4.7% on the eighth hospital
   day and the LLM index also decreased to 6. These findings suggest that
   the presence of fat-containing macrophages in BAL fluid is not specific
   for the diagnosis of FES, but serial changes in the percentage of these
   cells and the LLM index may be helpful in the follow-up of disease
   severity.
ZB 1
TC 3
ZS 0
ZA 0
Z8 0
ZR 0
Z9 3
DA 2001-08-01
UT WOS:000171402100009
PM 11678008
ER

PT J
AU West, Matthew
   Cheng, You
   He, Yingnan
   Leng, Yu
   Magdamo, Colin
   Hyman, Bradley
   Dickson, John R.
   Serrano-Pozo, Alberto
   Blacker, Deborah
   Das, Sudeshna
TI Unsupervised Deep Learning of Electronic Health Records to Characterize
   Heterogeneity Across Alzheimer Disease and Related Dementias:
   Cross-Sectional Study
SO JMIR AGING
VL 8
AR e65178
DI 10.2196/65178
DT Article
PD 2025
PY 2025
AB Background: Alzheimer disease and related dementias (ADRD) exhibit
   prominent heterogeneity. Identifying clinically meaningful ADRD subtypes
   is essential for tailoring treatments to specific patient phenotypes.
   Objective: We aimed to use unsupervised learning techniques on
   electronic health records (EHRs) from memory clinic patients to identify
   ADRD subtypes. Methods: We used pretrained embeddings of non-ADRD
   diagnosis codes (International Classification ofDiseases,Ninth Revision)
   and large language model (LLM)-derived embeddings of clinical notes from
   patient EHRs. Hierarchical clustering of these embeddings was used to
   identify ADRD subtypes. Clusters were characterized regarding their
   demographic and clinical features. Results: We analyzed a cohort of 3454
   patients with ADRD from a memory clinic at Massachusetts General
   Hospital, each with a specialist diagnosis. Clustering pretrained
   embeddings of the non-ADRD diagnosis codes in patient EHRs revealed the
   following 3 patient subtypes: one with skin conditions, another with
   psychiatric disorders and an earlier age of onset, and a third with
   diabetes complications. Similarly, using LLM-derived embeddings of
   clinical notes, we identified 3 subtypes of patients as follows: one
   with psychiatric manifestations and higher prevalence of female
   participants (prevalence ratio: 1.59), another with cardiovascular and
   motor problems and higher prevalence of male participants (prevalence
   ratio: 1.75), and a third one with geriatric health disorders. Notably,
   we observed significant overlap between clusters from both data
   modalities (chi 24=89.4; P<.001). Conclusions: By integrating
   International Classification ofDiseases,Ninth Revision codes and
   LLM-derived embeddings, our analysis delineated 2 distinctADRD subtypes
   with sex-specific comorbid and clinical presentations, offering insights
   for potential precision medicine approaches.
ZB 0
Z8 0
ZR 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-04-13
UT WOS:001461835800001
PM 40163031
ER

PT J
AU Skoulakis, Charalambos E.
   Stavroulaki, Pelagia
   Moschotzopoulos, Panagiotis
   Paxinos, Mihalis
   Fericean, Angela
   Valagiannis, Dimitris E.
TI Laryngeal leiomyosarcoma: a case report and review of the literature
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 263
IS 10
BP 929
EP 934
DI 10.1007/s00405-006-0092-0
DT Article
PD OCT 2006
PY 2006
AB Laryngeal leiomyosarcoma (LLM) is a rare malignancy originating from the
   smooth muscles of blood vessels or from aberrant undifferentiated
   mesenchymal tissue. Histological diagnosis may be particularly difficult
   and correct diagnosis is based on immunohistochemical investigations and
   electron microscopy. A case report of a LLM in a 74-year-old man is
   presented. Direct laryngoscopy revealed a large glottic lesion causing
   airway compromise and an emergency tracheotomy was performed. Subsequent
   total laryngectomy confirmed the diagnosis of leiomyosarcoma. Lung
   metastases developed 8 months following treatment, despite the absence
   of local or regional recurrence, and the patient died 3 months later. A
   review of the English and French literature revealed 30 previous cases
   of LLM. Clinical presentation, histological diagnosis, and management of
   this rare malignancy are analyzed aiming to improve our knowledge
   regarding the best treatment modality.
Z8 0
TC 17
ZR 0
ZS 0
ZB 4
ZA 0
Z9 17
DA 2006-10-01
UT WOS:000240396200009
PM 16804717
ER

PT J
AU Omiye, Jesutofunmi A.
   Gui, Haiwen
   Daneshjou, Roxana
   Cai, Zhuo Ran
   Muralidharan, Vijaytha
TI Principles, applications, and future of artificial intelligence in
   dermatology
SO FRONTIERS IN MEDICINE
VL 10
AR 1278232
DI 10.3389/fmed.2023.1278232
DT Review
PD OCT 12 2023
PY 2023
AB This paper provides an overview of artificial-intelligence (AI), as
   applied to dermatology. We focus our discussion on methodology, AI
   applications for various skin diseases, limitations, and future
   opportunities. We review how the current image-based models are being
   implemented in dermatology across disease subsets, and highlight the
   challenges facing widespread adoption. Additionally, we discuss how the
   future of AI in dermatology might evolve and the emerging paradigm of
   large language, and multi-modal models to emphasize the importance of
   developing responsible, fair, and equitable models in dermatology.
Z8 1
ZS 0
TC 16
ZR 0
ZB 1
ZA 0
Z9 17
DA 2023-11-05
UT WOS:001087234600001
PM 37901399
ER

PT J
AU Seifen, Christopher
   Bahr-Hamm, Katharina
   Gouveris, Haralampos
   Pordzik, Johannes
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Simulation-Based Evaluation of Large Language Models for Comorbidity
   Detection in Sleep Medicine - a Pilot Study on ChatGPT o1 Preview
SO NATURE AND SCIENCE OF SLEEP
VL 17
BP 677
EP 688
DI 10.2147/NSS.S510254
DT Article
PD 2025
PY 2025
AB Purpose: Timely identification of comorbidities is critical in sleep
   medicine, where large language models (LLMs) like ChatGPT are currently
   emerging as transformative tools. Here, we investigate whether the novel
   LLM ChatGPT o1 preview can identify individual health risks or
   potentially existing comorbidities from the medical data of fictitious
   sleep medicine patients. Methods: We conducted a simulation-based study
   using 30 fictitious patients, designed to represent realistic variations
   in demographic and clinical parameters commonly seen in sleep medicine.
   Each profile included personal data (eg, body mass index, smoking
   status, drinking habits), blood pressure, and routine blood test
   results, along with a predefined sleep medicine diagnosis. Each patient
   profile was evaluated independently by the LLM and a sleep medicine
   specialist (SMS) for identification of potential comorbidities or
   individual health risks. Their recommendations were compared for
   concordance across lifestyle changes and further medical measures.
   Results: The LLM achieved high concordance with the SMS for lifestyle
   modification recommendations, including 100% concordance on smoking
   cessation (kappa = 1; p < 0.001), 97% on alcohol reduction (kappa =
   0.92; p < 0.001) and endocrinological examination (kappa = 0.92; p <
   0.001) or 93% on weight loss (kappa = 0.86; p < 0.001). However, it
   exhibited a tendency to over-recommend further medical measures
   (particularly 57% concordance for cardiological examination (kappa =
   0.08; p = 0.28) and 33% for gastrointestinal examination (kappa = 0.1; p
   = 0.22)) compared to the SMS. Conclusion: Despite the obvious limitation
   of using fictitious data, the findings suggest that LLMs like ChatGPT
   have the potential to complement clinical workflows in sleep medicine by
   identifying individual health risks and comorbidities. As LLMs continue
   to evolve, their integration into healthcare could redefine the approach
   to patient evaluation and risk stratification. Future research should
   contextualize the findings within broader clinical applications ideally
   testing locally run LLMs meeting data protection requirements.
ZA 0
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-05-10
UT WOS:001480706400001
PM 40321662
ER

PT J
AU Huang, Andy S.
   Hirabayashi, Kyle
   Barna, Laura
   Parikh, Deep
   Pasquale, Louis R.
TI Assessment of a Large Language Model's Responses to Questions and Cases
   About Glaucoma and Retina Management
SO JAMA OPHTHALMOLOGY
VL 142
IS 4
BP 371
EP 375
DI 10.1001/jamaophthalmol.2023.6917
EA APR 2024
DT Article
PD APR 2024
PY 2024
AB Importance: Large language models (LLMs) are revolutionizing medical
   diagnosis and treatment, offering unprecedented accuracy and ease
   surpassing conventional search engines. Their integration into medical
   assistance programs will become pivotal for ophthalmologists as an
   adjunct for practicing evidence-based medicine. Therefore, the
   diagnostic and treatment accuracy of LLM-generated responses compared
   with fellowship-trained ophthalmologists can help assess their accuracy
   and validate their potential utility in ophthalmic subspecialties.
   Objective: To compare the diagnostic accuracy and comprehensiveness of
   responses from an LLM chatbot with those of fellowship-trained glaucoma
   and retina specialists on ophthalmological questions and real patient
   case management. Design, Setting, and Participants: This comparative
   cross-sectional study recruited 15 participants aged 31 to 67 years,
   including 12 attending physicians and 3 senior trainees, from eye
   clinics affiliated with the Department of Ophthalmology at Icahn School
   of Medicine at Mount Sinai, New York, New York. Glaucoma and retina
   questions (10 of each type) were randomly selected from the American
   Academy of Ophthalmology's Commonly Asked Questions. Deidentified
   glaucoma and retinal cases (10 of each type) were randomly selected from
   ophthalmology patients seen at Icahn School of Medicine at Mount
   Sinai-affiliated clinics. The LLM used was GPT-4 (version dated May 12,
   2023). Data were collected from June to August 2023. Main Outcomes and
   Measures: Responses were assessed via a Likert scale for medical
   accuracy and completeness. Statistical analysis involved the
   Mann-Whitney U test and the Kruskal-Wallis test, followed by pairwise
   comparison. Results: The combined question-case mean rank for accuracy
   was 506.2 for the LLM chatbot and 403.4 for glaucoma specialists (n =
   831; Mann-Whitney U = 27976.5; P < .001), and the mean rank for
   completeness was 528.3 and 398.7, respectively (n = 828; Mann-Whitney U
   = 25218.5; P < .001). The mean rank for accuracy was 235.3 for the LLM
   chatbot and 216.1 for retina specialists (n = 440; Mann-Whitney U =
   15518.0; P = .17), and the mean rank for completeness was 258.3 and
   208.7, respectively (n = 439; Mann-Whitney U = 13123.5; P = .005). The
   Dunn test revealed a significant difference between all pairwise
   comparisons, except specialist vs trainee in rating chatbot
   completeness. The overall pairwise comparisons showed that both trainees
   and specialists rated the chatbot's accuracy and completeness more
   favorably than those of their specialist counterparts, with specialists
   noting a significant difference in the chatbot's accuracy (z = 3.23; P =
   .007) and completeness (z = 5.86; P < .001). Conclusions and Relevance:
   This study accentuates the comparative proficiency of LLM chatbots in
   diagnostic accuracy and completeness compared with fellowship-trained
   ophthalmologists in various clinical scenarios. The LLM chatbot
   outperformed glaucoma specialists and matched retina specialists in
   diagnostic and treatment accuracy, substantiating its role as a
   promising diagnostic adjunct in ophthalmology.
Z8 1
ZS 0
ZR 0
ZA 0
TC 53
ZB 8
Z9 53
DA 2024-03-21
UT WOS:001174564400007
PM 38386351
ER

PT J
AU Zhou, Jin
   Li, Xiaoqin
   Xia, Qianjun
   Yu, Liangcai
TI Innovations in otolaryngology using LLM for early detection of
   sleep-disordered breathing
SO SLAS TECHNOLOGY
VL 32
AR 100278
DI 10.1016/j.slast.2025.100278
EA MAR 2025
DT Article
PD JUN 2025
PY 2025
AB Sleep Disordered Breathing (SDB), including conditions like Obstructive
   Sleep Apnea (OSA), represents a major health concern, characterized by
   irregular airflow during sleep due to airway obstruction. SDB can result
   in serious health problems. Implementation of early intervention is
   vital whenever patient outcomes are to be considered. This research aims
   to advance research on otolaryngology using Machine Learning (ML)
   models, and Large Language Models (LLM) for identification of SDB using
   Electronic Health Record (HER). The approach proposes a hybrid ML
   framework combining the Dynamic Seagull Search algorithm-driven Large
   Language model (DSS-LLM). The extensive clinical dataset is used to
   train the model. It includes patient demographics, medical history,
   sleep habits, comorbidities, and physical measurements. Data
   pre-processing involves handling missing values, applying NLP
   techniques, and normalization. Feature extraction is done using
   Principal Component Analysis (PCA) to reduce the dimensionality of the
   hyperparameters and finally for selecting the best set of predictors.
   The extracted features are then used to train the proposed DSS-LLM
   model, which incorporates the DSS algorithm to optimize the LLM
   classifier, improving classification accuracy and model robustness.
   Subsequently, the idea of LLM is introduced for its application on
   textual clinical records comprising physicians' reports and patients'
   symptoms. The findings from an experiment suggest that the proposed
   model enhances the classification accuracy achieved to 98.91 %,
   precision attained by 98.9 %, recall achieved to 98.92 % and F-1 score
   attained by 98.58 % as compared to the models developed earlier. This
   research provides a novel solution to the screening of OSA at the
   pre-clinical level which involves hybrid machine learning models
   integrated with LLMs. This proposed framework is expected to boost
   clinical judgment and thereby increase better ophthalmology outcomes for
   patients.
ZS 0
TC 0
ZA 0
ZB 0
Z8 0
ZR 0
Z9 0
DA 2025-04-06
UT WOS:001457142200001
PM 40122382
ER

PT J
AU Khan, Maria Palwasha
   O'Sullivan, Eoin Daniel
TI A comparison of the diagnostic ability of large language models in
   challenging clinical cases
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
VL 7
AR 1379297
DI 10.3389/frai.2024.1379297
DT Article
PD AUG 5 2024
PY 2024
AB Introduction The rise of accessible, consumer facing large language
   models (LLM) provides an opportunity for immediate diagnostic support
   for clinicians.Objectives To compare the different performance
   characteristics of common LLMS utility in solving complex clinical cases
   and assess the utility of a novel tool to grade LLM output.Methods Using
   a newly developed rubric to assess the models' diagnostic utility, we
   measured to models' ability to answer cases according to accuracy,
   readability, clinical interpretability, and an assessment of safety.
   Here we present a comparative analysis of three LLM models-Bing, Chat
   GPT, and Gemini-across a diverse set of clinical cases as presented in
   the New England Journal of Medicines case series.Results Our results
   suggest that models performed differently when presented with identical
   clinical information, with Gemini performing best. Our grading tool had
   low interobserver variability and proved a reliable tool to grade LLM
   clinical output.Conclusion This research underscores the variation in
   model performance in clinical scenarios and highlights the importance of
   considering diagnostic model performance in diverse clinical scenarios
   prior to deployment. Furthermore, we provide a new tool to assess LLM
   output.
TC 1
Z8 0
ZB 0
ZA 0
ZS 0
ZR 0
Z9 1
DA 2024-08-22
UT WOS:001292883600001
PM 39161790
ER

PT J
AU Ghorbian, Mohsen
   Ghobaei-Arani, Mostafa
   Ghorbian, Saied
TI Transforming breast cancer diagnosis and treatment with large language
   Models: A comprehensive survey
SO METHODS
VL 239
BP 85
EP 110
DI 10.1016/j.ymeth.2025.04.001
EA APR 2025
DT Article
PD JUL 2025
PY 2025
AB Breast cancer (BrCa), being one of the most prevalent forms of cancer in
   women, poses many challenges in the field of treatment and diagnosis due
   to its complex biological mechanisms. Early and accurate diagnosis plays
   a fundamental role in improving survival rates, but the limitations of
   existing imaging methods and clinical data interpretation often prevent
   optimal results. Large Language Models (LLMs), which are developed based
   on advanced architectures such as transformers, have brought about a
   significant revolution in data processing and medical decision-making.
   By analyzing a large volume of medical and clinical data, these models
   enable early diagnosis by identifying patterns in images and medical
   records and provide personalized treatment strategies by integrating
   genetic markers and clinical guidelines. Despite the transformative
   potential of these models, their use in BrCa management faces challenges
   such as data sensitivity, algorithm transparency, ethical
   considerations, and model compatibility with the details of medical
   applications that need to be addressed to achieve reliable results. This
   review systematically reviews the impact of LLMs on BrCa treatment and
   diagnosis. This study's objectives include analyzing the role of LLM
   technology in diagnosing and treating this disease. The findings
   indicate that the application of LLMs has resulted in significant
   improvements in various aspects of BrCa management, such as a 35%
   increase in the Efficiency of Diagnosis and BrCa Treatment (EDBC), a 30%
   enhancement in the System's Clinical Trust and Reliability (SCTR), and a
   20% improvement in the quality of patient education and information
   (IPEI). Ultimately, this study demonstrates the importance of LLMs in
   advancing precision medicine for BrCa and paves the way for effective
   patient-centered care solutions.
ZS 0
ZR 0
TC 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001466448900001
PM 40199412
ER

PT J
AU Bhayana, Rajesh
   Alwahbi, Omar
   Ladak, Aly Muhammad
   Deng, Yangqing
   Dias, Adriano Basso
   Elbanna, Khaled
   Gomez, Jorge Abreu
   Jajodia, Ankush
   Jhaveri, Kartik
   Johnson, Sarah
   Kajal, Dilkash
   Wang, David
   Soong, Christine
   Kielar, Ania
   Krishna, Satheesh
TI Leveraging Large Language Models to Generate Clinical Histories for
   Oncologic Imaging Requisitions
SO RADIOLOGY
VL 314
IS 2
AR e242134
DI 10.1148/radiol.242134
DT Article
PD FEB 2025
PY 2025
AB Background: Clinical information improves imaging interpretation, but
   physician-provided histories on requisitions for oncologic imaging often
   lack key details. Purpose: To evaluate large language models (LLMs) for
   automatically generating clinical histories for oncologic imaging
   requisitions from clinical notes and compare them with original
   requisition histories. Materials and Methods: In total, 207 patients
   with CT performed at a cancer center from January to November 2023 and
   with an electronic health record clinical note coinciding with ordering
   date were randomly selected. A multidisciplinary team informed selection
   of 10 parameters important for oncologic imaging history, including
   primary oncologic diagnosis, treatment history, and acute symptoms.
   Clinical notes were independently reviewed to establish the reference
   standard regarding presence of each parameter. After prompt engineering
   with seven patients, GPT-4 (version 0613; OpenAI) was prompted on April
   9, 2024, to automatically generate structured clinical histories for the
   200 remaining patients. Using the reference standard, LLM extraction
   performance was calculated (recall, precision, F1 score). LLM-generated
   and original requisition histories were compared for completeness
   (proportion including each parameter), and 10 radiologists performed
   pairwise comparison for quality, preference, and subjective likelihood
   of harm. Results: For the 200 LLM-generated histories, GPT-4 performed
   well, extracting oncologic parameters from clinical notes (F1 = 0.983).
   Compared with original requisition histories, LLM-generated histories
   more frequently included parameters critical for radiologist
   interpretation, including primary oncologic diagnosis (99.5% vs 89% [199
   and 178 of 200 histories, respectively]; P < .001), acute or worsening
   symptoms (15% vs 4% [29 and seven of 200]; P < .001), and relevant
   surgery (61% vs 12% [122 and 23 of 200]; P < .001). Radiologists
   preferred LLM-generated histories for imaging interpretation (89% vs 5%,
   7% equal; P < .001), indicating they would enable more complete
   interpretation (86% vs 0%, 15% equal; P < .001) and have a lower
   likelihood of harm (3% vs 55%, 42% neither; P < .001). Conclusion: An
   LLM enabled accurate automated clinical histories for oncologic imaging
   from clinical notes. Compared with original requisition histories,
   LLM-generated histories were more complete and were preferred by
   radiologists for imaging interpretation and perceived safety.
ZA 0
Z8 0
ZR 0
ZB 0
ZS 0
TC 1
Z9 1
DA 2025-03-08
UT WOS:001434851700023
PM 39903072
ER

PT J
AU Jain, Anish J.
   Boyev, Artem
   Azimuddin, Ahad M.
   Roland, Christina
   Newhook, Timothy E.
   Cao, Hop S. Tran
   Tzeng, Ching-Wei D.
   Vauthey, Jean-Nicolas
   Chun, Yun Shin
TI PROGNOSTIC FACTORS FOR SURGICAL RESECTION OF LEIOMYOSARCOMA LIVER
   METASTASIS
SO GASTROENTEROLOGY
VL 164
IS 6
MA 1093
BP S1501
EP S1501
SU S
DT Meeting Abstract
PD MAY 2023
PY 2023
CT Digestive Disease Week (DDW)
CY MAY 06-09, 2023
CL Chicago, IL
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
DA 2023-10-19
UT WOS:001040954706335
ER

PT C
AU Zhu, Jinyang
   Gong, Qingyue
   Zhou, Chunfang
   Luan, Huidan
GP Assoc Computing Machinery
TI ZhongJing: A Locally Deployed Large Language Model for Traditional
   Chinese Medicine and Corresponding Evaluation Methodology An LLM for the
   TCM Field and the Corresponding Evaluation Method
SO PROCEEDINGS OF 2023 4TH INTERNATIONAL SYMPOSIUM ON ARTIFICIAL
   INTELLIGENCE FOR MEDICINE SCIENCE, ISAIMS 2023
BP 1036
EP 1042
DI 10.1145/3644116.3644294
DT Proceedings Paper
PD 2023
PY 2023
AB The success of ChatGPT has showcased the potential applications of Large
   Language Models (LLMs) in the field of Traditional Chinese Medicine
   (TCM), encompassing areas such as medical diagnosis, adjunctive therapy,
   and TCM talent cultivation. However, the current challenges, including
   hardware constraints, insufficient model domain knowledge, and
   difficulties in domain-specific evaluation, have constrained the fusion
   of LLMs with TCM. In an attempt to address these issues, this paper
   introduces ZhongJing, a domain-specific LLM fine-tuned within the domain
   of TCM, capable of generating responses at a rate of 8 tokens per
   second, smoothly operating on local personal computers. To assess the
   model's domain expertise, this paper introduces the TCMEval evaluation
   method, designed concerning medical students' exams. Experimental
   results demonstrate that ZhongJing achieves a 6.49 TCMEval Score
   improvement over Chinese-LLaMA2 in the field of TCM, indicating the
   model's ability to generate more specialized responses compared to
   baseline models.
CT 4th International Symposium on Artificial Intelligence for Medicine
   Science (ISAIMS)
CY OCT 20-22, 2023
CL Chengdu, PEOPLES R CHINA
ZA 0
ZB 0
ZR 0
ZS 0
Z8 0
TC 2
Z9 2
DA 2024-07-18
UT WOS:001213963600173
ER

PT J
AU Shah, Krish
   Xu, Andrew Y.
   Sharma, Yatharth
   Daher, Mohammed
   Mcdonald, Christopher
   Diebo, Bassel G.
   Daniels, Alan H.
TI Large Language Model Prompting Techniques for Advancement in Clinical
   Medicine
SO JOURNAL OF CLINICAL MEDICINE
VL 13
IS 17
AR 5101
DI 10.3390/jcm13175101
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs have the potential to revolutionize clinical
   medicine by enhancing healthcare access, diagnosis, surgical planning,
   and education. However, their utilization requires careful, prompt
   engineering to mitigate challenges like hallucinations and biases.
   Proper utilization of LLMs involves understanding foundational concepts
   such as tokenization, embeddings, and attention mechanisms, alongside
   strategic prompting techniques to ensure accurate outputs. For
   innovative healthcare solutions, it is essential to maintain ongoing
   collaboration between AI technology and medical professionals. Ethical
   considerations, including data security and bias mitigation, are
   critical to their application. By leveraging LLMs as supplementary
   resources in research and education, we can enhance learning and support
   knowledge-based inquiries, ultimately advancing the quality and
   accessibility of medical care. Continued research and development are
   necessary to fully realize the potential of LLMs in transforming
   healthcare.
ZB 1
ZS 0
Z8 0
TC 9
ZA 0
ZR 0
Z9 9
DA 2024-09-21
UT WOS:001311343800001
PM 39274316
ER

PT J
AU Gilbert, M.
   Crutchfield, A.
   Luo, B.
   Thind, K.
   Ghanem, A. I.
   Siddiqui, F.
TI Using a Large Language Model (LLM) for Automated Extraction of Discrete
   Elements from Clinical Notes for Creation of Cancer Databases
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3371
BP E625
EP E625
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
ZA 0
ZS 0
ZB 0
ZR 0
TC 1
Z9 1
DA 2024-12-16
UT WOS:001325892302054
ER

PT J
AU Nasir, Khurram
   Blaha, Michael J.
   Budoff, Matthew J.
   Blankstien, Ron
   Agatston, Arthur S.
   Sibley, Christopher T.
   Shaw, Leslee J.
   Blumenthal, Roger S.
   Krumholz, Harlan
TI Eligibility for Lipid Lowering Therapy, Coronary Artery Calcification,
   and CHD Events - National Implications for the Appropriate Use of
   Preventive Pharmacotherapy: Multi-Ethnic Study of Atherosclerosis (MESA)
SO CIRCULATION
VL 126
IS 21
MA 16758
SU S
DT Meeting Abstract
PD NOV 20 2012
PY 2012
Z8 0
ZS 0
TC 0
ZR 0
ZA 0
ZB 0
Z9 0
DA 2012-11-20
UT WOS:000208885006271
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Liu, Jilei
   Shen, Hongru
   Chen, Kexin
   Li, Xiangchun
TI Large language model produces high accurate diagnosis of cancer from
   end-motif profiles of cell-free DNA
SO BRIEFINGS IN BIOINFORMATICS
VL 25
IS 5
AR bbae430
DI 10.1093/bib/bbae430
DT Article
PD SEP 2 2024
PY 2024
AB Instruction-tuned large language models (LLMs) demonstrate exceptional
   ability to align with human intentions. We present an LLM-based
   model-instruction-tuned LLM for assessment of cancer (iLLMAC)-that can
   detect cancer using cell-free deoxyribonucleic acid (cfDNA) end-motif
   profiles. Developed on plasma cfDNA sequencing data from 1135 cancer
   patients and 1106 controls across three datasets, iLLMAC achieved area
   under the receiver operating curve (AUROC) of 0.866 [95% confidence
   interval (CI), 0.773-0.959] for cancer diagnosis and 0.924 (95% CI,
   0.841-1.0) for hepatocellular carcinoma (HCC) detection using 16
   end-motifs. Performance increased with more motifs, reaching 0.886 (95%
   CI, 0.794-0.977) and 0.956 (95% CI, 0.89-1.0) for cancer diagnosis and
   HCC detection, respectively, with 64 end-motifs. On an external-testing
   set, iLLMAC achieved AUROC of 0.912 (95% CI, 0.849-0.976) for cancer
   diagnosis and 0.938 (95% CI, 0.885-0.992) for HCC detection with 64
   end-motifs, significantly outperforming benchmarked methods.
   Furthermore, iLLMAC achieved high classification performance on datasets
   with bisulfite and 5-hydroxymethylcytosine sequencing. Our study
   highlights the effectiveness of LLM-based instruction-tuning for
   cfDNA-based cancer detection.
ZA 0
ZR 0
Z8 0
ZB 1
TC 4
ZS 0
Z9 4
DA 2024-09-08
UT WOS:001304494500001
PM 39222060
ER

PT J
AU Park, SaYoon
   Chang-EopKim
TI Enhancing Korean Medicine Education with Large Language Models: Focusing
   on the Development of Educational Artificial Intelligence
Z1 거대언어모델을 활용한 한의학 교육 강화: 교육용 인공지능 개발을 중심으로
SO Journal of Physiology & Pathology in Korean Medicine
S1 동의생리병리학회지
VL 37
IS 5
BP 134
EP 138
DT research-article
PD 2023
PY 2023
AB Large language models (LLMs) have introduced groundbreaking innovations
   in various fields, including healthcare, where they augment medical
   diagnosis, decision-making, and facilitate patient-doctor communication
   through their exceptional contextual understanding and inferential
   abilities. In the realm of Korean medicine (KM), the utilization of LLMs
   is highly anticipated. However, it demands additional training with
   domain-specific KM data for seamless integration of KM knowledge. There
   are two predominant strategies for training domain-specific LLMs in the
   KM domain. The first approach entails direct manipulation of the LLM's
   internals by either pretraining a base model on an extensive corpus of
   KM data or fine-tuning a pretrained model's parameters using KM-related
   question-answering datasets. The second approach avoids internal model
   manipulation and leverages techniques like prompt engineering, retrieval
   augmented generation, and cognitive augmentation. Domain-specific LLMs
   specialized for KM hold the potential for diverse applications, ranging
   from personalized medical education plans and content generation to
   knowledge integration, curriculum development, automated student
   assessment, virtual patient simulations, and advanced research and
   scholarly activities. These advancements are poised to significantly
   impact the field of KM and medical education at large.
ZB 0
Z8 0
TC 0
ZA 0
ZS 0
ZR 0
Z9 0
DA 2023-01-01
UT KJD:ART003011785
ER

PT J
AU Savage, Thomas
   Wang, John
   Gallo, Robert
   Boukil, Abdessalem
   Patel, Vishwesh
   Safavi-Naini, Seyed Amir Ahmad
   Soroush, Ali
   Chen, Jonathan H.
TI Large language model uncertainty proxies: discrimination and calibration
   for medical diagnosis and treatment
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 32
IS 1
BP 139
EP 149
DI 10.1093/jamia/ocae254
EA OCT 2024
DT Article
PD OCT 12 2024
PY 2024
AB Introduction The inability of large language models (LLMs) to
   communicate uncertainty is a significant barrier to their use in
   medicine. Before LLMs can be integrated into patient care, the field
   must assess methods to estimate uncertainty in ways that are useful to
   physician-users.Objective Evaluate the ability for uncertainty proxies
   to quantify LLM confidence when performing diagnosis and treatment
   selection tasks by assessing the properties of discrimination and
   calibration.Methods We examined confidence elicitation (CE), token-level
   probability (TLP), and sample consistency (SC) proxies across GPT3.5,
   GPT4, Llama2, and Llama3. Uncertainty proxies were evaluated against 3
   datasets of open-ended patient scenarios.Results SC discrimination
   outperformed TLP and CE methods. SC by sentence embedding achieved the
   highest discriminative performance (ROC AUC 0.68-0.79), yet with poor
   calibration. SC by GPT annotation achieved the second-best
   discrimination (ROC AUC 0.66-0.74) with accurate calibration. Verbalized
   confidence (CE) was found to consistently overestimate model
   confidence.Discussion and Conclusions SC is the most effective method
   for estimating LLM uncertainty of the proxies evaluated. SC by sentence
   embedding can effectively estimate uncertainty if the user has a set of
   reference cases with which to re-calibrate their results, while SC by
   GPT annotation is the more effective method if the user does not have
   reference cases and requires accurate raw calibration. Our results
   confirm LLMs are consistently over-confident when verbalizing their
   confidence (CE).
ZS 0
ZA 0
ZB 2
TC 6
ZR 0
Z8 0
Z9 6
DA 2024-10-17
UT WOS:001330240100001
PM 39396184
ER

PT J
AU Rosskopf, Steffen
   Meder, Benjamin
TI Healthcare 4.0-Medizin im Wandel
SO HERZ
VL 49
IS 5
BP 350
EP 354
DI 10.1007/s00059-024-05267-w
EA AUG 2024
DT Review
PD OCT 2024
PY 2024
AB Healthcare 4.0 describes the future transformation of the healthcare
   sector driven by the combination of digital technologies, such as
   artificial intelligence (AI), big data and the Internet of Medical
   Things, enabling the advancement of precision medicine. This overview
   article addresses various areas such as large language models (LLM),
   diagnostics and robotics, shedding light on the positive aspects of
   Healthcare 4.0 and showcasing exciting methods and application examples
   in cardiology. It delves into the broad knowledge base and enormous
   potential of LLMs, highlighting their immediate benefits as digital
   assistants or for administrative tasks. In diagnostics, the increasing
   usefulness of wearables is emphasized and an AI for predicting heart
   filling pressures based on cardiac magnetic resonance imaging (MRI) is
   introduced. Additionally, it discusses the revolutionary methodology of
   a digital simulation of the physical heart (digital twin). Finally, it
   addresses both regulatory frameworks and a brief vision of data-driven
   healthcare delivery, explaining the need for investments in technical
   personnel and infrastructure to achieve a more effective medicine.
Z8 0
ZB 0
ZS 0
ZA 0
TC 0
ZR 0
Z9 0
DA 2024-08-14
UT WOS:001287384100001
PM 39115627
ER

PT J
AU Pugh, Samuel L.
   Chandler, Chelsea
   Cohen, Alex S.
   Diaz-Asper, Catherine
   Elvevag, Brita
   Foltz, Peter W.
TI Assessing dimensions of thought disorder with large language models: The
   tradeoff of accuracy and consistency
SO PSYCHIATRY RESEARCH
VL 341
AR 116119
DI 10.1016/j.psychres.2024.116119
EA SEP 2024
DT Article
PD NOV 2024
PY 2024
AB Natural Language Processing (NLP) methods have shown promise for the
   assessment of formal thought disorder, a hallmark feature of
   schizophrenia in which disturbances to the structure, organization, or
   coherence of thought can manifest as disordered or incoherent speech. We
   investigated the suitability of modern Large Language Models (LLMs-
   e.g., GPT-3.5, GPT-4, and Llama 3) to predict expert-generated ratings
   for three dimensions of thought disorder (coherence, content, and
   tangentiality) assigned to speech samples collected from both patients
   with a diagnosis of schizophrenia (n = 26) and healthy control
   participants (n = 25). In addition to (1) evaluating the accuracy of
   LLM-generated ratings relative to human experts, we also (2)
   investigated the degree to which the LLMs produced consistent ratings
   across multiple trials, and we (3) sought to understand the factors that
   impacted the consistency of LLM-generated output. We found that
   machine-generated ratings of the level of thought disorder in speech
   matched favorably those of expert humans, and we identified a tradeoff
   between accuracy and consistency in LLM ratings. Unlike traditional NLP
   methods, LLMs were not always consistent in their predictions, but these
   inconsistencies could be mitigated with careful parameter selection and
   ensemble methods. We discuss implications for NLP-based assessment of
   thought disorder and provide recommendations of best practices for
   integrating these methods in the field of psychiatry.
TC 2
ZS 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 2
DA 2024-09-16
UT WOS:001309569000001
PM 39226873
ER

PT B
AU Shubbar, Safa
Z2  
TI Advancing Autism Spectrum Disorder Diagnosis: A Phenotype-Genotype
   Co-Analysis and Retrieval-Augmented LLM Framework for Clinical Decision
   Support
DT Dissertation/Thesis
PD Jan 01 2025
PY 2025
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
UT PQDT:123210398
ER

PT J
AU Wada, Akihiko
   Akashi, Toshiaki
   Shih, George
   Hagiwara, Akifumi
   Nishizawa, Mitsuo
   Hayakawa, Yayoi
   Kikuta, Junko
   Shimoji, Keigo
   Sano, Katsuhiro
   Kamagata, Koji
   Nakanishi, Atsushi
   Aoki, Shigeki
TI Optimizing GPT-4 Turbo Diagnostic Accuracy in Neuroradiology through
   Prompt Engineering and Confidence Thresholds
SO DIAGNOSTICS
VL 14
IS 14
AR 1541
DI 10.3390/diagnostics14141541
DT Article
PD JUL 2024
PY 2024
AB Background and Objectives: Integrating large language models (LLMs) such
   as GPT-4 Turbo into diagnostic imaging faces a significant challenge,
   with current misdiagnosis rates ranging from 30-50%. This study
   evaluates how prompt engineering and confidence thresholds can improve
   diagnostic accuracy in neuroradiology. Methods: We analyze 751
   neuroradiology cases from the American Journal of Neuroradiology using
   GPT-4 Turbo with customized prompts to improve diagnostic precision.
   Results: Initially, GPT-4 Turbo achieved a baseline diagnostic accuracy
   of 55.1%. By reformatting responses to list five diagnostic candidates
   and applying a 90% confidence threshold, the highest precision of the
   diagnosis increased to 72.9%, with the candidate list providing the
   correct diagnosis at 85.9%, reducing the misdiagnosis rate to 14.1%.
   However, this threshold reduced the number of cases that responded.
   Conclusions: Strategic prompt engineering and high confidence thresholds
   significantly reduce misdiagnoses and improve the precision of the LLM
   diagnostic in neuroradiology. More research is needed to optimize these
   approaches for broader clinical implementation, balancing accuracy and
   utility.
Z8 0
ZS 0
ZR 0
ZA 0
TC 5
ZB 0
Z9 5
DA 2024-08-01
UT WOS:001276606000001
PM 39061677
ER

PT J
AU Choi, Hongyoon
   Lee, Dongjoo
   Kang, Yeon-koo
   Suh, Minseok
TI Empowering PET imaging reporting with retrieval-augmented large language
   models and reading reports database: a pilot single center study
SO EUROPEAN JOURNAL OF NUCLEAR MEDICINE AND MOLECULAR IMAGING
VL 52
IS 7
BP 2452
EP 2462
DI 10.1007/s00259-025-07101-9
EA JAN 2025
DT Article
PD JUN 2025
PY 2025
AB PurposeThe potential of Large Language Models (LLMs) in enhancing a
   variety of natural language tasks in clinical fields includes medical
   imaging reporting. This pilot study examines the efficacy of a
   retrieval-augmented generation (RAG) LLM system considering zero-shot
   learning capability of LLMs, integrated with a comprehensive database of
   PET reading reports, in improving reference to prior reports and
   decision making.MethodsWe developed a custom LLM framework with
   retrieval capabilities, leveraging a database of over 10 years of PET
   imaging reports from a single center. The system uses vector space
   embedding to facilitate similarity-based retrieval. Queries prompt the
   system to generate context-based answers and identify similar cases or
   differential diagnoses. From routine clinical PET readings, experienced
   nuclear medicine physicians evaluated the performance of system in terms
   of the relevance of queried similar cases and the appropriateness score
   of suggested potential diagnoses.ResultsThe system efficiently organized
   embedded vectors from PET reports, showing that imaging reports were
   accurately clustered within the embedded vector space according to the
   diagnosis or PET study type. Based on this system, a proof-of-concept
   chatbot was developed and showed the framework's potential in
   referencing reports of previous similar cases and identifying exemplary
   cases for various purposes. From routine clinical PET readings, 84.1% of
   the cases retrieved relevant similar cases, as agreed upon by all three
   readers. Using the RAG system, the appropriateness score of the
   suggested potential diagnoses was significantly better than that of the
   LLM without RAG. Additionally, it demonstrated the capability to offer
   differential diagnoses, leveraging the vast database to enhance the
   completeness and precision of generated reports.ConclusionThe
   integration of RAG LLM with a large database of PET imaging reports
   suggests the potential to support clinical practice of nuclear medicine
   imaging reading by various tasks of AI including finding similar cases
   and deriving potential diagnoses from them. This study underscores the
   potential of advanced AI tools in transforming medical imaging reporting
   practices.
ZR 0
Z8 0
TC 1
ZS 0
ZB 0
ZA 0
Z9 1
DA 2025-01-25
UT WOS:001401835700001
PM 39843863
ER

PT J
AU Hua, Rui
   Dong, Xin
   Wei, Yu
   Shu, Zixin
   Yang, Pengcheng
   Hu, Yunhui
   Zhou, Shuiping
   Sun, He
   Yan, Kaijing
   Yan, Xijun
   Chang, Kai
   Li, Xiaodong
   Bai, Yuning
   Zhang, Runshun
   Wang, Wenjia
   Zhou, Xuezhong
TI Lingdan: enhancing encoding of traditional Chinese medicine knowledge
   for clinical reasoning tasks with large language models
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
DI 10.1093/jamia/ocae087
EA JUL 2024
DT Article; Early Access
PY 2024
AB Objective The recent surge in large language models (LLMs) across
   various fields has yet to be fully realized in traditional Chinese
   medicine (TCM). This study aims to bridge this gap by developing a large
   language model tailored to TCM knowledge, enhancing its performance and
   accuracy in clinical reasoning tasks such as diagnosis, treatment, and
   prescription recommendations.Materials and Methods This study harnessed
   a wide array of TCM data resources, including TCM ancient books,
   textbooks, and clinical data, to create 3 key datasets: the TCM
   Pre-trained Dataset, the Traditional Chinese Patent Medicine (TCPM)
   Question Answering Dataset, and the Spleen and Stomach Herbal
   Prescription Recommendation Dataset. These datasets underpinned the
   development of the Lingdan Pre-trained LLM and 2 specialized models: the
   Lingdan-TCPM-Chat Model, which uses a Chain-of-Thought process for
   symptom analysis and TCPM recommendation, and a Lingdan Prescription
   Recommendation model (Lingdan-PR) that proposes herbal prescriptions
   based on electronic medical records.Results The Lingdan-TCPM-Chat and
   the Lingdan-PR Model, fine-tuned on the Lingdan Pre-trained LLM,
   demonstrated state-of-the art performances for the tasks of TCM clinical
   knowledge answering and herbal prescription recommendation. Notably,
   Lingdan-PR outperformed all state-of-the-art baseline models, achieving
   an improvement of 18.39% in the Top@20 F1-score compared with the best
   baseline.Conclusion This study marks a pivotal step in merging advanced
   LLMs with TCM, showcasing the potential of artificial intelligence to
   help improve clinical decision-making of medical diagnostics and
   treatment strategies. The success of the Lingdan Pre-trained LLM and its
   derivative models, Lingdan-TCPM-Chat and Lingdan-PR, not only
   revolutionizes TCM practices but also opens new avenues for the
   application of artificial intelligence in other specialized medical
   fields. Our project is available at
   https://github.com/TCMAI-BJTU/LingdanLLM.
Z8 4
ZR 0
ZA 0
ZS 0
TC 7
ZB 0
Z9 11
DA 2024-07-28
UT WOS:001273695100001
PM 39038795
ER

PT J
AU Rush, Benjamin
   Binkley, Neil
   Krueger, Diane
   Yamada, Yosuke
   Kuchnia, Adam J.
TI Combination of DXA and BIS Predicts Jump Power Better Than Traditional
   Measures of Sarcopenia
SO JBMR PLUS
VL 5
IS 8
AR e10527
DI 10.1002/jbm4.10527
DT Article
PD AUG 2021
PY 2021
AB Traditional diagnostic criteria for sarcopenia use dual-energy X-ray
   absorptiometry (DXA)-measured appendicular lean mass (ALM), normalized
   to height (ALM/ht(2)) or body mass index (ALM/BMI) to define low muscle
   mass. However, muscle function declines with aging before the loss of
   muscle mass is detected by ALM. This is likely due, in part, to
   qualitative muscle changes such as extracellular and intracellular fluid
   compartment shifts uncaptured by DXA. We propose combining bioimpedance
   spectroscopy (BIS), which estimates extracellular and intracellular
   compartment volume, with DXA to more accurately predict muscle function.
   This combination may help incorporate muscle quality, thereby improving
   sarcopenia diagnosis. We cross-sectionally analyzed data from 248 Black
   and White participants aged 25 to 75 years from the Midlife in the
   United States Refresher Cohort. We proposed two novel muscle measures:
   ALM corrected by the BIS-derived whole-body extracellular to
   intracellular fluid ratio (E/I) and leg lean mass (LLM) corrected by
   leg-specific E/I, creating (ALM/(E/I)(W)) and (LLM/(E/I)(L)),
   respectively. We compared the associations of traditional muscle
   measures, ALM/(E/I)(W), and LLM/(E/I)(L), with grip strength and lower
   limb power using jumping mechanography. LLM/(E/I)(L) explained jump
   power best at R-2 = 0.803 compared with ALM/(E/I)(W) (p < 0.0001) and
   all other measures. ALM/(E/I)(W) explained jump power second best (R-2 =
   0.759) but not significantly better than traditional muscle measures. No
   muscle measure performed better than covariates when predicting handgrip
   strength. LLM/(E/I)(L) outperformed ALM/ht(2) and ALM/BMI when
   predicting jump power. We propose LLM/(E/I)(L) is a powerful and
   clinically relevant method that accounts for muscle quality. (c) 2021
   The Authors. JBMR Plus published by Wiley Periodicals LLC on behalf of
   American Society for Bone and Mineral Research.
TC 9
ZS 0
ZA 0
Z8 1
ZR 0
ZB 5
Z9 11
DA 2021-10-15
UT WOS:000704606600007
PM 34368612
ER

PT J
AU Meng, Xiangbin
   Yan, Xiangyu
   Zhang, Kuo
   Liu, Da
   Cui, Xiaojuan
   Yang, Yaodong
   Zhang, Muhan
   Cao, Chunxia
   Wang, Jingjia
   Wang, Xuliang
   Gao, Jun
   Wang, Yuan-Geng-Shuo
   Ji, Jia-ming
   Qiu, Zifeng
   Li, Muzi
   Qian, Cheng
   Guo, Tianze
   Ma, Shuangquan
   Wang, Zeying
   Guo, Zexuan
   Lei, Youlan
   Shao, Chunli
   Wang, Wenyao
   Fan, Haojun
   Tang, Yi-Da
TI The application of large language models in medicine: A scoping review
SO ISCIENCE
VL 27
IS 5
AR 109713
DI 10.1016/j.isci.2024.109713
EA MAY 2024
DT Review
PD MAY 17 2024
PY 2024
AB This study systematically reviewed the application of large language
   models (LLMs) in medicine, analyzing 550 selected studies from a vast
   literature search. LLMs like ChatGPT transformed healthcare by enhancing
   diagnostics, medical writing, education, and project management. They
   assisted in drafting medical documents, creating training simulations,
   and streamlining research processes. Despite their growing utility in
   assisted diagnosis and improving doctor -patient communication,
   challenges persisted, including limitations in contextual understanding
   and the risk of over -reliance. The surge in LLM-related research
   indicated a focus on medical writing, diagnostics, and patient
   communication, but highlighted the need for careful integration,
   considering validation, ethical concerns, and the balance with
   traditional medical practice. Future research directions suggested a
   focus on multimodal LLMs, deeper algorithmic understanding, and ensuring
   responsible, effective use in healthcare.
ZR 0
Z8 0
ZS 0
ZB 7
ZA 0
TC 57
Z9 57
DA 2024-06-12
UT WOS:001240677700001
PM 38746668
ER

PT J
AU Mbadjeu Hondjeu, Arnaud Romeo
   Zhao, Zi Ying
   Newton, Luka
   Ajenkar, Anass
   Hladkowicz, Emily
   Ladha, Karim
   Wijeysundera, Duminda N.
   Mcisaac, Daniel I.
TI Large language models in perioperative medicine-applications and future
   prospects: a narrative review
SO CANADIAN JOURNAL OF ANESTHESIA-JOURNAL CANADIEN D ANESTHESIE
DI 10.1007/s12630-025-02980-w
EA JUN 2025
DT Review; Early Access
PY 2025
AB PurposeLarge language models (LLMs) are a subset of artificial
   intelligence (AI) and linguistics designed to help computers understand
   and analyze human language. Clinical applications of LLMs have recently
   been recognised for their potential enhanced analytic capacity.
   Availability and performance of LLMs are expected to increase
   substantially over time with a significant impact on patient care and
   health care provider workflow. Despite increasing recognition of LLMs,
   insights on the utilities, associated benefits and limitations are
   scarce among perioperative clinicians. In this narrative review, we
   delve into the functionalities and prospects of existing LLMs and their
   clinical application in perioperative medicine. Furthermore, we
   summarize challenges and constraints that must be addressed to fully
   realize the potential of LLMs.SourceWe searched MEDLINE, Google Scholar,
   and PubMed (R) databases for articles referencing LLMs in perioperative
   care.Principal findingsWe found that in the perioperative setting (from
   surgical diagnosis to discharge postoperatively), LLMs have the
   potential to improve the efficiency and accuracy of health care delivery
   by extracting and summarizing clinical data, making recommendations on
   the basis of these findings, as well as addressing patient queries.
   Moreover, LLMs can be used for clinical decision-making support,
   surveillance tools, predictive modelling, and enhancement of medical
   research and education.ConclusionsThe integration of LLMs into
   perioperative medicine presents a significant opportunity to enhance
   patient care, clinical decision-making, and operational efficiency.
   These models can streamline processes, provide personalized patient
   education, and offer robust decision support. Nevertheless, their
   clinical implementation requires addressing several key challenges,
   including managing hallucinations, ensuring data security, and
   mitigating inherent biases. If these challenges are met, LLMs can
   revolutionize perioperative practice, improving both patient outcomes
   and clinician workflow.
   ObjectifLes grands mod & egrave;les de langage (LLM) sont & agrave; la
   crois & eacute;e des chemins de l'intelligence artificielle (IA) et de
   la linguistique et sont con & ccedil;us pour aider les ordinateurs &
   agrave; comprendre et analyser le langage humain. Les applications
   cliniques des LLM ont r & eacute;cemment & eacute;t & eacute; reconnues
   pour leur capacit & eacute; analytique potentiellement am & eacute;lior
   & eacute;e. La disponibilit & eacute; et les performances des LLM
   devraient augmenter consid & eacute;rablement au fil du temps, ce qui
   aura un impact significatif sur les soins & agrave; la patient &
   egrave;le et le flux de travail des prestataires de soins de sant &
   eacute;. Malgr & eacute; la reconnaissance croissante des LLM, les &
   eacute;quipes cliniques p & eacute;riop & eacute;ratoires ont peu
   d'informations sur leurs utilit & eacute;s, ainsi que sur les avantages
   et limites qui y sont associ & eacute;s. Dans ce compte rendu narratif,
   nous nous penchons sur les fonctionnalit & eacute;s et les perspectives
   des LLM existants et leur application clinique en m & eacute;decine p &
   eacute;riop & eacute;ratoire. Nous r & eacute;sumons & eacute;galement
   les d & eacute;fis et les contraintes qui doivent & ecirc;tre abord &
   eacute;s pour r & eacute;aliser pleinement le potentiel des
   LLM.SourcesNous avons recherch & eacute; des articles faisant r &
   eacute;f & eacute;rence & agrave; des LLM en soins p & eacute;riop &
   eacute;ratoires dans les bases de donn & eacute;es MEDLINE, Google
   Scholar et PubMed (R).Constatations principalesNous avons constat &
   eacute; que dans le cadre p & eacute;riop & eacute;ratoire (du
   diagnostic chirurgical au cong & eacute; postop & eacute;ratoire), les
   LLM ont le potentiel d'am & eacute;liorer l'efficacit & eacute; et la pr
   & eacute;cision de la prestation des soins de sant & eacute; en
   extrayant et en r & eacute;sumant les donn & eacute;es cliniques, en
   formulant des recommandations sur la base de ces r & eacute;sultats,
   ainsi qu'en r & eacute;pondant aux questions des patients et patientes.
   De plus, les LLM peuvent & ecirc;tre utilis & eacute;s pour l'aide &
   agrave; la prise de d & eacute;cision clinique, les outils de
   surveillance, la mod & eacute;lisation pr & eacute;dictive et l'am &
   eacute;lioration de la recherche m & eacute;dicale et de l'&
   eacute;ducation.ConclusionL'int & eacute;gration des LLM dans la m &
   eacute;decine p & eacute;riop & eacute;ratoire repr & eacute;sente une
   opportunit & eacute; majeure d'am & eacute;liorer les soins & agrave; la
   patient & egrave;le, la prise de d & eacute;cision clinique et
   l'efficacit & eacute; op & eacute;rationnelle. Ces mod & egrave;les
   peuvent rationaliser les processus, fournir une & eacute;ducation
   personnalis & eacute;e & agrave; la patient & egrave;le et offrir une
   aide & agrave; la d & eacute;cision solide. N & eacute;anmoins, leur
   mise en oe uvre clinique n & eacute;cessite de relever plusieurs d &
   eacute;fis cl & eacute;s, notamment la prise en charge des
   hallucinations, la s & eacute;curit & eacute; des donn & eacute;es et
   l'att & eacute;nuation des pr & eacute;jug & eacute;s inh &
   eacute;rents. Si ces d & eacute;fis sont relev & eacute;s, les LLM
   pourraient r & eacute;volutionner la pratique p & eacute;riop &
   eacute;ratoire, en am & eacute;liorant & agrave; la fois les devenirs
   pour la patient & egrave;le et le flux de travail des & eacute;quipes
   cliniques.
ZA 0
Z8 0
ZS 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-06-12
UT WOS:001504392500001
PM 40490617
ER

PT J
AU Wu, Shao-Hong
   Tong, Wen-Juan
   Li, Ming-De
   Hu, Hang-Tong
   Lu, Xiao-Zhou
   Huang, Ze-Rong
   Lin, Xin-Xin
   Lu, Rui-Fang
   Lu, Ming-De
   Chen, Li-Da
   Wang, Wei
TI Collaborative Enhancement of Consistency and Accuracy in US Diagnosis of
   Thyroid Nodules Using Large Language Models
SO RADIOLOGY
VL 310
IS 3
AR e232255
DI 10.1148/radiol.232255
DT Article
PD MAR 2024
PY 2024
AB Background: Large language models (LLMs) hold substantial promise for
   medical imaging interpretation. However, there is a lack of studies on
   their feasibility in handling reasoning questions associated with
   medical diagnosis. Purpose: To investigate the viability of leveraging
   three publicly available LLMs to enhance consistency and diagnostic
   accuracy in medical imaging based on standardized reporting, with
   pathology as the reference standard. Materials and Methods: US images of
   thyroid nodules with pathologic results were retrospectively collected
   from a tertiary referral hospital between July 2022 and December 2022
   and used to evaluate malignancy diagnoses generated by three
   LLMs-OpenAI's ChatGPT 3.5, ChatGPT 4.0, and Google's Bard. Inter- and
   intra-LLM agreement of diagnosis were evaluated. Then, diagnostic
   performance, including accuracy, sensitivity, specificity, and area
   under the receiver operating characteristic curve (AUC), was evaluated
   and compared for the LLMs and three interactive approaches: human reader
   combined with LLMs, image -to -text model combined with LLMs, and an end
   -to -end convolutional neural network model. Results: A total of 1161 US
   images of thyroid nodules (498 benign, 663 malignant) from 725 patients
   (mean age, 42.2 years +/- 14.1 [SD]; 516 women) were evaluated. ChatGPT
   4.0 and Bard displayed substantial to almost perfect intra-LLM agreement
   (kappa range, 0.65-0.86 [95% CI: 0.64, 0.86]), while ChatGPT 3.5 showed
   fair to substantial agreement (kappa range, 0.36-0.68 [95% CI: 0.36,
   0.68]). ChatGPT 4.0 had an accuracy of 78%-86% (95% CI: 76%, 88%) and
   sensitivity of 86%-95% (95% CI: 83%, 96%), compared with 74%-86% (95%
   CI: 71%, 88%) and 74%-91% (95% CI: 71%, 93%), respectively, for Bard.
   Moreover, with ChatGPT 4.0, the image-to-text-LLM strategy exhibited an
   AUC (0.83 [95% CI: 0.80, 0.85]) and accuracy (84% [95% CI: 82%, 86%])
   comparable to those of the human-LLM interaction strategy with two
   senior readers and one junior reader and exceeding those of the
   human-LLM interaction strategy with one junior reader. Conclusion: LLMs,
   particularly integrated with image -to -text approaches, show potential
   in enhancing diagnostic medical imaging. ChatGPT 4.0 was optimal for
   consistency and diagnostic accuracy when compared with Bard and ChatGPT
   3.5. (c) RSNA, 2024 Supplemental material is available for this article.
Z8 3
ZA 0
ZR 0
TC 23
ZB 3
ZS 0
Z9 25
DA 2024-06-21
UT WOS:001208969200035
PM 38470237
ER

PT J
AU Kashyap, Aditya M.
   Rao, Delip
   Boland, Mary Regina
   Shen, Li
   Callison-Burch, Chris
TI Predicting explainable dementia types with LLM-aided feature engineering
SO BIOINFORMATICS
VL 41
IS 4
AR btaf156
DI 10.1093/bioinformatics/btaf156
DT Article
PD APR 2025
PY 2025
AB Motivation The integration of Machine Learning and Artificial
   Intelligence (AI) into healthcare has immense potential due to the
   rapidly growing volume of clinical data. However, existing AI models,
   particularly Large Language Models (LLMs) like GPT-4, face significant
   challenges in terms of explainability and reliability, particularly in
   high-stakes domains like healthcare.Results This paper proposes a novel
   LLM-aided feature engineering approach that enhances interpretability by
   extracting clinically relevant features from the Oxford Textbook of
   Medicine. By converting clinical notes into concept vector
   representations and employing a linear classifier, our method achieved
   an accuracy of 0.72, outperforming a traditional n-gram Logistic
   Regression baseline (0.64) and the GPT-4 baseline (0.48), while focusing
   on high-level clinical features. We also explore using Text Embeddings
   to reduce the overall time and cost of our approach by 97%.Availability
   and implementation All code relevant to this paper is available at:
   https://github.com/AdityaKashyap423/Dementia_LLM_Feature_Engineering/tre
   e/main.
TC 0
ZR 0
ZS 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-02
UT WOS:001473768800001
PM 40199828
ER

PT J
AU Sun, Virginia
   Heemelaar, Julius
   Hadzic, Ibrahim
   Raghu, Vineet
   Wu, Chia-Yun
   Zubiri, Leyre
   Ghamari, Azin
   Suero-Abreu, Giselle
   Wu, Jessica
   Hathaway, Nora
   Gilman, Hannah
   Villani, Alexandra-Chloe
   Ho, Sam
   Zlotoff, Daniel
   Blum, Steven
   Sullivan, Ryan
   Reynolds, Kerry
   Neilan, Tomas
TI Enhancing early detection of ICI myocarditis cases during
   hospitalization: A role for large language models
SO CIRCULATION
VL 150
MA 4119426
DI 10.1161/circ.150.suppl_1.4119426
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
TC 0
ZA 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
DA 2025-02-10
UT WOS:001398742700200
ER

PT J
AU Zhuang, Yi
   Yu, Lingkai
   Jiang, Nan
   Ge, Yujia
TI TCM-KLLaMA: Intelligent generation model for Traditional Chinese
   Medicine Prescriptions based on knowledge graph and large language
   model.
SO Computers in biology and medicine
VL 189
BP 109887
EP 109887
DI 10.1016/j.compbiomed.2025.109887
DT Journal Article
PD 2025-May
PY 2025
AB Traditional Chinese medicine (TCM) prescriptions are a basic component
   of TCM treatment, developed by assessing patient symptoms and
   prescribing a mix of herbs. Accurate prescription generation is critical
   for enhancing treatment outcomes and maintaining patient safety.
   However, conventional methods based on Large Language Models (LLMs)
   focus mainly on symptom information, neglecting other TCM diagnostic
   expertise, such as tongue and pulse diagnosis, and are prone to
   hallucination, which is unacceptable in medical applications. To address
   these challenges, the paper proposes an effective prescription
   generation model enriched by a TCM knowledge graph (KG) called the
   TCM-KLLaMA model. In this model, the Chinese-LLaMA2-7B model is provided
   with a new output layer and loss function to suppress hallucinations and
   increase recommendation accuracy. A TCM KG including symptoms, tongue
   diagnosis, and pulse diagnosis was developed, and the model was
   fine-tuned utilizing the suggested synonym and matching knowledge
   injection (SMKI) mechanism. Extensive experiments demonstrate that the
   TCM- KLLaMA outperforms baseline models in both Precision and F1 Score,
   proving its superior performance in prescription generation tasks.
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-03-11
UT MEDLINE:40056842
PM 40056842
ER

PT J
AU Liu, Xiaohong
   Liu, Hao
   Yang, Guoxing
   Jiang, Zeyu
   Cui, Shuguang
   Zhang, Zhaoze
   Wang, Huan
   Tao, Liyuan
   Sun, Yongchang
   Song, Zhu
   Hong, Tianpei
   Yang, Jin
   Gao, Tianrun
   Zhang, Jiangjiang
   Li, Xiaohu
   Zhang, Jing
   Sang, Ye
   Yang, Zhao
   Xue, Kanmin
   Wu, Song
   Zhang, Ping
   Yang, Jian
   Song, Chunli
   Wang, Guangyu
TI A generalist medical language model for disease diagnosis assistance
SO NATURE MEDICINE
VL 31
IS 3
DI 10.1038/s41591-024-03416-6
EA JAN 2025
DT Article
PD MAR 2025
PY 2025
AB The delivery of accurate diagnoses is crucial in healthcare and
   represents the gateway to appropriate and timely treatment. Although
   recent large language models (LLMs) have demonstrated impressive
   capabilities in few-shot or zero-shot learning, their effectiveness in
   clinical diagnosis remains unproven. Here we present MedFound, a
   generalist medical language model with 176 billion parameters,
   pre-trained on a large-scale corpus derived from diverse medical text
   and real-world clinical records. We further fine-tuned MedFound to learn
   physicians' inferential diagnosis with a self-bootstrapping
   strategy-based chain-of-thought approach and introduced a unified
   preference alignment framework to align it with standard clinical
   practice. Extensive experiments demonstrate that our medical LLM
   outperforms other baseline LLMs and specialized models in
   in-distribution (common diseases), out-of-distribution (external
   validation) and long-tailed distribution (rare diseases) scenarios
   across eight specialties. Further ablation studies indicate the
   effectiveness of key components in our medical LLM training approach. We
   conducted a comprehensive evaluation of the clinical applicability of
   LLMs for diagnosis involving artificial intelligence (AI) versus
   physician comparison, AI-assistance study and human evaluation
   framework. Our proposed framework incorporates eight clinical evaluation
   metrics, covering capabilities such as medical record summarization,
   diagnostic reasoning and risk management. Our findings demonstrate the
   model's feasibility in assisting physicians with disease diagnosis as
   part of the clinical workflow.
Z8 0
ZB 0
ZA 0
ZS 0
TC 3
ZR 0
Z9 3
DA 2025-01-13
UT WOS:001391696700001
PM 39779927
ER

PT J
AU Dhingra, Lovedeep
   Shankar, Sumukh Vasisht
   Biswas, Dhruva
   Aminorroaya, Arya
   Sangha, Veer
   Camargos, Aline Pedroso
   Oikonomou, Evangelos K.
   Khera, Rohan
TI AUTOMATED DETECTION OF OCCLUSIVE MYOCARDIAL INFARCTION FROM IMAGES OF
   ELECTROCARDIOGRAMS USING DEEP LEARNING
SO JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY
VL 85
IS 12
MA 936-21
BP 1756
EP 1756
SU S
DT Meeting Abstract
PD APR 1 2025
PY 2025
CT Annual Meeting of the American-College-of-Cardiology (ACC)
CY MAR 29-31, 2025
CL Chicago, IL
SP Amer Coll Cardiol
ZS 0
ZB 0
ZA 0
TC 0
Z8 0
ZR 0
Z9 0
DA 2025-04-18
UT WOS:001463305700005
ER

PT J
AU Borrelli, O.
   Battaglia, M.
   Galos, F.
   Aloi, M.
   De Angelis, D.
   Moretti, C.
   Mancini, V.
   Cucchiara, S.
   Midulla, F.
TI Non-acid gastro-oesophageal reflux in children with suspected pulmonary
   aspiration
SO DIGESTIVE AND LIVER DISEASE
VL 42
IS 2
BP 115
EP 121
DI 10.1016/j.dld.2009.06.011
DT Article
PD FEB 2010
PY 2010
AB Background & aims: In a group of children with suspected pulmonary
   aspiration, we aimed to describe the type and physical characteristics
   of gastro-oesophageal reflux (GOR) episodes, and to determine their
   correlation with the lipid-laden macrophage (LLM) content in
   bronchoalveolar lavage (BAL).
   Patients and methods: Twenty-one children with a diagnosis of bronchial
   asthma, recurrent lung consolidations and recurrent laryngotracheitis
   underwent 24-h multichannel intraluminal impedance and pH (MII-pH)
   monitoring, fibreoptic bronchoscopy and BAL. The following parameters
   were evaluated: total number of reflux episodes, number of acid reflux
   [AR: pH < 4] and non-acid reflux [NAR] episodes [pH > 4], height of
   reflux episodes, LLM content and percentage of neutrophils in the BAL.
   Results: The number of NAR episodes and the number of those reaching the
   proximal oesophagus were significantly higher in patients with recurrent
   lung consolidations than ill those with bronchial asthma and
   laryngotracheitis (p < 0.01 and p < 0.01). BAL studies showed a
   significantly higher LLM content in children with recurrent lung
   consolidations than in those with bronchial asthma and laryngotracheitis
   (p < 0.01). The LLM content correlated significantly with the total
   number of reflux episodes (r = 0.73; p < 0.001) and with those reaching
   the proximal oesophagus (r = 0.67: p < 0.001). Finally, the LLM content
   cot-related with the number of NAR episodes (r = 0.61: p < 0.01), with
   those reaching the proximal oesophagus (r = 0.64: p < 0.01) and with the
   percentage of BAL neutrophils (r = 0.7; p < 0.01).
   Conclusion: NAR episodes reaching the proximal oesophagus correlate with
   diagnostic marker for Pulmonary micro-aspiration. MII-pH monitoring
   increases the yield in identifying types and proximal extension of
   reflux episodes, that discriminate between patients with and without
   pulmonary aspiration. (C) 2009 Editrice Gastroenterologica Italiana
   S.r.l. Published by Elsevier Ltd. All rights reserved.
ZS 1
ZB 9
ZR 0
Z8 0
ZA 0
TC 24
Z9 24
DA 2010-02-01
UT WOS:000274988900006
PM 19640811
ER

PT J
AU Yun, Hye Sun
   Bickmore, Timothy
TI Online Health Information-Seeking in the Era of Large Language Models:
   Cross-Sectional Web-Based Survey Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e68560
DI 10.2196/68560
DT Article
PD MAR 31 2025
PY 2025
AB Background: As large language model (LLM)-based chatbots such as ChatGPT
   (OpenAI) grow in popularity, it is essential to understand their role in
   delivering online health information compared to other resources. These
   chatbots often generate inaccurate content, posing potential safety
   risks. This motivates the need to examine how users perceive and act on
   health information provided by LLM-based chatbots. Objective: This study
   investigates the patterns, perceptions, and actions of users seeking
   health information online, including LLM-based chatbots. The
   relationships between online health information-seeking behaviors and
   important sociodemographic characteristics are examined as well.
   Methods: A web-based survey of crowd workers was conducted via Prolific.
   The questionnaire covered sociodemographic information, trust in health
   care providers, eHealth literacy, artificial intelligence (AI)
   attitudes, chronic health condition status, online health information
   source types, perceptions, and actions, such as cross-checking or
   adherence. Quantitative and qualitative analyses were applied. Results:
   Most participants consulted search engines (291/297, 98%) and
   health-related websites (203/297, 68.4%) for their health information,
   while21.2% (63/297) used LLM-based chatbots, with ChatGPT and Microsoft
   Copilot being the most popular. Most participants (268/297, 90.2%)
   sought information on health conditions, with fewer seeking advice on
   medication (179/297, 60.3%), treatments (137/297, 46.1%), and
   self-diagnosis (62/297, 23.2%). Perceived information quality and trust
   varied little across source types. The preferred source for validating
   information from the internet was consulting health care professionals
   (40/132, 30.3%), while only a very small percentage of participants
   (5/214, 2.3%) consulted AI tools to cross-check information from search
   engines and health-related websites. For information obtained from
   LLM-based chatbots,19.4% (12/63) of participants cross-checked the
   information, while 48.4% (30/63) of participants followed the advice.
   Both of these rates were lower than information from search engines,
   health-related websites, forums, or social media. Furthermore, use of
   LLM-based chatbots for health information was negatively correlated with
   age (rho=-0.16, P=.006). In contrast, attitudes surrounding AI for
   medicine had significant positive correlations with the number of source
   types consulted for health advice (rho=0.14, P=.01), use of LLM-based
   chatbotsfor health information (rho=0.31, P<.001), and number of health
   topics searched (rho=0.19, P<.001). Conclusions:Although traditional
   online sources remain dominant, LLM-based chatbots are emerging as a
   resource for health information for some users, specifically those who
   are younger and have a higher trust in AI. The perceived quality and
   trustworthiness of health information varied little across source types.
   However, the adherence to health information from LLM-based chatbots
   seemed more cautious compared to search engines or health-related
   websites. As LLMs continue to evolve, enhancing their accuracy and
   transparency will be essential in mitigating any potential risks by
   supporting responsible information-seeking while maximizing the
   potential of AI in health contexts.
ZR 0
Z8 0
TC 1
ZS 0
ZB 0
ZA 0
Z9 1
DA 2025-04-27
UT WOS:001470101200010
PM 40163112
ER

PT J
AU Arnold, Philipp
   Henkel, Maurice
   Bamberg, Fabian
   Kotter, Elmar
TI Integration of large language models into the clinic. Revolution in
   analysing and processing patient data to increase efficiency and quality
   in radiology
SO RADIOLOGIE
DI 10.1007/s00117-025-01431-3
EA MAR 2025
DT Review; Early Access
PY 2025
AB BackgroundLarge Language Models (LLMs) like ChatGPT, Llama and Claude
   are transforming healthcare by interpreting complex text, extracting
   information, and providing guideline-based support. Radiology, with its
   high patient volume and digital workflows, is a ideal field for LLM
   integration. ObjectiveAssessment of the potential of LLMs to enhance
   efficiency, standardization, and decision support in radiology, while
   addressing ethical and regulatory challenges. Material and methodsPilot
   studies at Freiburg and Basel university hospitals evaluated local LLM
   systems for tasks like prior report summarization and guideline-driven
   reporting. Integration with Picture Archiving and Communication System
   (PACS) and Electronic Health Record (EHR) systems was achieved via
   Digital Imaging and Communications in Medicine (DICOM) and Fast
   Healthcare Interoperability Resources (FHIR) standards. Metrics included
   time savings, compliance with the European Union (EU) Artificial
   Intelligence (AI) Act, and user acceptance. ResultsLLMs demonstrate
   significant potential as a support tool for radiologists in clinical
   practice by reducing reporting times, automating routine tasks, and
   ensuring consistent, high-quality results. They also support
   interdisciplinary workflows (e.g., tumor boards) and meet data
   protection requirements when locally implemented. DiscussionLocal LLM
   systems are feasible and beneficial in radiology, enhancing efficiency
   and diagnostic quality. Future work should refine transparency, expand
   applications, and ensure LLMs complement medical expertise while
   adhering to ethical and legal standards.
ZS 0
ZA 0
Z8 0
ZR 0
TC 0
ZB 0
Z9 0
DA 2025-03-26
UT WOS:001442977100001
PM 40072530
ER

PT J
AU Zheng, Ce
   Ye, Hongfei
   Guo, Jinming
   Yang, Junrui
   Fei, Ping
   Yuan, Yuanzhi
   Huang, Danqing
   Huang, Yuqiang
   Peng, Jie
   Xie, Xiaoling
   Xie, Meng
   Zhao, Peiquan
   Chen, Li
   Zhang, Mingzhi
TI Development and evaluation of a large language model of ophthalmology in
   Chinese
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1390
EP 1397
DI 10.1136/bjo-2023-324526
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background Large language models (LLMs), such as ChatGPT, have
   considerable implications for various medical applications. However,
   ChatGPT's training primarily draws from English-centric internet data
   and is not tailored explicitly to the medical domain. Thus, an
   ophthalmic LLM in Chinese is clinically essential for both healthcare
   providers and patients in mainland China.
   Methods We developed an LLM of ophthalmology (MOPH) using Chinese
   corpora and evaluated its performance in three clinical scenarios:
   ophthalmic board exams in Chinese, answering evidence-based
   medicine-oriented ophthalmic questions and diagnostic accuracy for
   clinical vignettes. Additionally, we compared MOPH's performance to that
   of human doctors.
   Results In the ophthalmic exam, MOPH's average score closely aligned
   with the mean score of trainees (64.7 (range 62-68) vs 66.2 (range
   50-92), p=0.817), but achieving a score above 60 in all seven mock
   exams. In answering ophthalmic questions, MOPH demonstrated an adherence
   of 83.3% (25/30) of responses following Chinese guidelines (Likert scale
   4-5). Only 6.7% (2/30, Likert scale 1-2) and 10% (3/30, Likert scale 3)
   of responses were rated as 'poor or very poor' or 'potentially
   misinterpretable inaccuracies' by reviewers. In diagnostic accuracy,
   although the rate of correct diagnosis by ophthalmologists was superior
   to that by MOPH (96.1% vs 81.1%, p>0.05), the difference was not
   statistically significant.
   Conclusion This study demonstrated the promising performance of MOPH, a
   Chinese-specific ophthalmic LLM, in diverse clinical scenarios. MOPH has
   potential real-world applications in Chinese-language ophthalmology
   settings.
ZS 0
ZA 0
TC 4
ZR 0
Z8 0
ZB 0
Z9 4
DA 2024-07-29
UT WOS:001274616900001
PM 39019566
ER

PT C
AU Labbe, Thomas
   Castel, Pierre
   Sanner, Jean-Michel
   Saleh, Majd
GP IEEE
TI ChatGPT for phenotypes extraction: one model to rule them all?
SO 2023 45TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN
   MEDICINE & BIOLOGY SOCIETY, EMBC
SE IEEE Engineering in Medicine and Biology Society Conference Proceedings
DI 10.1109/EMBC40787.2023.10340611
DT Proceedings Paper
PD 2023
PY 2023
AB Information Extraction (IE) is a core task in Natural Language
   Processing (NLP) where the objective is to identify factual knowledge in
   textual documents (often unstructured), and feed downstream use cases
   with the resulting output. In genomic medicine for instance, being able
   to extract the most precise list of phenotypes associated to a patient
   allows to improve genetic disease diagnostic, which represents a vital
   step in the modern deep phenotyping approach. As most of the phenotypic
   information lies in clinical reports, the challenge is to build an IE
   pipeline to automatically recognize phenotype concepts from free-text
   notes. A new machine learning paradigm around large language models
   (LLM) has given rise of an increasing number of academic works on this
   topic lately, where sophisticated combinations of different technics
   have been employed to improve the phenotypes extraction accuracy. Even
   more recently released, the ChatGPT1 application nevertheless raises the
   question of the relevance of these approches compared to this new
   generic one based on an instruction-oriented LLM. In this paper, we
   propose a rigorous evaluation of ChatGPT and the current
   state-of-the-art solutions on this specific task, and discuss the
   possible impacts and the technical evolutions to consider in the medical
   domain.
CT 45th Annual International Conference of the
   IEEE-Engineering-in-Medicine-and-Biology-Society (EMBC)
CY JUL 24-27, 2023
CL Sydney, AUSTRALIA
SP IEEE; IEEE Engn Med & Biol Soc
ZR 0
TC 3
Z8 0
ZA 0
ZB 2
ZS 0
Z9 3
DA 2024-02-23
UT WOS:001133788302189
PM 38082605
ER

PT J
AU Wang, Xu
   Mao, April W.
   Pan, Sirui
   Wang, Dawei
   He, Lili
   Vogel, Hannes
   Mao, Jian-Hua
   Weiss, William
   Li, Tao
   Chang, Hang
TI Cellular morphometric biomarkers and large language model predict
   prognosis and treatment response in neuroblastoma patients: A
   retrospective and double-blind prospective single arm clinical study
SO EUROPEAN JOURNAL OF CANCER
VL 218
AR 115273
DI 10.1016/j.ejca.2025.115273
EA FEB 2025
DT Article
PD MAR 11 2025
PY 2025
AB Background: The heterogeneity of Neuroblastoma (NB) leads to variation
   in response to treatment , outcomes. The aim of the current study is to
   discover AI-empowered cellular morphometric biomarkers (CMBs), to
   establish the corresponding CMB risk score (CMBRS), CMB risk group
   (CMBRG), large language model driven CMB risk score (CMB-LLM-RS) , large
   language model driven CMB risk group (CMB-LLM-RG), and to investigate
   and validate their prognostic and predictive power in NB. Methods: In
   this study, the retrospective cohort enrolled 84 primary NBs between
   1/2020 and 12/2021, followed up through 11/22/2024; the prospective
   cohort enrolled 67 primary NBs between 1/2022 and 7/2023, followed up
   through 11/22/2024. Results: We identified 9 CMBs from a retrospective
   NB cohort, enabling the CMBRS, CMBRG, CMB-LLM-RS, and CMB-LLM-RG. Both
   CMBRG and CMB-LLM-RG are significantly associated with prognosis (p <
   0.0001) and treatment response (p < 0.0001). Furthermore, we
   double-blindly validated the predictive power of CMBRG and CMB-LLM-RG in
   a prospective NB cohort, which confirms their potential value in real
   clinical settings. Impor- tantly, CMBRG provides clinical value
   independent of the International Neuroblastoma Risk Group (INRG)
   classification system in both retrospective and prospective NB cohorts
   (p < 0.05); and the combination of CMBRG and INRG significantly
   increases prognostic and predictive performance for NB patients.
   Conclusions: These findings suggest that CMBRG and CMB-LLM-RG have
   prognostic and predictive value for NB and warrants evaluation in larger
   multicenter cohorts.
ZA 0
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-02-23
UT WOS:001423930700001
PM 39908653
ER

PT J
AU Kozaily, Elie
   Geagea, Mabelissa
   Akdogan, Ecem R.
   Atkins, Jessica
   Elshazly, Mohamed B.
   Guglin, Maya
   Tedford, Ryan J.
   Wehbe, Ramsey M.
TI Accuracy and consistency of online large language model-based artificial
   intelligence chat platforms in answering patients' questions about heart
   failure
SO INTERNATIONAL JOURNAL OF CARDIOLOGY
VL 408
AR 132115
DI 10.1016/j.ijcard.2024.132115
EA MAY 2024
DT Article
PD AUG 1 2024
PY 2024
AB Background: Heart failure (HF) is a prevalent condition associated with
   significant morbidity. Patients may have questions that they feel
   embarrassed to ask or will face delays awaiting responses from their
   healthcare providers which may impact their health behavior. We aimed to
   investigate the potential of large language model (LLM) based artificial
   intelligence (AI) chat platforms in complementing the delivery of
   patient -centered care. Methods: Using online patient forums and
   physician experience, we created 30 questions related to diagnosis,
   management and prognosis of HF. The questions were posed to two
   LLM-based AI chat platforms (OpenAI's ChatGPT-3.5 and Google's Bard).
   Each set of answers was evaluated by two HF experts, independently and
   blinded to each other, for accuracy (adequacy of content) and
   consistency of content. Results: ChatGPT provided mostly appropriate
   answers (27/30, 90%) and showed a high degree of consistency (93%). Bard
   provided a similar content in its answers and thus was evaluated only
   for adequacy (23/30, 77%). The two HF experts' grades were concordant in
   83% and 67% of the questions for ChatGPT and Bard, respectively.
   Conclusion: LLM-based AI chat platforms demonstrate potential in
   improving HF education and empowering patients, however, these platforms
   currently suffer from issues related to factual errors and difficulty
   with more contemporary recommendations. This inaccurate information may
   pose serious and life -threatening implications for patients that should
   be considered and addressed in future research.
TC 13
ZB 0
ZS 0
ZR 0
ZA 0
Z8 0
Z9 13
DA 2024-06-15
UT WOS:001240180400001
PM 38697402
ER

PT J
AU Franke, Georg-Nikolaus
   Maier, Jacqueline
   Wildenberger, Kathrin
   Guenther, Christine
   Cross, Michael
   Ernst, Thomas
   Fabisch, Christian
   Niederwieser, Dietger
   Hochhaus, Andreas
   Lange, Thoralf
TI Incidence of Low Level Mutations in Newly Diagnosed CML Patients: A
   Substudy of the German Tiger Trial
SO BLOOD
VL 130
MA 252
SU 1
DT Meeting Abstract
PD DEC 7 2017
PY 2017
CT 59th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2017
CL Atlanta, GA
ZR 0
Z8 0
ZA 0
ZS 0
TC 2
ZB 1
Z9 2
DA 2018-07-13
UT WOS:000432419400307
ER

PT J
AU Abi-Rafeh, Jad
   Mroueh, Vanessa J.
   Bassiri-Tehrani, Brian
   Marks, Jacob
   Kazan, Roy
   Nahai, Foad
TI Complications Following Body Contouring: Performance Validation of Bard,
   a Novel AI Large Language Model, in Triaging and Managing Postoperative
   Patient Concerns
SO AESTHETIC PLASTIC SURGERY
VL 48
IS 5
BP 953
EP 976
DI 10.1007/s00266-023-03819-9
EA JAN 2024
DT Article
PD MAR 2024
PY 2024
AB Introduction Large language models (LLM) have revolutionized the way
   humans interact with artificial intelligence (AI) technology, with
   marked potential for applications in esthetic surgery. The present study
   evaluates the performance of Bard, a novel LLM, in identifying and
   managing postoperative patient concerns for complications following body
   contouring surgery.Methods The American Society of Plastic Surgeons'
   website was queried to identify and simulate all potential postoperative
   complications following body contouring across different acuities and
   severity. Bard's accuracy was assessed in providing a differential
   diagnosis, soliciting a history, suggesting a most-likely diagnosis,
   appropriate disposition, treatments/interventions to begin from home,
   and red-flag signs/symptoms indicating deterioration, or requiring
   urgent emergency department (ED) presentation.Results Twenty-two
   simulated body contouring complications were examined. Overall, Bard
   demonstrated a 59% accuracy in listing relevant diagnoses on its
   differentials, with a 52% incidence of incorrect or misleading
   diagnoses. Following history-taking, Bard demonstrated an overall
   accuracy of 44% in identifying the most-likely diagnosis, and a 55%
   accuracy in suggesting the indicated medical dispositions. Helpful
   treatments/interventions to begin from home were suggested with a 40%
   accuracy, whereas red-flag signs/symptoms, indicating deterioration,
   were shared with a 48% accuracy. A detailed analysis of performance,
   stratified according to latency of postoperative presentation (<48hours,
   48hours-1month, or >1month postoperatively), and according to acuity and
   indicated medical disposition, is presented herein.Conclusions Despite
   promising potential of LLMs and AI in healthcare-related applications,
   Bard's performance in the present study significantly falls short of
   accepted clinical standards, thus indicating a need for further research
   and development prior to adoption.Level of Evidence IV This journal
   requires that authors assign a level of evidence to each article. For a
   full description of these Evidence-Based Medicine ratings, please refer
   to the Table of Contents or the online Instructions to Authors
   www.springer.com/00266.
ZS 0
ZB 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-02-03
UT WOS:001150315000001
PM 38273152
ER

PT J
AU Fougere, Bertrand
   Sourdet, Sandrine
   Lilamand, Matthieu
   Tabue-Teguod, Maturin
   Teysseyre, Bernard
   Dupuy, Charlotte
   Vellas, Bruno
   Rolland, Yves
   Nourhashemi, Fati
   van Kan, Gabor Abellan
TI Untangling the overlap between frailty and low lean mass: Data from
   Toulouse frailty day hospital
SO ARCHIVES OF GERONTOLOGY AND GERIATRICS
VL 75
BP 209
EP 213
DI 10.1016/j.archger.2017.12.013
DT Article
PD MAR-APR 2018
PY 2018
AB Background: The decline in lean mass, observed in older people, has been
   frequently associated with frailty. This assumption has scarcely been
   assessed. This study explored the association between current proposed
   definitions of low lean mass and the Fried phenotype of frailty.
   Methods: Cross-sectional study. Participants admitted to the Toulouse
   frailty day hospital, with an assessment of body composition, 70 years
   or older were included consecutively in the study. Low lean mass (LLM),
   was identified using five international operative definitions. To
   construct the definitions, muscle mass was assessed using Intelligent
   Dual Energy X-ray absorptiometry (I-DXA, LUNAR). Frailty was assessed
   using the Fried criteria.
   Results: Data from 283 participants, mean age 82 years and 71% of women
   were analyzed. LLM was identified between 8.5% and 39.2% of the
   participants according to the different definitions. Frailty was
   identified in 46.6% of the sample. 9.1%-48.5% of the frail older people
   had LLM depending on the definition. The highest association between
   frailty and LLM was observed with the definition proposed by the
   Foundation for the National Institutes of Health (FNIH) Sarcopenia
   Project [adjusted Odds Ratio 2.64; 95% confidence interval 1.5-4.8].
   Conclusion: The decline in lean mass is a component of the frailty
   syndrome but not universally present. Indeed, LLM and frailty were
   associated and partly overlapped. Future research including longitudinal
   studies should exploit the added value of combining LLM and frailty
   measures in preventing disability and other negative health outcomes.
TC 8
ZA 0
ZR 0
ZS 0
ZB 3
Z8 0
Z9 8
DA 2018-03-13
UT WOS:000426105800032
PM 29426485
ER

PT J
AU Vrdoljak, Josip
   Boban, Zvonimir
   Males, Ivan
   Skrabic, Roko
   Kumric, Marko
   Ottosen, Anna
   Clemencau, Alexander
   Bozic, Josko
   Volker, Sebastian
TI Evaluating large language and large reasoning models as decision support
   tools in emergency internal medicine.
SO Computers in biology and medicine
VL 192
IS Pt B
BP 110351
EP 110351
DI 10.1016/j.compbiomed.2025.110351
DT Journal Article
PD 2025-Jun
PY 2025
AB BACKGROUND: Large Language Models (LLMs) hold promise for clinical
   decision support, but their real-world performance varies. We compared
   three leading models (OpenAI's "o1" Large Reasoning Model (LRM),
   Anthropic's Claude-3.5-Sonnet, and Meta's Llama-3.2-70B) to human
   experts in an emergency internal medicine setting.
   METHODS: We conducted a prospective comparative study on 73 anonymized
   patient cases from the Emergency Internal Medicine ward of the
   University Hospital Split, Croatia (June-September 2024). Two
   independent internal medicine specialists, blinded to model identity,
   graded the LLM-generated reports in two steps: (1) they evaluated the
   relevance of recommended diagnostic tests based on the patient's signs,
   symptoms, and medical history; (2) after reviewing the actual diagnostic
   test results, they assessed each model's final diagnosis, therapy plan,
   and follow-up recommendations. The same evaluative framework was applied
   to human-authored reports. Likert scales (1-4 or 1-3) were used, and
   statistical comparisons included the Friedman and Wilcoxon signed-rank
   tests.
   RESULTS: The o1 model achieved a mean final rating (3.63) statistically
   indistinguishable from human physicians (3.67; p=0.62).
   Claude-3.5-Sonnet (3.38) and Llama-3.2-70B (3.23) scored significantly
   lower (p<0.01 vs. o1), largely due to errors in therapy planning and
   non-medication recommendations. Despite this gap, all three models
   demonstrated ≥90% accuracy in final diagnoses and patient admission
   decisions. The o1 model correctly classified all abnormal lab values
   (100%), while Claude-3.5-Sonnet and Llama-3.2-70B showed minor errors
   (99.5% and 99% accuracy, respectively).
   CONCLUSIONS: When evaluated on real-world emergency cases, an advanced
   LLM with enhanced reasoning (o1) can match expert-level clinical
   performance, underscoring its potential utility as a decision-support
   tool.
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
TC 0
Z9 0
DA 2025-05-16
UT MEDLINE:40359675
PM 40359675
ER

PT J
AU Claure-Del Granado, Rolando
   Moya-Mamani, Juan C.
   Malhotra, Rakesh
   Dasgupta, Subhasis
TI Performance of an Artificial Intelligence-Generated Risk Score for AKI
   Prediction
SO JOURNAL OF THE AMERICAN SOCIETY OF NEPHROLOGY
VL 35
IS 10
MA FR-PO036
DI 10.1681/ASN.202482byjb75
SU S
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Kidney Week
CY OCT 24-27, 2024
CL San Diego, CA
Z8 0
TC 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 0
DA 2025-03-21
UT WOS:001405917800150
ER

PT J
AU McCrary, Myles R.
   Galambus, Justine
   Chen, Wei-Shen
TI Evaluating the diagnostic performance of a large language model-powered
   chatbot for providing immunohistochemistry recommendations in
   dermatopathology
SO JOURNAL OF CUTANEOUS PATHOLOGY
VL 51
IS 9
BP 689
EP 695
DI 10.1111/cup.14631
EA MAY 2024
DT Article
PD SEP 2024
PY 2024
AB BackgroundLarge language model (LLM)-powered chatbots such as ChatGPT
   have numerous applications. However, their effectiveness in
   dermatopathology has not been formally evaluated. Dermatopathological
   cases often require immunohistochemical workup. Here, we evaluate the
   performance of a chatbot in providing diagnostically useful information
   on immunohistochemistry relating to dermatological diseases.MethodsWe
   queried a commonly used chatbot for the immunophenotypes of 51 cutaneous
   diseases, including a diverse variety of epidermal, adnexal,
   hematolymphoid, and soft tissue entities. We requested it to provide
   references for each diagnosis. All tests were repeated, compiled,
   quantified, and then compared with established literature
   standards.ResultsClustering analysis demonstrated that recommendations
   correlated with tumor type, suggesting chatbots can supply appropriate
   panels. However, a significant portion of recommendations were factually
   incorrect (13.9%). Citations were rarely clinically useful (24.5%). Many
   were confabulated (27.2%). Prompt responses for cutaneous adnexal
   lesions tended to be less accurate while literature references were less
   useful. Reference retrieval performance was associated with the number
   of PubMed entries per entity.ConclusionsThis foundational study suggests
   that LLM-powered chatbots may be useful for generating
   immunohistochemical panels for dermatologic diagnoses. However, specific
   performance capabilities and biases must be considered. In addition,
   extreme caution is advised regarding the tendencies to fabricate
   material. Future models intentionally fine-tuned to augment diagnostic
   medicine may prove to be valuable.
Z8 1
ZB 2
ZS 0
ZR 0
TC 4
ZA 0
Z9 5
DA 2024-05-23
UT WOS:001221968800001
PM 38744501
ER

PT J
AU Rutledge, Geoffrey W.
TI Diagnostic accuracy of GPT-4 on common clinical scenarios and
   challenging cases
SO LEARNING HEALTH SYSTEMS
VL 8
IS 3
DI 10.1002/lrh2.10438
EA JUN 2024
DT Article
PD JUL 2024
PY 2024
AB Introduction: Large language models (LLMs) have a high diagnostic
   accuracy when they evaluate previously published clinical cases.
   Methods: We compared the accuracy of GPT-4's differential diagnoses for
   previously unpublished challenging case scenarios with the diagnostic
   accuracy for previously published cases. Results: For a set of
   previously unpublished challenging clinical cases, GPT-4 achieved 61.1%
   correct in its top 6 diagnoses versus the previously reported 49.1% for
   physicians. For a set of 45 clinical vignettes of more common clinical
   scenarios, GPT-4 included the correct diagnosis in its top 3 diagnoses
   100% of the time versus the previously reported 84.3% for physicians.
   Conclusions: GPT-4 performs at a level at least as good as, if not
   better than, that of experienced physicians on highly challenging cases
   in internal medicine. The extraordinary performance of GPT-4 on
   diagnosing common clinical scenarios could be explained in part by the
   fact that these cases were previously published and may have been
   included in the training dataset for this LLM.
TC 3
ZR 0
ZB 0
Z8 0
ZS 0
ZA 0
Z9 3
DA 2024-07-08
UT WOS:001254090000001
PM 39036534
ER

PT J
AU Nascimento, Jose Jerovane da Costa
   Marques, Adriell Gomes
   Souza, Lucas do Nascimento
   Dourado, Carlos Mauricio Jaborandy de Mattos
   Barros, Antonio Carlos da Silva
   de Albuquerque, Victor Hugo C.
   Sousa, Luis Fabricio de Freitas
TI A novel generative model for brain tumor detection using magnetic
   resonance imaging
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
VL 121
AR 102498
DI 10.1016/j.compmedimag.2025.102498
EA FEB 2025
DT Article
PD APR 2025
PY 2025
AB Brain tumors area disease that kills thousands of people worldwide each
   year. Early identification through diagnosis is essential for monitoring
   and treating patients. The proposed study brings anew method through
   intelligent computational cells that are capable of segmenting the tumor
   region with high precision. The method uses deep learning to detect
   brain tumors with the "You only look once"(Yolov8) framework, and a
   fine-tuning process at the end of the network layer using intelligent
   computational cells capable of traversing the detected region,
   segmenting the edges of the brain tumor. In addition, the method uses a
   classification pipeline that combines a set of classifiers and
   extractors combined with grid search, to find the best combination and
   the best parameters for the dataset. The method obtained satisfactory
   results above 98% accuracy for region detection, and above 99% for brain
   tumor segmentation and accuracies above 98% for binary classification of
   brain tumor, and segmentation time obtaining less than 1 s, surpassing
   the state of the art compared to the same database, demonstrating the
   effectiveness of the proposed method. The new approach proposes the
   classification of different databases through data fusion to classify
   the presence of tumor in MRI images, as well as the patient's life span.
   The segmentation and classification steps are validated by comparing
   them with the literature, with comparisons between works that used the
   same dataset. The method addresses anew generative AI for brain tumor
   capable of generating a pre-diagnosis through input data through Large
   Language Model (LLM), and can be used in systems to aid medical imaging
   diagnosis. As a contribution, this study employs new detection models
   combined with innovative methods based on digital image processing to
   improve segmentation metrics, as well as the use of Data Fusion,
   combining two tumor datasets to enhance classification performance. The
   study also utilizes LLM models to refine the pre-diagnosis obtained
   post-classification. Thus, this study proposes a Computer-Aided
   Diagnosis (CAD) method through AI with PDI, CNN, and LLM.
TC 0
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
Z9 0
DA 2025-03-03
UT WOS:001431977700001
PM 39985841
ER

PT J
AU Cardamone, Nicholas C.
   Olfson, Mark
   Schmutte, Timothy
   Ungar, Lyle
   Liu, Tony
   Cullen, Sara W.
   Williams, Nathaniel J.
   Marcus, Steven C.
TI Classifying Unstructured Text in Electronic Health Records for Mental
   Health Prediction Models: Large Language Model Evaluation Study
SO JMIR MEDICAL INFORMATICS
VL 13
AR e65454
DI 10.2196/65454
DT Article
PD 2025
PY 2025
AB Background: Prediction models have demonstrated a range of applications
   across medicine, including using electronic health record (EHR) data to
   identify hospital readmission and mortality risk. Large language models
   (LLMs) can transform unstructured EHR text into structured features,
   which can then be integrated into statistical prediction models,
   ensuring that the results are both clinically meaningful and
   interpretable. Objective: This study aims to compare the classification
   decisions made by clinical experts with those generated by a
   state-of-the-art LLM, using terms extracted from a large EHR data set of
   individuals with mental health disorders seen in emergency departments
   (EDs). Methods: Using a dataset from the EHR systems of more than 50
   health care provider organizations in the United States from 2016 to
   2021, we extracted all clinical terms that appeared in at least 1000
   records of individuals admitted to the ED for a mental health-related
   problem from a source population of over 6 million ED episodes. Two
   experienced mental health clinicians (one medically trained psychiatrist
   and one clinical psychologist) reached consensus on the classification
   of EHR terms and diagnostic codes into categories. We evaluated an LLM's
   agreement with clinical judgment across three classification tasks as
   follows: (1) classify terms into "mental health" or "physical health",
   (2) classify mental health terms into 1 of 42 prespecified categories,
   and (3) classify physical health terms into 1 of 19 prespecified broad
   categories. Results: There was high agreement between the LLM and
   clinical experts when categorizing 4553 terms as "mental health" or
   "physical health" (kappa=0.77, 95% CI 0.75-0.80). However, there was
   still considerable variability in LLM-clinician agreement on the
   classification of mental health terms (kappa=0.62, 95% CI 0.59-0.66) and
   physical health terms (kappa=0.69, 95% CI 0.67-0.70). Conclusions: The
   LLM displayed high agreement with clinical experts when classifying EHR
   terms into certain mental health or physical health term categories.
   However, agreement with clinical experts varied considerably within both
   sets of mental and physical health term categories. Importantly, the use
   of LLMs presents an alternative to manual human coding, presenting great
   potential to create interpretable features for prediction models.
ZS 0
TC 2
ZR 0
ZA 0
ZB 0
Z8 0
Z9 2
DA 2025-02-14
UT WOS:001415993800001
PM 39864953
ER

PT J
AU Bannett, Yair
   Gunturkun, Fatma
   Pillai, Malvika
   Herrmann, Jessica E.
   Luo, Ingrid
   Huffman, Lynne C.
   Feldman, Heidi M.
TI Applying Large Language Models to Assess Quality of Care: Monitoring
   ADHD Medication Side Effects
SO PEDIATRICS
VL 155
IS 1
AR e2024067223
DI 10.1542/peds.2024-067223
DT Article
PD JAN 1 2024
PY 2024
AB OBJECTIVE: To assess the accuracy of a large language model (LLM) in
   measuring clinician adherence to practice guidelines for monitoring side
   effects after prescribing medications for children with
   attention-deficit/hyperactivity disorder (ADHD). METHODS: Retrospective
   population-based cohort study of electronic health records. Cohort
   included children aged 6 to 11 years with ADHD diagnosis and 2 or more
   ADHD medication encounters (stimulants or nonstimulants prescribed)
   between 2015 and 2022 in a community-based primary health care network
   (n = 1201). To identify documentation of side effects inquiry, we
   trained, tested, and deployed an open-source LLM (LLaMA) on all clinical
   notes from ADHD-related encounters (ADHD diagnosis or ADHD medication
   prescription), including in-clinic/telehealth and telephone encounters
   (n = 15 628 notes). Model performance was assessed using holdout and
   deployment test sets, compared with manual medical record review.
   RESULTS: The LLaMA model accurately classified notes that contained side
   effects inquiry (sensitivity = 87.2, specificity = 86.3, area under
   curve = 0.93 on holdout test set). Analyses revealed no model bias in
   relation to patient sex or insurance. Mean age (SD) at first
   prescription was 8.8 (1.6) years; characteristics were mostly similar
   across patients with and without documented side effects inquiry. Rates
   of documented side effects inquiry were lower for telephone encounters
   than for in-clinic/telehealth encounters (51.9% vs 73.0%, P < .001).
   Side effects inquiry was documented in 61.4% of encounters after
   stimulant prescriptions and 48.5% of encounters after nonstimulant
   prescriptions (P = .041). CONCLUSIONS: Deploying an LLM on a variable
   set of clinical notes, including telephone notes, offered scalable
   measurement of quality of care and uncovered opportunities to improve
   psychopharmacological medication management in primary care.
ZR 0
TC 1
Z8 0
ZS 0
ZA 0
ZB 0
Z9 1
DA 2025-03-23
UT WOS:001445125700006
PM 39701141
ER

PT J
AU Doshi, Jalpa A.
   Zhu, Jingsan
   Volpp, Kevin
TI Impact of a prescription copayment increase on lipid lowering medication
   adherence in veterans
SO CIRCULATION
VL 117
IS 21
MA 10
BP E412
EP E412
DT Meeting Abstract
PD MAY 27 2008
PY 2008
CT 9th Scientific Forum on Quality of Care and Outcomes Research in
   Cardiovascular Disease and Stroke
CY APR 30-MAY 02, 2008
CL Baltimore, MD
ZR 0
ZB 0
ZA 0
ZS 0
TC 0
Z8 0
Z9 0
DA 2008-05-27
UT WOS:000256160700030
ER

PT J
AU John, Annette
   Alhajj, Reda
   Rokne, Jon
TI A systematic review of AI as a digital twin for prostate cancer care
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 268
AR 108804
DI 10.1016/j.cmpb.2025.108804
EA MAY 2025
DT Review
PD AUG 2025
PY 2025
AB Artificial Intelligence (AI) and Digital Twin (DT) technologies are
   rapidly transforming healthcare, offering the potential for
   personalized, accurate, and efficient medical care. This systematic
   review focuses on the intersection of AI-based digital twins and their
   applications in prostate cancer pathology. A digital twin, when applied
   to healthcare, creates a dynamic, data-driven virtual model that
   simulates a patient's biological systems in real-time. By incorporating
   AI techniques such as Machine Learning (ML) and Deep Learning (DL),
   these systems enhance predictive accuracy, enable early diagnosis, and
   facilitate individualized treatment strategies for prostate cancer. This
   review systematically examines recent advances (2020-2025) in AI-driven
   digital twins for prostate cancer, highlighting key methodologies,
   algorithms, and data integration strategies. The literature analysis
   also reveals substantial progress in image processing, predictive
   modeling, and clinical decision support systems, which are the basic
   tools used when implementing digital twins for prostate cancer care. Our
   survey also critically evaluates the strengths and limitations of
   current approaches, identifying gaps such as the need for real-time data
   integration, improved explainability in AI models, and more robust
   clinical validation. It concludes with a discussion of future research
   directions, emphasizing the importance of integrating multi-modal data
   with Large Language Models (LLMs) and Vision-Language Models (VLMs),
   scalability, and ethical considerations in advancing AI-driven digital
   twins for prostate cancer diagnosis and treatment. This paper provides a
   comprehensive resource for researchers and clinicians, offering insights
   into how AI-based digital twins can enhance precision medicine and
   improve patient outcomes in prostate cancer care.
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
DA 2025-05-23
UT WOS:001490802200002
PM 40347618
ER

PT J
AU Sarma, Karthik
   Hanss, Kaitlin
   Glowinski, Anne
   Halls, Andrew
   Krystal, Andrew
   Butte, Atul
TI Can Large Language Model-Based AI Reason About Behavioral Health?
   Preliminary Evaluation of a Decision Tree-Based LLM Algorithm for
   Psychiatric Case Diagnosis
SO NEUROPSYCHOPHARMACOLOGY
VL 49
MA P44
BP 90
EP 91
SU 1
DT Meeting Abstract
PD DEC 2024
PY 2024
CT 63rd Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP)
CY DEC 08-11, 2023
CL Phoenix, AZ
SP Amer Coll Neuropsychopharmacol
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
ZA 0
Z9 0
DA 2025-02-23
UT WOS:001421429700202
ER

PT J
AU Wang, Ling
   Li, Jinglin
   Zhuang, Boyang
   Huang, Shasha
   Fang, Meilin
   Wang, Cunze
   Li, Wen
   Zhang, Mohan
   Gong, Shurong
TI Accuracy of Large Language Models When Answering Clinical Research
   Questions: Systematic Review and Network Meta-Analysis
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e64486
DI 10.2196/64486
DT Review
PD APR 30 2025
PY 2025
AB Background: Large language models (LLMs) have flourished and gradually
   become an important research and application direction in the medical
   field. However, due to the high degree of specialization, complexity,
   and specificity of medicine, which results in extremely high accuracy
   requirements, controversy remains about whether LLMscan be used in the
   medical field. More studies have evaluated the performance of various
   types of LLMs in medicine, but the conclusions are inconsistent.
   Objective: This study uses a network meta-analysis (NMA) to assess the
   accuracy of LLMs when answering clinical research questions to provide
   high-level evidence-based evidence for its future development and
   application in the medical field. Methods: In this systematic review and
   NMA, we searched PubMed, Embase, Web of Science, and Scopus from
   inception until October 14, 2024. Studies on the accuracy of LLMs when
   answering clinical research questions were included and screened by
   reading published reports. The systematic review and NMA were conducted
   to compare the accuracy of different LLMs when answering clinical
   research questions, including objective questions, open-ended questions,
   top 1 diagnosis, top 3 diagnosis, top 5 diagnosis, and triage and
   classification. The NMA was performed using Bayesian frequency theory
   methods. Indirect intercomparisons between programs were performed using
   a grading scale. A larger surface under the cumulative ranking curve
   (SUCRA) value indicates a higher ranking of the corresponding LLM
   accuracy. Results: The systematic review and NMA examined 168 articles
   encompassing 35,896 questions and 3063 clinical cases. Of the 168
   studies, 40 (23.8%) were considered to have a low risk of bias, 128
   (76.2%) had a moderate risk, and none were rated as having a high risk.
   ChatGPT-4o (SUCRA=0.9207) demonstrated strong performance in terms of
   accuracy for objective questions, followed by Aeyeconsult (SUCRA=0.9187)
   and ChatGPT-4 (SUCRA=0.8087). ChatGPT-4 (SUCRA=0.8708) excelled at
   answering open-ended questions. In terms of accuracy for top 1 diagnosis
   and top 3 diagnosis of clinical cases, human experts (SUCRA=0.9001 and
   SUCRA=0.7126, respectively) rankedthehighest, whileClaude3 Opus
   (SUCRA=0.9672) performed well at the top 5 diagnosis. Gemini
   (SUCRA=0.9649) had the highest rated SUCRA value for accuracy in the
   area of triage and classification. Conclusions: Our study indicates that
   ChatGPT-4o has an advantage when answering objective questions. For
   open-ended questions, ChatGPT-4 may be more credible. Humans are more
   accurate at the top 1 diagnosis and top 3 diagnosis. Claude 3 Opus
   performs better atthetop5diagnosis, whilefortriage and classification,
   Gemini is more advantageous. This analysis offers valuable insights for
   clinicians and medical practitioners, empowering them to effectively
   leverage LLMs for improved decision-making in learning, diagnosis, and
   management of various clinical scenarios.
ZB 0
ZA 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-05-30
UT WOS:001495307800003
PM 40305085
ER

PT J
AU Li, Hongyang
   Gerkin, Richard C.
   Bakke, Alyssa
   Norel, Raquel
   Cecchi, Guillermo
   Laudamiel, Christophe
   Niv, Masha Y.
   Ohla, Kathrin
   Hayes, John E.
   Parma, Valentina
   Meyer, Pablo
TI Text-based predictions of COVID-19 diagnosis from self-reported
   chemosensory descriptions
SO COMMUNICATIONS MEDICINE
VL 3
IS 1
AR 104
DI 10.1038/s43856-023-00334-5
DT Article
PD JUL 27 2023
PY 2023
AB Background There is a prevailing view that humans' capacity to use
   language to characterize sensations like odors or tastes is poor,
   providing an unreliable source of information.
   Methods Here, we developed a machine learning method based on Natural
   Language Processing (NLP) using Large Language Models (LLM) to predict
   COVID-19 diagnosis solely based on text descriptions of acute changes in
   chemosensation, i.e., smell, taste and chemesthesis, caused by the
   disease. The dataset of more than 1500 subjects was obtained from survey
   responses early in the COVID-19 pandemic, in Spring 2020.
   Results When predicting COVID-19 diagnosis, our NLP model performs
   comparably (AUC ROC similar to 0.65) to models based on self-reported
   changes in function collected via quantitative rating scales. Further,
   our NLP model could attribute importance of words when performing the
   prediction; sentiment and descriptive words such as "smell", "taste",
   "sense", had strong contributions to the predictions. In addition,
   adjectives describing specific tastes or smells such as "salty",
   "sweet", "spicy", and "sour" also contributed considerably to
   predictions.
   Conclusions Our results show that the description of perceptual symptoms
   caused by a viral infection can be used to fine-tune an LLM model to
   correctly predict and interpret the diagnostic status of a subject. In
   the future, similar models may have utility for patient verbatims from
   online health portals or electronic health records.
ZB 1
ZR 0
Z8 0
ZA 0
TC 3
ZS 0
Z9 3
DA 2023-08-22
UT WOS:001037431200001
PM 37500763
ER

PT C
AU Jiang, Yixing
   Irvin, Jeremy A.
   Ng, Andrew Y.
   Zou, James
BE Hunter, L
   Altman, RB
   Ritchie, MD
   Murray, T
   Klein, TE
TI VetLLM: Large Language Model for Predicting Diagnosis from Veterinary
   Notes
SO BIOCOMPUTING 2024, PSB 2024
SE Biocomputing-Pacific Symposium on Biocomputing
BP 120
EP 133
DT Proceedings Paper
PD 2024
PY 2024
AB Lack of diagnosis coding is a barrier to leveraging veterinary notes for
   medical and public health research. Previous work is limited to develop
   specialized rule-based or customized supervised learning models to
   predict diagnosis coding, which is tedious and not easily transferable.
   In this work, we show that open-source large language models (LLMs)
   pretrained on general corpus can achieve reasonable performance in a
   zero-shot setting. Alpaca-7B can achieve a zero-shot F1 of 0.538 on CSU
   test data and 0.389 on PP test data, two standard benchmarks for coding
   from veterinary notes. Furthermore, with appropriate fine-tuning, the
   performance of LLMs can be substantially boosted, exceeding those of
   strong state-of-the-art supervised models. VetLLM, which is fine-tuned
   on Alpaca-7B using just 5000 veterinary notes, can achieve a F1 of 0.747
   on CSU test data and 0.637 on PP test data. It is of note that our
   fine-tuning is data-efficient: using 200 notes can outperform supervised
   models trained with more than 100,000 notes. The findings demonstrate
   the great potential of leveraging LLMs for language processing tasks in
   medicine, and we advocate this new paradigm for processing clinical
   text.
CT 29th Pacific Symposium on Biocomputing (PSB)
CY JAN 03-07, 2024
CL Kohala Coast, HI
ZS 0
ZR 0
Z8 0
ZB 0
TC 1
ZA 0
Z9 1
DA 2024-08-02
UT WOS:001258333100010
PM 38160274
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Assessing the use of the novel tool Claude 3 in comparison to ChatGPT
   4.0 as an artificial intelligence tool in the diagnosis and therapy of
   primary head and neck cancer cases
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6099
EP 6109
DI 10.1007/s00405-024-08828-1
EA AUG 2024
DT Article
PD NOV 2024
PY 2024
AB ObjectivesHead and neck squamous cell carcinoma (HNSCC) is a complex
   malignancy that requires a multidisciplinary tumor board approach for
   individual treatment planning. In recent years, artificial intelligence
   tools have emerged to assist healthcare professionals in making informed
   treatment decisions. This study investigates the application of the
   newly published LLM Claude 3 Opus compared to the currently most
   advanced LLM ChatGPT 4.0 for the diagnosis and therapy planning of
   primary HNSCC. The results were compared to that of a conventional
   multidisciplinary tumor board; (2) Materials and Methods: We conducted a
   study in March 2024 on 50 consecutive primary head and neck cancer
   cases. The diagnostics and MDT recommendations were compared to the
   Claude 3 Opus and ChatGPT 4.0 recommendations for each patient and rated
   by two independent reviewers for the following parameters: clinical
   recommendation, explanation, and summarization in addition to the
   Artificial Intelligence Performance Instrument (AIPI); (3) Results: In
   this study, Claude 3 achieved better scores for the diagnostic workup of
   patients than ChatGPT 4.0 and provided treatment recommendations
   involving surgery, chemotherapy, and radiation therapy. In terms of
   clinical recommendations, explanation and summarization Claude 3 scored
   similar to ChatGPT 4.0, listing treatment recommendations which were
   congruent with the MDT, but failed to cite the source of the
   information; (4) Conclusion: This study is the first analysis of Claude
   3 for primary head and neck cancer cases and demonstrates a superior
   performance in the diagnosis of HNSCC than ChatGPT 4.0 and similar
   results for therapy recommendations. This marks the advent of a newly
   launched advanced AI model that may be superior to ChatGPT 4.0 for the
   assessment of primary head and neck cancer cases and may assist in the
   clinical diagnostic and MDT setting.
   Claude 3 OpusHNSCCMultidisciplinary TumorboardArtificial IntelligenceLLM
ZA 0
ZS 0
ZB 4
TC 17
Z8 0
ZR 0
Z9 17
DA 2024-08-13
UT WOS:001285919100001
PM 39112556
ER

PT J
AU Bhayana, Rajesh
   Jajodia, Ankush
   Chawla, Tanya
   Deng, Yangqing
   Bouchard-Fortier, Genevieve
   Haider, Masoom
   Krishna, Satheesh
TI Accuracy of Large Language Model-based Automatic Calculation of
   Ovarian-Adnexal Reporting and Data System MRI Scores from Pelvic MRI
   Reports
SO RADIOLOGY
VL 315
IS 1
AR e241554
DI 10.1148/radiol.241554
DT Article
PD APR 2025
PY 2025
AB Background: Ovarian-Adnexal Reporting and Data System (O-RADS) for MRI
   helps assign malignancy risk, but radiologist adoption is inconsistent.
   Automatic assignment of O-RADS scores from reports could increase
   adoption and accuracy. Purpose: To evaluate the accuracy of large
   language models (LLMs), after strategic optimization, for automatically
   calculating O-RADS scores from reports. Materials and Methods: This
   retrospective single-center study from a large quaternary care cancer
   center included consecutive gadolinium chelate-enhanced pelvic MRI
   reports with at least one assigned O-RADS score from July 2021 to
   October 2023. Reports from January 2018 to October 2019 (before O-RADS
   MRI implementation) were randomly selected for additional testing.
   Reference standard O-RADS scores were determined by radiologists
   interpreting reports. After prompt optimization using a subset of
   reports, two LLM-based strategies were evaluated: few-shot learning with
   GPT-4 (version 0613; OpenAI) prompted with O-RADS rules ("LLM only") and
   a hybrid strategy leveraging GPT-4 to classify features fed into a
   deterministic formula ("hybrid"). Accuracy of each model and originally
   reported scores were calculated and compared using the McNemar test.
   Results: A total of 284 reports from 284 female patients (mean age, 53.2
   years +/- 16.3 [SD]) with 372 adnexal lesions were included: 10 reports
   in the training set (16 lesions), 134 reports in the internal test set 1
   (173 lesions; 158 O-RADS assigned), and 140 reports in internal test set
   2 (183 lesions). For assigning O-RADS MRI scores, the hybrid model
   accuracy (97%; 168 of 173) outperformed LLM-only model (90%; 155 of 173;
   P = .006). For lesions with an originally reported O-RADS score, hybrid
   model accuracy exceeded that of reporting radiologists (97% [153 of 158]
   vs 88% [139 of 158]; P = .004). Hybrid model also outperformed LLM-only
   model for 183 lesions from before O-RADS implementation (95% [173 of
   183] vs 87% [159 of 183], respectively; P = .01). Conclusion: A hybrid
   LLM-based application, combining LLM feature classification with
   deterministic elements, accurately assigned O-RADS MRI scores from
   report descriptions, exceeding both an LLM-only strategy and the
   original reporting radiologist. (c) RSNA, 2025
ZR 0
ZS 0
TC 1
ZA 0
ZB 0
Z8 0
Z9 1
DA 2025-04-20
UT WOS:001464808700007
PM 40167432
ER

PT J
AU Capovilla, Giovanni
   Salvador, Renato
   Provenzano, Luca
   Voltarel, Guerrino
   Perazzolo, Anna
   Briscolini, Dario
   Nicoletti, Loredana
   Costantini, Andrea
   Merigliano, Stefano
   Costantini, Mario
TI EXTENDING MYOTOMY BOTH DOWNWARDS AND UPWARDS FOR MANOMETRIC PATTERN III
   ACHALASIA PATIENTS IMPROVES THE FINAL OUTCOME
SO GASTROENTEROLOGY
VL 154
IS 6
MA Su1153
BP S1301
EP S1301
SU 1
DT Meeting Abstract
PD MAY 2018
PY 2018
CT Annual Meeting of the American-Society-for-Gastrointestinal-Endoscopy /
   Digestive Disease Week
CY JUN 02-05, 2018
CL Washington, DC
SP Amer Soc Gastrointestinal Endoscopy
TC 0
ZB 0
ZR 0
ZS 0
Z8 0
ZA 0
Z9 0
DA 2018-12-07
UT WOS:000450011105183
ER

PT J
AU Kamgno, Joseph
   Nguipdop-Djomo, Patrick
   Gounoue, Raceline
   Tejiokem, Mathurin
   Kuesel, Annette C.
TI Effect of Two or Six Doses 800 mg of Albendazole Every Two Months on
   Loa loa Microfilaraemia: A Double Blind, Randomized,
   Placebo-Controlled Trial
SO PLOS NEGLECTED TROPICAL DISEASES
VL 10
IS 3
AR e0004492
DI 10.1371/journal.pntd.0004492
DT Article
PD MAR 2016
PY 2016
AB Background
   Loiasis is a parasitic infection endemic in the African rain forest
   caused by the filarial nematode Loa loa. Loiasis can be co-endemic with
   onchocerciasis and/or lymphatic filariasis. Ivermectin, the drug used in
   the control of these diseases, can induce serious adverse reactions in
   patients with high L loa microfilaraemia (LLM). A drug is needed which
   can lower LLM below the level that represents a risk so that ivermectin
   mass treatment to support onchocerciasis and lymphatic filariasis
   elimination can be implemented safely.
   Methodology
   Sixty men and women from a loiasis endemic area in Cameroon were
   randomized after stratification by screening LLM (<= 30000, 30001-50000,
   > 50000) to three treatment arms: two doses albendazole followed by 4
   doses matching placebo (n = 20), six doses albendazole (n = 20)
   albendazole or 6 doses matching placebo (n = 20) administered every two
   months. LLM was measured before each treatment and 14, 18, 21 and 24
   months after the first treatment. Monitoring for adverse events occurred
   three and seven days as well as 2 months after each treatment.
   Principal Findings
   None of the adverse events recorded were considered treatment related.
   The percentages of participants with >= 50% decrease in LLM from
   pre-treatment for >= 4 months were 53%, 17% and 11% in the 6-dose,
   2-dose and placebo treatment arms, respectively. The difference between
   the 6-dose and the placebo arm was significant (p = 0.01). The
   percentages of participants with LLM < 8100 mf/ml for >= 4 months were
   21%, 11% and 0% in the 6-dose, 2- dose and placebo treatment arms,
   respectively.
   Conclusions/Significance
   The 6-dose regimen reduced LLM significantly, but the reduction was
   insufficient to eliminate the risk of severe and/or serious adverse
   reactions during ivermectin mass drug administration in loiasis
   co-endemic areas.
TC 24
ZB 17
Z8 0
ZS 0
ZA 0
ZR 0
Z9 24
DA 2016-04-27
UT WOS:000373272500025
PM 26967331
ER

PT J
AU Beattie, J.
   Neufeld, S.
   Yang, D. X.
   Chukwuma, C.
   Gul, A.
   Desai, N. B.
   Dohopolski, M.
   Jiang, S. B.
TI Utilizing Large Language Models for Enhanced Clinical Trial Matching
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3341
BP E611
EP E611
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-12-16
UT WOS:001325892302025
ER

PT J
AU Tu, Tao
   Schaekermann, Mike
   Palepu, Anil
   Saab, Khaled
   Freyberg, Jan
   Tanno, Ryutaro
   Wang, Amy
   Li, Brenna
   Amin, Mohamed
   Cheng, Yong
   Vedadi, Elahe
   Tomasev, Nenad
   Azizi, Shekoofeh
   Singhal, Karan
   Hou, Le
   Webson, Albert
   Kulkarni, Kavita
   Mahdavi, S. Sara
   Semturs, Christopher
   Gottweis, Juraj
   Barral, Joelle
   Chou, Katherine
   Corrado, Greg S.
   Matias, Yossi
   Karthikesalingam, Alan
   Natarajan, Vivek
TI Towards conversational diagnostic artificial intelligence
SO NATURE
DI 10.1038/s41586-025-08866-7
EA APR 2025
DT Article; Early Access
PY 2025
AB At the heart of medicine lies physician-patient dialogue, where skillful
   history-taking enables effective diagnosis, management and enduring
   trust1,2. Artificial intelligence (AI) systems capable of diagnostic
   dialogue could increase accessibility and quality of care. However,
   approximating clinicians' expertise is an outstanding challenge. Here we
   introduce AMIE (Articulate Medical Intelligence Explorer), a large
   language model (LLM)-based AI system optimized for diagnostic dialogue.
   AMIE uses a self-play-based3 simulated environment with automated
   feedback for scaling learning across disease conditions, specialties and
   contexts. We designed a framework for evaluating clinically meaningful
   axes of performance, including history-taking, diagnostic accuracy,
   management, communication skills and empathy. We compared AMIE's
   performance to that of primary care physicians in a randomized,
   double-blind crossover study of text-based consultations with validated
   patient-actors similar to objective structured clinical examination4,5.
   The study included 159 case scenarios from providers in Canada, the
   United Kingdom and India, 20 primary care physicians compared to AMIE,
   and evaluations by specialist physicians and patient-actors. AMIE
   demonstrated greater diagnostic accuracy and superior performance on 30
   out of 32 axes according to the specialist physicians and 25 out of 26
   axes according to the patient-actors. Our research has several
   limitations and should be interpreted with caution. Clinicians used
   synchronous text chat, which permits large-scale LLM-patient
   interactions, but this is unfamiliar in clinical practice. While further
   research is required before AMIE could be translated to real-world
   settings, the results represent a milestone towards conversational
   diagnostic AI.
ZS 0
ZA 0
ZB 0
ZR 0
TC 5
Z8 0
Z9 5
DA 2025-04-15
UT WOS:001462553800001
PM 40205050
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT J
AU Saibene, Alberto Maria
   Allevi, Fabiana
   Calvo-Henriquez, Christian
   Maniaci, Antonino
   Mayo-Yanez, Miguel
   Paderno, Alberto
   Vaira, Luigi Angelo
   Felisati, Giovanni
   Craig, John R.
TI Reliability of large language models in managing odontogenic sinusitis
   clinical scenarios: a preliminary multidisciplinary evaluation
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 1835
EP 1841
DI 10.1007/s00405-023-08372-4
EA JAN 2024
DT Article
PD APR 2024
PY 2024
AB PurposeThis study aimed to evaluate the utility of large language model
   (LLM) artificial intelligence tools, Chat Generative Pre-Trained
   Transformer (ChatGPT) versions 3.5 and 4, in managing complex
   otolaryngological clinical scenarios, specifically for the
   multidisciplinary management of odontogenic sinusitis (ODS).MethodsA
   prospective, structured multidisciplinary specialist evaluation was
   conducted using five ad hoc designed ODS-related clinical scenarios. LLM
   responses to these scenarios were critically reviewed by a
   multidisciplinary panel of eight specialist evaluators (2 ODS experts, 2
   rhinologists, 2 general otolaryngologists, and 2 maxillofacial
   surgeons). Based on the level of disagreement from panel members, a
   Total Disagreement Score (TDS) was calculated for each LLM response, and
   TDS comparisons were made between ChatGPT3.5 and ChatGPT4, as well as
   between different evaluators.ResultsWhile disagreement to some degree
   was demonstrated in 73/80 evaluator reviews of LLMs' responses, TDSs
   were significantly lower for ChatGPT4 compared to ChatGPT3.5. Highest
   TDSs were found in the case of complicated ODS with orbital abscess,
   presumably due to increased case complexity with dental, rhinologic, and
   orbital factors affecting diagnostic and therapeutic options. There were
   no statistically significant differences in TDSs between evaluators'
   specialties, though ODS experts and maxillofacial surgeons tended to
   assign higher TDSs.ConclusionsLLMs like ChatGPT, especially newer
   versions, showed potential for complimenting evidence-based clinical
   decision-making, but substantial disagreement was still demonstrated
   between LLMs and clinical specialists across most case examples,
   suggesting they are not yet optimal in aiding clinical management
   decisions. Future studies will be important to analyze LLMs' performance
   as they evolve over time.
ZB 3
TC 17
ZA 0
Z8 1
ZR 0
ZS 0
Z9 18
DA 2024-01-19
UT WOS:001137890900006
PM 38189967
ER

PT J
AU Liu, Wei
   Liu, Jun
   Tang, Yitao
   Liu, Chaozhong
   Song, Meiyi
   Ju, Zhenlin
   Kumar, Shweth V.
   Lu, Yiling
   Akbani, Rehan
   Mills, Gordon
   Liang, Han
TI TCPAplus: An LLM-empowered chatbot for analyzing a large protein
   expression atlas of human cancers
SO CANCER RESEARCH
VL 84
IS 7
MA LB247
DI 10.1158/1538-7445.AM2024-LB247
SU S
DT Meeting Abstract
PD APR 1 2024
PY 2024
CT Annual Meeting of the American-Association-for-Cancer-Research (AACR)
CY APR 05-10, 2024
CL San Diego, CA
SP Amer Assoc Cancer Res
ZA 0
ZB 0
Z8 0
ZR 0
ZS 0
TC 0
Z9 0
DA 2024-05-19
UT WOS:001203184200459
ER

PT J
AU Dai, Yizheng
   Shao, Xin
   Zhang, Jinlu
   Chen, Yulong
   Chen, Qian
   Liao, Jie
   Chi, Fei
   Zhang, Junhua
   Fan, Xiaohui
TI TCMChat: A generative large language model for traditional Chinese
   medicine
SO PHARMACOLOGICAL RESEARCH
VL 210
AR 107530
DI 10.1016/j.phrs.2024.107530
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB The utilization of ground-breaking large language models (LLMs)
   accompanied with dialogue system has been progressively prevalent in the
   medical domain. Nevertheless, the expertise of LLMs in Traditional
   Chinese Medicine (TCM) remains restricted despite several TCM LLMs
   proposed recently. Herein, we introduced TCMChat
   (https://xomics.com.cn/tcmchat), a generative LLM with pre-training (PT)
   and supervised fine-tuning (SFT) on large-scale curated TCM text
   knowledge and Chinese Question-Answering (QA) datasets. In detail, we
   first compiled a customized collection of six scenarios of Chinese
   medicine as the training set by text mining and manual verification,
   involving TCM knowledgebase, choice question, reading comprehension,
   entity extraction, medical case diagnosis, and herb or formula
   recommendation. Next, we subjected the model to PT and SFT, using the
   Baichuan2-7B-Chat as the foundation model. The benchmarking datasets and
   case studies further demonstrate the superior performance of TCMChat in
   comparison to existing models. Our code, data and model are publicly
   released on GitHub (https://github.com/ZJUFanLab/TCMChat) and
   HuggingFace (https://huggingface. co/ZJUFanLab), providing high-quality
   knowledgebase for the research of TCM modernization with a userfriendly
   dialogue web tool.
Z8 0
TC 0
ZR 0
ZS 0
ZB 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001374093600001
PM 39617279
ER

PT J
AU Kohler, Rachel A.
   Poffenberger, Paige
   Lilly, Christa
   Pyles, Lee A.
TI Mid- To Long- Term Follow-up Care Insufficiencies From A Cross-sectional
   School- Based Cholesterol Screening Program
SO CIRCULATION
VL 145
MA A078
DI 10.1161/circ.145.suppl_1.078
SU 1
DT Meeting Abstract
PD MAR 1 2022
PY 2022
CT American-Heart-Association's Epidemiology and Prevention/Lifestyle and
   Cardiometabolic Health Scientific Sessions
CY MAR 01-04, 2022
CL Chicago, IL
SP Amer Heart Assoc
TC 1
Z8 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 1
DA 2022-06-18
UT WOS:000805839700068
ER

PT J
AU Ra, Sinyoung
   Kim, Jonghun
   Na, Inye
   Ko, Eun Sook
   Park, Hyunjin
TI Enhancing radiomics features via a large language model for classifying
   benign and malignant breast tumors in mammography
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 265
AR 108765
DI 10.1016/j.cmpb.2025.108765
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Background and Objectives: Radiomics is widely used to assist in
   clinical decision-making, disease diagnosis, and treatment planning for
   various target organs, including the breast. Recent advances in large
   language models (LLMs) have helped enhance radiomics analysis. Materials
   and Methods: Herein, we sought to improve radiomics analysis by
   incorporating LLM-learned clinical knowledge, to classify benign and
   malignant tumors in breast mammography. We extracted radiomics features
   from the mammograms based on the region of interest and retained the
   features related to the target task. Using prompt engineering, we
   devised an input sequence that reflected the selected features and the
   target task. The input sequence was fed to the chosen LLM (LLaMA
   variant), which was fine-tuned using low-rank adaptation to enhance
   radiomics features. This was then evaluated on two mammogram datasets
   (VinDr-Mammo and INbreast) against conventional baselines. Results: The
   enhanced radiomics-based method performed better than baselines using
   conventional radiomics features tested on two mammogram datasets,
   achieving accuracies of 0.671 for the VinDr-Mammo dataset and 0.839 for
   the INbreast dataset. Conventional radiomics models require retraining
   from scratch for an unseen dataset using a new set of features. In
   contrast, the model developed in this study effectively reused the
   common features between the training and unseen datasets by explicitly
   linking feature names with feature values, leading to extensible
   learning across datasets. Our method performed better than the baseline
   method in this retraining setting using an unseen dataset. Conclusions:
   Our method, one of the first to incorporate LLM into radiomics, has the
   potential to improve radiomics analysis.
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
ZB 0
Z9 0
DA 2025-04-21
UT WOS:001466026900001
PM 40203779
ER

PT J
AU Ihara, Keiko
   Dumkrieger, Gina
   Zhang, Pengfei
   Takizawa, Tsubasa
   Schwedt, Todd J.
   Chiang, Chia-Chun
TI Application of Artificial Intelligence in the Headache Field
SO CURRENT PAIN AND HEADACHE REPORTS
VL 28
IS 10
BP 1049
EP 1057
DI 10.1007/s11916-024-01297-5
EA JUL 2024
DT Review
PD OCT 2024
PY 2024
AB Purpose of ReviewHeadache disorders are highly prevalent worldwide.
   Rapidly advancing capabilities in artificial intelligence (AI) have
   expanded headache-related research with the potential to solve unmet
   needs in the headache field. We provide an overview of AI in headache
   research in this article.Recent FindingsWe briefly introduce machine
   learning models and commonly used evaluation metrics. We then review
   studies that have utilized AI in the field to advance diagnostic
   accuracy and classification, predict treatment responses, gather
   insights from various data sources, and forecast migraine attacks.
   Furthermore, given the emergence of ChatGPT, a type of large language
   model (LLM), and the popularity it has gained, we also discuss how LLMs
   could be used to advance the field. Finally, we discuss the potential
   pitfalls, bias, and future directions of employing AI in headache
   medicine.SummaryMany recent studies on headache medicine incorporated
   machine learning, generative AI and LLMs. A comprehensive understanding
   of potential pitfalls and biases is crucial to using these novel
   techniques with minimum harm. When used appropriately, AI has the
   potential to revolutionize headache medicine.
ZA 0
ZR 0
TC 2
ZB 0
Z8 0
ZS 0
Z9 2
DA 2024-07-18
UT WOS:001264634300002
PM 38976174
ER

PT J
AU Waldeyer, Christoph
   Seiffert, Moritz
   Staebel, Nils
   Braetz, Julian
   Kohsiack, Rebecca
   Ojeda, Francisco
   Schofer, Niklas
   Karakas, Mahir
   Zeller, Tanja
   Sinning, Christoph
   Schrage, Benedikt
   Westermann, Dirk
   Sydow, Karsten
   Blankenberg, Stefan
   Brunner, Fabian J.
   Schnabel, Renate B.
TI Lipid Management After First Diagnosis of Coronary Artery Disease:
   Contemporary Results From an Observational Cohort Study
SO CLINICAL THERAPEUTICS
VL 39
IS 11
BP 2311
EP 2320
DI 10.1016/j.clinthera.2017.10.005
DT Article
PD NOV 2017
PY 2017
AB Purpose: Although the efficacy of lipid-lowering medication (LLM) in
   patients with coronary artery disease (CAD) is well established, the
   majority of patients fail to achieve their LDL-C goals. The evidence for
   measurement of LDL-C to achieve these goals is limited. The goal of the
   present study, therefore, was to analyze ambulatory LLM management in
   relation to performance of LDL-C measurements and achieved LDL-C levels
   after the initial diagnosis of CAD.
   Methods: The study followed up a subcohort of 200 patients with newly
   diagnosed CAD of the INTERCATH trial, an observational study including
   patients undergoing coronary angiography. In addition to baseline
   information, data were collected on LLM, performance of lipid
   measurements, and laboratory results at a minimum of 6 months'
   postdischarge.
   Findings: The mean age of the sample was 67.9 years, and 36.0% were
   women. In 34.5% of all patients, no measurement of LDL-C levels was
   performed during follow-up. We found no differences in baseline
   characteristics between patients with and without LDL-C measurements
   during follow-up. In patierits with measurement of LDL-C levels, the
   frequency of intensification of statin medication according to LDL-C
   reduction was higher compared with those patients without LDL-C
   measurement (23.6% vs 4.3%; P < 0.001); all other categories of
   intensity adjustment were comparable. In patients with 3 LDL-C
   measurements, achieved LDL-C levels were significantly lower (mean, 81
   mg/dL), and a higher proportion reached an LDL-C level <70 mg/dL (44.7%)
   compared with patients with 1 (95 mg/dL [P = 0.013]; 21.8%) or 2 (91
   mg/dL [P = 0.037]; 28.9%) LDL-C measurements despite comparable LDLC
   levels at baseline. Ezetimibe was used in 3.5% of the entire study
   cohort.
   Implications: We found no differences in patient characteristics between
   patients with and without LDL-C measurements after being newly diagnosed
   with CAD. Performance and frequency of LDL-C measurements were clearly
   associated with better, higher frequency of intensification of statin
   medication, lower achieved LDL-C levels, and a higher proportion of
   patients achieving the LDL-C goal of <70 mg/dL. These results suggest an
   important role of LDL-C measurements for secondary prevention after the
   initial diagnosis of CAD. (C) 2017 Elsevier HS Journals, Inc. All rights
   reserved.
ZB 8
ZS 0
TC 14
ZR 0
ZA 0
Z8 0
Z9 14
DA 2017-12-27
UT WOS:000417773600020
PM 29103665
ER

PT J
AU Chen, Hui
   Xu, Zanmei
   Chen, Lijuan
   Wang, Mingmin
   Zhang, Peng
   Pang, Fei
   Wang, Kai
TI AI-enabled precision oncology era: Advanced and interactive
   interpretation of next-gneneration sequencing (NGS) reports
SO CANCER RESEARCH
VL 84
IS 6
MA 2315
DI 10.1158/1538-7445.AM2024-2315
SU S
DT Meeting Abstract
PD MAR 15 2024
PY 2024
CT Annual Meeting of the American-Association-for-Cancer-Research (AACR)
CY APR 05-10, 2024
CL San Diego, CA
SP Amer Assoc Cancer Res
Z8 0
ZB 0
ZR 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2024-07-31
UT WOS:001252656304116
ER

PT J
AU Schramm, Severin
   Preis, Silas
   Metz, Marie-Christin
   Jung, Kirsten
   Schmitz-Koep, Benita
   Zimmer, Claus
   Wiestler, Benedikt
   Hedderich, Dennis M.
   Kim, Su Hwan
TI Impact of Multimodal Prompt Elements on Diagnostic Performance of GPT-4V
   in Challenging Brain MRI Cases
SO RADIOLOGY
VL 314
IS 1
AR e240689
DI 10.1148/radiol.240689
DT Article
PD JAN 2025
PY 2025
AB Background: Studies have explored the application of multimodal large
   language models (LLMs) in radiologic differential diagnosis. Yet, how
   different multimodal input combinations affect diagnostic performance is
   not well understood. Purpose: To evaluate the impact of varying
   multimodal input elements on the accuracy of OpenAI's GPT-4 with vision
   (GPT-4V)-based brain MRI differential diagnosis. Materials and Methods:
   Sixty brain MRI cases with a challenging yet verified diagnosis were
   selected. Seven prompt groups with variations of four input elements
   (image without modifiers [I], annotation [A], medical history [H], and
   image description [D]) were defined. For each MRI case and prompt group,
   three identical queries were performed using an LLM-based search engine
   (Perplexity AI, powered by GPT-4V). The accuracy of LLM-generated
   differential diagnoses was rated using a binary and a numeric scoring
   system and analyzed using a chi 2 test and a Kruskal-Wallis test.
   Results were corrected for false-discovery rate with use of the
   Benjamini-Hochberg procedure. Regression analyses were performed to
   determine the contribution of each input element to diagnostic
   performance. Results: The prompt group containing I, A, H, and D as
   input exhibited the highest diagnostic accuracy (124 of 180 responses
   [69%]). Significant differences were observed between prompt groups that
   contained D among their inputs and those that did not. Unannotated (I)
   (four of 180 responses [2.2%]) or annotated radiologic images alone (I
   and A) (two of 180 responses [1.1%]) yielded very low diagnostic
   accuracy. Regression analyses confirmed a large positive effect of D on
   diagnostic accuracy (odds ratio [OR], 68.03; P < .001), as well as a
   moderate positive effect of H (OR, 4.18; P < .001). Conclusion: The
   textual description of radiologic image findings was identified as the
   strongest contributor to the performance of GPT-4V in brain MRI
   differential diagnosis, followed by the medical history; unannotated or
   annotated images alone yielded very low diagnostic performance. (c)
   RSNA, 2025
ZR 0
TC 3
ZS 0
Z8 0
ZA 0
ZB 0
Z9 3
DA 2025-02-03
UT WOS:001406613800012
PM 39835982
ER

PT J
AU Huo, Bright
   Boyle, Amy
   Marfo, Nana
   Tangamornsuksan, Wimonchat
   Steen, Jeremy P.
   Mckechnie, Tyler
   Lee, Yung
   Mayol, Julio
   Antoniou, Stavros A.
   Thirunavukarasu, Arun James
   Sanger, Stephanie
   Ramji, Karim
   Guyatt, Gordon
TI Large Language Models for Chatbot Health Advice Studies: A Systematic
   Review
SO JAMA NETWORK OPEN
VL 8
IS 2
AR e2457879
DI 10.1001/jamanetworkopen.2024.57879
DT Article
PD FEB 4 2025
PY 2025
AB Importance There is much interest in the clinical integration of large
   language models (LLMs) in health care. Many studies have assessed the
   ability of LLMs to provide health advice, but the quality of their
   reporting is uncertain. Objective To perform a systematic review to
   examine the reporting variability among peer-reviewed studies evaluating
   the performance of generative artificial intelligence (AI)-driven
   chatbots for summarizing evidence and providing health advice to inform
   the development of the Chatbot Assessment Reporting Tool (CHART).
   Evidence Review A search of MEDLINE via Ovid, Embase via Elsevier, and
   Web of Science from inception to October 27, 2023, was conducted with
   the help of a health sciences librarian to yield 7752 articles. Two
   reviewers screened articles by title and abstract followed by full-text
   review to identify primary studies evaluating the clinical accuracy of
   generative AI-driven chatbots in providing health advice (chatbot health
   advice studies). Two reviewers then performed data extraction for 137
   eligible studies. Findings A total of 137 studies were included. Studies
   examined topics in surgery (55 [40.1%]), medicine (51 [37.2%]), and
   primary care (13 [9.5%]). Many studies focused on treatment (91
   [66.4%]), diagnosis (60 [43.8%]), or disease prevention (29 [21.2%]).
   Most studies (136 [99.3%]) evaluated inaccessible, closed-source LLMs
   and did not provide enough information to identify the version of the
   LLM under evaluation. All studies lacked a sufficient description of LLM
   characteristics, including temperature, token length, fine-tuning
   availability, layers, and other details. Most studies (136 [99.3%]) did
   not describe a prompt engineering phase in their study. The date of LLM
   querying was reported in 54 (39.4%) studies. Most studies (89 [65.0%])
   used subjective means to define the successful performance of the
   chatbot, while less than one-third addressed the ethical, regulatory,
   and patient safety implications of the clinical integration of LLMs.
   Conclusions and Relevance In this systematic review of 137 chatbot
   health advice studies, the reporting quality was heterogeneous and may
   inform the development of the CHART reporting standards. Ethical,
   regulatory, and patient safety considerations are crucial as interest
   grows in the clinical integration of LLMs.
TC 5
Z8 0
ZS 0
ZB 0
ZR 0
ZA 0
Z9 5
DA 2025-02-14
UT WOS:001416067000009
PM 39903463
ER

PT J
AU Li, Shusheng
   Tan, Wenjun
   Zhang, Changshuai
   Li, Jiale
   Ren, Haiyan
   Guo, Yanliang
   Jia, Jing
   Liu, Yangyang
   Pan, Xingfang
   Guo, Jing
   Meng, Wei
   He, Zhaoshui
TI Taming large language models to implement diagnosis and evaluating the
   generation of LLMs at the semantic similarity level in acupuncture and
   moxibustion
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 264
AR 125920
DI 10.1016/j.eswa.2024.125920
EA DEC 2024
DT Article
PD MAR 10 2025
PY 2025
AB With the rapid advancement of artificial intelligence and deep learning
   technologies, large language models (LLMs) such as ChatGPT and GPT-4
   have made significant progress in comprehending and responding to human
   instructions. Acupuncture and moxibustion, therapeutic modalities in
   Traditional Chinese Medicine (TCM), possess extensive knowledge
   beneficial for patient treatment. Currently, acupuncture diagnosis
   relies on the experience and skills of individual acupuncturists,
   emphasizing the need for research to improve diagnostic accuracy through
   objective methods. Therefore, the integration of LLMs into the field of
   acupuncture can facilitate the recommendation of personalized
   acupuncture treatment programs. However, the application of general LLMs
   to the field of acupuncture diagnosis often yields suboptimal results.
   In addition, most LLM evaluation metrics depend solely on literal
   overlap and fail to capture semantic similarity. To address these
   challenges, this paper introduces AcupunctureGPT, a specialized large
   language model for acupuncture diagnosis, aimed at exploring the
   potential application of LLMs in this field. Patient Diagnostic
   Acupuncture Data is constructed to enhance the diagnostic capabilities
   of AcupunctureGPT in acupuncture. The Generated Knowledge Filter
   Prompting approach is proposed to improve the accuracy of LLMs in
   identifying similar diseases through the development and filtering of
   knowledge statements. The Sentence Similarity Evaluation Module (SSEM)
   is employed to assess the generation quality of LLMs at the semantic
   level. The Sentence Adaptive Enhancement Fusion Module (SAEFM), proposed
   within SSEM, enhances the adaptive fusion of output features at various
   levels. Experimental results demonstrate that AcupunctureGPT outperforms
   other large language models in diagnosing diseases and devising
   reasonable treatment plans. Furthermore, the evaluation metrics proposed
   in this paper have been validated for effectiveness.
TC 0
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
Z9 0
DA 2024-12-13
UT WOS:001372992400001
ER

PT J
AU Gabriel, Rodney A.
   Litake, Onkar
   Simpson, Sierra
   Burton, Brittany N.
   Waterman, Ruth S.
   Macias, Alvaro A.
TI On the development and validation of large language model- based
   classifiers for identifying social determinants of health
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
VL 121
IS 39
AR e2320716121
DI 10.1073/pnas.2320716121
DT Article
PD SEP 24 2024
PY 2024
AB The assessment of social determinants of health (SDoH) within healthcare
   systems is crucial for comprehensive patient care and addressing health
   disparities. Current challenges arise from the limited inclusion of
   structured SDoH information within electronic health record (EHR)
   systems, often due to the lack of standardized diagnosis codes. This
   study delves into the transformative potential of large language models
   (LLM) to overcome these challenges. LLM-based classifiers-using
   Bidirectional Encoder Representations from Transformers (BERT) and A
   Robustly Optimized BERT Pretraining Approach (RoBERTa)-were developed
   for SDoH concepts, including homelessness, food insecurity, and domestic
   violence, using synthetic training datasets generated by generative pre-
   trained transformers combined with authentic clinical notes. Models were
   then validated on separate datasets: Medical Information Mart for
   Intensive Care- III and our institutional EHR data. When training the
   model with a combination of synthetic and authentic notes, validation on
   our institutional dataset yielded an area under the receiver operating
   characteristics curve of 0.78 for detecting homelessness, 0.72 for
   detecting food insecurity, and 0.83 for detecting domestic violence.
   This study underscores the potential of LLMs in extracting SDoH
   information from clinical text. Automated detection of SDoH may be
   instrumental for healthcare providers in identifying at- risk patients,
   guiding targeted interventions, and contributing to population health
   initiatives aimed at mitigating disparities.
TC 5
ZA 0
ZS 0
ZR 0
ZB 2
Z8 0
Z9 5
DA 2024-12-11
UT WOS:001369554000005
PM 39284061
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT J
AU Albagieh, Hamad
   Alzeer, Zaid O.
   Alasmari, Osama N.
   Alkadhi, Abdullah A.
   Naitah, Abdulaziz N.
   Almasaad, Khaled F.
   Alshahrani, Turki S.
   Alshahrani, Khalid S.
   Almahmoud, Mohammed I.
TI Comparing Artificial Intelligence and Senior Residents in Oral Lesion
   Diagnosis: A Comparative Study
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 1
AR e51584
DI 10.7759/cureus.51584
DT Article
PD JAN 3 2024
PY 2024
AB Introduction: Artificial intelligence (AI) is a field of computer
   science that seeks to build intelligent machines that can carry out
   tasks that usually necessitate human intelligence. AI may help dentists
   with a variety of dental tasks, including clinical diagnosis and
   treatment planning. This study aims to compare the performance of AI and
   oral medicine residents in diagnosing different cases, providing
   treatment, and determining if it is reliable to assist them in their
   field of work. Methods: The study conducted a comparative analysis of
   the responses from third-and fourth-year residents trained in Oral
   Medicine and Pathology at King Saud University, College of Dentistry.
   The residents were given a closed multiple-choice test consisting of 19
   questions with four response options labeled A-D and one question with
   five response options labeled A-E. The test was administered via Google
   Forms, and each resident's response was stored electronically in an
   Excel sheet (Microsoft (R) Corp., Redmond, WA). The residents' answers
   were then compared to the responses generated by three major language
   models: OpenAI, Stablediffusion, and PopAI. The questions were inputted
   into the language models in the same format as the original test, and
   prior to each question, an artificial intelligence chat session was
   created to eliminate memory retention bias. The input was done on
   November 19, 2023, the same day the official multiple-choice test was
   administered. The study had a sample size of 20 residents trained in
   Oral Medicine and Pathology at King Saud University, College of
   Dentistry, consisting of both third-year and fourth-year residents.
   Result: The responses of three large language models (LLM), including
   OpenAI, Stablediffusion, and PopAI, as well as the responses of 20
   senior residents for 20 clinical cases about oral lesion diagnosis.
   There were no significant variations observed for the remaining
   questions in the responses to only two questions (10%). For the
   remaining questions, there were no significant differences. The median
   (IQR) score of LLMs was 50.0 (45.0 to 60.0), with a minimum of 40 (for
   stable diffusion) and a maximum of 70 (for OpenAI). The median (IQR)
   score of senior residents was 65.0 (55.0-75.0). The highest and lowest
   scores of residents were 40 and 90, respectively. There was no
   significant difference in the percent scores of residents and LLMs (p =
   0.211). The agreement level was measured using the Kappa value. The
   agreement among senior dental residents was observed to be weak, with a
   Kappa value of 0.396. In contrast, the agreement among LLMs demonstrated
   a moderate level, with a Kappa value of 0.622, suggesting a more
   cohesive alignment in responses among the artificial intelligence
   models. When comparing residents' responses with those generated by
   different OpenAI models, including OpenAI, Stablediffusion, and PopAI,
   the agreement levels were consistently categorized as weak, with Kappa
   values of 0.402, 0.381, and 0.392, respectively. Conclusion: What the
   current study reveals is that when comparing the response score, there
   is no significant difference, in contrast to the agreement analysis
   among the residents, which was low compared to the LLMs, in which it was
   high. Dentists should consider that AI is very beneficial in providing
   diagnosis and treatment and use it to assist them.
ZA 0
ZR 0
TC 6
ZB 1
ZS 0
Z8 0
Z9 6
DA 2024-03-17
UT WOS:001165530200012
PM 38173951
ER

PT J
AU Hamamoto, Ryuji
   Komatsu, Masaaki
   Yamada, Masayoshi
   Kobayashi, Kazuma
   Takahashi, Masamichi
   Miyake, Mototaka
   Jinnai, Shunichi
   Koyama, Takafumi
   Kouno, Nobuji
   Machino, Hidenori
   Takahashi, Satoshi
   Asada, Ken
   Ueda, Naonori
   Kaneko, Syuzo
TI Current status and future direction of cancer research using artificial
   intelligence for clinical application
SO CANCER SCIENCE
VL 116
IS 2
BP 297
EP 307
DI 10.1111/cas.16395
EA NOV 2024
DT Review
PD FEB 2025
PY 2025
AB The expectations for artificial intelligence (AI) technology have
   increased considerably in recent years, mainly due to the emergence of
   deep learning. At present, AI technology is being used for various
   purposes and has brought about change in society. In particular, the
   rapid development of generative AI technology, exemplified by ChatGPT,
   has amplified the societal impact of AI. The medical field is no
   exception, with a wide range of AI technologies being introduced for
   basic and applied research. Further, AI-equipped software as a medical
   device (AI-SaMD) is also being approved by regulatory bodies. Combined
   with the advent of big data, data-driven research utilizing AI is
   actively pursued. Nevertheless, while AI technology has great potential,
   it also presents many challenges that require careful consideration. In
   this review, we introduce the current status of AI-based cancer
   research, especially from the perspective of clinical application, and
   discuss the associated challenges and future directions, with the aim of
   helping to promote cancer research that utilizes effective AI
   technology.
ZR 0
ZS 0
TC 1
Z8 0
ZB 0
ZA 0
Z9 1
DA 2024-11-25
UT WOS:001357844100001
PM 39557634
ER

PT J
AU Savage, Thomas
   Nayak, Ashwin
   Gallo, Robert
   Rangan, Ekanath
   Chen, Jonathan H.
TI Diagnostic reasoning prompts reveal the potential for large language
   model interpretability in medicine
SO NPJ DIGITAL MEDICINE
VL 7
IS 1
AR 20
DI 10.1038/s41746-024-01010-1
DT Article
PD JAN 24 2024
PY 2024
AB One of the major barriers to using large language models (LLMs) in
   medicine is the perception they use uninterpretable methods to make
   clinical decisions that are inherently different from the cognitive
   processes of clinicians. In this manuscript we develop diagnostic
   reasoning prompts to study whether LLMs can imitate clinical reasoning
   while accurately forming a diagnosis. We find that GPT-4 can be prompted
   to mimic the common clinical reasoning processes of clinicians without
   sacrificing diagnostic accuracy. This is significant because an LLM that
   can imitate clinical reasoning to provide an interpretable rationale
   offers physicians a means to evaluate whether an LLMs response is likely
   correct and can be trusted for patient care. Prompting methods that use
   diagnostic reasoning have the potential to mitigate the "black box"
   limitations of LLMs, bringing them one step closer to safe and effective
   use in medicine.
TC 65
ZS 0
Z8 2
ZB 13
ZA 0
ZR 0
Z9 66
DA 2024-02-04
UT WOS:001148298600001
PM 38267608
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Mizuta, Kazuya
   Sakamoto, Tetsu
   Tokumasu, Kazuki
   Shimizu, Taro
TI Diagnostic performance of generative artificial intelligences for a
   series of complex case reports
SO DIGITAL HEALTH
VL 10
AR 20552076241265215
DI 10.1177/20552076241265215
DT Article
PD 2024
PY 2024
AB Background Diagnostic performance of generative artificial intelligences
   (AIs) using large language models (LLMs) across comprehensive medical
   specialties is still unknown. Objective We aimed to evaluate the
   diagnostic performance of generative AIs using LLMs in complex case
   series across comprehensive medical fields. Methods We analyzed
   published case reports from the American Journal of Case Reports from
   January 2022 to March 2023. We excluded pediatric cases and those
   primarily focused on management. We utilized three generative AIs to
   generate the top 10 differential-diagnosis (DDx) lists from case
   descriptions: the fourth-generation chat generative pre-trained
   transformer (ChatGPT-4), Google Gemini (previously Bard), and LLM Meta
   AI 2 (LLaMA2) chatbot. Two independent physicians assessed the inclusion
   of the final diagnosis in the lists generated by the AIs. Results Out of
   557 consecutive case reports, 392 were included. The inclusion rates of
   the final diagnosis within top 10 DDx lists were 86.7% (340/392) for
   ChatGPT-4, 68.6% (269/392) for Google Gemini, and 54.6% (214/392) for
   LLaMA2 chatbot. The top diagnoses matched the final diagnoses in 54.6%
   (214/392) for ChatGPT-4, 31.4% (123/392) for Google Gemini, and 23.0%
   (90/392) for LLaMA2 chatbot. ChatGPT-4 showed higher diagnostic accuracy
   than Google Gemini (P < 0.001) and LLaMA2 chatbot (P < 0.001).
   Additionally, Google Gemini outperformed LLaMA2 chatbot within the top
   10 DDx lists (P < 0.001) and as the top diagnosis (P = 0.010).
   Conclusions This study demonstrated the diagnostic performance of
   generative AIs including ChatGPT-4, Google Gemini, and LLaMA2 chatbot.
   ChatGPT-4 exhibited higher diagnostic accuracy than the other platforms.
   These findings suggest the importance of understanding the differences
   in diagnostic performance among generative AIs, especially in complex
   case series across comprehensive medical fields, like general medicine.
Z8 0
ZR 0
ZA 0
ZS 0
TC 5
ZB 0
Z9 5
DA 2024-07-31
UT WOS:001276296100001
PM 39229463
ER

PT J
AU Sezgin, Emre
   Jackson, Daniel I.
   Kocaballi, A. Baki
   Bibart, Mindy
   Zupanec, Sue
   Landier, Wendy
   Audino, Anthony
   Ranalli, Mark
   Skeens, Micah
TI Can Large Language Models Aid Caregivers of Pediatric Cancer Patients in
   Information Seeking? A Cross-Sectional Investigation
SO CANCER MEDICINE
VL 14
IS 1
AR e70554
DI 10.1002/cam4.70554
DT Article
PD JAN 2025
PY 2025
AB PurposeCaregivers in pediatric oncology need accurate and understandable
   information about their child's condition, treatment, and side effects.
   This study assesses the performance of publicly accessible large
   language model (LLM)-supported tools in providing valuable and reliable
   information to caregivers of children with cancer. MethodsIn this
   cross-sectional study, we evaluated the performance of the four
   LLM-supported tools-ChatGPT (GPT-4), Google Bard (Gemini Pro), Microsoft
   Bing Chat, and Google SGE-against a set of frequently asked questions
   (FAQs) derived from the Children's Oncology Group Family Handbook and
   expert input (In total, 26 FAQs and 104 generated responses). Five
   pediatric oncology experts assessed the generated LLM responses using
   measures including accuracy, clarity, inclusivity, completeness,
   clinical utility, and overall rating. Additionally, the content quality
   was evaluated including readability, AI disclosure, source credibility,
   resource matching, and content originality. We used descriptive analysis
   and statistical tests including Shapiro-Wilk, Levene's, Kruskal-Wallis
   H-tests, and Dunn's post hoc tests for pairwise comparisons.
   ResultsChatGPT shows high overall performance when evaluated by the
   experts. Bard also performed well, especially in accuracy and clarity of
   the responses, whereas Bing Chat and Google SGE had lower overall
   scores. Regarding the disclosure of responses being generated by AI, it
   was observed less frequently in ChatGPT responses, which may have
   affected the clarity of responses, whereas Bard maintained a balance
   between AI disclosure and response clarity. Google SGE generated the
   most readable responses whereas ChatGPT answered with the most
   complexity. LLM tools varied significantly (p < 0.001) across all expert
   evaluations except inclusivity. Through our thematic analysis of expert
   free-text comments, emotional tone and empathy emerged as a unique theme
   with mixed feedback on expectations from AI to be empathetic.
   ConclusionLLM-supported tools can enhance caregivers' knowledge of
   pediatric oncology. Each model has unique strengths and areas for
   improvement, indicating the need for careful selection based on specific
   clinical contexts. Further research is required to explore their
   application in other medical specialties and patient demographics,
   assessing broader applicability and long-term impacts.
ZA 0
TC 2
Z8 0
ZS 0
ZB 1
ZR 0
Z9 2
DA 2025-01-13
UT WOS:001391811100001
PM 39776222
ER

PT J
AU Gencer, Gulcan
   Gencer, Kerem
TI Large Language Models in Healthcare: A Bibliometric Analysis and
   Examination of Research Trends
SO JOURNAL OF MULTIDISCIPLINARY HEALTHCARE
VL 18
BP 223
EP 238
DI 10.2147/JMDH.S502351
DT Article
PD 2025
PY 2025
AB Background: The integration of large language models (LLMs) in
   healthcare has generated significant interest due to their potential to
   improve diagnostic accuracy, personalization of treatment, and patient
   care efficiency. Objective: This study aims to conduct a comprehensive
   bibliometric analysis to identify current research trends, main themes
   and future directions regarding applications in the healthcare sector.
   Methods: A systematic scan of publications until 08.05.2024 was carried
   out from an important database such as Web of Science.Using bibliometric
   tools such as VOSviewer and CiteSpace, we analyzed data covering
   publication counts, citation analysis, co-authorship, co- occurrence of
   keywords and thematic development to map the intellectual landscape and
   collaborative networks in this field. Results: The analysis included
   more than 500 articles published between 2021 and 2024. The United
   States, Germany and the United Kingdom were the top contributors to this
   field. The study highlights that neural network applications in
   diagnostic imaging, natural language processing for clinical
   documentation, and patient data in the field of general internal
   medicine, radiology, medical informatics, health care services, surgery,
   oncology, ophthalmology, neurology, orthopedics and psychiatry have seen
   significant growth in publications over the past two years. Keyword
   trend analysis revealed emerging sub-themes such as clinical research,
   artificial intelligence, ChatGPT, education, natural language
   processing, clinical management, virtual reality, chatbot, indicating a
   shift towards addressing the broader implications of LLM application in
   healthcare. Conclusion: The use of LLM in healthcare is an expanding
   field with significant academic and clinical interest. This bibliometric
   analysis not only maps the current state of the research, but also
   identifies important areas that require further research and
   development. Continued advances in this field are expected to
   significantly impact future healthcare applications, with a focus on
   increasing the accuracy and personalization of patient care through
   advanced data analytics.
ZR 0
Z8 0
ZS 0
ZA 0
TC 3
ZB 0
Z9 3
DA 2025-01-25
UT WOS:001400829200001
PM 39844924
ER

PT J
AU Zada, Zaid
   Goldstein, Ariel
   Michelmann, Sebastian
   Simony, Erez
   Price, Amy
   Hasenfratz, Liat
   Barham, Emily
   Zadbood, Asieh
   Doyle, Werner
   Friedman, Daniel
   Dugan, Patricia
   Melloni, Lucia
   Devore, Sasha
   Flinker, Adeen
   Devinsky, Orrin
   Nastase, Samuel A.
   Hasson, Uri
TI A shared model-based linguistic space for transmitting our thoughts from
   brain to brain in natural conversations
SO NEURON
VL 112
IS 18
DI 10.1016/j.neuron.2024.06.025
EA SEP 2024
DT Article
PD SEP 25 2024
PY 2024
AB Effective communication hinges on a mutual understanding of word meaning
   in different contexts. We recorded brain activity using
   electrocorticography during spontaneous, face-to-face conversations in
   five pairs of epilepsy patients. We developed a model-based coupling
   framework that aligns brain activity in both speaker and listener to a
   shared embedding space from a large language model (LLM). The
   context-sensitive LLM embeddings allow us to track the exchange of
   linguistic information, word by word, from one brain to another in
   natural conversations. Linguistic content emerges in the speaker's brain
   before word articulation and rapidly re-emerges in the listener's brain
   after word articulation. The contextual embeddings better capture
   word-by-word neural alignment between speaker and listener than
   syntactic and articulatory models. Our findings indicate that the
   contextual embeddings learned by LLMs can serve as an explicit numerical
   model of the shared, context-rich meaning space humans use to
   communicate their thoughts to one another.
ZB 3
ZA 0
TC 10
Z8 0
ZR 0
ZS 0
Z9 10
DA 2024-10-09
UT WOS:001324629500001
PM 39096896
ER

PT J
AU Pang, Lizhi
   Zhou, Fei
   Chen, Peiwen
TI Lipid-Laden Macrophages Recycle Myelin to Feed Glioblastoma
SO CANCER RESEARCH
VL 84
IS 22
BP 3712
EP 3714
DI 10.1158/0008-5472.CAN-24-3362
DT Editorial Material
PD NOV 15 2024
PY 2024
AB Tumor-associated microglia and macrophages (TAM) make up the largest
   immune cell population in the glioblastoma (GBM) tumor microenvironment.
   Given the heterogeneity and plasticity of TAMs in the GBM tumor
   microenvironment, understanding the context-dependent cancer cell-TAM
   symbiotic interaction is crucial for understanding GBM biology and
   developing effective therapies. In a recent issue of Cell, Kloosterman
   and colleagues identified a subpopulation of glycoprotein nonmetastatic
   melanoma protein Bhigh lipid-laden microglia and macrophages (LLM) in
   GBM. Mesenchymal-like GBM cells help generate the LLM phenotype.
   Reciprocally, LLMs are epigenetically rewired to recycle myelin and
   transfer the lipid from myelin to cancer cells, fueling mesenchymal-like
   GBM progression in a liver X receptor/ABCA1-dependent manner. Together,
   leveraging LLMs opens new therapeutic possibilities for rewiring the
   metabolism-mediated tumor-TAM interaction during GBM progression.
TC 0
ZA 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 0
DA 2024-12-01
UT WOS:001357968300004
PM 39292810
ER

PT J
AU Shieh, Allen
   Tran, Brandon
   He, Gene
   Kumar, Mudit
   Freed, Jason A.
   Majety, Priyanka
TI Assessing ChatGPT 4.0's test performance and clinical diagnostic
   accuracy on USMLE STEP 2 CK and clinical case reports
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 9330
DI 10.1038/s41598-024-58760-x
DT Article
PD APR 23 2024
PY 2024
AB While there is data assessing the test performance of artificial
   intelligence (AI) chatbots, including the Generative Pre-trained
   Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on
   its diagnostic accuracy of clinical cases. We assessed the large
   language model (LLM), ChatGPT 4.0, on its ability to answer questions
   from the United States Medical Licensing Exam (USMLE) Step 2, as well as
   its ability to generate a differential diagnosis based on corresponding
   clinical vignettes from published case reports. A total of 109 Step 2
   Clinical Knowledge (CK) practice questions were inputted into both
   ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer.
   Compared to its previous version, ChatGPT 3.5, we found improved
   accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to
   87.2% (p = 0.035) respectively. Utilizing the topics tested on Step 2 CK
   questions, we additionally found 63 corresponding published case report
   vignettes and asked ChatGPT 4.0 to come up with its top three
   differential diagnosis. ChatGPT 4.0 accurately created a shortlist of
   differential diagnoses in 74.6% of the 63 case reports (74.6%). We
   analyzed ChatGPT 4.0's confidence in its diagnosis by asking it to rank
   its top three differentials from most to least likely. Out of the 47
   correct diagnoses, 33 were the first (70.2%) on the differential
   diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our
   study shows the continued iterative improvement in ChatGPT's ability to
   answer standardized USMLE questions accurately and provides insights
   into ChatGPT's clinical diagnostic accuracy.
ZA 0
TC 32
ZS 0
Z8 0
ZB 3
ZR 0
Z9 32
DA 2024-06-29
UT WOS:001207399200004
PM 38654011
ER

PT J
AU Maier, Jacqueline
   Schubert, Karoline
   Cross, Michael
   Leiblein, Sabine
   Wildenberger, Kathrin
   Giles, Frank
   Hochhaus, Andreas
   Frank, Oliver
   Niederwieser, Dietger
   Lange, Thoralf
TI Low Level BCR-ABL Mutations Below the Detection Limit of Current
   Standard Screening Techniques Occur Predominantly in the CD34+Progenitor
   Cell Compartment in Chronic Phase CML Patients At Diagnosis. A Substudy
   of the ENEST1st Trial
SO BLOOD
VL 120
IS 21
MA 1671
DI 10.1182/blood.V120.21.1671.1671
DT Meeting Abstract
PD NOV 16 2012
PY 2012
CT 54th Annual Meeting and Exposition of the American-Society-of-Hematology
   (ASH)
CY DEC 08-11, 2012
CL Atlanta, GA
SP Amer Soc Hematol (ASH)
ZS 0
Z8 0
ZB 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2013-03-06
UT WOS:000314049600368
ER

PT J
AU Wang, Xueqi
   Ye, Haiyan
   Zhang, Sumian
   Yang, Mei
   Wang, Xuebin
TI Evaluation of the Performance of Three Large Language Models in Clinical
   Decision Support: A Comparative Study Based on Actual Cases
SO JOURNAL OF MEDICAL SYSTEMS
VL 49
IS 1
AR 23
DI 10.1007/s10916-025-02152-9
DT Article
PD FEB 14 2025
PY 2025
AB Background Generative large language models (LLMs) are increasingly
   integrated into the medical field. However, their actual efficacy in
   clinical decision-making remains partially unexplored. This study aimed
   to assess the performance of the three LLMs, ChatGPT-4, Gemini, and
   Med-Go, in the domain of professional medicine when confronted with
   actual clinical cases. Methods This study involved 134 clinical cases
   spanning nine medical disciplines. Each LLM was required to provide
   suggestions for diagnosis, diagnostic criteria, differential diagnosis,
   examination and treatment for every case. Responses were scored by two
   experts using a predefined rubric. Results In overall performance among
   the models, Med-Go achieved the highest median score (37.5, IQR
   31.9-41.5), while Gemini recorded the lowest (33.0, IQR 25.5-36.6),
   showing significant statistical difference among the three LLMs (p <
   0.001). Analysis revealed that responses related to differential
   diagnosis were the weakest, while those pertaining to treatment
   recommendations were the strongest. Med-Go displayed notable performance
   advantages in gastroenterology, nephrology, and neurology. Conclusions
   The findings show that all three LLMs achieved over 60% of the maximum
   possible score, indicating their potential applicability in clinical
   practice. However, inaccuracies that could lead to adverse decisions
   underscore the need for caution in their application. Med-Go's superior
   performance highlights the benefits of incorporating specialized medical
   knowledge into LLMs training. It is anticipated that further development
   and refinement of medical LLMs will enhance their precision and safety
   in clinical use.
Z8 0
TC 2
ZR 0
ZA 0
ZB 0
ZS 0
Z9 2
DA 2025-02-20
UT WOS:001421570100001
PM 39948214
ER

PT J
AU Zeng, Shuyan
   Kong, Qingzhou
   Wu, Xiaoqi
   Ma, Tian
   Wang, Limei
   Xu, Leiqi
   Kou, Guanjun
   Zhang, Mingming
   Yang, Xiaoyun
   Zuo, Xiuli
   Li, Yueyue
   Li, Yanqing
TI Artificial Intelligence-Generated Patient Education Materials for
   Helicobacter pylori Infection: A Comparative Analysis
SO HELICOBACTER
VL 29
IS 4
AR e13115
DI 10.1111/hel.13115
DT Article
PD JUL 2024
PY 2024
AB Background: Patient education contributes to improve public awareness of
   Helicobacter pylori. Large language models (LLMs) offer opportunities to
   revolutionize patient education transformatively. This study aimed to
   assess the quality of patient educational materials (PEMs) generated by
   LLMs and compared with physician sourced. Materials and Methods: Unified
   instruction about composing a PEM about H. pylori at a sixth-grade
   reading level in both English and Chinese were given to physician and
   five LLMs (Bing Copilot, Claude 3 Opus, Gemini Pro, ChatGPT-4, and ERNIE
   Bot 4.0). The assessments of the completeness and comprehensibility of
   the Chinese PEMs were conducted by five gastroenterologists and 50
   patients according to three-point Likert scale. Gastroenterologists were
   asked to evaluate both English and Chinese PEMs and determine the
   accuracy and safety. The accuracy was assessed by six-point Likert
   scale. The minimum acceptable scores were 4, 2, and 2 for accuracy,
   completeness, and comprehensibility, respectively. The Flesch-Kincaid
   and Simple Measure of Gobbledygook scoring systems were employed as
   readability assessment tools. Results: Accuracy and comprehensibility
   were acceptable for English PEMs of all sources, while completence was
   not satisfactory. Physician-sourced PEM had the highest accuracy mean
   score of 5.60 and LLM-generated English PEMs ranged from 4.00 to 5.40.
   The completeness score was comparable between physician-sourced PEM and
   LLM-generated PEMs in English. Chinese PEMs from LLMs proned to have
   lower score in accuracy and completeness assessment than English PEMs.
   The mean score for completeness of five LLM-generated Chinese PEMs was
   1.82-2.70 in patients' perspective, which was higher than
   gastroenterologists' assessment. Comprehensibility was satisfactory for
   all PEMs. No PEM met the recommended sixth-grade reading level.
   Conclusion: LLMs have potential in assisting patient education. The
   accuracy and comprehensibility of LLM-generated PEMs were acceptable,
   but further optimization on improving completeness and accounting for a
   variety of linguistic contexts are essential for enhancing the
   feasibility.
ZR 0
Z8 0
TC 3
ZA 0
ZB 1
ZS 0
Z9 3
DA 2024-08-10
UT WOS:001283715200001
PM 39097925
ER

PT J
AU Magda Maria Sales Carneiro-Sampaio
TI Expansion of the Pediatric Clinical Research Laboratory (LIM 36) and
   establishment of a coordinating area for the support centre for research
   in children and adolescent health issues (NAP-CriAd-USP)
DT Awarded Grant
PD Apr 01 2013
PY 2013
AB The Department of Pediatrics of the University of São Paulo Medical
   School (FMUSP) located the Children's Institute (ICR), has only one
   research laboratory (LlM-36), which has been harboring a growing number
   of research groups in the areas of Genetic Genomics, Immunology,
   Oncology-Hematology, Rheumatology and Pulmonology. In order to increase
   the area of the laboratory, the Council of the Department of Pediatrics
   (MPE) and the Board of Directors of the Children's Institute decided to
   assign a physical area of…. m2, adjoining to the office of MPE, to be
   adapted to harbor the administrative support structure of LlM-36 (which
   besides being in charge of price quotes, purchasing and accounting, also
   advertises research funding opportunities to MPE and ICR researchers.
   These Councils believe that the new area can also be used to establish
   the coordinating team of the newly founded Center for Research Support
   on Children and Adolescent Health (NAP CriAd) which was created with
   support of the USP Dean of Research and will be headquartered at ICr. In
   addition to teaching in the Department of Pediatrics and medical FMUSP
   ICR, NAP CriAd also houses researchers from FSP, EE, IP, FD and the
   Departments of Legal Medicine and Psychiatry of the Medical School,
   which are involved in two major research lines: i) Interfaces between
   Health Sciences and the Law, whose main focus is "The right to Health",
   ii) the impact of recent changes in lifestyle of our society on children
   and adolescent health. The following projects are already in
   development: 1. Assessment of costs and legal feasibility of a program
   of care to patients with rare diseases in the State of S. Paulo, 2.
   Child Friendly Diagnosis: assessing the impact of rationalization and
   humanization of imaging and laboratory diagnostic techniques, 3. The
   influence of digital media and television in adolescent health, 4.
   Conjugality and parenting in reconstituted families, 5. Interfaces of
   breastfeeding in the prison system: law, duty, meanings and reality, 5.
   The ''Way Back Project": application of molecular genetic techniques in
   the identification of missing children. (AU)
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
TC 0
Z9 0
G1 12/51599-7
DA 2023-12-08
UT GRANTS:16419752
ER

PT J
AU Silva, Gisele S.
   Khera, Rohan
   Schwamm, Lee H.
TI Reviewer Experience Detecting and Judging Human Versus Artificial
   Intelligence Content: The Stroke Journal Essay Contest
SO STROKE
VL 55
IS 10
BP 2573
EP 2578
DI 10.1161/STROKEAHA.124.045012
DT Review
PD OCT 2024
PY 2024
AB Artificial intelligence (AI) large language models (LLMs) now produce
   human-like general text and images. LLMs' ability to generate persuasive
   scientific essays that undergo evaluation under traditional peer review
   has not been systematically studied. To measure perceptions of quality
   and the nature of authorship, we conducted a competitive essay contest
   in 2024 with both human and AI participants. Human authors and 4
   distinct LLMs generated essays on controversial topics in stroke care
   and outcomes research. A panel of Stroke Editorial Board members (mostly
   vascular neurologists), blinded to author identity and with varying
   levels of AI expertise, rated the essays for quality, persuasiveness,
   best in topic, and author type. Among 34 submissions (22 human and 12
   LLM) scored by 38 reviewers, human and AI essays received mostly similar
   ratings, though AI essays were rated higher for composition quality.
   Author type was accurately identified only 50% of the time, with prior
   LLM experience associated with improved accuracy. In multivariable
   analyses adjusted for author attributes and essay quality, only
   persuasiveness was independently associated with odds of a reviewer
   assigning AI as author type (adjusted odds ratio, 1.53 [95% CI,
   1.09-2.16]; P=0.01). In conclusion, a group of experienced editorial
   board members struggled to distinguish human versus AI authorship, with
   a bias against best in topic for essays judged to be AI generated.
   Scientific journals may benefit from educating reviewers on the types
   and uses of AI in scientific writing and developing thoughtful policies
   on the appropriate use of AI in authoring manuscripts.
ZA 0
Z8 0
ZR 0
ZS 0
ZB 1
TC 4
Z9 4
DA 2024-10-24
UT WOS:001337182000002
PM 39224979
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Mizuta, Kazuya
   Sakamoto, Tetsu
   Tokumasu, Kazuki
   Shimizu, Taro
TI Evaluating ChatGPT-4's Accuracy in Identifying Final Diagnoses Within
   Differential Diagnoses Compared With Those of Physicians: Experimental
   Study for Diagnostic Cases
SO JMIR FORMATIVE RESEARCH
VL 8
AR e59267
DI 10.2196/59267
DT Article
PD 2024
PY 2024
AB Background: The potential of artificial intelligence (AI) chatbots,
   particularly ChatGPT with GPT-4 (OpenAI), in assistingwith medical
   diagnosis is an emerging research area. However, it is not yet clear how
   well AI chatbots can evaluate whether thefinal diagnosis is included in
   differential diagnosis lists. Objective: This study aims to assess the
   capability of GPT-4 in identifying the final diagnosis from
   differential-diagnosis listsand to compare its performance with that of
   physicians for case report series. Methods: We used a database of
   differential-diagnosis lists from case reports in the American Journal
   of Case Reports,corresponding to final diagnoses. These lists were
   generated by 3 AI systems: GPT-4, Google Bard (currently Google
   Gemini),and Large Language Models by Meta AI 2 (LLaMA2). The primary
   outcome was focused on whether GPT-4's evaluationsidentified the final
   diagnosis within these lists. None of these AIs received additional
   medical training or reinforcement. Forcomparison, 2 independent
   physicians also evaluated the lists, with any inconsistencies resolved
   by another physician. Results: The 3 AIs generated a total of 1176
   differential diagnosis lists from 392 case descriptions. GPT-4's
   evaluations concurredwith those of the physicians in 966 out of 1176
   lists (82.1%). The Cohen kappa coefficient was 0.63 (95% CI 0.56-0.69),
   indicatinga fair to good agreement between GPT-4 and the physicians'
   evaluations. Conclusions: GPT-4 demonstrated a fair to good agreement in
   identifying the final diagnosis from differential-diagnosis
   lists,comparable to physicians for case report series. Its ability to
   compare differential diagnosis lists with final diagnoses suggests
   itspotential to aid clinical decision-making support through diagnostic
   feedback. While GPT-4 showed a fair to good agreement forevaluation, its
   application in real-world scenarios and further validation in diverse
   clinical environments are essential to fullyunderstand its utility in
   the diagnostic process.
ZS 0
ZB 0
TC 5
ZA 0
ZR 0
Z8 0
Z9 5
DA 2024-09-21
UT WOS:001303612400011
PM 38924784
ER

PT J
AU Mora, J.
   Chen, S.
   Mak, R. H.
   Bitterman, D. S.
TI Cancer Treatment Information Differences by Bilingual Prompting in Large
   Language Model Chatbots
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3415
BP E645
EP E646
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001325892302096
ER

PT J
AU Franke, Georg-Nikolaus
   Maier, Jacqueline
   Schubert, Karoline
   Cross, Michael
   Leiblein, Sabine
   Wildenberger, Kathrin
   Giles, Frank
   Hochhaus, Andreas
   Frank, Oliver
   Niederwieser, Dietger
   Lange, Thoralf
TI Low Level BCR-ABL Mutations and Response to Treatment: A Substudy of the
   ENEST1st Trial
SO BLOOD
VL 124
IS 21
DT Meeting Abstract
PD DEC 6 2014
PY 2014
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2015-03-25
UT WOS:000349242700194
ER

PT J
AU Zheng, Neil S.
   Keloth, Vipina K.
   You, Kisung
   Kats, Daniel
   Li, Darrick K.
   Deshpande, Ohm
   Sachar, Hamita
   Xu, Hua
   Laine, Loren
   Shung, Dennis L.
TI Detection of Gastrointestinal Bleeding With Large Language Models to Aid
   Quality Improvement and Appropriate Reimbursement
SO GASTROENTEROLOGY
VL 168
IS 1
DI 10.1053/j.gastro.2024.09.014
EA DEC 2024
DT Article
PD JAN 2025
PY 2025
AB BACKGROUND & AIMS: Early identification and accurate characterization of
   overt gastrointestinal bleeding (GIB)enables opportunities to optimize
   patient management and ensures appropriately risk-adjusted coding for
   claims-based quality measures and reimbursement. Recent advancements in
   generative artificial intelligence, particularly large language models
   (LLMs), create opportunities to support accurate identification of
   clinical conditions. In this study, we present the fi rst LLM-based
   pipeline for identification of overt GIB in the electronic health record
   (EHR). We demonstrate 2 clinically relevant applications: the automated
   detection of recurrent bleeding and appropriate reimbursement coding for
   patients with GIB. METHODS: Development of the LLMbased pipeline was
   performed on 17,712 nursing notes from 1108 patients who were
   hospitalized with acute GIB and underwent endoscopy in the hospital from
   2014 to 2023. The pipeline was used to train an EHR-based machine
   learning model for detection of recurrent bleeding on 546 patients
   presenting to 2 hospitals and externally validated on 562 patients
   presenting to 4 different hospitals. The pipeline was used to develop an
   algorithm for appropriate reimbursement coding on 7956 patients who
   underwent endoscopy in the hospital from 2019 to 2023. RESULTS: The
   LLM-based pipeline accurately detected melena (positive predictive
   value, 0.972; sensitivity, 0.900), hematochezia (positive predictive
   value, 0.900; sensitivity, 0.908), and hematemesis (positive predictive
   value, 0.859; sensitivity, 0.932). The EHRbased machine learning model
   identified recurrent bleeding with area under the curve of 0.986,
   sensitivity of 98.4%, and specificity of 97.5%. The reimbursement coding
   algorithm resulted in an average per-patient reimbursement increase of
   $1299 to $3247 with a total difference of $697,460 to $1,743,649.
   CONCLUSIONS: An LLM-based pipeline can robustly detect overt GIB in the
   EHR with clinically relevant applications in detection of recurrent
   bleeding and appropriate reimbursement coding.
ZR 0
TC 2
Z8 0
ZA 0
ZB 1
ZS 0
Z9 2
DA 2025-01-13
UT WOS:001391995700001
PM 39304088
ER

PT J
AU Zhu, L.
   Anand, A.
   Gevorkyan, G.
   Mcgee, L. A.
   Rwigema, J. C.
   Rong, Y.
   Patel, S. H.
TI Testing and Validation of a Custom Trained Large Language Model for HN
   Patients with Guardrails
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 118
IS 5
MA 182
BP E52
EP E53
DT Meeting Abstract
PD APR 1 2024
PY 2024
CT Multidisciplinary Head and Neck Cancers Symposium
CY FEB 29-MAR 02, 2024
CL Phoenix, AZ
TC 1
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
Z9 1
DA 2024-10-18
UT WOS:001300212900102
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik Y.
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on the Ocular Hypertension Treatment Study
   Dataset Using Chat Generative Pre-Trained Transformer as a Large
   Language Model
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100599
DI 10.1016/j.xops.2024.100599
EA SEP 2024
DT Article
PD JAN-FEB 2025
PY 2025
AB Purpose: To evaluate the capabilities of Chat Generative Pre-Trained
   Transformer (ChatGPT), as a large language model (LLM), for diagnosing
   glaucoma using the Ocular Hypertension Treatment Study (OHTS) dataset,
   and comparing the diagnostic capability of ChatGPT 3.5 and ChatGPT 4.0.
   Design: Prospective data collection study. Participants: A total of 3170
   eyes of 1585 subjects from the OHTS were included in this study.
   Methods: We selected demographic, clinical, ocular, visual field, optic
   nerve head photo, and history of disease parameters of each participant
   and developed case reports by converting tabular data into textual
   format based on information from both eyes of all subjects. We then
   developed a procedure using the application programming interface of
   ChatGPT, a LLM-based chatbot, to automatically input prompts into a chat
   box. This was followed by querying 2 different generations of ChatGPT
   (versions 3.5 and 4.0) regarding the underlying diagnosis of each
   subject. We then evaluated the output responses based on several
   objective metrics. Main Outcome Measures: Area under the receiver
   operating characteristic curve (AUC), accuracy, specificity,
   sensitivity, and F1 score. Results: Chat Generative Pre-Trained
   Transformer 3.5 achieved AUC of 0.74, accuracy of 66%, specificity of
   64%, sensitivity of 85%, and F1 score of 0.72. Chat Generative
   Pre-Trained Transformer 4.0 obtained AUC of 0.76, accuracy of 87%,
   specificity of 90%, sensitivity of 61%, and F1 score of 0.92.
   Conclusions: The accuracy of ChatGPT 4.0 in diagnosing glaucoma based on
   input data from OHTS was promising. The overall accuracy of ChatGPT 4.0
   was higher than ChatGPT 3.5. However, ChatGPT 3.5 was found to be more
   sensitive than ChatGPT 4.0. In its current forms, ChatGPT may serve as a
   useful tool in exploring disease status of ocular hypertensive eyes when
   specific data are available for analysis. In the future, leveraging LLMs
   with multimodal capabilities, allowing for integration of imaging and
   diagnostic testing as part of the analyses, could further enhance
   diagnostic capabilities and enhance diagnostic accuracy. Financial
   Disclosures: Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100599 (c) 2024 by the American Academy of Ophthalmology.
   This is an open access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-ncnd/4.0/).
ZR 0
ZB 0
ZA 0
Z8 0
TC 3
ZS 0
Z9 3
DA 2024-10-16
UT WOS:001330416200001
PM 39346574
ER

PT J
AU Young, Cameron C.
   Enichen, Ellie
   Rivera, Christian
   Auger, Corinne A.
   Grant, Nathan
   Rao, Arya
   Succi, Marc D.
TI Diagnostic Accuracy of a Custom Large Language Model on Rare Pediatric
   Disease Case Reports
SO AMERICAN JOURNAL OF MEDICAL GENETICS PART A
VL 197
IS 2
DI 10.1002/ajmg.a.63878
EA SEP 2024
DT Article
PD FEB 2025
PY 2025
AB Accurately diagnosing rare pediatric diseases frequently represent a
   clinical challenge due to their complex and unusual clinical
   presentations. Here, we explore the capabilities of three large language
   models (LLMs), GPT-4, Gemini Pro, and a custom-built LLM (GPT-4
   integrated with the Human Phenotype Ontology [GPT-4 HPO]), by evaluating
   their diagnostic performance on 61 rare pediatric disease case reports.
   The performance of the LLMs were assessed for accuracy in identifying
   specific diagnoses, listing the correct diagnosis among a differential
   list, and broad disease categories. In addition, GPT-4 HPO was tested on
   100 general pediatrics case reports previously assessed on other LLMs to
   further validate its performance. The results indicated that GPT-4 was
   able to predict the correct diagnosis with a diagnostic accuracy of
   13.1%, whereas both GPT-4 HPO and Gemini Pro had diagnostic accuracies
   of 8.2%. Further, GPT-4 HPO showed an improved performance compared with
   the other two LLMs in identifying the correct diagnosis among its
   differential list and the broad disease category. Although these
   findings underscore the potential of LLMs for diagnostic support,
   particularly when enhanced with domain-specific ontologies, they also
   stress the need for further improvement prior to integration into
   clinical practice.
Z8 0
ZR 0
ZS 0
TC 3
ZA 0
ZB 0
Z9 3
DA 2024-09-18
UT WOS:001310786300001
PM 39268988
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Feldman, Mitchell J.
   Hoffer, Edward P.
   Conley, Jared J.
   Chang, Jaime
   Chung, Jeanhee A.
   Jernigan, Michael C.
   Lester, William T.
   Strasser, Zachary H.
   Chueh, Henry C.
TI Dedicated AI Expert System vs Generative AI With Large Language Model
   for Clinical Diagnoses
SO JAMA NETWORK OPEN
VL 8
IS 5
AR e2512994
DI 10.1001/jamanetworkopen.2025.12994
DT Article
PD MAY 29 2025
PY 2025
AB Importance Large language models (LLMs) have not yet been compared with
   traditional diagnostic decision support systems (DDSSs) on unpublished
   clinical cases. Objective To compare the performance of 2 widely used
   LLMs (ChatGPT, version 4 [hereafter, LLM1] and Gemini, version 1.5
   [hereafter, LLM2]) with a DDSS (DXplain [hereafter, DDSS]) on 36
   unpublished general medicine cases. Design, Setting, and Participants
   This diagnostic study, conducted from October 6, 2023, to November 22,
   2024, looked for the presence of the known case diagnosis in the
   differential diagnoses of the LLMs and DDSS after data from previously
   unpublished clinical cases from 3 academic medical centers were entered.
   The systems' performance was assessed both with and without laboratory
   test data. Each case was reviewed by 3 physicians blinded to the case
   diagnosis. Physicians identified all clinical findings as well as the
   subset deemed relevant to making the diagnosis for mapping to the DDSS's
   controlled vocabulary. Two other physicians, also blinded to the
   diagnoses, entered the data from these cases into the DDSS, LLM1, and
   LLM2. Exposures All cases were entered into each LLM twice, with and
   without laboratory test results. For the DDSS, each case was entered 4
   times: for all findings and for findings relevant to the diagnosis, each
   with and without laboratory test results. The top 25 diagnoses in each
   resulting differential diagnosis were reviewed. Main Outcomes and
   Measures Presence or absence of the case diagnosis in the system's
   differential diagnosis and, when present, in which quintile it appeared
   in the top 25 diagnoses. Results Among 36 patient cases of various races
   and ethnicities, genders, and ages (mean [SD] age, 51.4 [16.4] years),
   in the version with all findings but no laboratory test results, the
   DDSS listed the case diagnosis in its differential diagnosis more often
   (56% [20 of 36]) than LLM1 (42% [15 of 36]) and LLM2 (39% [14 of 36]),
   although this difference did not reach statistical significance (DDSS vs
   LLMI, P = .09; DDSS vs LLM2, P = .08). All 3 systems listed the case
   diagnosis in most cases if laboratory test results were included (all
   findings DDSS, 72% [26 of 36]; LLM1, 64% [23 of 36]; and LLM2, 58% [21
   of 36]). Conclusions and Relevance In this diagnostic study comparing
   the performance of a traditional DDSS and current LLMs on unpublished
   clinical cases, in most cases, every system listed the case diagnosis in
   their top 25 diagnoses if laboratory test results were included. A
   hybrid approach that combines the parsing and expository linguistic
   capabilities of LLMs with the deterministic and explanatory capabilities
   of traditional DDSSs may produce synergistic benefits.
ZA 0
Z8 0
TC 0
ZR 0
ZB 0
ZS 0
Z9 0
DA 2025-06-05
UT WOS:001499415200009
PM 40440012
ER

PT J
AU van Diessen, Eric
   van Amerongen, Ramon A.
   Zijlmans, Maeike
   Otte, Willem M.
TI Potential merits and flaws of large language models in epilepsy care: A
   critical review
SO EPILEPSIA
VL 65
IS 4
BP 873
EP 886
DI 10.1111/epi.17907
EA FEB 2024
DT Review
PD APR 2024
PY 2024
AB The current pace of development and applications of large language
   models (LLMs) is unprecedented and will impact future medical care
   significantly. In this critical review, we provide the background to
   better understand these novel artificial intelligence (AI) models and
   how LLMs can be of future use in the daily care of people with epilepsy.
   Considering the importance of clinical history taking in diagnosing and
   monitoring epilepsy-combined with the established use of electronic
   health records-a great potential exists to integrate LLMs in epilepsy
   care. We present the current available LLM studies in epilepsy.
   Furthermore, we highlight and compare the most commonly used LLMs and
   elaborate on how these models can be applied in epilepsy. We further
   discuss important drawbacks and risks of LLMs, and we provide
   recommendations for overcoming these limitations.
ZA 0
TC 5
ZS 0
ZR 0
Z8 0
ZB 0
Z9 5
DA 2024-02-10
UT WOS:001155360500001
PM 38305763
ER

PT J
AU McCoy Jr, Thomas H.
   Perlis, Roy H.
TI Dimensional Measures of Psychopathology in Children and Adolescents
   Using Large Language Models
SO BIOLOGICAL PSYCHIATRY
VL 96
IS 12
BP 940
EP 947
DI 10.1016/j.biopsych.2024.05.008
EA NOV 2024
DT Article
PD DEC 15 2024
PY 2024
AB BACKGROUND: To enable greater use of National Institute of Mental Health
   Research Domain Criteria (RDoC) in real- world settings, we applied
   large language models (LLMs) to estimate dimensional psychopathology
   from narrative clinical notes. METHODS: We conducted a cohort study
   using health records from individuals age #18 years evaluated in the
   psychiatric emergency department of a large academic medical center
   between November 2008 and March 2015. Outcomes were hospital admission
   and length of emergency department stay. RDoC domains were estimated
   using a Health Insurance Portability and Accountability Act-compliant
   LLM (gpt-4-1106-preview) and compared with a previously validated
   token-based approach. RESULTS: The cohort included 3059 individuals
   (median age 16 years [interquartile range, 13-18]; 1580 [52%] female,
   1479 [48%] male; 105 [3.4%] identified as Asian, 329 [11%] as Black, 288
   [9.4%] as Hispanic, 474 [15%] as other race, and 1863 [61%] as White),
   of whom 1695 (55%) were admitted. Correlation between LLM-extracted RDoC
   scores and the token-based scores ranged from small to medium as
   assessed by Kendall's tau (0.14-0.22). In logistic regression models
   adjusting for sociodemographic and clinical features, admission
   likelihood was associated with greater scores on all domains, with the
   exception of the sensorimotor domain, which was inversely associated (p
   < .001 for all adjusted associations). Tests for bias suggested modest
   but statistically significant differences in positive valence scores by
   race (p < .05 for Asian, Black, and Hispanic individuals). CONCLUSIONS:
   An LLM extracted estimates of 6 RDoC domains in an explainable manner,
   which were associated with clinical outcomes. This approach can
   contribute to a new generation of prediction models or biological
   investigations based on dimensional psychopathology.
ZS 0
TC 6
Z8 0
ZB 3
ZR 0
ZA 0
Z9 6
DA 2024-11-23
UT WOS:001356681000001
PM 38866172
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Tokumasu, Kazuki
   Shiraishi, Tatsuya
   Suzuki, Tomoharu
   Shimizu, Taro
TI Comparative Analysis of Diagnostic Performance: Differential Diagnosis
   Lists by LLaMA3 Versus LLaMA2 for Case Reports
SO JMIR FORMATIVE RESEARCH
VL 8
AR e64844
DI 10.2196/64844
DT Article
PD 2024
PY 2024
AB Background: Generative artificial intelligence (AI), particularly in the
   form of large language models, has rapidly developed. The LLaMA series
   are popular and recently updated from LLaMA2 to LLaMA3. However, the
   impacts of the update on diagnostic performance have not been well
   documented. Objective: We conducted a comparative evaluation of the
   diagnostic performance in differential diagnosis lists generated by
   LLaMA3 and LLaMA2 for case reports. Methods: We analyzed case reports
   published in the AmericanJournal of Case Reports from 2022 to 2023.
   After excluding nondiagnostic and pediatric cases, we input the
   remaining cases into LLaMA3 and LLaMA2 using the same prompt and the
   same adjustable parameters. Diagnostic performance was defined by
   whether the differential diagnosis lists included thefinal diagnosis.
   Multiple physicians independently evaluated whether the final diagnosis
   was included in the top 10 differentials generated by LLaMA3 and LLaMA2.
   Results: In our comparative evaluation of the diagnostic performance
   between LLaMA3 and LLaMA2, we analyzed differential diagnosis lists for
   392 case reports. The final diagnosis was included in the top 10
   differentials generated by LLaMA3 in 79.6% (312/392) of the cases,
   compared to 49.7% (195/392) for LLaMA2, indicating a statistically
   significant improvement (P<.001). Additionally, LLaMA3 showed higher
   performance in including the final diagnosis in the top 5 differentials,
   observed in 63% (247/392) of cases, compared to LLaMA2's 38% (149/392, P
   <.001). Furthermore, the top diagnosis was accurately identified by
   LLaMA3 in 33.9% (133/392) of cases, significantly higher than the 22.7%
   (89/392) achieved by LLaMA2 (P<.001). The analysis across various
   medical specialties revealed variations in diagnostic performance with
   LLaMA3 consistently outperforming LLaMA2. Conclusions: The results
   reveal that the LLaMA3 model significantly outperforms LLaMA2 per
   diagnostic performance, with a higher percentage of case reports having
   the final diagnosis listed within the top 10, top 5, and as the top
   diagnosis. Overall diagnostic performance improved almost 1.5 times from
   LLaMA2 to LLaMA3. These findings support the rapid development and
   continuous refinement of generativeAI systems to enhance diagnostic
   processes in medicine. However, these findings should be carefully
   interpreted for clinical application, as generativeAI, including the
   LLaMA series, has not been approved for medical applications such as
   AI-enhanced diagnostics.
ZA 0
TC 0
Z8 0
ZB 0
ZR 0
ZS 0
Z9 0
DA 2025-01-29
UT WOS:001402019000006
PM 39561356
ER

PT J
AU Zhang, Peng
   Shi, Jiayu
   Boulos, Maged N. Kamel
TI Generative AI in Medicine and Healthcare: Moving Beyond the 'Peak of
   Inflated Expectations'
SO FUTURE INTERNET
VL 16
IS 12
AR 462
DI 10.3390/fi16120462
DT Review
PD DEC 2024
PY 2024
AB The rapid development of specific-purpose Large Language Models (LLMs),
   such as Med-PaLM, MEDITRON-70B, and Med-Gemini, has significantly
   impacted healthcare, offering unprecedented capabilities in clinical
   decision support, diagnostics, and personalized health monitoring. This
   paper reviews the advancements in medicine-specific LLMs, the
   integration of Retrieval-Augmented Generation (RAG) and prompt
   engineering, and their applications in improving diagnostic accuracy and
   educational utility. Despite the potential, these technologies present
   challenges, including bias, hallucinations, and the need for robust
   safety protocols. The paper also discusses the regulatory and ethical
   considerations necessary for integrating these models into mainstream
   healthcare. By examining current studies and developments, this paper
   aims to provide a comprehensive overview of the state of LLMs in
   medicine and highlight the future directions for research and
   application. The study concludes that while LLMs hold immense potential,
   their safe and effective integration into clinical practice requires
   rigorous testing, ongoing evaluation, and continuous collaboration among
   stakeholders.
ZR 0
TC 4
ZB 0
ZA 0
ZS 0
Z8 0
Z9 4
DA 2025-01-01
UT WOS:001384353900001
ER

PT J
AU Xia, Shujun
   Hua, Qing
   Mei, Zihan
   Xu, Wenwen
   Lai, Limei
   Wei, Minyan
   Qin, Yu
   Luo, Lin
   Wang, Changhua
   Huo, ShengNan
   Fu, Lijun
   Zhou, Feidu
   Wu, Jiang
   Zhang, Li
   Lv, De
   Li, Jianxin
   Wang, Xin
   Li, Ning
   Song, Yanyan
   Zhou, Jianqiao
TI Clinical application potential of large language model: a study based on
   thyroid nodules
SO ENDOCRINE
VL 87
IS 1
BP 206
EP 213
DI 10.1007/s12020-024-03981-3
EA JUL 2024
DT Article
PD JAN 2025
PY 2025
AB Background Limited data indicated the performance of large language
   model (LLM) taking on the role of doctors. We aimed to investigate the
   potential for ChatGPT-3.5 and New Bing Chat acting as doctors using
   thyroid nodules as an example. Methods A total of 145 patients with
   thyroid nodules were included for generating questions. Each question
   was entered into chatbot of ChatGPT-3.5 and New Bing Chat five times and
   five responses were acquired respectively. These responses were compared
   with answers given by five junior doctors. Responses from five senior
   doctors were regarded as gold standard. Accuracy and reproducibility of
   responses from ChatGPT-3.5 and New Bing Chat were evaluated. Results The
   accuracy of ChatGPT-3.5 and New Bing Chat in answering Q2, Q3, Q5 were
   lower than that of junior doctors (all P < 0.05), while both LLMs were
   comparable to junior doctors when answering Q4 and Q6. In terms of "high
   reproducibility and accuracy", ChatGPT-3.5 outperformed New Bing Chat in
   Q1 and Q5 (P < 0.001 and P = 0.008, respectively), but showed no
   significant difference in Q2, Q3, Q4, and Q6 (P > 0.05 for all). New
   Bing Chat generated higher accuracy than ChatGPT-3.5 (72.41% vs 58.62%)
   (P = 0.003) in decision making of thyroid nodules, and both were less
   accurate than junior doctors (89.66%, P < 0.001 for both). Conclusions
   The exploration of ChatGPT-3.5 and New Bing Chat in the diagnosis and
   management of thyroid nodules illustrates that LLMs currently
   demonstrate the potential for medical applications, but do not yet reach
   the clinical decision-making capacity of doctors.
Z8 0
TC 3
ZA 0
ZS 0
ZR 0
ZB 0
Z9 3
DA 2024-08-06
UT WOS:001281038100001
PM 39080210
ER

PT J
AU Cook, David A.
   Overgaard, Joshua
   Pankratz, V. Shane
   Del Fiol, Guilherme
   Aakre, Chris A.
TI Virtual Patients Using Large Language Models: Scalable, Contextualized
   Simulation of Clinician-Patient Dialogue With Feedback
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e68486
DI 10.2196/68486
DT Article
PD APR 4 2025
PY 2025
AB Background: Virtual patients (VPs) are computer screen-based simulations
   of patient-clinician encounters. VP use is limited by cost and low
   scalability. Objective: We aimed to show that VPs powered by large
   language models (LLMs) can generate authentic dialogues, accurately
   represent patient preferences, and provide personalized feedback on
   clinical performance. We also explored using LLMs to rate the quality of
   dialogues and feedback. Methods: We conducted an intrinsic evaluation
   study rating 60 VP-clinician conversations. We used carefully engineered
   prompts to direct OpenAI's generative pretrained transformer (GPT) to
   emulate a patient and provide feedback. Using 2 outpatient medicine
   topics (chronic cough diagnosis and diabetes management), each with
   permutations representing different patient preferences, we created 60
   conversations (dialogues plus feedback): 48 with a human clinician and
   12 "self-chat" dialogues with GPT role-playing both the VP and
   clinician. Primary outcomes were dialogue authenticity and feedback
   quality, rated using novel instruments for which we conducted a
   validation study collecting evidence of content, internal structure
   (reproducibility), relations with other variables, and response process.
   Each conversation was rated by 3 physicians and by GPT. Secondary
   outcomes included user experience, bias, patient preferences represented
   in the dialogues, and conversation features that influenced Results: The
   average cost per conversation was US $0.51 for GPT-4.0-Turbo and US
   $0.02 for GPT-3.5-Turbo. Mean (SD) conversation ratings, maximum 6, were
   overall dialogue authenticity 4.7 (0.7), overall user experience 4.9
   (0.7), and average feedback quality 4.7 (0.6). For dialogues created
   using GPT-4.0-Turbo, physician ratings of patient preferences aligned
   with intended preferences in 20 to 47 of 48 dialogues (42%-98%).
   Subgroup comparisons revealed higher ratings for dialogues using
   GPT-4.0-Turbo versus GPT-3.5-Turbo and for human-generated versus
   self-chat dialogues. Feedback ratings were similar for human-generated
   versus GPT-generated ratings, whereas authenticity ratings were lower.
   We did not perceive bias in any conversation. Dialogue features that
   detracted from authenticity included that GPT was verbose or used
   atypical vocabulary was easily convinced by clinician suggestions (n=35,
   19%), or was not disaffected by poor clinician performance (n=32, 18%).
   developed (content evidence), and we confirmed expected relations with
   other variables (higher ratings for advanced LLMs and human-generated
   dialogues). Reproducibility was suboptimal, due largely to variation in
   LLM performance rather than rater idiosyncrasies. Conclusions:
   LLM-powered VPs can simulate patient-clinician dialogues, demonstrably
   represent patient preferences, and provide personalized performance
   feedback. This approach is scalable, globally accessible, and
   inexpensive. LLM-generated ratings of feedback quality are similar to
   human ratings.
TC 0
Z8 0
ZA 0
ZS 0
ZR 0
ZB 0
Z9 0
DA 2025-04-27
UT WOS:001470073100004
PM 39854611
ER

PT J
AU Li, Ang
   Wang, Yunxin
   Chen, Hongxu
TI AI driven cardiovascular risk prediction using NLP and Large Language
   Models for personalized medicine in athletes
SO SLAS TECHNOLOGY
VL 32
AR 100286
DI 10.1016/j.slast.2025.100286
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB The performance and long-term health of athletes are significantly
   influenced by their cardiovascular resilience and associated risk
   factors. This study explores the innovative applications of Natural
   Language Processing (NLP) and Large Language Models (LLMs) in biomedical
   diagnostics, particularly for AI-driven arrhythmia detection,
   hypertrophic cardiomyopathy (HCM) in athletes, and personalized
   medicine. The complexity of analysing diverse biomedical datasets, such
   as electrocardiograms (ECG), clinical records, genetic screening
   reports, and imaging results, poses challenges in obtaining precise
   early diagnoses. To address these issues, we introduce a hybrid machine
   learning (ML) framework that integrates the Wolf Pack Search Algorithm
   Dynamic Random Forest (WPSA-DRF) with a RoBERTa-based LLM to enhance the
   accuracy of cardiovascular disease predictions. Using advanced NLP
   techniques, including biomedical text mining, entity recognition, and
   feature extraction, the system processes structured and unstructured
   clinical data to detect abnormalities associated with sudden cardiac
   arrest (SCA), arrhythmias, and genetic cardiomyopathies. The proposed
   system achieves a diagnostic accuracy of 92.5 %, precision of 92.7 %,
   recall of 99.23 %, and F1-score of 95.6 %, outperforming traditional
   diagnostic methodologies. Furthermore, the research underscores the role
   of LLMs in personalized medicine, identifying patient-specific risk
   factors and optimizing treatment pathways for cardiac patients. This
   work highlights how NLP-driven AI solutions are transforming biomedical
   research, accelerating early disease detection, and improving clinical
   decision-making for both athletes and the general population.
ZR 0
TC 0
ZA 0
ZS 0
Z8 0
ZB 0
Z9 0
DA 2025-05-08
UT WOS:001478484900001
PM 40216258
ER

PT J
AU Dinc, Mehmed T
   Bardak, Ali E
   Bahar, Furkan
   Noronha, Craig
TI Comparative analysis of large language models in clinical diagnosis:
   performance evaluation across common and complex medical cases.
SO JAMIA open
VL 8
IS 3
BP ooaf055
EP ooaf055
DI 10.1093/jamiaopen/ooaf055
DT Journal Article
PD 2025-Jun
PY 2025
AB Objectives: This study aimed to systematically evaluate and compare the
   diagnostic performance of leading large language models (LLMs) in common
   and complex clinical scenarios, assessing their potential for enhancing
   clinical reasoning and diagnostic accuracy in authentic clinical
   decision-making processes.
   Materials and Methods: Diagnostic capabilities of advanced LLMs
   (Anthropic's Claude, OpenAI's GPT variants, Google's Gemini) were
   assessed using 60 common cases and 104 complex, real-world cases from
   Clinical Problem Solvers' morning rounds. Clinical details were
   disclosed in stages, mirroring authentic clinical decision-making.
   Models were evaluated on primary and differential diagnosis accuracy at
   each stage.
   Results: Advanced LLMs showed high diagnostic accuracy (>90%) in common
   scenarios, with Claude 3.7 achieving perfect accuracy (100%) in certain
   conditions. In complex cases, Claude 3.7 achieved the highest accuracy
   (83.3%) at the final diagnostic stage, significantly outperforming
   smaller models. Smaller models notably performed well in common
   scenarios, matching the performance of larger models.
   Discussion: This study evaluated leading LLMs for diagnostic accuracy
   using staged information disclosure, mirroring real-world practice.
   Notably, Claude 3.7 Sonnet was the top performer. Employing a novel
   LLM-based evaluation method for large-scale analysis, the research
   highlights artificial intelligence's (AI's) potential to enhance
   diagnostics. It underscores the need for useful frameworks to translate
   accuracy into clinical impact and integrate AI into medical education.
   Conclusion: Leading LLMs show remarkable diagnostic accuracy in diverse
   clinical cases. To fully realize their potential for improving patient
   care, we must now focus on creating practical implementation frameworks
   and translational research to integrate these powerful AI tools into
   medicine.
ZS 0
TC 0
ZA 0
Z8 0
ZB 0
ZR 0
Z9 0
DA 2025-06-15
UT MEDLINE:40510808
PM 40510808
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT J
AU Mira, Felipe Ahumada
   Favier, Valentin
   Nunes, Heloisa dos Santos Sobreira
   de Castro, Joana Vaz
   Carsuzaa, Florent
   Meccariello, Giuseppe
   Vicini, Claudio
   De Vito, Andrea
   Lechien, Jerome R.
   Estomba, Carlos Chiesa
   Maniaci, Antonino
   Iannella, Giannicola
   Rojas, Eduardo Pena
   Cornejo, Jenifer Barros
   Cammaroto, Giovanni
TI Chat GPT for the management of obstructive sleep apnea: do we have a
   polar star?
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 2087
EP 2093
DI 10.1007/s00405-023-08270-9
EA NOV 2023
DT Article
PD APR 2024
PY 2024
AB PurposeThis study explores the potential of the Chat-Generative
   Pre-Trained Transformer (Chat-GPT), a Large Language Model (LLM), in
   assisting healthcare professionals in the diagnosis of obstructive sleep
   apnea (OSA). It aims to assess the agreement between Chat-GPT's
   responses and those of expert otolaryngologists, shedding light on the
   role of AI-generated content in medical decision-making.MethodsA
   prospective, cross-sectional study was conducted, involving 350
   otolaryngologists from 25 countries who responded to a specialized OSA
   survey. Chat-GPT was tasked with providing answers to the same survey
   questions. Responses were assessed by both super-experts and
   statistically analyzed for agreement.ResultsThe study revealed that
   Chat-GPT and expert responses shared a common answer in over 75% of
   cases for individual questions. However, the overall consensus was
   achieved in only four questions. Super-expert assessments showed a
   moderate agreement level, with Chat-GPT scoring slightly lower than
   experts. Statistically, Chat-GPT's responses differed significantly from
   experts' opinions (p = 0.0009). Sub-analysis revealed areas of
   improvement for Chat-GPT, particularly in questions where super-experts
   rated its responses lower than expert consensus.ConclusionsChat-GPT
   demonstrates potential as a valuable resource for OSA diagnosis,
   especially where access to specialists is limited. The study emphasizes
   the importance of AI-human collaboration, with Chat-GPT serving as a
   complementary tool rather than a replacement for medical professionals.
   This research contributes to the discourse in otolaryngology and
   encourages further exploration of AI-driven healthcare applications.
   While Chat-GPT exhibits a commendable level of consensus with expert
   responses, ongoing refinements in AI-based healthcare tools hold
   significant promise for the future of medicine, addressing the
   underdiagnosis and undertreatment of OSA and improving patient outcomes.
ZS 0
ZB 5
Z8 0
TC 23
ZR 0
ZA 0
Z9 23
DA 2023-12-07
UT WOS:001103635400001
PM 37980605
ER

PT J
AU Patel, Anisha V.
   Jasani, Sona
   Alashqar, Abdelrahman
   Panakam, Aisvarya
   Amin, Kanhai
   Sheth, Sangini S.
TI Evaluating the Accuracy and Utility of Large Language Models in
   Answering Common Contraception Questions
SO OBSTETRICS AND GYNECOLOGY
VL 143
IS 5S
MA 2683633
BP 13S
EP 13S
DI 10.1097/01.AOG.0001013000.12240.72
SU 5
DT Meeting Abstract
PD MAY 2024
PY 2024
CT 72nd Annual Clinical and Scientific Meeting of the
   American-College-of-Obstetricians-and-Gynecologists
CY MAY 17-19, 2024
CL San Francisco, CA
SP Amer Coll Obstetricians & Gynecologists
ZR 0
Z8 0
ZS 0
ZA 0
TC 0
ZB 0
Z9 0
DA 2024-07-14
UT WOS:001258908200021
ER

PT J
AU Niu, Hao
   Alvarez-Alvarez, Ismael
   Chen, Minjun
TI Artificial Intelligence: An Emerging Tool for Studying Drug-Induced
   Liver Injury
SO LIVER INTERNATIONAL
VL 45
IS 3
AR e70038
DI 10.1111/liv.70038
DT Review
PD MAR 2025
PY 2025
AB Drug-induced liver injury (DILI) is a complex and potentially severe
   adverse reaction to drugs, herbal products or dietary supplements. DILI
   can mimic other liver diseases clinical presentation, and currently
   lacks specific diagnostic biomarkers, which hinders its diagnosis. In
   some cases, DILI may progress to acute liver failure. Given its public
   health risk, novel methodologies to enhance the understanding of DILI
   are crucial. Recently, the increasing availability of larger datasets
   has highlighted artificial intelligence (AI) as a powerful tool to
   construct complex models. In this review, we summarise the evidence
   about the use of AI in DILI research, explaining fundamental AI concepts
   and its subfields. We present findings from AI-based approaches in DILI
   investigations for risk stratification, prognostic evaluation and
   causality assessment and discuss the adoption of natural language
   processing (NLP) and large language models (LLM) in the clinical
   setting. Finally, we explore future perspectives and challenges in
   utilising AI for DILI research.
ZR 0
ZS 0
ZA 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-03-12
UT WOS:001427185500001
PM 39982029
ER

PT J
AU Dihan, Qais A.
   Brown, Andrew D.
   Chauhan, Muhammad Z.
   Alzein, Ahmad F.
   Abdelnaem, Seif E.
   Kelso, Sean D.
   Rahal, Dania A.
   Park, Royce
   Ashraf, Mohammadali
   Azzam, Amr
   Morsi, Mahmoud
   Warner, David B.
   Sallam, Ahmed B.
   Saeed, Hajirah N.
   Elhusseiny, Abdelrahman M.
TI Leveraging large language models to improve patient education on dry eye
   disease
SO EYE
VL 39
IS 6
BP 1115
EP 1122
DI 10.1038/s41433-024-03476-5
EA DEC 2024
DT Article
PD APR 2025
PY 2025
AB BACKGROUND/OBJECTIVES: Dry eye disease (DED) is an exceedingly common
   diagnosis in patients, yet recent analyses have demonstrated patient
   education materials (PEMs) on DED to be of low quality and readability.
   Our study evaluated the utility and performance of three large language
   models (LLMs) in enhancing and generating new patient education
   materials (PEMs) on dry eye disease (DED). SUBJECTS/METHODS: We
   evaluated PEMs generated by ChatGPT-3.5, ChatGPT-4, Gemini Advanced,
   using three separate prompts. Prompts A and B requested they generate
   PEMs on DED, with Prompt B specifying a 6th-grade reading level, using
   the SMOG (Simple Measure of Gobbledygook) readability formula. Prompt C
   asked for a rewrite of existing PEMs at a 6th-grade reading level. Each
   PEM was assessed on readability (SMOG, FKGL: Flesch-Kincaid Grade
   Level), quality (PEMAT: Patient Education Materials Assessment Tool,
   DISCERN), and accuracy (Likert Misinformation scale). RESULTS: All
   LLM-generated PEMs in response to Prompt A and B were of high quality
   (median DISCERN = 4), understandable (PEMAT understandability >= 70%)
   and accurate (Likert Score=1). LLM-generated PEMs were not actionable
   (PEMAT Actionability <70%). ChatGPT-4 and Gemini Advanced rewrote
   existing PEMs (Prompt C) from a baseline readability level (FKGL: 8.0
   +/- 2.4, SMOG: 7.9 +/- 1.7) to targeted 6th-grade reading level;
   rewrites contained little to no misinformation (median Likert
   misinformation=1 (range: 1-2)). However, only ChatGPT-4 rewrote PEMs
   while maintaining high quality and reliability (median DISCERN = 4).
   CONCLUSION: LLMs (notably ChatGPT-4) were able to generate and rewrite
   PEMs on DED that were readable, accurate, and high quality. Our study
   underscores the value of leveraging LLMs as supplementary tools to
   improving PEMs.
ZR 0
ZS 0
TC 5
Z8 0
ZA 0
ZB 0
Z9 5
DA 2024-12-22
UT WOS:001379292900001
PM 39681711
ER

PT J
AU Hu, Dingyi
   Jiang, Zhiguo
   Shi, Jun
   Xie, Fengying
   Wu, Kun
   Tang, Kunming
   Cao, Ming
   Huai, Jianguo
   Zheng, Yushan
TI Pathology report generation from whole slide images with knowledge
   retrieval and multi-level regional feature selection
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 263
AR 108677
DI 10.1016/j.cmpb.2025.108677
EA MAR 2025
DT Article
PD MAY 2025
PY 2025
AB Background and objectives: With the development of deep learning
   techniques, the computer-assisted pathology diagnosis plays a crucial
   role in clinical diagnosis. An important task within this field is
   report generation, which provides doctors with text descriptions of
   whole slide images (WSIs). Report generation from WSIs presents
   significant challenges due to the structural complexity and pathological
   diversity of tissues, as well as the large size and high information
   density of WSIs. The objective of this study is to design histopathology
   report generation method that can efficiently generate reports from WSIs
   and is suitable for clinical practice. Methods: In this paper, we
   propose a novel approach for generating pathology reports from WSIs,
   leveraging knowledge retrieval and multi-level regional feature
   selection. To deal with the uneven distribution pathological information
   in WSIs, we introduce a multi-level regional feature encoding network
   and a feature selection module that extracts multi-level region
   representations and filters out region features irrelevant the
   diagnosis, enabling more efficient report generation. Moreover, we
   design a knowledge retrieval module improve the report generation
   performance that can leverage the diagnostic information from historical
   cases. Additionally, we propose an out-of-domain application mode based
   on large language model (LLM). The use of LLM enhances the scalability
   of the generation model and improves its adaptability to data from
   different sources. Results: The proposed method is evaluated on a public
   datasets and one in-house dataset. On the public GastricADC (991 WSIs),
   our method outperforms state-of-the-art text generation methods and
   achieved 0.568 and 0.345 on metric Rouge-L and Bleu-4, respectively. On
   the in-house Gastric-3300 (3309 WSIs), our method achieved significantly
   better performance with Rouge-L of 0.690, which surpassed the
   second-best state-of-the-art method Wcap 6.3%. Conclusions: We present
   an advanced method for pathology report generation from WSIs, addressing
   the key challenges associated with the large size and complex
   pathological structures of these images. In particular, the multi-level
   regional feature selection module effectively captures diagnostically
   significant regions of varying sizes. The knowledge retrieval-based
   decoder leverages historical diagnostic data to enhance report accuracy.
   Our method not only improves the informativeness and relevance of the
   generated pathology reports but also outperforms the state-of-the-art
   techniques.
ZS 0
ZB 0
ZA 0
Z8 0
ZR 0
TC 0
Z9 0
DA 2025-03-12
UT WOS:001437933700001
PM 40023962
ER

PT J
AU Zhang, Chi
   Yang, Hao
   Liu, Xingyun
   Wu, Rongrong
   Zong, Hui
   Wu, Erman
   Zhou, Yi
   Li, Jiakun
   Shen, Bairong
TI A Knowledge-Enhanced Platform (MetaSepsisKnowHub) for Retrieval
   Augmented Generation-Based Sepsis Heterogeneity and Personalized
   Management: Development Study.
SO Journal of medical Internet research
VL 27
BP e67201
EP e67201
DI 10.2196/67201
DT Journal Article
PD 2025 Jun 06
PY 2025
AB BACKGROUND: Sepsis is a severe syndrome of organ dysfunction caused by
   infection; it has high heterogeneity and high in-hospital mortality,
   representing a grim clinical challenge for precision medicine in
   critical care.
   OBJECTIVE: We aimed to extract reported sepsis biomarkers to provide
   users with comprehensive biomedical information and integrate retrieval
   augmented generation (RAG) and prompt engineering to enhance the
   accuracy, stability, and interpretability of clinical decisions
   recommended by large language models (LLMs).
   METHODS: To address the challenge, we established and updated the first
   knowledge-enhanced platform, MetaSepsisKnowHub, comprising 427 sepsis
   biomarkers and 423 studies, aiming to systematically collect and
   annotate sepsis biomarkers to guide personalized clinical
   decision-making in the diagnosis and treatment of human sepsis. We
   curated a tailored LLM framework incorporating RAG and prompt
   engineering and incorporated 2 performance evaluation scales: the System
   Usability Scale and the Net Promoter Score.
   RESULTS: The overall quantitative ratings of expert-reviewed clinical
   recommendations based on RAG surpassed baseline responses generated by 4
   LLMs and showed a statistically significant improvement in textual
   questions (GPT-4: mean 75.79, SD 7.11 vs mean 81.59, SD 9.87; P=.02;
   GPT-4o: mean 70.36, SD 7.63 vs mean 77.98, SD 13.26; P=.02;
   Qwen2.5-instruct: mean 77.08 SD 3.75 vs mean 85.46, SD 7.27; P<.001; and
   DeepSeek-R1: mean 77.67, SD 3.66 vs mean 86.42, SD 8.56; P<.001), but no
   significant statistical differences could be measured in clinical
   scenarios. The RAG assessment score comparing RAG-based responses and
   expert-provided benchmark answers illustrated prominent factual
   correctness, accuracy, and knowledge recall compared to the baseline
   responses. After use, the average the System Usability Scale score was
   82.20 (SD 14.17) and the Net Promoter Score was 72, demonstrating high
   user satisfaction and loyalty.
   CONCLUSIONS: We highlight the pioneering MetaSepsisKnowHub platform, and
   we show that combining MetaSepsisKnowHub with RAG can minimize
   limitations on precision and maximize the breadth of LLMs to shorten the
   bench-to-bedside distance, serving as a knowledge-enhanced paradigm for
   future application of artificial intelligence in critical care medicine.
ZS 0
ZR 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
DA 2025-06-08
UT MEDLINE:40478618
PM 40478618
ER

PT J
AU Cangelosi, Davide
   Blengio, Fabiola
   Versteeg, Rogier
   Eggert, Angelika
   Garaventa, Alberto
   Gambini, Claudio
   Conte, Massimo
   Eva, Alessandra
   Muselli, Marco
   Varesio, Luigi
TI Logic Learning Machine creates explicit and stable rules stratifying
   neuroblastoma patients
SO BMC BIOINFORMATICS
VL 14
AR S12
DI 10.1186/1471-2105-14-S7-S12
SU 7
DT Article
PD APR 22 2013
PY 2013
AB Background: Neuroblastoma is the most common pediatric solid tumor.
   About fifty percent of high risk patients die despite treatment making
   the exploration of new and more effective strategies for improving
   stratification mandatory. Hypoxia is a condition of low oxygen tension
   occurring in poorly vascularized areas of the tumor associated with poor
   prognosis. We had previously defined a robust gene expression signature
   measuring the hypoxic component of neuroblastoma tumors (NB-hypo) which
   is a molecular risk factor. We wanted to develop a prognostic classifier
   of neuroblastoma patients' outcome blending existing knowledge on
   clinical and molecular risk factors with the prognostic NB-hypo
   signature. Furthermore, we were interested in classifiers outputting
   explicit rules that could be easily translated into the clinical
   setting.
   Results: Shadow Clustering (SC) technique, which leads to final models
   called Logic Learning Machine (LLM), exhibits a good accuracy and
   promises to fulfill the aims of the work. We utilized this algorithm to
   classify NB-patients on the bases of the following risk factors: Age at
   diagnosis, INSS stage, MYCN amplification and NB-hypo. The algorithm
   generated explicit classification rules in good agreement with existing
   clinical knowledge. Through an iterative procedure we identified and
   removed from the dataset those examples which caused instability in the
   rules. This workflow generated a stable classifier very accurate in
   predicting good and poor outcome patients. The good performance of the
   classifier was validated in an independent dataset. NB-hypo was an
   important component of the rules with a strength similar to that of
   tumor staging.
   Conclusions: The novelty of our work is to identify stability, explicit
   rules and blending of molecular and clinical risk factors as the key
   features to generate classification rules for NB patients to be conveyed
   to the clinic and to be used to design new therapies. We derived,
   through LLM, a set of four stable rules identifying a new class of poor
   outcome patients that could benefit from new therapies potentially
   targeting tumor hypoxia or its consequences.
ZR 0
ZB 8
TC 24
ZS 0
ZA 0
Z8 1
Z9 25
DA 2013-04-22
UT WOS:000318869400012
PM 23815266
ER

PT J
AU Negussie, Enyew
   Stranden, Ismo
   Mantysaari, Esa A.
TI Genetic analysis of liability to clinical mastitis, with somatic cell
   score and production traits using bivariate threshold-linear and
   linear-linear models
SO LIVESTOCK SCIENCE
VL 117
IS 1
BP 52
EP 59
DI 10.1016/j.livsci.2007.11.009
DT Article
PD AUG 2008
PY 2008
AB Inferences about genetic and residual correlation estimates and sire
   evaluations involving a categorical trait with linear model are
   ambiguous and mostly based on data simulations. In this study, estimates
   of variance components and prediction of breeding values in a model with
   a categorical and a continuous trait were compared between
   threshold-linear (TLM) and linear-linear models (LLM) in analysis of
   large clinical mastitis (CM) field data. Data on CM, somatic cell score
   (SCS), 305-day milk (W), protein (PY) and fat yield (FY) from
   first-lactation Finnish Ayrshire cows were used. Four bivariate analyses
   were made using a TLM in Bayesian analysis. Each analysis fitted CM and
   one continuous trait at a time. Corresponding bivariate analyses were
   made using a Gaussian linear model. Estimates of heritabilities for CM
   were 0.06 and 0.02 from TLM and LLM, respectively whilst heritability
   estimates of the continuous traits were similar from both models.
   Genetic correlations between CM-SCS, CM-MY, CM-PY, and CM-FY from TLM
   and LLM were 0.63 and 0.63; 0.36 and 0.36; 0.32 and 0.32-1 0.30 and
   0.29, respectively. Estimates of residual correlations were 0.11 and
   0.06; -0.04 and -0.02; -0.03 and -0.02; -0.05 and -0.03 between CM-SCS,
   CM-MY, CM-PY, and CM-FY, respectively. Comparison between the models
   indicates similar estimates of genetic correlations with no
   underestimation with the linear model analysis. In CM evaluation, the
   comparison of model's predictive ability showed greater improvements in
   accuracy with the bivariate than with the univariate models. There was,
   however no clear advantage of univariate threshold model over univariate
   linear model, except for less accuracy sires. (C) 2007 Elsevier B.V. All
   rights reserved.
ZR 0
ZA 0
ZS 0
ZB 42
Z8 1
TC 44
Z9 46
DA 2008-08-01
UT WOS:000258815300007
ER

PT J
AU Stanley, Jack
   Rabot, Emmett
   Reddy, Siva
   Belilovsky, Eugene
   Mottron, Laurent
   Bzdok, Danilo
TI Large language models deconstruct the clinical intuition behind
   diagnosing autism
SO CELL
VL 188
IS 8
DI 10.1016/j.cell.2025.02.025
EA APR 2025
DT Article
PD APR 17 2025
PY 2025
AB Efforts to use genome-wide assays or brain scans to diagnose autism have
   seen diminishing returns. Yet the clinical intuition of healthcare
   professionals, based on longstanding first-hand experience, remains the
   gold standard for diagnosis of autism. We leveraged deep learning to
   deconstruct and interrogate the logic of expert clinician intuition from
   clinical reports to inform our understanding of autism. After
   pre-training on hundreds of millions of general sentences, we finessed
   large language models (LLMs) on >4,000 free-form health records from
   healthcare professionals to distinguish confirmed versus suspected
   autism cases. By introducing an explainability strategy, our extended
   language model architecture could pin down the most salient single
   sentences in what drives clinical thinking toward correct diagnoses. Our
   framework flagged the most autism-critical DSM-5 criteria to be
   stereotyped repetitive behaviors, special interests, and
   perception-based behaviors, which challenges today's focus on deficits
   in social interplay, suggesting necessary revision of long-trusted
   diagnostic criteria in gold-standard instruments.
ZS 0
ZB 0
ZA 0
ZR 0
Z8 0
TC 0
Z9 0
DA 2025-05-06
UT WOS:001476532200001
PM 40147442
ER

PT J
AU Cong, Yan
   Lacroix, Arianna N.
   Lee, Jiyeon
TI Clinical efficacy of pre-trained large language models through the lens
   of aphasia
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 15573
DI 10.1038/s41598-024-66576-y
DT Article
PD JUL 6 2024
PY 2024
AB The rapid development of large language models (LLMs) motivates us to
   explore how such state-of-the-art natural language processing systems
   can inform aphasia research. What kind of language indices can we derive
   from a pre-trained LLM? How do they differ from or relate to the
   existing language features in aphasia? To what extent can LLMs serve as
   an interpretable and effective diagnostic and measurement tool in a
   clinical context? To investigate these questions, we constructed
   predictive and correlational models, which utilize mean surprisals from
   LLMs as predictor variables. Using AphasiaBank archived data, we
   validated our models' efficacy in aphasia diagnosis, measurement, and
   prediction. Our finding is that LLMs-surprisals can effectively detect
   the presence of aphasia and different natures of the disorder, LLMs in
   conjunction with the existing language indices improve models' efficacy
   in subtyping aphasia, and LLMs-surprisals can capture common agrammatic
   deficits at both word and sentence level. Overall, LLMs have potential
   to advance automatic and precise aphasia prediction. A natural language
   processing pipeline can be greatly benefitted from integrating LLMs,
   enabling us to refine models of existing language disorders, such as
   aphasia.
ZS 0
ZB 0
ZR 0
Z8 0
ZA 0
TC 1
Z9 1
DA 2024-07-20
UT WOS:001265339000052
PM 38971898
ER

PT J
AU Quinn, Matthew
   Milner, John D.
   Schmitt, Phillip
   Morrissey, Patrick
   Lemme, Nicholas
   Marcaccio, Stephen
   DeFroda, Steven
   Tabaddor, Ramin
   Owens, Brett D.
TI Artificial Intelligence Large Language Models Address Anterior Cruciate
   Ligament Reconstruction: Superior Clarity and Completeness by Gemini
   Compared With ChatGPT-4 in Response to American Academy of Orthopaedic
   Surgeons Clinical Practice Guidelines
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 6
BP 2002
EP 2008
DI 10.1016/j.arthro.2024.09.020
DT Article
PD JUN 2025
PY 2025
AB Purpose: To assess the ability of ChatGPT-4 and Gemini to generate
   accurate and relevant responses to the 2022 American Academy of
   Orthopaedic Surgeons (AAOS) Clinical Practice Guidelines (CPG) for
   anterior cruciate ligament reconstruction (ACLR). Methods: Responses
   from ChatGPT-4 and Gemini to prompts derived from all 15 AAOS guidelines
   were evaluated by 7 fellowship-trained orthopaedic sports medicine
   surgeons using a structured questionnaire assessing 5 key
   characteristics on a scale from 1 to 5. The prompts were categorized
   into 3 areas: diagnosis and preoperative management, surgical timing and
   technique, and rehabilitation and prevention. Statistical analysis
   included mean scoring, standard deviation, and 2-sided t tests to
   compare the performance between the 2 large language models (LLMs).
   Scores were then evaluated for inter-rater reliability (IRR). Results:
   Overall, both LLMs performed well with mean scores >4 for the 5 key
   characteristics. Gemini demonstrated superior performance in overall
   clarity (4.848 +/- 0.36 vs 4.743 +/- 0.481, P = .034), but all other
   characteristics demonstrated nonsignificant differences (P > .05).
   Gemini also demonstrated superior clarity in the surgical timing and
   technique (P = .038) as well as the prevention and rehabilitation (P =
   .044) subcategories. Additionally, Gemini had superior performance
   completeness scores in the rehabilitation and prevention subcategory (P
   = .044), but no statistically significant differences were found amongst
   the other subcategories. The overall IRR was found to be 0.71
   (moderate). Conclusions: Both Gemini and ChatGPT-4 demonstrate an
   overall good ability to generate accurate and relevant responses to
   question prompts based on the 2022 AAOS CPG for ACLR. However, Gemini
   demonstrated superior clarity in multiple domains in addition to
   superior completeness for questions pertaining to rehabilitation and
   prevention. Clinical Relevance: The current study addresses a current
   gap in the LLM and ACLR literature by comparing the performance of
   ChatGPT-4 to Gemini, which is growing in popularity with more than 300
   million individual uses in May 2024 alone. Moreover, the results
   demonstrated superior performance of Gemini in both clarity and
   completeness, which are critical elements of a tool being used by
   patients for educational purposes. Additionally, the current study uses
   question prompts based on the AAOS CPG, which may be used as a method of
   standardization for future investigations on performance of LLM
   platforms. Thus, the results of this study may be of interest to both
   the readership of Arthroscopy and patients.
ZB 0
ZR 0
ZS 0
ZA 0
TC 3
Z8 0
Z9 3
DA 2025-06-13
UT WOS:001505151400026
PM 39313138
ER

PT J
AU Wenz, Frederik
   Ebener, Stefan
TI Artificial intelligence applications in oncology: opportunities,
   feasibility, and regulatory challenges
SO ONKOLOGIE
VL 30
IS 5
SI SI
BP 339
EP 346
DI 10.1007/s00761-023-01428-4
EA NOV 2023
DT Review
PD MAY 2024
PY 2024
AB The integration of artificial intelligence (AI) into oncology promises a
   revolution in diagnosis, treatment, and research. Various applications
   are considered, with a focus on stress and burnout experienced by
   oncologists. The potentials are comprehensively discussed, starting from
   prevention through wearables and AI-assisted analysis of health data to
   personalized treatment planning and accelerated drug development. One
   area of focus is AlphaFold, an AI application for protein folding. The
   management of patient data and the creation of medical reports are
   optimized by AI, with search engines and large language models (LLM)
   playing a prominent role. The increasing specialization of LLMs,
   particularly in medical text generation, underscores their growing
   importance. The feasibility of AI applications is emphasized, addressing
   the need for resources and training for medical personnel. Commercial
   organizations, such as DeepMind, play a crucial role in implementing AI
   in clinical practice. Regulatory challenges are discussed, including
   data privacy, quality control, liability, and ethical aspects. The
   European Health Data Space (EHDS) is a promising initiative for
   promoting secure data exchange within the European Union. Overall, AI
   can facilitate significant advancements in oncology. However, regulatory
   challenges require careful attention to ensure an ethically responsible
   and safe implementation. AI applications have the potential to improve
   cancer care, revolutionize patient management, and reduce the workload
   for medical personnel.
TC 0
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
Z9 0
DA 2024-04-02
UT WOS:001193607500001
ER

PT J
AU Dharmayat, Kanika Inamdar
   Vallejo-Vaz, Antonio J.
   Stevens, Christophe A. T.
   Brandts, Julia M.
   Lyons, Alexander R. M.
   Groselj, Urh
   Abifadel, Marianne
   Aguilar-Salinas, Carlos A.
   Alhabib, Khalid
   Alkhnifsawi, Mutaz
   Almahmeed, Wael
   Alnouri, Fahad
   Alonso, Rodrigo
   Al-Rasadi, Khalid
   Ashavaid, Tester F.
   Banach, Maciej
   Beliard, Sophie
   Binder, Christoph
   Bourbon, Mafalda
   Chlebus, Krzysztof
   Corral, Pablo
   Cruz, Diogo
   Descamps, Olivier S.
   Drogari, Euridiki
   Durst, Ronen
   Ezhov, Marat, V
   Genest, Jacques
   Harada-Shiba, Mariko
   Holven, Kirsten B.
   Humphries, Steve E.
   Khovidhunkit, Weerapan
   Lalic, Katarina
   Laufs, Ulrich
   Liberopoulos, Evangelos
   van Lennep, Jeanine Roeters
   Lima-Martinez, Marcos Miguel
   Lin, Jie
   Maher, Vincent
   Maerz, Winfried
   Miserez, Andre R.
   Mitchenko, Olena
   Nawawi, Hapizah
   Panayiotou, Andrie G.
   Paragh, Gyoergy
   Postadzhiyan, Arman
   Reda, Ashraf
   Reiner, Zeljko
   Reyes, Ximena
   Sadiq, Fouzia
   Sahebkar, Amirhossein
   Schunkert, Heribert
   Shek, Aleksandr B.
   Stroes, Eric
   Su, Ta-Chen
   Subramaniam, Tavintharan
   Susekov, Andrey
   Cardenas, Alejandra Vazquez
   Thanh Huong Truong
   Tselepis, Alexandros
   Vohnout, Branislav
   Wang, Luya
   Yamashita, Shizuya
   Al-Sarraf, Ahmad
   Al-Sayed, Nasreen
   Davletov, Kairat
   Dwiputra, Bambang
   Gaita, Dan
   Kayikcioglu, Meral
   Latkovskis, Gustavs
   Marais, A. David
   Matthias, Anne Thushara
   Mirrakhimov, Erkin
   Nordestgaard, Borge G.
   Petrulioniene, Zaneta
   Pojskic, Belma
   Sadoh, Wilson
   Tilney, Myra
   Tomlinson, Brian
   Tybjaerg-Hansen, Anne
   Viigimaa, Margus
   Catapano, Alberico L.
   Freiberger, Tomas
   Hovingh, G. Kees
   Mata, Pedro
   Soran, Handrean
   Raal, Frederick
   Watts, Gerald F.
   Santos, Raul
   Ray, Kausik K.
CA European Atherosclerosis Soc
TI Familial hypercholesterolaemia in children and adolescents from 48
   countries: a cross-sectional study
SO LANCET
VL 403
IS 10421
BP 55
EP 66
DI 10.1016/S0140-6736(23)01842-1
EA JAN 2024
DT Article
PD JAN 6 2024
PY 2024
AB Background: Approximately 450 000 children are born with familial
   hypercholesterolaemia worldwide every year, yet only 2<middle dot>1% of
   adults with familial hypercholesterolaemia were diagnosed before age 18
   years via current diagnostic approaches, which are derived from
   observations in adults. We aimed to characterise children and
   adolescents with heterozygous familial hypercholesterolaemia (HeFH) and
   understand current approaches to the identification and management of
   familial hypercholesterolaemia to inform future public health
   strategies. Methods: For this cross-sectional study, we assessed
   children and adolescents younger than 18 years with a clinical or
   genetic diagnosis of HeFH at the time of entry into the Familial
   Hypercholesterolaemia Studies Collaboration (FHSC) registry between Oct
   1, 2015, and Jan 31, 2021. Data in the registry were collected from 55
   regional or national registries in 48 countries. Diagnoses relying on
   self-reported history of familial hypercholesterolaemia and suspected
   secondary hypercholesterolaemia were excluded from the registry; people
   with untreated LDL cholesterol (LDL-C) of at least 13<middle dot>0
   mmol/L were excluded from this study. Data were assessed overall and by
   WHO region, World Bank country income status, age, diagnostic criteria,
   and index-case status. The main outcome of this study was to assess
   current identification and management of children and adolescents with
   familial hypercholesterolaemia. Findings: Of 63 093 individuals in the
   FHSC registry, 11 848 (18<middle dot>8%) were children or adolescents
   younger than 18 years with HeFH and were included in this study; 5756
   (50<middle dot>2%) of 11 476 included individuals were female and 5720
   (49<middle dot>8%) were male. Sex data were missing for 372 (3<middle
   dot>1%) of 11 848 individuals. Median age at registry entry was 9<middle
   dot>6 years (IQR 5<middle dot>8-13<middle dot>2). 10 099 (89<middle
   dot>9%) of 11 235 included individuals had a final genetically confirmed
   diagnosis of familial hypercholesterolaemia and 1136 (10<middle dot>1%)
   had a clinical diagnosis. Genetically confirmed diagnosis data or
   clinical diagnosis data were missing for 613 (5<middle dot>2%) of 11 848
   individuals. Genetic diagnosis was more common in children and
   adolescents from high-income countries (9427 [92<middle dot>4%] of 10
   202) than in children and adolescents from non-high-income countries
   (199 [48<middle dot>0%] of 415). 3414 (31<middle dot>6%) of 10 804
   children or adolescents were index cases.
   Familial-hypercholesterolaemia-related physical signs, cardiovascular
   risk factors, and cardiovascular disease were uncommon, but were more
   common in non-high-income countries. 7557 (72<middle dot>4%) of 10 428
   included children or adolescents were not taking lipid-lowering
   medication (LLM) and had a median LDL-C of 5<middle dot>00 mmol/L (IQR
   4<middle dot>05-6<middle dot>08). Compared with genetic diagnosis, the
   use of unadapted clinical criteria intended for use in adults and
   reliant on more extreme phenotypes could result in 50-75% of children
   and adolescents with familial hypercholesterolaemia not being
   identified. Interpretation: Clinical characteristics observed in adults
   with familial hypercholesterolaemia are uncommon in children and
   adolescents with familial hypercholesterolaemia, hence detection in this
   age group relies on measurement of LDL-C and genetic confirmation.
   Where genetic testing is unavailable, increased availability and use of
   LDL-C measurements in the first few years of life could help reduce the
   current gap between prevalence and detection, enabling increased use of
   combination LLM to reach recommended LDL-C targets early in life.
ZS 0
TC 29
Z8 0
ZA 0
ZB 10
ZR 0
Z9 29
DA 2024-02-21
UT WOS:001161858100001
PM 38101429
ER

PT J
AU Sheng, Bin
   Guan, Zhouyu
   Lim, Lee-Ling
   Jiang, Zehua
   Mathioudakis, Nestoras
   Li, Jiajia
   Liu, Ruhan
   Bao, Yuqian
   Bee, Yong Mong
   Wang, Ya-Xing
   Zheng, Yingfeng
   Tan, Gavin Siew Wei
   Ji, Hongwei
   Car, Josip
   Wang, Haibo
   Klonoff, David C.
   Li, Huating
   Tham, Yih-Chung
   Wong, Tien Yin
   Jia, Weiping
TI Large language models for diabetes care: Potentials and prospects
SO SCIENCE BULLETIN
VL 69
IS 5
BP 583
EP 588
DI 10.1016/j.scib.2024.01.004
EA MAR 2024
DT Editorial Material
PD MAR 15 2024
PY 2024
Z8 1
ZB 2
ZR 0
TC 27
ZS 0
ZA 0
Z9 27
DA 2024-05-25
UT WOS:001226928500001
PM 38220476
ER

PT J
AU Goh, Ethan
   Gallo, Robert
   Hom, Jason
   Strong, Eric
   Weng, Yingjie
   Kerman, Hannah
   Cool, Josephine
   Kanjee, Zahir
   Parsons, Andrew S
   Ahuja, Neera
   Horvitz, Eric
   Yang, Daniel
   Milstein, Arnold
   Olson, Andrew P J
   Rodman, Adam
   Chen, Jonathan H
TI Influence of a Large Language Model on Diagnostic Reasoning: A
   Randomized Clinical Vignette Study.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2024.03.12.24303785
DT Preprint
PD 2024 Mar 14
PY 2024
AB Importance: Diagnostic errors are common and cause significant
   morbidity. Large language models (LLMs) have shown promise in their
   performance on both multiple-choice and open-ended medical reasoning
   examinations, but it remains unknown whether the use of such tools
   improves diagnostic reasoning.
   Objective: To assess the impact of the GPT-4 LLM on physicians'
   diagnostic reasoning compared to conventional resources.
   Design: Multi-center, randomized clinical vignette study.
   Setting: The study was conducted using remote video conferencing with
   physicians across the country and in-person participation across
   multiple academic medical institutions.
   Participants: Resident and attending physicians with training in family
   medicine, internal medicine, or emergency medicine.
   Interventions: Participants were randomized to access GPT-4 in addition
   to conventional diagnostic resources or to just conventional resources.
   They were allocated 60 minutes to review up to six clinical vignettes
   adapted from established diagnostic reasoning exams.
   Main Outcomes and Measures: The primary outcome was diagnostic
   performance based on differential diagnosis accuracy, appropriateness of
   supporting and opposing factors, and next diagnostic evaluation steps.
   Secondary outcomes included time spent per case and final diagnosis.
   Results: 50 physicians (26 attendings, 24 residents) participated, with
   an average of 5.2 cases completed per participant. The median diagnostic
   reasoning score per case was 76.3 percent (IQR 65.8 to 86.8) for the
   GPT-4 group and 73.7 percent (IQR 63.2 to 84.2) for the conventional
   resources group, with an adjusted difference of 1.6 percentage points
   (95% CI -4.4 to 7.6; p=0.60). The median time spent on cases for the
   GPT-4 group was 519 seconds (IQR 371 to 668 seconds), compared to 565
   seconds (IQR 456 to 788 seconds) for the conventional resources group,
   with a time difference of -82 seconds (95% CI -195 to 31; p=0.20). GPT-4
   alone scored 15.5 percentage points (95% CI 1.5 to 29, p=0.03) higher
   than the conventional resources group.
   Conclusions and Relevance: In a clinical vignette-based study, the
   availability of GPT-4 to physicians as a diagnostic aid did not
   significantly improve clinical reasoning compared to conventional
   resources, although it may improve components of clinical reasoning such
   as efficiency. GPT-4 alone demonstrated higher performance than both
   physician groups, suggesting opportunities for further improvement in
   physician-AI collaboration in clinical practice.
ZR 0
Z8 0
ZS 0
ZB 0
ZA 0
TC 2
Z9 2
DA 2024-04-03
UT MEDLINE:38559045
PM 38559045
ER

PT J
AU Wu, Wanying
   Guo, Yuhu
   Li, Qi
   Jia, Congzhuo
TI Exploring the potential of large language models in identifying
   metabolic dysfunction-associated steatotic liver disease: A comparative
   study of non-invasive tests and artificial intelligence-generated
   responses
SO LIVER INTERNATIONAL
VL 45
IS 4
DI 10.1111/liv.16112
EA NOV 2024
DT Article
PD APR 2025
PY 2025
AB Background and AimsThis study sought to assess the capabilities of large
   language models (LLMs) in identifying clinically significant metabolic
   dysfunction-associated steatotic liver disease (MASLD).MethodsWe
   included individuals from NHANES 2017-2018. The validity and reliability
   of MASLD diagnosis by GPT-3.5 and GPT-4 were quantitatively examined and
   compared with those of the Fatty Liver Index (FLI) and United States FLI
   (USFLI). A receiver operating characteristic curve was conducted to
   assess the accuracy of MASLD diagnosis via different scoring systems.
   Additionally, GPT-4V's potential in clinical diagnosis using ultrasound
   images from MASLD patients was evaluated to provide assessments of LLM
   capabilities in both textual and visual data interpretation.ResultsGPT-4
   demonstrated comparable performance in MASLD diagnosis to FLI and USFLI
   with the AUROC values of .831 (95% CI .796-.867), .817 (95% CI
   .797-.837) and .827 (95% CI .807-.848), respectively. GPT-4 exhibited a
   trend of enhanced accuracy, clinical relevance and efficiency compared
   to GPT-3.5 based on clinician evaluation. Additionally, Pearson's r
   values between GPT-4 and FLI, as well as USFLI, were .718 and .695,
   respectively, indicating robust and moderate correlations. Moreover,
   GPT-4V showed potential in understanding characteristics from hepatic
   ultrasound imaging but exhibited limited interpretive accuracy in
   diagnosing MASLD compared to skilled radiologists.ConclusionsGPT-4
   achieved performance comparable to traditional risk scores in diagnosing
   MASLD and exhibited improved convenience, versatility and the capacity
   to offer user-friendly outputs. The integration of GPT-4V highlights the
   capacities of LLMs in handling both textual and visual medical data,
   reinforcing their expansive utility in healthcare practice.
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
DA 2024-11-23
UT WOS:001354198800001
PM 39526465
ER

PT J
AU Kedia, Nikita
   Sanjeev, Suvansh
   Ong, Joshua
   Chhablani, Jay
TI ChatGPT and Beyond: An overview of the growing field of large language
   models and their use in ophthalmology
SO EYE
VL 38
IS 7
BP 1252
EP 1261
DI 10.1038/s41433-023-02915-z
EA JAN 2024
DT Review
PD MAY 2024
PY 2024
AB ChatGPT, an artificial intelligence (AI) chatbot built on large language
   models (LLMs), has rapidly gained popularity. The benefits and
   limitations of this transformative technology have been discussed across
   various fields, including medicine. The widespread availability of
   ChatGPT has enabled clinicians to study how these tools could be used
   for a variety of tasks such as generating differential diagnosis lists,
   organizing patient notes, and synthesizing literature for scientific
   research. LLMs have shown promising capabilities in ophthalmology by
   performing well on the Ophthalmic Knowledge Assessment Program,
   providing fairly accurate responses to questions about retinal diseases,
   and in generating differential diagnoses list. There are current
   limitations to this technology, including the propensity of LLMs to
   "hallucinate", or confidently generate false information; their
   potential role in perpetuating biases in medicine; and the challenges in
   incorporating LLMs into research without allowing "AI-plagiarism" or
   publication of false information. In this paper, we provide a balanced
   overview of what LLMs are and introduce some of the LLMs that have been
   generated in the past few years. We discuss recent literature evaluating
   the role of these language models in medicine with a focus on ChatGPT.
   The field of AI is fast-paced, and new applications based on LLMs are
   being generated rapidly; therefore, it is important for ophthalmologists
   to be aware of how this technology works and how it may impact patient
   care. Here, we discuss the benefits, limitations, and future
   advancements of LLMs in patient care and research.
ZR 0
TC 13
Z8 0
ZS 0
ZA 0
ZB 4
Z9 13
DA 2024-01-22
UT WOS:001135855200003
PM 38172581
ER

PT J
AU Lara-Abelenda, Francisco J.
   Chushig-Muzo, David
   Peiro-Corbacho, Pablo
   Wagner, Ana M.
   Granja, Conceicao
   Soguero-Ruiz, Cristina
TI Personalized glucose forecasting for people with type 1 diabetes using
   large language models
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 265
AR 108737
DI 10.1016/j.cmpb.2025.108737
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Background and objective: Type 1 Diabetes (T1D) is an autoimmune disease
   that requires exogenous insulin via Multiple Daily Injections (MDIs) or
   subcutaneous pumps to maintain targeted glucose levels. Despite the
   advances in Continuous Glucose Monitoring (CGM), controlling glucose
   levels remains challenging. Large Language Models (LLMs) have produced
   impressive results in text processing, but their performance with other
   data modalities remains unexplored. The aim of this study is three-fold.
   First, to evaluate the effectiveness of LLM-based models for glucose
   forecasting. Second, to compare the performance of different models for
   predicting glucose in T1D individuals treated with MDIs and pumps.
   Lastly, to create a personalized approach based on patient-specific
   training and adaptive model selection. Methods: CGM data from the T1DEXI
   study were used for forecasting glucose levels. Different predictive
   models were evaluated using the mean absolute error (MAE) and the root
   mean squared error and considering the Prediction Horizons (PHs) of 60,
   90, and 120 min. Results: For short-term PHs (60 and 90 min), the
   personalized approach achieved the best results, with an average MAE of
   15.7 and 20.2 for MDIs, and a MAE of 15.2 and 17.2 for pumps. For
   long-term PH (120 min), TIDE obtained an MAE of 19.8 for MDIs, whereas
   Patch-TST obtained a MAE of 18.5. Conclusion: LLM-based models provided
   similar MAE values to state-of-the-art models but presented a reduced
   variability. The proposed personalized approach obtained the best
   results for short-term periods. Our work contributes to developing
   personalized glucose prediction models for enhancing glycemic control,
   reducing diabetes-related complications.
ZA 0
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-04-20
UT WOS:001464793700001
PM 40188577
ER

PT J
AU Bellamkonda, Nikhil
   Farlow, Janice L.
   Haring, Catherine T.
   Sim, Michael W.
   Seim, Nolan B.
   Cannon, Richard B.
   Monroe, Marcus M.
   Agrawal, Amit
   Rocco, James W.
   McCrary, Hilary C.
TI Evaluating the Accuracy of ChatGPT in Common Patient Questions Regarding
   HPV plus Oropharyngeal Carcinoma
SO ANNALS OF OTOLOGY RHINOLOGY AND LARYNGOLOGY
VL 133
IS 9
BP 814
EP 819
DI 10.1177/00034894241259137
EA JUL 2024
DT Article
PD SEP 2024
PY 2024
AB Objectives: Large language model (LLM)-based chatbots such as ChatGPT
   have been publicly available and increasingly utilized by the general
   public since late 2022. This study sought to investigate ChatGPT
   responses to common patient questions regarding Human Papilloma Virus
   (HPV) positive oropharyngeal cancer (OPC). Methods: This was a
   prospective, multi-institutional study, with data collected from high
   volume institutions that perform >50 transoral robotic surgery cases per
   year. The 100 most recent discussion threads including the term "HPV" on
   the American Cancer Society's Cancer Survivors Network's Head and Neck
   Cancer public discussion board were reviewed. The 11 most common
   questions were serially queried to ChatGPT 3.5; answers were recorded. A
   survey was distributed to fellowship trained head and neck oncologic
   surgeons at 3 institutions to evaluate the responses. Results: A total
   of 8 surgeons participated in the study. For questions regarding HPV
   contraction and transmission, ChatGPT answers were scored as clinically
   accurate and aligned with consensus in the head and neck surgical
   oncology community 84.4% and 90.6% of the time, respectively. For
   questions involving treatment of HPV+ OPC, ChatGPT was clinically
   accurate and aligned with consensus 87.5% and 91.7% of the time,
   respectively. For questions regarding the HPV vaccine, ChatGPT was
   clinically accurate and aligned with consensus 62.5% and 75% of the
   time, respectively. When asked about circulating tumor DNA testing, only
   12.5% of surgeons thought responses were accurate or consistent with
   consensus. Conclusion: ChatGPT 3.5 performed poorly with questions
   involving evolving therapies and diagnostics-thus, caution should be
   used when using a platform like ChatGPT 3.5 to assess use of advanced
   technology. Patients should be counseled on the importance of consulting
   their surgeons to receive accurate and up to date recommendations, and
   use LLM's to augment their understanding of these important
   health-related topics.
ZB 0
Z8 0
ZR 0
ZA 0
TC 1
ZS 0
Z9 1
DA 2024-08-06
UT WOS:001280661600001
PM 39075853
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on a Large Language Model Chatbot
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1636
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
TC 0
ZB 0
Z8 0
ZA 0
ZS 0
Z9 0
DA 2024-12-01
UT WOS:001312227704264
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT J
AU Kunze, Kyle N.
   Nwachukwu, Benedict U.
   Cote, Mark P.
   Ramkumar, Prem N.
TI Large Language Models Applied to Health Care Tasks May Improve Clinical
   Efficiency, Value of Care Rendered, Research, and Medical Education
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 3
BP 547
EP 556
DI 10.1016/j.arthro.2024.12.010
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
AB Large language models (LLMs) are generative artificial intelligence
   models that create content on the basis of the data on which it was
   trained. Processing capabilities have evolved from text only to being
   multimodal including text, images, audio, and video features. In health
   care settings, LLMs are being applied to several clinically important
   areas, including patient care and workflow efficiency, communications,
   hospital operations and data management, medical education, practice
   management, and health care research. Under the umbrella of patient
   care, several core use cases of LLMs include simplifying documentation
   tasks, enhancing patient communication (interactive language and
   written), conveying medical knowledge, and performing medical triage and
   diagnosis. However, LLMs warrant scrutiny when applied to health care
   tasks, as errors may have negative implications for health care
   outcomes, specifically in the context of perpetuating bias, ethical
   considerations, and cost-effectiveness. Customized LLMs developed for
   more narrow purposes may help overcome certain performance limitations,
   transparency challenges, and biases present in contemporary generalized
   LLMs by curating training data. Methods of customizing LLMs broadly fall
   under 4 categories: prompt engineering, retrieval augmented generation,
   fine-tuning, and agentic augmentation, with each approach conferring
   different information-retrieval properties for the LLM. Level of
   Evidence: Level V, expert opinion.
TC 1
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
Z9 1
DA 2025-02-26
UT WOS:001425552200001
PM 39694303
ER

PT J
AU Afshar, Majid
   Gao, Yanjun
   Gupta, Deepak
   Croxford, Emma
   Demner-Fushman, Dina
TI On the role of the UMLS in supporting diagnosis generation proposed by
   Large Language Models
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 157
AR 104707
DI 10.1016/j.jbi.2024.104707
EA AUG 2024
DT Article
PD SEP 2024
PY 2024
AB Objective: Traditional knowledge-based and machine learning diagnostic
   decision support systems have benefited from integrating the medical
   domain knowledge encoded in the Unified Medical Language System (UMLS).
   The emergence of Large Language Models (LLMs) to supplant traditional
   systems poses questions of the quality and extent of the medical
   knowledge in the models' internal knowledge representations and the need
   for external knowledge sources. The objective of this study is
   three-fold: to probe the diagnosis-related medical knowledge of popular
   LLMs, to examine the benefit of providing the UMLS knowledge to LLMs
   (grounding the diagnosis predictions), and to evaluate the correlations
   between human judgments and the UMLS-based metrics for generations by
   LLMs. Methods: We evaluated diagnoses generated by LLMs from consumer
   health questions and daily care notes in the electronic health records
   using the ConsumerQA and Problem Summarization datasets. Probing LLMs
   for the UMLS knowledge was performed by prompting the LLM to complete
   the diagnosis-related UMLS knowledge paths. Grounding the predictions
   was examined in an approach that integrated the UMLS graph paths and
   clinical notes in prompting the LLMs. The results were compared to
   prompting without the UMLS paths. The final experiments examined the
   alignment of different evaluation metrics, UMLS-based and non-UMLS, with
   human expert evaluation. Results: In probing the UMLS knowledge, GPT-3.5
   significantly outperformed Llama2 and a simple baseline yielding an F1
   score of 10.9% in completing one-hop UMLS paths for a given concept.
   Grounding diagnosis predictions with the UMLS paths improved the results
   for both models on both tasks, with the highest improvement (4%) in
   SapBERT score. There was a weak correlation between the widely used
   evaluation metrics (ROUGE and SapBERT) and human judgments. Conclusion:
   We found that while popular LLMs contain some medical knowledge in their
   internal representations, augmentation with the UMLS knowledge provides
   performance gains around diagnosis generation. The UMLS needs to be
   tailored for the task to improve the LLMs predictions. Finding
   evaluation metrics that are aligned with human judgments better than the
   traditional ROUGE and BERT-based scores remains an open research
   question.
ZA 0
ZR 0
ZS 0
TC 2
ZB 0
Z8 0
Z9 2
DA 2024-09-02
UT WOS:001300508200001
PM 39142598
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Artificial intelligence for image recognition in diagnosing oral and
   oropharyngeal cancer and leukoplakia
SO SCIENTIFIC REPORTS
VL 15
IS 1
AR 3625
DI 10.1038/s41598-025-85920-4
DT Article
PD JAN 29 2025
PY 2025
AB Visual diagnosis is one of the key features of squamous cell carcinoma
   of the oral cavity (OSCC) and oropharynx (OPSCC), both subsets of head
   and neck squamous cell carcinoma (HNSCC) with a heterogeneous clinical
   appearance. Advancements in artificial intelligence led to Image
   recognition being introduced recently into large language models (LLMs)
   such as ChatGPT 4.0. This exploratory study, for the first time,
   evaluated the application of image recognition by ChatGPT to diagnose
   squamous cell carcinoma and leukoplakia based on clinical images, with
   images without any lesion as a control group. A total of 45 clinical
   images were analyzed, comprising 15 cases each of SCC, leukoplakia, and
   non-lesion images. ChatGPT 4.0 was tasked with providing the most likely
   diagnosis based on these images in scenario one. In scenario two the
   image and the clinical history were provided, whereas in scenario three
   only the clinical history was given. The results and the accuracy of the
   LLM were rated by two independent reviewers and the overall performance
   was evaluated using the modified Artificial Intelligence Performance
   Index (AIPI. In this study, ChatGPT 4.0 demonstrated the ability to
   correctly identify leukoplakia cases using image recognition alone,
   while the ability to diagnose SCC was insufficient, but improved by
   including the clinical history in the prompt. Providing only the
   clinical history resulted in a misclassification of most leukoplakia and
   some SCC cases. Oral cavity lesions were more likely to be diagnosed
   correctly. In this exploratory study of 45 images of oral lesions,
   ChatGPT 4.0 demonstrated a convincing performance for detecting SCC only
   when the clinical history was added, whereas Leukoplakia was detected
   solely by image recognition. ChatGPT is therefore currently insufficient
   for reliable OPSCC and OSCC diagnosis, but further technological
   advancements may pave the way for the use in the clinical setting.
ZR 0
ZS 0
Z8 0
TC 2
ZA 0
ZB 0
Z9 2
DA 2025-02-09
UT WOS:001410929000012
PM 39880876
ER

PT J
AU Omar, Mahmud
   Brin, Dana
   Glicksberg, Benjamin
   Klang, Eyal
TI Utilizing natural language processing and large language models in the
   diagnosis and prediction of infectious diseases: A systematic review
SO AMERICAN JOURNAL OF INFECTION CONTROL
VL 52
IS 9
BP 992
EP 1001
DI 10.1016/j.ajic.2024.03.016
EA AUG 2024
DT Article
PD SEP 2024
PY 2024
AB Background: Natural Language Processing (NLP) and Large Language Models
   (LLMs) hold largely untapped potential in infectious disease management.
   This review explores their current use and uncovers areas needing more
   attention. Methods: This analysis followed systematic review procedures,
   registered with the Prospective Register of Systematic Reviews. We
   conducted a search across major databases including PubMed, Embase, Web
   of Science, and Scopus, up to December 2023, using keywords related to
   NLP, LLM, and infectious diseases. We also employed the Quality
   Assessment of Diagnostic Accuracy Studies-2 tool for evaluating the
   quality and robustness of the included studies. Results: Our review
   identified 15 studies with diverse applications of NLP in infectious
   disease management. Notable examples include GPT-4's application in
   detecting urinary tract infections and BERTweet's use in Lyme Disease
   surveillance through social media analysis. These models demonstrated
   effective disease monitoring and public health tracking capabilities.
   However, the effectiveness varied across studies. For instance, while
   some NLP tools showed high accuracy in pneumonia detection and high
   sensitivity in identifying invasive mold diseases from medical reports,
   others fell short in areas like bloodstream infection management.
   Conclusions: This review highlights the yet-to-be-fully-realized promise
   of NLP and LLMs in infectious disease management. It calls for more
   exploration to fully harness AI's capabilities, particularly in the
   areas of diagnosis, surveillance, predicting disease courses, and
   tracking epidemiological trends. (c) 2024 Association for Professionals
   in Infection Control and Epidemiology, Inc. Published by Elsevier Inc.
   All rights are reserved, including those for text and data mining, AI
   training, and similar technologies.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 2
TC 15
Z9 15
DA 2024-08-29
UT WOS:001297798000001
PM 38588980
ER

PT J
AU Dai, Jiayi
   Kim, Mi-Young
   Sutton, Reed T.
   Mitchell, Joseph R.
   Goebel, Randolph G.
   Baumgart, Daniel C.
TI DEVELOPMENT OF IBDBERT - NATURAL LANGUAGE PROCESSING ANALYSIS OF CROHN'S
   DISEASE COMPUTED TOMOGRAPHY ENTEROGRAPHY (CTE) REPORTS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Sa2032
BP S612
EP S612
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZR 0
TC 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837702379
ER

PT J
AU McCoy, Thomas H.
   Castro, Victor M.
   Perlis, Roy H.
TI Estimating depression severity in narrative clinical notes using large
   language models
SO JOURNAL OF AFFECTIVE DISORDERS
VL 381
BP 270
EP 274
DI 10.1016/j.jad.2025.04.014
EA APR 2025
DT Article
PD JUL 15 2025
PY 2025
AB Background: Depression treatment guidelines emphasize measurement-based
   care using patient-reported outcome measures, yet their impact on
   narrative documentation quality remains underexplored. Methods: We
   sampled 15,000 narrative clinical outpatient notes from the electronic
   health record of a large academic medical center, reflecting visits
   between January 2, 2019 and January 30, 2024, for which a 9-item Patient
   Health Questionnaire (PHQ-9) was completed at the same time. After
   censoring PHQ-9 scores from notes, we estimated severity of depressive
   symptoms with a foundational large language model (gpt4o-08-06) in a
   HIPAA-compliant enclave. We estimated correlation between true PHQ-9 and
   model-estimated score and examined the predictive performance of the
   model for moderate or greater depressive symptoms. Results: Mean age was
   46.3 years (SD 14.9); 9083 (60.6 %) identified as female. 925 (6.2 %)
   identified as Asian, 638 (4.3 %) as Black, 853 (5.7 %) as another race,
   and 12,187 (81.2 %) as White. A total of 1044 (7.0 %) identified as
   Hispanic ethnicity, while 12,699 (84.7 %) were non-Hispanic. Mean
   measured PHQ-9 score was 1.23 (SD 3.45); 721 (4.8 %) met criteria for
   moderate or greater depressive symptoms. LLM-predicted PHQ-9 scores were
   modestly correlated with actual scores (r2 = 0.264 (95 % CI
   0.252-0.276)); PPV for moderate or greater depression was 0.309 (95 % CI
   0.302-0.317). Performance was consistent across demographic subgroups,
   with modest differences identified by race, ethnicity, and sex.
   Conclusion: A foundational LLM performed poorly but consistently across
   subgroups in imputing PHQ-9 scores from notes when actual PHQ-9
   reporting was ablated. This result suggests the extent to which
   inclusion of PROMs may impoverish documentation of psychiatric symptoms.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-04-26
UT WOS:001469145100001
PM 40187432
ER

PT J
AU Sinha, Rooma
   Raina, Rohit
   Bag, Moumita
   Rupa, Bana
TI Empowering gynaecologists with Artificial Intelligence: Tailoring
   surgical solutions for fibroids
SO EUROPEAN JOURNAL OF OBSTETRICS & GYNECOLOGY AND REPRODUCTIVE BIOLOGY
VL 299
BP 72
EP 77
DI 10.1016/j.ejogrb.2024.06.001
EA JUN 2024
DT Article
PD AUG 2024
PY 2024
AB Background: In recent years, the integration of Artificial intelligence
   (AI) into various fields of medicine including Gynaecology, has shown
   promising potential. Surgical treatment of fibroid is myomectomy if
   uterine preservation and fertility are the primary aims. AI usage begins
   with the involvement of LLM (Large Language Model) from the point when a
   patient visits a gynecologist, from identifying signs and symptoms to
   reaching a diagnosis, providing treatment plans, and patient counseling.
   Objective: Use of AI (ChatGPT versus Google Bard) in the surgical
   management of fibroid. Study design: Identifying the patient's problems
   using LLMs like ChatGPT and Google Bard and giving a treatment option in
   8 clinical scenarios of fibroid. Data entry was done using M.S. Excel
   and was statistically analyzed using Statistical Package for Social
   Sciences (SPSS Version 26) for M.S. Windows 2010. All results were
   presented in tabular form. Data were analyzed using nonparametric tests
   Chi-square tests or Fisher exact test. p values < 0.05 were considered
   statistically significant. The sensitivity of both techniques was
   calculated. We have used Cohen's Kappa to know the degree of agreement.
   Results: We found that on the first attempt, ChatGPT gave general
   answers in 62.5 % of cases and specific answers in 37.5 % of cases.
   ChatGPT showed improved sensitivity on successive prompts 37.5 % to 62.5
   % on the third prompt. Google Bard could not identify the clinical
   question in 50 % of cases and gave incorrect answers in 12.5 % of cases
   (p = 0.04). Google Bard showed the same sensitivity of 25 % on all
   prompts. Conclusion: AI helps to reduce the time to diagnose and plan a
   treatment strategy for fibroid and acts as a powerful tool in the hands
   of a gynecologist. However, the usage of AI by patients for
   self-treatment is to be avoided and should be used only for education
   and counseling about fibroids.
ZS 0
ZR 0
ZB 0
ZA 0
Z8 0
TC 2
Z9 2
DA 2024-06-29
UT WOS:001251789000001
PM 38838389
ER

PT J
AU Nielsen, Jacob P. S.
   Gronhoj, Christian
   Skov, Lone
   Gyldenlove, Mette
TI Usefulness of the large language model ChatGPT (GPT-4) as a diagnostic
   tool and information source in dermatology
SO JEADV CLINICAL PRACTICE
VL 3
IS 5
BP 1570
EP 1575
DI 10.1002/jvc2.459
EA JUN 2024
DT Article
PD DEC 2024
PY 2024
AB BackgroundThe field of artificial intelligence is rapidly evolving. As
   an easily accessible platform with vast user engagement, the Chat
   Generative Pre-Trained Transformer (ChatGPT) holds great promise in
   medicine, with the latest version, GPT-4, capable of analyzing clinical
   images.ObjectivesTo evaluate ChatGPT as a diagnostic tool and
   information source in clinical dermatology.MethodsA total of 15 clinical
   images were selected from the Danish web atlas, Danderm, depicting
   various common and rare skin conditions. The images were uploaded to
   ChatGPT version GPT-4, which was prompted with 'Please provide a
   description, a potential diagnosis, and treatment options for the
   following dermatological condition'. The generated responses were
   assessed by senior registrars in dermatology and consultant
   dermatologists in terms of accuracy, relevance, and depth (scale 1-5),
   and in addition, the image quality was rated (scale 0-10). Demographic
   and professional information about the respondents was
   registered.ResultsA total of 23 physicians participated in the study.
   The majority of the respondents were consultant dermatologists (83%),
   and 48% had more than 10 years of training. The overall image quality
   had a median rating of 10 out of 10 [interquartile range (IQR): 9-10].
   The overall median rating of the ChatGPT generated responses was 2 (IQR:
   1-4), while overall median ratings in terms of relevance, accuracy, and
   depth were 2 (IQR: 1-4), 3 (IQR: 2-4) and 2 (IQR: 1-3),
   respectively.ConclusionsDespite the advancements in ChatGPT, including
   newly added image processing capabilities, the chatbot demonstrated
   significant limitations in providing reliable and clinically useful
   responses to illustrative images of various dermatological conditions.
ZA 0
TC 1
ZR 0
ZB 0
Z8 0
ZS 0
Z9 1
DA 2024-06-08
UT WOS:001237597700001
ER

PT J
AU Meyer, Nathaniel S
   Meyer, John W
TI A Practical Guide to the Utilization of ChatGPT in the Emergency
   Department: A Systematic Review of Current Applications, Future
   Directions, and Limitations.
SO Cureus
VL 17
IS 4
BP e81802
EP e81802
DI 10.7759/cureus.81802
DT Journal Article; Review
PD 2025-Apr
PY 2025
AB The rapid development of artificial intelligence (AI) tools across
   various medical specialties highlights the potential for AI to transform
   medicine over the next 20 years. Despite this potential, the adoption of
   AI can feel incremental and disconnected from the daily practice of
   individual clinicians. For emergency department (ED) physicians
   practicing in 2025, recognizing and evaluating AI tools available for
   immediate integration into practice is essential. One such tool is
   ChatGPT (OpenAI, San Francisco, California, United States), a large
   language model (LLM) that is free, easily accessible via smartphones or
   computers, and widely used across industries. However, its usability in
   the ED setting remains poorly characterized. This review explores the
   current evidence surrounding ChatGPT 4's applications in various ED
   physician tasks, documenting its strengths and limitations. While
   ChatGPT demonstrates significant utility in language generation and
   administrative tasks, its potential for supporting more complex tasks in
   medical decision-making is emerging but not yet robust. The available
   evidence is limited and variable and lacks standardization, reflecting a
   field still in its early stages of development. Notably, the performance
   improvements observed between ChatGPT 3.5 and ChatGPT 4 suggest that
   future iterations, such as the anticipated release of ChatGPT 5, could
   significantly impact these findings. This review provides a
   comprehensive snapshot of the current state of evidence regarding
   ChatGPT's use in the ED, offering both an evaluation of its capabilities
   and a practical guide for its appropriate use by ED clinicians today.
ZB 0
TC 0
ZS 0
Z8 0
ZA 0
ZR 0
Z9 0
DA 2025-05-09
UT MEDLINE:40330395
PM 40330395
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Kim, Junyoung
   Wang, Kai
   Weng, Chunhua
   Liu, Cong
TI Assessing the utility of large language models for phenotype-driven gene
   prioritization in the diagnosis of rare genetic disease
SO AMERICAN JOURNAL OF HUMAN GENETICS
VL 111
IS 10
BP 2189
EP 2202
DI 10.1016/j.ajhg.2024.08.010
EA OCT 2024
DT Article
PD OCT 3 2024
PY 2024
AB Phenotype-driven gene prioritization is fundamental to diagnosing rare
   genetic disorders. While traditional approaches rely on curated
   knowledge graphs with phenotype-gene relations, recent advancements in
   large language models (LLMs) promise a streamlined text-to- gene
   solution. In this study, we evaluated five LLMs, including two
   generative pre-trained transformers (GPT) series and three Llama2
   series, assessing their performance across task completeness, gene
   prediction accuracy, and adherence to required output structures. We
   conducted experiments, exploring various combinations of models,
   prompts, phenotypic input types, and task difficulty levels. Our
   findings revealed that the best-performed LLM, GPT-4, achieved an
   average accuracy of 17.0% in identifying diagnosed genes within the top
   50 predictions, which still falls behind traditional tools. However,
   accuracy increased with the model size. Consistent results were observed
   over time, as shown in the dataset curated after 2023. Advanced
   techniques such as retrieval-augmented generation (RAG) and few-shot
   learning did not improve the accuracy. Sophisticated prompts were more
   likely to enhance task completeness, especially in smaller models.
   Conversely, complicated prompts tended to decrease output structure
   compliance rate. LLMs also achieved better-than-random prediction
   accuracy with free-text input, though performance was slightly lower
   than with standardized concept input. Bias analysis showed that highly
   cited genes, such as BRCA1, , TP53, , and PTEN, , are more likely to be
   predicted. Our study provides valuable insights into integrating LLMs
   with genomic analysis, contributing to the ongoing discussion on their
   utilization in clinical workflows.
ZR 0
Z8 0
TC 1
ZS 0
ZA 0
ZB 1
Z9 1
DA 2024-10-18
UT WOS:001331490700001
PM 39255797
ER

PT J
AU Verma, Anurag
   Hsu, Po Ya
   Kripke, Colleen
   Howard, William
   Sirugo, Giorgio
   Myes, Kelly
TI Advanced Machine Learning Models for Classifying Transthyretin
   Amyloidosis in Clinical Settings
SO CIRCULATION
VL 150
MA 4147767
DI 10.1161/circ.150.suppl_1.4147767
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
CT American-Heart-Association Resuscitation Science Symposium
CY NOV 16-18, 2024
CL Chicago, IL
SP Amer Heart Assoc
ZA 0
TC 0
Z8 0
ZS 0
ZR 0
ZB 0
Z9 0
DA 2025-02-13
UT WOS:001400066404173
ER

PT J
AU Ohse, Julia
   Hadzic, Bakir
   Mohammed, Parvez
   Peperkorn, Nicolina
   Fox, Janosch
   Krutzki, Joshua
   Lyko, Alexander
   Fan, Mingyu
   Zheng, Xiaohu
   Raetsch, Matthias
   Shiban, Youssef
TI GPT-4 shows potential for identifying social anxiety from clinical
   interview data
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30498
DI 10.1038/s41598-024-82192-2
DT Article
PD DEC 16 2024
PY 2024
AB While the potential of Artificial Intelligence (AI)-particularly Natural
   Language Processing (NLP) models-for detecting symptoms of depression
   from text has been vastly researched, only a few studies examine such
   potential for the detection of social anxiety symptoms. We investigated
   the ability of the large language model (LLM) GPT-4 to correctly infer
   social anxiety symptom strength from transcripts obtained from
   semi-structured interviews. N = 51 adult participants were recruited
   from a convenience sample of the German population. Participants filled
   in a self-report questionnaire on social anxiety symptoms (SPIN) prior
   to being interviewed on a secure online teleconference platform.
   Transcripts from these interviews were then evaluated by GPT-4. GPT-4
   predictions were highly correlated (r = 0.79) with scores obtained on
   the social anxiety self-report measure. Following the cut-off
   conventions for this population, an F1 accuracy score of 0.84 could be
   obtained. Future research should examine whether these findings hold
   true in larger and more diverse datasets.
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 1
Z9 1
DA 2024-12-27
UT WOS:001379708000008
PM 39681627
ER

PT J
AU Du, Xinsong
   Novoa-Laurentiev, John
   Plasek, Joseph M.
   Chuang, Ya-Wen
   Wang, Liqin
   Marshall, Gad A.
   Mueller, Stephanie K.
   Chang, Frank
   Datta, Surabhi
   Paek, Hunki
   Lin, Bin
   Wei, Qiang
   Wang, Xiaoyan
   Wang, Jingqi
   Ding, Hao
   Manion, Frank J.
   Du, Jingcheng
   Bates, David W.
   Zhou, Li
TI Enhancing early detection of cognitive decline in the elderly: a
   comparative study utilizing large language models in clinical notes
SO EBIOMEDICINE
VL 109
AR 105401
DI 10.1016/j.ebiom.2024.105401
EA OCT 2024
DT Article
PD NOV 2024
PY 2024
AB Background: Large language models (LLMs) have shown promising
   performance in various healthcare domains, but their effectiveness in
   identifying specific clinical conditions in real medical records is less
   explored. This study evaluates LLMs for detecting signs of cognitive
   decline in real electronic health record (EHR) clinical notes, comparing
   their error profiles with traditional models. The insights gained will
   inform strategies for performance enhancement. Methods: This study,
   conducted at Mass General Brigham in Boston, MA, analyzed clinical notes
   from the four years prior to a 2019 diagnosis of mild cognitive
   impairment in patients aged 50 and older. We used a randomly annotated
   sample of 4,949 note sections, filtered with keywords related to
   cognitive functions, for model development. For testing, a random
   annotated sample of 1,996 note sections without keyword filtering was
   utilized. We developed prompts for two LLMs, Llama 2 and GPT-4, on
   HIPAA-compliant cloud-computing platforms using multiple approaches
   (e.g., both hard and soft prompting and error analysis-based
   instructions) to select the optimal LLM-based method. Baseline models
   included a hierarchical attention-based neural network and XGBoost.
   Subsequently, we constructed an ensemble of the three models using a
   majority vote approach. Results: GPT-4 demonstrated superior accuracy
   and efficiency compared to Llama 2, but did not outperform traditional
   models. The ensemble model outperformed the individual models, achieving
   a precision of 90.3%, a recall of 94.2%, and an F1-score of 92.2%.
   Notably, the ensemble model showed a significant improvement in
   precision, increasing from a range of 70%-79% to above 90%, compared to
   the best-performing single model. Error analysis revealed that 63
   samples were incorrectly predicted by at least one model; however, only
   2 cases (3.2%) were mutual errors across all models, indicating diverse
   error profiles among them. Conclusions: LLMs and
   traditional machine learning models trained using local EHR data
   exhibited diverse error profiles. The ensemble of these models was found
   to be complementary, enhancing diagnostic performance. Future research
   should investigate integrating LLMs with smaller, localized models and
   incorporating medical data and domain knowledge to enhance performance
   on specific tasks.
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 3
Z9 3
DA 2024-10-31
UT WOS:001338984600001
PM 39396423
ER

PT J
AU Li, Xue
   Yuan, Ye
   Yang, Yang
   Guan, Yi
   Wang, Haotian
   Jiang, Jingchi
   Shi, Huaizhang
   Liu, Xiguang
TI Quality-Controllable automatic construction method of Chinese knowledge
   graph for medical decision-making applications
SO INFORMATION PROCESSING & MANAGEMENT
VL 62
IS 4
AR 104148
DI 10.1016/j.ipm.2025.104148
EA MAR 2025
DT Article
PD JUL 2025
PY 2025
AB Medical Knowledge Graphs (KGs) store complex medical knowledge in a
   structured manner, increasingly becoming the foundation of medical
   artificial intelligence. They provide interpretable evidence for disease
   diagnosis and treatment, and enhance the accuracy and interpretability
   of medical information in large language models (LLMs), thus mitigating
   the hallucination issues. However, existing medical KGs lack diverse
   knowledge types, sufficient coverage, fine granularity, and high
   quality, resulting in low utilization rates. To address these issues,
   this paper, under the guidance of medical professionals, proposes
   guidelines and automated methods for constructing a Chinese medical KG,
   drawing from existing experience in building KGs and the requirements of
   medical decision systems. The construction principles include (1)
   universality and personalization, (2) comprehensiveness and granularity,
   (3) knowledge quality control. Furthermore, the automated construction
   method integrates a chain of thought-based knowledge mining approach and
   an axiom logic-based quality control module, which improves the
   scalability of mining and the quality of the knowledge. Based on these,
   a Chinese medical KG named WiMedKG has been developed. It meets the
   established construction guidelines by: (1) including both commonsense
   and experiential medical knowledge, (2) comprehensively covering 111
   departments with content ranging from clinical practice to preventive
   medicine and rehabilitation treatments. The granularity of the knowledge
   is detailed, featuring 29 entity types, 128 refined relationship types,
   and 40 attribute types, comprising a total of 367,108 entities,
   3,176,389 relational triples, and 1,021,966 attribute triples. (3) The
   knowledge has been validated and completed, receiving an evaluation
   score of 90.66% from medical professionals, which demonstrates the
   reliability of the quality-controlled automatic KG construction method.
   Finally, we constructed medical LLM WiMedLLM enhanced by WiMedKG.
   Experimental results on the medical test dataset show an average
   performance improvement of 1.51% after KG enhancement, demonstrating the
   necessity of KG construction and the effectiveness of the automatic
   construction method. The data and system resources can be found on our
   page: https://github.com/lx-hit/WiMedKG.
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-04-06
UT WOS:001455489300001
ER

PT J
AU Tong, Linjian
   Zhang, Chaoyang
   Liu, Rui
   Yang, Jia
   Sun, Zhiming
TI Comparative performance analysis of large language models: ChatGPT-3.5,
   ChatGPT-4 and Google Gemini in glucocorticoid-induced osteoporosis
SO JOURNAL OF ORTHOPAEDIC SURGERY AND RESEARCH
VL 19
IS 1
AR 574
DI 10.1186/s13018-024-04996-2
DT Article
PD SEP 18 2024
PY 2024
AB Backgrounds The use of large language models (LLMs) in medicine can help
   physicians improve the quality and effectiveness of health care by
   increasing the efficiency of medical information management, patient
   care, medical research, and clinical decision-making. Methods We
   collected 34 frequently asked questions about glucocorticoid-induced
   osteoporosis (GIOP), covering topics related to the disease's clinical
   manifestations, pathogenesis, diagnosis, treatment, prevention, and risk
   factors. We also generated 25 questions based on the 2022 American
   College of Rheumatology Guideline for the Prevention and Treatment of
   Glucocorticoid-Induced Osteoporosis (2022 ACR-GIOP Guideline). Each
   question was posed to the LLM (ChatGPT-3.5, ChatGPT-4, and Google
   Gemini), and three senior orthopedic surgeons independently rated the
   responses generated by the LLMs. Three senior orthopedic surgeons
   independently rated the answers based on responses ranging between 1 and
   4 points. A total score (TS) > 9 indicated 'good' responses, 6 <= TS <=
   9 indicated 'moderate' responses, and TS < 6 indicated 'poor' responses.
   Results In response to the general questions related to GIOP and the
   2022 ACR-GIOP Guidelines, Google Gemini provided more concise answers
   than the other LLMs. In terms of pathogenesis, ChatGPT-4 had
   significantly higher total scores (TSs) than ChatGPT-3.5. The TSs for
   answering questions related to the 2022 ACR-GIOP Guideline by ChatGPT-4
   were significantly higher than those for Google Gemini. ChatGPT-3.5 and
   ChatGPT-4 had significantly higher self-corrected TSs than pre-corrected
   TSs, while Google Gemini self-corrected for responses that were not
   significantly different than before. Conclusions Our study showed that
   Google Gemini provides more concise and intuitive responses than
   ChatGPT-3.5 and ChatGPT-4. ChatGPT-4 performed significantly better than
   ChatGPT3.5 and Google Gemini in terms of answering general questions
   about GIOP and the 2022 ACR-GIOP Guidelines. ChatGPT3.5 and ChatGPT-4
   self-corrected better than Google Gemini.
ZA 0
Z8 0
TC 1
ZB 0
ZR 0
ZS 0
Z9 1
DA 2024-09-23
UT WOS:001314945200001
PM 39289734
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Celiker, Pelin
   Naeini, Parisa Emami
TI Determining the utility of large language models in generating the ICD10
   code for uveitis and uveitis related conditions
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2024-12-01
UT WOS:001312227701039
ER

PT J
AU Peters, Tobias M.
   Scharlau, Ingrid
TI Interacting with fallible AI: is distrust helpful when receiving AI
   misclassifications?
SO FRONTIERS IN PSYCHOLOGY
VL 16
AR 1574809
DI 10.3389/fpsyg.2025.1574809
DT Article
PD MAY 27 2025
PY 2025
AB Due to the application of artificial intelligence (AI) in high-risk
   domains such as law and medicine, trustworthy AI and trust in AI are
   increasingly relevant to science and the public. A typical conception,
   for example, in the context of medical diagnosis, is that a
   knowledgeable user receives AI-generated classifications as advice.
   Research to improve such interactions often aims to foster users' trust,
   which, in turn, should improve combined human-AI performance. Given that
   AI models can err, we argue that the possibility of critically reviewing
   and thus distrusting an AI decision is an equally interesting target for
   research. We created two image classification scenarios in which
   participants received mock-up AI advice. The quality of the advice
   decreases during a phase of the experiment. We studied task performance,
   as well as participants' trust and distrust, and tested whether an
   instruction to remain skeptical and to review each piece of advice led
   to better performance compared to a neutral condition. Our results
   indicate that this instruction does not improve but rather worsens the
   participants' performance. Repeated single-item self-reports of trust
   and distrust indicate an increase in trust and a decrease in distrust
   following the decline in AI's classification quality, with no difference
   between the two instructions. Furthermore, through a Bayesian Signal
   Detection Theory analysis, we provide a procedure to assess appropriate
   reliance in detail by quantifying whether the issues of under- and
   over-reliance have been mitigated. We discuss the implications of our
   results for the usage of disclaimers before interacting with AI, as
   prominently used in current LLM-based chatbots, and for trust and
   distrust research.
TC 0
ZR 0
ZS 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2025-06-13
UT WOS:001504755900001
PM 40497113
ER

PT J
AU Feng, Jia-Li
   Qin, Xiwen
TI Does adherence to lipid-lowering medications improve cancer survival? A
   nationwide study of breast and colorectal cancer, and melanoma
SO BRITISH JOURNAL OF CLINICAL PHARMACOLOGY
VL 87
IS 4
BP 1847
EP 1858
DI 10.1111/bcp.14573
EA OCT 2020
DT Article
PD APR 2021
PY 2021
AB Aims Inconclusive findings of lipid-lowering medications (LLMs) on
   cancer survival benefit require more evidence. We tested the hypothesis
   that adherence to this drug is associated with reduced cancer-specific
   mortality in a homogeneous population who had used this drug before
   cancer diagnosis. Methods The Australian Cancer Database was linked to
   the Pharmaceutical Benefits Scheme database, and to the National Death
   Index (up to 2015). Medication adherence was calculated by proportion of
   days covered. Cox regression models with time-varying covariates were
   used to derive multivariable-adjusted cause-specific hazard ratio (HR)
   and 95% confidence interval (CI) for the associations between adherence
   to LLMs, statins, lipophilic, and hydrophilic statins and
   cancer-specific mortality. Results From 2003 to 2013, 3 separate cohorts
   of 20 046, 11 719 and 6430 female patients with newly diagnosed breast,
   colorectal cancer, and melanoma respectively were identified. The 1-year
   adherence was similar at 1-year prediagnosis in the 3 cohorts, on
   average 82%. Each 10% increase in 1-year adherence to LLMs was inversely
   associated with cancer-specific mortality among women with breast cancer
   (fully adjusted HR = 0.92, 95% CI 0.91-0.93), colorectal cancer (fully
   adjusted HR = 0.92, 95% CI 0.91-0.93), or melanoma (fully adjusted HR =
   0.97, 95% CI 0.94-1.00). The reductions in cancer-specific mortality
   were more pronounced for women who adhered to lipophilic than
   hydrophilic statins in all 3 cancers albeit not statistically
   significant for melanoma. Conclusion Among LLM users, adherence to this
   drug is associated with a decrease in cancer-specific mortality. If
   confirmed, LLMs could be considered as an adjuvant cancer therapy to
   improve prognosis in cancer survivors.
TC 16
Z8 0
ZB 8
ZR 0
ZA 0
ZS 0
Z9 17
DA 2020-10-20
UT WOS:000579737200001
PM 33084072
ER

PT J
AU Lee, Gabriela Georgina
   Goodman, Deniz
   Chang, Ta Chen
TI Racial and Gender Bias in Artificial Intelligence Generated
   Ophthalmologic Educational Material
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
DA 2024-12-01
UT WOS:001312227701049
ER

PT J
AU Parsa, Shyon
   Somani, Sulaiman
   Hernandez-Boussard, Tina
   Rodriguez, Fatima
TI Large Language Modeling-Enabled Analysis of Atrial Fibrillation Topics
   and Sentiments on Social Media
SO CIRCULATION
VL 150
MA 4129223
DI 10.1161/circ.150.suppl_1.4129223
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
Z8 0
ZB 0
ZS 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-02-10
UT WOS:001398742701086
ER

PT J
AU Bullen, Lindsey E.
   Evola, Maria G.
   Griffith, Emily H.
   Seiler, Gabriela S.
   Saker, Korinn E.
TI Validation of ultrasonographic muscle thickness measurements as compared
   to the gold standard of computed tomography in dogs
SO PEERJ
VL 5
DI 10.7717/peerj.2926
DT Article
PD JAN 25 2017
PY 2017
AB Objective. The objective was to quantitatively evaluate the validity of
   utrasonographic (US) muscle measurements as compared to the gold
   standard of computed tomography (CT) in the canine. Design. This was a
   prospective study. Population. Twenty-five, client-owned dogs scheduled
   for CT as part of a diagnostic work-up for the management of their
   primary disease process were included. Materials and Methods-Specific
   appendicular (cubital flexors and extensors, coxofemoral flexors and
   extensors) and axial (temporalis, supraspinatus, infraspinatus, lum bar
   epaxials) muscle groups were selected for quantitative measure based on
   CT planning and patient position. Prior to CT scan, the skin over the
   muscle sites was' shaved and marked with a permanent marker. Patient
   body position was determined based on the patient's CT plan; positioning
   was consistent between CT and US imaging. To ensure identical imaging
   position for both CT and US measurements, radio-opaque fiducial markers
   were placed directly over the skin marks once the dog was positioned.
   Quantitative measurements (cm) for both lean muscle mass (LMM) and
   subcutaneous adipose (SQA) were recorded. Statistical comparisons
   between CT and US values were done separately for each site and type.
   Results. Muscle groups and associated SQA measured by US and CT were not
   statistically different based on an adjusted p-value using Bonferroni's
   correction (p < 0.0031). In addition, all LMM and SQA sites had good
   reliability and agreement (Cronbach's alpha= 0.8-1.0) between the two
   metrics, excluding the coxofemoral extensor muscle group (Cronbach's
   alpha= 0.73232). Linear regression analysis of muscle measures indicated
   close agreement (slope range 0.93-1.09) and minimal bias of variation
   (intercept range 0.05-0.11) between CT versus US modalities, with the
   exception of the coxofemoral extensor muscle. Similarly, SQA CT and US
   measures indicated close agreement with the slope range of 0.88-1.02 and
   minimal bias of variation with an intercept range of 0.021-0.098,
   excluding the cubital flexor and extensor groups. Additionally, the R-2
   values for these remaining LMM and SQA sites are reported as >0.897 for
   LLM and >.0 8289 for SQA. Conclusions. Ultrasound imaging of selected
   appendicular and axial muscle groups in dogs can provide comparable
   assessment of muscle thickness to the current gold
Z8 0
ZS 0
ZA 0
ZR 0
ZB 3
TC 7
Z9 7
DA 2017-03-29
UT WOS:000394705900005
PM 28149695
ER

PT J
AU Cangelosi, Davide
   Muselli, Marco
   Parodi, Stefano
   Blengio, Fabiola
   Becherini, Pamela
   Versteeg, Rogier
   Conte, Massimo
   Varesio, Luigi
TI Use of Attribute Driven Incremental Discretization and Logic Learning
   Machine to build a prognostic classifier for neuroblastoma patients
SO BMC BIOINFORMATICS
VL 15
AR S4
DI 10.1186/1471-2105-15-S5-S4
SU 5
DT Article
PD MAY 6 2014
PY 2014
AB Background: Cancer patient's outcome is written, in part, in the gene
   expression profile of the tumor. We previously identified a 62-probe
   sets signature (NB-hypo) to identify tissue hypoxia in neuroblastoma
   tumors and showed that NB-hypo stratified neuroblastoma patients in good
   and poor outcome [1]. It was important to develop a prognostic
   classifier to cluster patients into risk groups benefiting of defined
   therapeutic approaches. Novel classification and data discretization
   approaches can be instrumental for the generation of accurate predictors
   and robust tools for clinical decision support. We explored the
   application to gene expression data of Rulex, a novel software suite
   including the Attribute Driven Incremental Discretization technique for
   transforming continuous variables into simplified discrete ones and the
   Logic Learning Machine model for intelligible rule generation.
   Results: We applied Rulex components to the problem of predicting the
   outcome of neuroblastoma patients on the bases of 62 probe sets NB-hypo
   gene expression signature. The resulting classifier consisted in 9 rules
   utilizing mainly two conditions of the relative expression of 11 probe
   sets. These rules were very effective predictors, as shown in an
   independent validation set, demonstrating the validity of the LLM
   algorithm applied to microarray data and patients' classification. The
   LLM performed as efficiently as Prediction Analysis of Microarray and
   Support Vector Machine, and outperformed other learning algorithms such
   as C4.5. Rulex carried out a feature selection by selecting a new
   signature (NB-hypo-II) of 11 probe sets that turned out to be the most
   relevant in predicting outcome among the 62 of the NB-hypo signature.
   Rules are easily interpretable as they involve only few conditions.
   Furthermore, we demonstrate that the application of a weighted
   classification associated with the rules improves the classification of
   poorly represented classes.
   Conclusions: Our findings provided evidence that the application of
   Rulex to the expression values of NB-hypo signature created a set of
   accurate, high quality, consistent and interpretable rules for the
   prediction of neuroblastoma patients' outcome. We identified the Rulex
   weighted classification as a flexible tool that can support clinical
   decisions. For these reasons, we consider Rulex to be a useful tool for
   cancer classification from microarray gene expression data.
ZA 0
TC 23
ZS 0
ZR 0
ZB 8
Z8 0
Z9 23
DA 2014-07-09
UT WOS:000337464500004
PM 25078098
ER

PT J
AU Huang, Thomas
   Safranek, Conrad
   Socrates, Vimig
   Chartash, David
   Wright, Donald
   Dilip, Monisha
   Sangal, Rohit B.
   Taylor, Richard Andrew
TI Patient-Representing Population's Perceptions of GPT-GeneratedVersus
   Standard Emergency Department Discharge Instructions:Randomized Blind
   Survey Assessment
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 26
AR e60336
DI 10.2196/60336
DT Article
PD AUG 2 2024
PY 2024
AB Background: Discharge instructions are a key form of documentation and
   patient communication in the time of transition fromthe emergency
   department (ED) to home. Discharge instructions are time-consuming and
   often underprioritized, especially inthe ED, leading to discharge delays
   and possibly impersonal patient instructions. Generative artificial
   intelligence and largelanguage models (LLMs) offer promising methods of
   creating high-quality and personalized discharge instructions;
   however,there exists a gap in understanding patient perspectives of
   LLM-generated discharge instructions. Objective: We aimed to assess the
   use of LLMs such as ChatGPT in synthesizing accurate and
   patient-accessible dischargeinstructions in the ED. Methods: We
   synthesized 5 unique, fictional ED encounters to emulate real ED
   encounters that included a diverse set of clinicianhistory, physical
   notes, and nursing notes. These were passed to GPT-4 in Azure OpenAI
   Service (Microsoft) to generateLLM-generated discharge instructions.
   Standard discharge instructions were also generated for each of the 5
   unique ED encounters.All GPT-generated and standard discharge
   instructions were then formatted into standardized after-visit summary
   documents.These after-visit summaries containing either GPT-generated or
   standard discharge instructions were randomly and blindlyadministered to
   Amazon MTurk respondents representing patient populations through Amazon
   MTurk Survey Distribution.Discharge instructions were assessed based on
   metrics of interpretability of significance, understandability, and
   satisfaction. Results: Our findings revealed that survey
   respondents'perspectives regarding GPT-generated and standard discharge
   instructionswere significantly (P=.01) more favorable toward
   GPT-generated return precautions, and all other sections were
   considerednoninferior to standard discharge instructions. Of the 156
   survey respondents, GPT-generated discharge instructions were
   assignedfavorable ratings, "agree" and "strongly agree," more frequently
   along the metric of interpretability of significancein
   dischargeinstruction subsections regarding diagnosis, procedures,
   treatment, post-ED medications or any changes to medications, andreturn
   precautions. Survey respondents found GPT-generated instructions to be
   more understandablewhen rating procedures,treatment, post-ED medications
   or medication changes, post-ED follow-up, and return precautions.
   Satisfactionwith GPT-generateddischarge instruction subsections was the
   most favorable in procedures, treatment, post-ED medications or
   medication changes,and return precautions. Wilcoxon rank-sum test of
   Likert responses revealed significant differences (P=.01) in the
   interpretabilityof significantreturn precautions in GPT-generated
   discharge instructions compared to standard discharge instructions but
   not forother evaluation metrics and discharge instruction subsections
   Conclusions: This study demonstrates the potential for LLMs such as
   ChatGPT to act as a method of augmenting currentdocumentation workflows
   in the ED to reduce the documentation burden of physicians. The ability
   of LLMs to provide tailoredinstructions for patients by improving
   readability and making instructions more applicable to patients could
   improve upon themethods of communication that currently exist
ZB 1
ZS 0
ZR 0
TC 5
Z8 0
ZA 0
Z9 5
DA 2024-09-13
UT WOS:001304413300003
PM 39094112
ER

PT J
AU Ullah, Ehsan
   Parwani, Anil
   Baig, Mirza Mansoor
   Singh, Rajendra
TI Challenges and barriers of using large language models (LLM) such as
   ChatGPT for diagnostic medicine with a focus on digital pathology - a
   recent scoping review
SO DIAGNOSTIC PATHOLOGY
VL 19
IS 1
AR 43
DI 10.1186/s13000-024-01464-7
DT Review
PD FEB 27 2024
PY 2024
AB BackgroundThe integration of large language models (LLMs) like ChatGPT
   in diagnostic medicine, with a focus on digital pathology, has garnered
   significant attention. However, understanding the challenges and
   barriers associated with the use of LLMs in this context is crucial for
   their successful implementation.MethodsA scoping review was conducted to
   explore the challenges and barriers of using LLMs, in diagnostic
   medicine with a focus on digital pathology. A comprehensive search was
   conducted using electronic databases, including PubMed and Google
   Scholar, for relevant articles published within the past four years. The
   selected articles were critically analyzed to identify and summarize the
   challenges and barriers reported in the literature.ResultsThe scoping
   review identified several challenges and barriers associated with the
   use of LLMs in diagnostic medicine. These included limitations in
   contextual understanding and interpretability, biases in training data,
   ethical considerations, impact on healthcare professionals, and
   regulatory concerns. Contextual understanding and interpretability
   challenges arise due to the lack of true understanding of medical
   concepts and lack of these models being explicitly trained on medical
   records selected by trained professionals, and the black-box nature of
   LLMs. Biases in training data pose a risk of perpetuating disparities
   and inaccuracies in diagnoses. Ethical considerations include patient
   privacy, data security, and responsible AI use. The integration of LLMs
   may impact healthcare professionals' autonomy and decision-making
   abilities. Regulatory concerns surround the need for guidelines and
   frameworks to ensure safe and ethical implementation.ConclusionThe
   scoping review highlights the challenges and barriers of using LLMs in
   diagnostic medicine with a focus on digital pathology. Understanding
   these challenges is essential for addressing the limitations and
   developing strategies to overcome barriers. It is critical for health
   professionals to be involved in the selection of data and fine tuning of
   the models. Further research, validation, and collaboration between AI
   developers, healthcare professionals, and regulatory bodies are
   necessary to ensure the responsible and effective integration of LLMs in
   diagnostic medicine.
TC 73
ZS 0
Z8 0
ZA 0
ZB 11
ZR 0
Z9 73
DA 2024-03-23
UT WOS:001174262700001
PM 38414074
ER

PT J
AU Wiest, Isabella Catharina
   Verhees, Falk Gerrik
   Ferber, Dyke
   Zhu, Jiefu
   Bauer, Michael
   Lewitzka, Ute
   Pfennig, Andrea
   Mikolas, Pavol
   Kather, Jakob Nikolas
TI Detection of suicidality from medical text using privacy-preserving
   large language models
SO BRITISH JOURNAL OF PSYCHIATRY
VL 225
IS 6
BP 532
EP 537
DI 10.1192/bjp.2024.134
EA NOV 2024
DT Review
PD DEC 2024
PY 2024
AB Background Attempts to use artificial intelligence (AI) in
   psychiatric disorders show moderate success, highlighting the potential
   of incorporating information from clinical assessments to improve the
   models. This study focuses on using large language models (LLMs) to
   detect suicide risk from medical text in psychiatric care. Aims To
   extract information about suicidality status from the admission notes in
   electronic health records (EHRs) using privacy-sensitive, locally hosted
   LLMs, specifically evaluating the efficacy of Llama-2 models. Method We
   compared the performance of several variants of the open source LLM
   Llama-2 in extracting suicidality status from 100 psychiatric reports
   against a ground truth defined by human experts, assessing accuracy,
   sensitivity, specificity and F1 score across different prompting
   strategies. Results A German fine-tuned Llama-2 model showed the highest
   accuracy (87.5%), sensitivity (83.0%) and specificity (91.8%) in
   identifying suicidality, with significant improvements in sensitivity
   and specificity across various prompt designs. Conclusions The study
   demonstrates the capability of LLMs, particularly Llama-2, in accurately
   extracting information on suicidality from psychiatric records while
   preserving data privacy. This suggests their application in surveillance
   systems for psychiatric emergencies and improving the clinical
   management of suicidality by improving systematic quality control and
   research.
ZR 0
TC 1
ZB 0
Z8 0
ZS 0
ZA 0
Z9 1
DA 2024-11-14
UT WOS:001348165300001
PM 39497458
ER

PT J
AU Jeyaraman, Madhan
   Balaji, Sangeetha
   Jeyaraman, Naveen
   Yadav, Sankalp
TI Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 15
IS 8
AR e43262
DI 10.7759/cureus.43262
DT Article
PD AUG 10 2023
PY 2023
AB The integration of artificial intelligence (AI) into healthcare promises
   groundbreaking advancements in patient care, revolutionizing clinical
   diagnosis, predictive medicine, and decision-making. This transformative
   technology uses machine learning, natural language processing, and large
   language models (LLMs) to process and reason like human intelligence.
   OpenAI's ChatGPT, a sophisticated LLM, holds immense potential in
   medical practice, research, and education. However, as AI in healthcare
   gains momentum, it brings forth profound ethical challenges that demand
   careful consideration. This comprehensive review explores key ethical
   concerns in the domain, including privacy, transparency, trust,
   responsibility, bias, and data quality. Protecting patient privacy in
   data-driven healthcare is crucial, with potential implications for
   psychological well-being and data sharing. Strategies like homomorphic
   encryption (HE) and secure multiparty computation (SMPC) are vital to
   preserving confidentiality. Transparency and trustworthiness of AI
   systems are essential, particularly in high-risk decision-making
   scenarios. Explainable AI (XAI) emerges as a critical aspect, ensuring a
   clear understanding of AI-generated predictions. Cybersecurity becomes a
   pressing concern as AI's complexity creates vulnerabilities for
   potential breaches. Determining responsibility in AI-driven outcomes
   raises important questions, with debates on AI's moral agency and human
   accountability. Shifting from data ownership to data stewardship enables
   responsible data management in compliance with regulations. Addressing
   bias in healthcare data is crucial to avoid AI-driven inequities. Biases
   present in data collection and algorithm development can perpetuate
   healthcare disparities. A public-health approach is advocated to address
   inequalities and promote diversity in AI research and the workforce.
   Maintaining data quality is imperative in AI applications, with
   convolutional neural networks showing promise in multi-input/mixed data
   models, offering a comprehensive patient perspective. In this
   ever-evolving landscape, it is imperative to adopt a multidimensional
   approach involving policymakers, developers, healthcare practitioners,
   and patients to mitigate ethical concerns. By understanding and
   addressing these challenges, we can harness the full potential of AI in
   healthcare while ensuring ethical and equitable outcomes.
ZR 0
Z8 2
TC 82
ZB 13
ZA 0
ZS 0
Z9 83
DA 2024-03-17
UT WOS:001168567200012
PM 37692617
ER

PT J
AU Wang, Yuli
   Hsu, Wen-Chi
   Dai, Yuwei
   Shi, Victoria
   Lin, Gigin
   Bai, Harrison
   Lin, Cheng Ting
TI Automatic assignment of CAD-RADS categories in coronary CTA reports
   using large language model
SO CIRCULATION
VL 150
MA 4119869
DI 10.1161/circ.150.suppl_1.4119869
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
ZS 0
ZA 0
TC 0
ZR 0
Z8 0
ZB 0
Z9 0
DA 2025-02-10
UT WOS:001398742700217
ER

PT J
AU Shaheen, Abdulla
   Afflitto, Gabriele Gallo
   Swaminathan, Swarup S.
TI ChatGPT-Assisted Classification fi cation of Postoperative Bleeding
   Following Microinvasive Glaucoma Surgery Using Electronic Health Record
   Data
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100602
DI 10.1016/j.xops.2024.100602
EA SEP 2024
DT Article
PD FEB 2025
PY 2025
AB Purpose: To evaluate the performance of a large language model (LLM) in
   classifying electronic health record (EHR) text, and to use this
   classification to evaluate the type and resolution of hemorrhagic events
   (HEs) after microinvasive glaucoma surgery (MIGS). Design: Retrospective
   cohort study. Participants: Eyes from the Bascom Palmer Glaucoma
   Repository. Methods: Eyes that underwent MIGS between July 1, 2014 and
   February 1, 2022 were analyzed. Chat Generative Pre-trained Transformer
   (ChatGPT) was used to classify deidentified EHR anterior chamber
   examination text into HE categories (no hyphema, microhyphema, clot, and
   hyphema). Agreement between classifications by ChatGPT and a glaucoma
   specialist was evaluated using Cohen's Kappa and precision-recall (PR)
   curve. Time to resolution of HEs was assessed using Cox
   proportional-hazards models. Goniotomy HE resolution was evaluated by
   degree of angle treatment (90 degrees-179 degrees,180 degrees-269
   degrees, 270 degrees-360 degrees). degrees-360 degrees ). Logistic
   regression was used to identify HE risk factors. Main Outcome Measures:
   Accuracy of ChatGPT HE classification and incidence and resolution of
   HEs. Results: The study included 434 goniotomy eyes (368 patients) and
   528 Schlemm's canal stent (SCS) eyes (390 patients). Chat Generative
   Pre-trained Transformer facilitated excellent HE classification (Cohen's
   kappa 0.93, area under PR curve 0.968). Using ChatGPT classifications,
   at postoperative day 1, HEs occurred in 67.8% of goniotomy and 25.2% of
   SCS eyes (P < 0.001). The 270 degrees degrees to 360 degrees degrees
   goniotomy group had the highest HE rate (84.0%, P < 0.001). At
   postoperative week 1, HEs were observed in 43.4% and 11.3% of goniotomy
   and SCS eyes, respectively (P < 0.001). By postoperative month 1, HE
   rates were 13.3% and 1.3% among goniotomy and SCS eyes, respectively (P
   < 0.001). Time to HE resolution differed between the goniotomy angle
   groups (log-rank P = 0.034); median time to resolution was 10, 10, and
   15 days for the 90 degrees degrees to 179 degrees, 180 degrees to 269
   degrees, and 270 degrees to 360 degrees groups, respectively. Risk
   factor analysis demonstrated greater goniotomy angle was the only
   significant predictor of HEs (odds ratio for 270 degrees-360 degrees:
   360 degrees : 4.08, P < 0.001). Conclusions: Large language models can
   be effectively used to classify longitudinal EHR free-text examination
   data with high accuracy, highlighting a promising direction for future
   LLM-assisted research and clinical decision support. Hemorrhagic events
   are relatively common self-resolving complications that occur more often
   in goniotomy cases and with larger goniotomy treatments. Time to HE
   resolution differs significantly between goniotomy groups. Financial
   Disclosure(s):Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100602<feminine ordinal indicator>2024 by the American
   Academy of Ophthalmology. This is an open access article under the CC
   BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
DA 2024-10-05
UT WOS:001321792000001
PM 39380881
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Tokumasu, Kazuki
   Ito, Takahiro
   Suzuki, Tomoharu
   Shimizu, Taro
TI Evaluating ChatGPT-4's Diagnostic Accuracy: Impact of Visual Data
   Integration
SO JMIR MEDICAL INFORMATICS
VL 12
AR e55627
DI 10.2196/55627
DT Article
PD 2024
PY 2024
AB Background: In the evolving field of health care, multimodal generative
   artificial intelligence (AI) systems, such as ChatGPT-4 with vision
   (ChatGPT-4V), represent a significant advancement, as they integrate
   visual data with text data. This integration has the potential to
   revolutionize clinical diagnostics by offering more comprehensive
   analysis capabilities. However, the impact on diagnostic accuracy of
   using image data to augment ChatGPT-4 remains unclear. Objective: This
   study aims to assess the impact of adding image data on ChatGPT-4's
   diagnostic accuracy and provide insights into how image data integration
   can enhance the accuracy of multimodal AI in medical diagnostics.
   Specifically, this study endeavored to compare the diagnostic accuracy
   between ChatGPT-4V, which processed both text and image data, and its
   counterpart, ChatGPT-4, which only uses text data. Methods: We
   identified a total of 557 case reports published in the American Journal
   of Case Reports from January 2022 to March 2023. After excluding cases
   that were nondiagnostic, pediatric, and lacking image data, we included
   363 case descriptions with their final diagnoses and associated images.
   We compared the diagnostic accuracy of ChatGPT-4V and ChatGPT-4 without
   vision based on their ability to include the final diagnoses within
   differential diagnosis lists. Two independent physicians evaluated their
   accuracy, with a third resolving any discrepancies, ensuring a rigorous
   and objective analysis. Results: The integration of image data into
   ChatGPT-4V did not significantly enhance diagnostic accuracy, showing
   that final diagnoses were included in the top 10 differential diagnosis
   lists at a rate of 85.1% (n=309), comparable to the rate of 87.9%
   (n=319) for the text -only version ( P =.33). Notably, ChatGPT-4V's
   performance in correctly identifying the top diagnosis was inferior, at
   44.4% (n=161), compared with 55.9% (n=203) for the text -only version (
   P =.002, chi 2 test). Additionally, ChatGPT-4's self -reports showed
   that image data accounted for 30% of the weight in developing the
   differential diagnosis lists in more than half of cases. Conclusions:
   Our findings reveal that currently, ChatGPT-4V predominantly relies on
   textual data, limiting its ability to fully use the diagnostic potential
   of visual information. This study underscores the need for further
   development of multimodal generative AI systems to effectively integrate
   and use clinical image data. Enhancing the diagnostic performance of
   such AI systems through improved multimodal data integration could
   significantly benefit patient care by providing more accurate and
   comprehensive diagnostic insights. Future research should focus on
   overcoming these limitations, paving the way for the practical
   application of advanced AI in medicine.
ZB 2
Z8 1
TC 11
ZA 0
ZR 0
ZS 0
Z9 11
DA 2024-05-16
UT WOS:001217446200001
PM 38592758
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Lin, Wei-Chun
   Reznick, Caleb
   Reznick, Leah
   Lucero, Abigail
   Campbell, J. Peter
   Ishikawa, Hiroshi
   Hribar, Michelle
TI Enhancing Amblyopia Identification Using NLP: A Study of BioClinical
   BERT and Flan-T5 Models
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZA 0
ZR 0
ZS 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2024-12-01
UT WOS:001312227701035
ER

PT J
AU Pandya, Vidish
   Ge, Alan
   Ramineni, Shreya
   Danilov, Alexandrina
   Kirdar, Faisal
   Di Biase, Luigi
   Ferrick, Kevin
   Krumerman, Andrew
TI From GPT-4 to GPT-4o: Progress and Challenges in ECG Interpretation
SO CIRCULATION
VL 150
MA 4142075
DI 10.1161/circ.150.suppl_1.4142075
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
CT American-Heart-Association Resuscitation Science Symposium
CY NOV 16-18, 2024
CL Chicago, IL
SP Amer Heart Assoc
ZR 0
TC 0
ZB 0
Z8 0
ZS 0
ZA 0
Z9 0
DA 2025-02-13
UT WOS:001400066400114
ER

PT J
AU Silverman, Anna L.
   Sushil, Madhumita
   Bhasuran, Balu
   Ludwig, Dana
   Buchanan, James
   Racz, Rebecca
   Parakala, Mahalakshmi
   El-Kamary, Samer
   Ahima, Ohenewaa
   Belov, Artur
   Choi, Lauren
   Billings, Monisha
   Li, Yan
   Habal, Nadia
   Liu, Qi
   Tiwari, Jawahar
   Butte, Atul J.
   Rudrapatna, Vivek A.
TI Algorithmic Identification of Treatment-Emergent Adverse Events From
   Clinical Notes Using Large Language Models: A Pilot Study in
   Inflammatory Bowel Disease
SO CLINICAL PHARMACOLOGY & THERAPEUTICS
VL 115
IS 6
BP 1391
EP 1399
DI 10.1002/cpt.3226
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB Outpatient clinical notes are a rich source of information regarding
   drug safety. However, data in these notes are currently underutilized
   for pharmacovigilance due to methodological limitations in text mining.
   Large language models (LLMs) like Bidirectional Encoder Representations
   from Transformers (BERT) have shown progress in a range of natural
   language processing tasks but have not yet been evaluated on adverse
   event (AE) detection. We adapted a new clinical LLM, University of
   California - San Francisco (UCSF)-BERT, to identify serious AEs (SAEs)
   occurring after treatment with a non-steroid immunosuppressant for
   inflammatory bowel disease (IBD). We compared this model to other
   language models that have previously been applied to AE detection. We
   annotated 928 outpatient IBD notes corresponding to 928 individual
   patients with IBD for all SAE-associated hospitalizations occurring
   after treatment with a non-steroid immunosuppressant. These notes
   contained 703 SAEs in total, the most common of which was failure of
   intended efficacy. Out of eight candidate models, UCSF-BERT achieved the
   highest numerical performance on identifying drug-SAE pairs from this
   corpus (accuracy 88-92%, macro F1 61-68%), with 5-10% greater accuracy
   than previously published models. UCSF-BERT was significantly superior
   at identifying hospitalization events emergent to medication use (P <
   0.01). LLMs like UCSF-BERT achieve numerically superior accuracy on the
   challenging task of SAE detection from clinical notes compared with
   prior methods. Future work is needed to adapt this methodology to
   improve model performance and evaluation using multicenter data and
   newer architectures like Generative pre-trained transformer (GPT). Our
   findings support the potential value of using large language models to
   enhance pharmacovigilance.
Z8 0
ZB 0
ZR 0
ZA 0
ZS 0
TC 6
Z9 6
DA 2024-03-28
UT WOS:001181392200001
PM 38459719
ER

PT J
AU Guillen-Grima, Francisco
   Guillen-Aguinaga, Sara
   Guillen-Aguinaga, Laura
   Alas-Brun, Rosa
   Onambele, Luc
   Ortega, Wilfrido
   Montejo, Rocio
   Aguinaga-Ontoso, Enrique
   Barach, Paul
   Aguinaga-Ontoso, Ines
TI Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical
   Residency Entrance Examination (MIR): Promising Horizons for AI in
   Clinical Medicine
SO CLINICS AND PRACTICE
VL 13
IS 6
BP 1460
EP 1487
DI 10.3390/clinpract13060130
DT Article
PD DEC 2023
PY 2023
AB The rapid progress in artificial intelligence, machine learning, and
   natural language processing has led to increasingly sophisticated large
   language models (LLMs) for use in healthcare. This study assesses the
   performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the
   MIR medical examination for access to medical specialist training in
   Spain. Our objectives included gauging the model's overall performance,
   analyzing discrepancies across different medical specialties, discerning
   between theoretical and practical questions, estimating error
   proportions, and assessing the hypothetical severity of errors committed
   by a physician. Material and methods: We studied the 2022 Spanish MIR
   examination results after excluding those questions requiring image
   evaluations or having acknowledged errors. The remaining 182 questions
   were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English.
   Logistic regression models analyzed the relationships between question
   length, sequence, and performance. We also analyzed the 23 questions
   with images, using GPT-4's new image analysis capability. Results: GPT-4
   outperformed GPT-3.5, scoring 86.81% in Spanish (p < 0.001). English
   translations had a slightly enhanced performance. GPT-4 scored 26.1% of
   the questions with images in English. The results were worse when the
   questions were in Spanish, 13.0%, although the differences were not
   statistically significant (p = 0.250). Among medical specialties, GPT-4
   achieved a 100% correct response rate in several areas, and the
   Pharmacology, Critical Care, and Infectious Diseases specialties showed
   lower performance. The error analysis revealed that while a 13.2% error
   rate existed, the gravest categories, such as "error requiring
   intervention to sustain life" and "error resulting in death", had a 0%
   rate. Conclusions: GPT-4 performs robustly on the Spanish MIR
   examination, with varying capabilities to discriminate knowledge across
   specialties. While the model's high success rate is commendable,
   understanding the error severity is critical, especially when
   considering AI's potential role in real-world medical practice and its
   implications for patient safety.
ZA 0
TC 28
Z8 0
ZS 1
ZB 6
ZR 0
Z9 28
DA 2024-01-17
UT WOS:001132385500001
PM 37987431
ER

PT J
AU Zhang, YuNing
   Dong, Yijie
   Mei, Zihan
   Hou, Yiqing
   Wei, Minyan
   Yeung, Yat Hin
   Xu, Jiale
   Hua, Qing
   Lai, LiMei
   Li, Ning
   Xia, ShuJun
   Zhou, Chun
   Zhou, JianQiao
TI Performance of large language models on benign prostatic hyperplasia
   frequently asked questions
SO PROSTATE
VL 84
IS 9
BP 807
EP 813
DI 10.1002/pros.24699
EA APR 2024
DT Article
PD JUN 2024
PY 2024
AB Background: Benign prostatic hyperplasia (BPH) is a common condition,
   yet it is challenging for the average BPH patient to find credible and
   accurate information about BPH. Our goal is to evaluate and compare the
   accuracy and reproducibility of large language models (LLMs), including
   ChatGPT-3.5, ChatGPT-4, and the New Bing Chat in responding to a BPH
   frequently asked questions (FAQs) questionnaire. Methods: A total of 45
   questions related to BPH were categorized into basic and professional
   knowledge. Three LLM-ChatGPT-3.5, ChatGPT-4, and New Bing Chat-were
   utilized to generate responses to these questions. Responses were graded
   as comprehensive, correct but inadequate, mixed with incorrect/outdated
   data, or completely incorrect. Reproducibility was assessed by
   generating two responses for each question. All responses were reviewed
   and judged by experienced urologists. Results: All three LLMs exhibited
   high accuracy in generating responses to questions, with accuracy rates
   ranging from 86.7% to 100%. However, there was no statistically
   significant difference in response accuracy among the three (p > 0.017
   for all comparisons). Additionally, the accuracy of the LLMs' responses
   to the basic knowledge questions was roughly equivalent to that of the
   specialized knowledge questions, showing a difference of less than 3.5%
   (GPT-3.5: 90% vs. 86.7%; GPT-4: 96.7% vs. 95.6%; New Bing: 96.7% vs.
   93.3%). Furthermore, all three LLMs demonstrated high reproducibility,
   with rates ranging from 93.3% to 97.8%. Conclusions: ChatGPT-3.5,
   ChatGPT-4, and New Bing Chat offer accurate and reproducible responses
   to BPH-related questions, establishing them as valuable resources for
   enhancing health literacy and supporting BPH patients in conjunction
   with healthcare professionals.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 2
TC 8
Z9 8
DA 2024-04-04
UT WOS:001194679200001
PM 38558009
ER

PT J
AU TOKEDE, OLUWABUNMI 
TI FullMouth: Enhancing Dental Clinical Data and Reducing Disparities
   through Innovative ML Approaches.
DT Awarded Grant
PD Sep 01 2024
PY 2024
AB Project Abstract/SummaryThe vast amount of health data created in the
   United States may hold the key to understanding disease,improving
   quality, and lowering healthcare costs. Electronic health records
   (EHRs), digital collections of patienthealthcare events and
   observations, are now ubiquitous in medicine and critical to healthcare
   delivery,operations, and research. EHR data is often classified as
   structured or unstructured. Structured EHR datainclude standardized
   diagnoses, medications, and laboratory values in fixed numerical or
   categorical fields. Forstructured data, challenges such as missing,
   incomplete, and inconsistent data are very prevalent.Unstructured data,
   in contrast, refer to free-form text written by healthcare providers,
   such as clinical notes anddischarge summaries. Dental care providers
   often write detailed findings, diagnoses, treatment plans andprognostic
   factors in free-text format for clinical care purposes. While this
   information is easily accessible duringpatient care, extracting it for
   generating meaningful insights for secondary analysis can be
   challenging. Utilizingthese records requires manual review by domain
   experts, which can be time-consuming and costly, particularlywhen
   dealing with a large number of patient records. Unstructured data
   represents about 60% of total EHR data.Recently, Large Language Models
   (LLMs) and newer deep learning approaches to Natural Language
   Processing(NLP) have made considerable advances, outperforming
   traditional statistical and rule-based systems on avariety of tasks.To
   fully realize the promise of health information technology in dentistry,
   it is important to address datamissingness and disparity in missingness.
   Through a periodontal use-case, this proposal will tackle the
   challengeof missing structured, and ‘technically’ inaccessible,
   unstructured clinical data. Periodontal (advanced gumdisease) problems
   are very pervasive, and unlike caries (whose prevalence has steadily
   declined over the pastfour decades), disease burden and tooth loss
   secondary to periodontal disease remain intractable. In preliminarywork
   at two dental institutions, we observed that most patients seen for a
   comprehensive oral evaluation hadmissing or incomplete documentation
   with respect to clinical periodontal indices/diagnosis, demographic,
   andhealth-related behavior information – all of which are critical in
   diagnosing and treating periodontal disease. Thissignificantly limits
   our ability to learn and improve. Aim 1 will focus on using LLM-based
   NLP approaches for theconversion of unstructured note entries into
   structured and machine-readable information. In Aim 2, we will
   useimputation techniques to fill in missing structured clinical data
   entries. Aim 3 will then evaluate the impact ofreduction in clinical
   data missingness for both clinical and research applications. This work
   builds on our priorwork in developing the BigMouth Dental Data
   Repository (which contains regularly updated structured data on4.6
   million patients). We will be supported by the collective strength of
   the 11 core BigMouth, and other allieddental institutions that currently
   share and/or contribute data to the repository.
TC 0
ZA 0
Z8 0
ZR 0
ZS 0
ZB 0
Z9 0
G1 11137246; 1R56DE034086-01; R56DE034086
DA 2024-09-29
UT GRANTS:17810133
ER

PT J
AU Somani, Sulaiman
   Kim, Dale
   Perez, Eduardo
   Ngo, Summer
   Hernandez-Boussard, Tina
   Rodriguez, Fatima
TI Large Language Models to Understand Reasons for Anticoagulation
   Nonprescription in Atrial Fibrillation
SO CIRCULATION
VL 150
MA 4144857
DI 10.1161/circ.150.suppl_1.4144857
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
CT American-Heart-Association Resuscitation Science Symposium
CY NOV 16-18, 2024
CL Chicago, IL
SP Amer Heart Assoc
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-02-13
UT WOS:001400066402089
ER

PT J
AU Shi, Michael
   Hanna, Jovana
   Clavell, Christine
   Eid, Kevin
   Eid, Alen
   Ghorayeb, Ghassan
   John Nguyen
TI Assessing Readability of Patient Education Materials: A Comparative
   Study of ASRS Resources and AI-Generated Content by Popular Large
   Language Models (ChatGPT 4.0 and Google Bard)
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 5646
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZS 0
ZR 0
ZB 0
Z8 0
TC 3
ZA 0
Z9 3
DA 2024-11-30
UT WOS:001313316206217
ER

PT J
AU Zhang, Yapei
   Shi, Min
   Liebman, Daniel L.
   Barna, Laura
   Pasquale, Louis R.
   Elze, Tobias
   Friedman, David S.
   Boland, Michael V.
   Shen, Lucy Q.
   Wang, Mengyu
TI Evaluation of the accuracy of AIgenerated clinical summaries from
   Glaucoma outpatient visits.
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1641
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
DA 2024-12-01
UT WOS:001312227704269
ER

PT J
AU Zhao, Fang-Fang
   He, Han-Jie
   Liang, Jia-Jian
   Cen, Jingyun
   Wang, Yun
   Lin, Hongjie
   Chen, Feifei
   Li, Tai-Ping
   Yang, Jian-Feng
   Chen, Lan
   Cen, Ling-Ping
TI Benchmarking the performance of large language models in uveitis: a
   comparative analysis of ChatGPT-3.5, ChatGPT-4.0, Google Gemini, and
   Anthropic Claude3
SO EYE
VL 39
IS 6
BP 1132
EP 1137
DI 10.1038/s41433-024-03545-9
EA DEC 2024
DT Article
PD APR 2025
PY 2025
AB Background/Objective This study aimed to evaluate the accuracy,
   comprehensiveness, and readability of responses generated by various
   Large Language Models (LLMs) (ChatGPT-3.5, Gemini, Claude 3, and
   GPT-4.0) in the clinical context of uveitis, utilizing a meticulous
   grading methodology. Methods Twenty-seven clinical uveitis questions
   were presented individually to four Large Language Models (LLMs):
   ChatGPT (versions GPT-3.5 and GPT-4.0), Google Gemini, and Claude. Three
   experienced uveitis specialists independently assessed the responses for
   accuracy using a three-point scale across three rounds with a 48-hour
   wash-out interval. The final accuracy rating for each LLM response
   ('Excellent', 'Marginal', or 'Deficient') was determined through a
   majority consensus approach. Comprehensiveness was evaluated using a
   three-point scale for responses rated 'Excellent' in the final accuracy
   assessment. Readability was determined using the Flesch-Kincaid Grade
   Level formula. Statistical analyses were conducted to discern
   significant differences among LLMs, employing a significance threshold
   of p < 0.05. Results Claude 3 and ChatGPT 4 demonstrated significantly
   higher accuracy compared to Gemini (p < 0.001). Claude 3 also showed the
   highest proportion of 'Excellent' ratings (96.3%), followed by ChatGPT 4
   (88.9%). ChatGPT 3.5, Claude 3, and ChatGPT 4 had no responses rated as
   'Deficient', unlike Gemini (14.8%) (p = 0.014). ChatGPT 4 exhibited
   greater comprehensiveness compared to Gemini (p = 0.008), and Claude 3
   showed higher comprehensiveness compared to Gemini (p = 0.042). Gemini
   showed significantly better readability compared to ChatGPT 3.5, Claude
   3, and ChatGPT 4 (p < 0.001). Gemini also had fewer words, letter
   characters, and sentences compared to ChatGPT 3.5 and Claude 3.
   Conclusions Our study highlights the outstanding performance of Claude 3
   and ChatGPT 4 in providing precise and thorough information regarding
   uveitis, surpassing Gemini. ChatGPT 4 and Claude 3 emerge as pivotal
   tools in improving patient understanding and involvement in their
   uveitis healthcare journey.
ZB 0
ZS 0
TC 6
ZR 0
ZA 0
Z8 0
Z9 6
DA 2024-12-25
UT WOS:001380600200001
PM 39690303
ER

PT J
AU Ozkan, Ecem
   Tekin, Aysun
   Ozkan, Mahmut Can
   Cabrera, Daniel
   Niven, Alexander
   Dong, Yue
TI Global Health care Professionals' Perceptions of Large Language Model
   Use In Practice: Cross-Sectional Survey Study
SO JMIR MEDICAL EDUCATION
VL 11
AR e58801
DI 10.2196/58801
DT Article
PD 2025
PY 2025
AB Background: ChatGPT is a large language model-based chatbot developed by
   OpenAI. ChatGPT has many potential applications to health care,
   including enhanced diagnostic accuracy and efficiency, improved
   treatment planning, and better patient outcomes. However, health care
   professionals' perceptions of ChatGPT and similar artificial
   intelligence tools are not well known. Understanding these attitudes is
   important to inform the best approaches to exploring their use in
   medicine. Objective: Our aim was to evaluate the health care
   professionals' awareness and perceptions regarding potential
   applications of ChatGPT in the medical field, including potential
   benefits and challenges of adoption. Methods: We designed a 33-question
   online survey that was distributed among health care professionals via
   targeted emails and professional Twitter and LinkedIn accounts. The
   survey included a range of questions to define respondents' demographic
   characteristics, familiarity with ChatGPT, perceptions of this tool's
   usefulness and reliability, and opinions on its potential to improve
   patient care, research, and education efforts. Results: One hundred and
   fifteen health care professionals from 21 countries responded to the
   survey, including physicians, nurses, researchers, and educators. Of
   these, 101 (87.8%) had heard of ChatGPT, mainly from peers, social
   media, and news, and 77 (76.2%) had used ChatGPT at least once.
   Participants found ChatGPT to be helpful for writing manuscripts (n=31,
   45.6%), emails (n=25, 36.8%), and grants (n=12, 17.6%); accessing the
   latest research and evidence-based guidelines (n=21, 30.9%); providing
   suggestions on diagnosis or treatment (n=15, 22.1%); and improving
   patient communication (n=12, 17.6%). Respondents also felt that the
   ability of ChatGPT to access and summarize research articles (n=22,
   46.8%), provide quick answers to clinical questions (n=15, 31.9%), and
   generate patient education materials (n=10, 21.3%) was helpful. However,
   there are concerns regarding the use of ChatGPT, for example, the
   accuracy of responses (n=14, 29.8%), limited applicability in specific
   practices (n=18, 38.3%), and legal and ethical considerations (n=6,
   12.8%), mainly related to plagiarism or copyright violations.
   Participants stated that safety protocols such as data encryption (n=63,
   62.4%) and access control (n=52, 51.5%) could assist in ensuring patient
   privacy and data security. Conclusions: Our findings show that ChatGPT
   use is widespread among health care professionals in daily clinical,
   research, and educational activities. The majority of our participants
   found ChatGPT to be useful; however, there are concerns about patient
   privacy, data security, and its legal and ethical issues as well as the
   accuracy of its information. Further studies are required to understand
   the impact of ChatGPT and other large language models on clinical,
   educational, and research outcomes, and the concerns regarding its use
   must be addressed systematically and through appropriate methods.
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-23
UT WOS:001490640700001
PM 40354644
ER

PT J
AU Gholami, Sina
   Jannat, Fatema
   Ong, Sally
   Thompson, Atalie C.
   Lim, Jennifer I.
   Leng, Theodore
   Tabkhivayghan, Hamed
   Alam, Minhaj Nur
TI FedMiM - Domain adaptive federated learning for classifying age-related
   macular degeneration
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 2769
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZB 0
ZA 0
ZS 0
ZR 0
TC 0
Z8 0
Z9 0
DA 2024-12-01
UT WOS:001312227708067
ER

PT J
AU Cardakli, Nur
   Kraus, Courtney L.
TI Utilization of a large language modelpowered chatbot to identify
   congenital glaucoma from other ocular etiologies
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
TC 0
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-12-01
UT WOS:001312227701034
ER

PT J
AU Fu, Sidney W.
   Tang, Cong
   Tan, Xiaohui
   Srivastava, Sudhir
TI Liquid biopsy for early cancer detection: technological revolutions and
   clinical dilemma
SO EXPERT REVIEW OF MOLECULAR DIAGNOSTICS
VL 24
IS 10
BP 937
EP 955
DI 10.1080/14737159.2024.2408744
EA OCT 2024
DT Review
PD OCT 2 2024
PY 2024
AB IntroductionLiquid biopsy is an innovative advancement in oncology,
   offering a noninvasive method for early cancer detection and monitoring
   by analyzing circulating tumor cells, DNA, RNA, and other biomarkers in
   bodily fluids. This technique has the potential to revolutionize
   precision oncology by providing real-time analysis of tumor dynamics,
   enabling early detection, monitoring treatment responses, and tailoring
   personalized therapies based on the molecular profiles of individual
   patients.Areas coveredIn this review, the authors discuss current
   methodologies, technological challenges, and clinical applications of
   liquid biopsy. This includes advancements in detecting minimal residual
   disease, tracking tumor evolution, and combining liquid biopsy with
   other diagnostic modalities for precision oncology. Key areas explored
   are the sensitivity, specificity, and integration of multi-omics, AI,
   ML, and LLM technologies.Expert opinionLiquid biopsy holds great
   potential to revolutionize cancer care through early detection and
   personalized treatment strategies. However, its success depends on
   overcoming technological and clinical hurdles, such as ensuring high
   sensitivity and specificity, interpreting results amidst tumor
   heterogeneity, and making tests accessible and affordable. Continued
   innovation and collaboration are crucial to fully realize the potential
   of liquid biopsy in improving early cancer detection, treatment, and
   monitoring.
ZR 0
ZA 0
Z8 0
ZB 2
TC 6
ZS 0
Z9 6
DA 2024-10-09
UT WOS:001325602700001
PM 39360748
ER

PT J
AU Olszewski, Robert
   Watros, Klaudia
   Manczak, Malgorzata
   Owoc, Jakub
   Jeziorski, Krzysztof
   Brzezinski, Jakub
TI Assessing the response quality and readability of chatbots in
   cardiovascular health, oncology, and psoriasis: A comparative study
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 190
AR 105562
DI 10.1016/j.ijmedinf.2024.105562
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background: Chatbots using the Large Language Model (LLM) generate human
   responses to questions from all categories. Due to staff shortages in
   healthcare systems, patients waiting for an appointment increasingly use
   chatbots to get information about their condition. Given the number of
   chatbots currently available, assessing the responses they generate is
   essential. Methods: Five chatbots with free access were selected
   (Gemini, Microsoft Copilot, PiAI, ChatGPT, ChatSpot) and blinded using
   letters (A, B, C, D, E). Each chatbot was asked questions about
   cardiology, oncology, and psoriasis. Responses were compared to
   guidelines from the European Society of Cardiology, American Academy of
   Dermatology and American Society of Clinical Oncology. All answers were
   assessed using readability scales (Flesch Reading Scale, Gunning Fog
   Scale Level, Flesch-Kincaid Grade Level and Dale-Chall Score). Using a
   3point Likert scale, two independent medical professionals assessed the
   compliance of the responses with the guidelines. Results: A total of 45
   questions were asked of all chatbots. Chatbot C gave the shortest
   answers, 7.0 (6.0 - 8.0), and Chatbot A the longest 17.5 (13.0 - 24.5).
   The Flesch Reading Ease Scale ranged from 16.3 (12.2 - 21.9) (Chatbot D)
   to 39.8 (29.0 - 50.4) (Chatbot A). Flesch-Kincaid Grade Level ranged
   from 12.5 (10.6 - 14.6) (Chatbot A) to 15.9 (15.1 - 17.1) (Chatbot D).
   Gunning Fog Scale Level ranged from 15.77 (Chatbot A) to 19.73 (Chatbot
   D). Dale-Chall Score ranged from 10.3 (9.3 - 11.3) (Chatbot A) to 11.9
   (11.5 - 12.4) (Chatbot D). Conclusion: This study indicates that
   chatbots vary in length, quality, and readability. They answer each
   question in their own way, based on the data they have pulled from the
   web. Reliability of the responses generated by chatbots is high. This
   suggests that people who want information from a chatbot need to be
   careful and verify the answers they receive, particularly when they ask
   about medical and health aspects.
ZS 0
ZR 0
TC 3
Z8 1
ZB 0
ZA 0
Z9 4
DA 2024-08-07
UT WOS:001281403200001
PM 39059084
ER

PT J
AU Chen, Xiaolan
   Zhang, Weiyi
   Zhao, Ziwei
   Xu, Pusheng
   Zheng, Yingfeng
   Shi, Danli
   He, Mingguang
TI ICGA-GPT: report generation and question answering for indocyanine green
   angiography images
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1450
EP 1456
DI 10.1136/bjo-2023-324446
EA MAR 2024
DT Article
PD OCT 2024
PY 2024
AB Background Indocyanine green angiography (ICGA) is vital for diagnosing
   chorioretinal diseases, but its interpretation and patient communication
   require extensive expertise and time-consuming efforts. We aim to
   develop a bilingual ICGA report generation and question-answering (QA)
   system.
   Methods Our dataset comprised 213 129 ICGA images from 2919
   participants. The system comprised two stages: image-text alignment for
   report generation by a multimodal transformer architecture, and large
   language model (LLM)-based QA with ICGA text reports and human-input
   questions. Performance was assessed using both qualitative metrics
   (including Bilingual Evaluation Understudy (BLEU), Consensus-based Image
   Description Evaluation (CIDEr), Recall-Oriented Understudy for Gisting
   Evaluation-Longest Common Subsequence (ROUGE-L), Semantic Propositional
   Image Caption Evaluation (SPICE), accuracy, sensitivity, specificity,
   precision and F1 score) and subjective evaluation by three experienced
   ophthalmologists using 5-point scales (5 refers to high quality).
   Results We produced 8757 ICGA reports covering 39 disease-related
   conditions after bilingual translation (66.7% English, 33.3% Chinese).
   The ICGA-GPT model's report generation performance was evaluated with
   BLEU scores (1-4) of 0.48, 0.44, 0.40 and 0.37; CIDEr of 0.82; ROUGE of
   0.41 and SPICE of 0.18. For disease-based metrics, the average
   specificity, accuracy, precision, sensitivity and F1 score were 0.98,
   0.94, 0.70, 0.68 and 0.64, respectively. Assessing the quality of 50
   images (100 reports), three ophthalmologists achieved substantial
   agreement (kappa=0.723 for completeness, kappa=0.738 for accuracy),
   yielding scores from 3.20 to 3.55. In an interactive QA scenario
   involving 100 generated answers, the ophthalmologists provided scores of
   4.24, 4.22 and 4.10, displaying good consistency (kappa=0.779).
   Conclusion This pioneering study introduces the ICGA-GPT model for
   report generation and interactive QA for the first time, underscoring
   the potential of LLMs in assisting with automated ICGA image
   interpretation.
ZS 0
TC 10
ZB 3
ZR 0
Z8 0
ZA 0
Z9 10
DA 2024-03-30
UT WOS:001189002900001
PM 38508675
ER

PT J
AU Kerr, Wesley T.
   Mcfarlane, Katherine N.
   Pucci, Gabriela Figueiredo
   Carns, Danielle R.
   Israel, Alex
   Vighetti, Lianne
   Pennell, Page B.
   Stern, John M.
   Xia, Zongqi
   Wang, Yanshan
TI Supervised machine learning compared to large language models for
   identifying functional seizures from medical records
SO EPILEPSIA
VL 66
IS 4
BP 1155
EP 1164
DI 10.1111/epi.18272
EA FEB 2025
DT Article
PD APR 2025
PY 2025
AB Objective The Functional Seizures Likelihood Score (FSLS) is a
   supervised machine learning-based diagnostic score that was developed to
   differentiate functional seizures (FS) from epileptic seizures (ES). In
   contrast to this targeted approach, large language models (LLMs) can
   identify patterns in data for which they were not specifically trained.
   To evaluate the relative benefits of each approach, we compared the
   diagnostic performance of the FSLS to two LLMs: ChatGPT and GPT-4.
   Methods In total, 114 anonymized cases were constructed based on
   patients with documented FS, ES, mixed ES and FS, or physiologic
   seizure-like events (PSLEs). Text-based data were presented in three
   sequential prompts to the LLMs, showing the history of present illness
   (HPI), electroencephalography (EEG) results, and neuroimaging results.
   We compared the accuracy (number of correct predictions/number of cases)
   and area under the receiver-operating characteristic (ROC) curves (AUCs)
   of the LLMs to the FSLS using mixed-effects logistic regression. Results
   The accuracy of FSLS was 74% (95% confidence interval [CI] 65%-82%) and
   the AUC was 85% (95% CI 77%-92%). GPT-4 was superior to both the FSLS
   and ChatGPT (p <.001), with an accuracy of 85% (95% CI 77%-91%) and AUC
   of 87% (95% CI 79%-95%). Cohen's kappa between the FSLS and GPT-4 was
   40% (fair). The LLMs provided different predictions on different days
   when the same note was provided for 33% of patients, and the LLM's
   self-rated certainty was moderately correlated with this observed
   variability (Spearman's rho(2): 30% [fair, ChatGPT] and 63%
   [substantial, GPT-4]). Significance Both GPT-4 and the FSLS identified a
   substantial subset of patients with FS based on clinical history. The
   fair agreement in predictions highlights that the LLMs identified
   patients differently from the structured score. The inconsistency of the
   LLMs' predictions across days and incomplete insight into their own
   consistency was concerning. This comparison highlights both benefits and
   cautions about how machine learning and artificial intelligence could
   identify patients with FS in clinical practice.
ZB 0
TC 0
ZR 0
ZA 0
ZS 0
Z8 0
Z9 0
DA 2025-02-23
UT WOS:001423350000001
PM 39960122
ER

PT C
AU Basi, Abdul
   Hussain, Khizar
   Hanif, Muhammad Abdullah
   Shafique, Muhammad
GP IEEE
TI RoboMed: On-Premise Medical Assistance Leveraging Large Language Models
   in Robotics
SO 2024 18TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, ROBOTICS AND
   VISION, ICARCV
SE International Conference on Control Automation Robotics and Vision
BP 710
EP 717
DI 10.1109/ICARCV63323.2024.10821547
DT Proceedings Paper
PD 2024
PY 2024
AB Large language models (LLMs) are revolutionizing numerous domains with
   their remarkable natural language processing (NLP) capabilities,
   attracting significant interest and widespread adoption. However,
   deploying LLMs in resource-constrained environments, such as edge
   computing and robotics systems without server infrastructure, while also
   aiming to minimize latency, presents significant challenges. Another
   challenge lies in delivering medical assistance to remote areas with
   limited healthcare facilities and infrastructure. To address this, we
   introduce RoboMed, an on-premise healthcare robot that utilizes compact
   versions of large language models (tiny-LLMs) integrated with LangChain
   as its backbone. Moreover, it incorporates automatic speech recognition
   (ASR) models for user interface, enabling efficient, edge-based
   preliminary medical diagnostics and support. RoboMed employs model
   optimizations to achieve minimal memory footprint and reduced latency
   during inference on embedded edge devices. The training process
   optimization involves low-rank adaptation (LoRA), which reduces the
   model's complexity without significantly impacting its performance. For
   fine-tuning, the LLM is trained on a diverse medical dataset compiled
   from online health forums, clinical case studies, and a distilled
   medicine corpus. This fine-tuning process utilizes reinforcement
   learning from human feedback (RLHF) to further enhance its
   domain-specific capabilities. The system is deployed on Nvidia Jetson
   development board and achieves 78% accuracy in medical consultations and
   scores 56 in USMLE benchmark, enabling an resource-efficient healthcare
   assistance robot that alleviates privacy concerns due to edge-based
   deployment, thereby empowering the community.
CT 18th International Conference on Control Automation Robotics and Vision
CY DEC 12-15, 2024
CL U ARAB EMIRATES
ZA 0
ZB 0
ZS 0
Z8 0
TC 0
ZR 0
Z9 0
DA 2025-04-02
UT WOS:001435120000114
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

PT C
AU Niraula, Trishna
   Stubblefield, Jonathan
GP ACM
TI Using Large Language Models to Translate Machine Results to Human
   Results
SO 14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH
   INFORMATICS, BCB 2023
DI 10.1145/3584371.3613036
DT Proceedings Paper
PD 2023
PY 2023
AB Chest x-rays are among the most common diagnostic studies used in most
   both inpatient and outpatient settings, and they represent a significant
   portion of the workload for radiologists. Many different machine
   learning models have been developed for the analysis of chest x-rays,
   including models capable of detecting and labeling the location and type
   of pathological findings. In addition, large language models (LLMs) such
   as ChatGPT have also been growing in popularity and have proven to be
   effective at a variety of writing tasks [2]. For this project, we will
   attempt to use LLMs to translate machine learning results into
   automatically generated radiology reports. This would provide quick
   pre-reads of chest x-rays which can later be corrected or validated by
   radiologists in a similar workflow used by cardiologists when reading
   electrocardiograms (ECGs).
   To perform this task, we will make use of the Open-I dataset of chest
   x-rays with associated radiology reports [1]. Additionally, we will use
   a top performing model from the competition on the CheXpert dataset [3,
   4]. This dataset consists of multiple chest xrays with expert-annotated
   bounding boxes labeling pathological findings [3]. We will use the
   top-performing model to label the type and location of pathological
   findings in the Open-I dataset [4]. Following this, we will
   algorithmically transform the bounding boxes into simple descriptions of
   the type and location of the pathological finding (i.e., consolidation
   lower left quadrant, atelectasis upper right quadrant, cardiomegaly). We
   will then train a LLM to translate these simple descriptions into a full
   radiology report.
   To evaluate the efficacy of our method, we will present a mixture of
   expert written and automatically generated radiology reports to
   volunteers to assess if the generated reports. Volunteers will be
   selected from a variety of expertise levels and backgrounds in medicine,
   including non-medical laymen, medical students, and physicians.
   Volunteers will be asked to evaluate whether they can distinguish
   between automatically generated and expert written reports and if both
   reports adequately convey the relevant information from the associated
   chest x-ray.
   If the LLMs can use simple descriptors of machine learning results to
   produce radiology reports, this would significantly improve patient care
   and the workload for physicians. Patients and nonradiologist physicians
   would benefit from immediately available results following the
   acquisition of a chest x-ray. Radiologists will be able to overread the
   chest x-rays later, either verifying the AI-generated results or
   providing corrections, similar to the practice of Cardiologists with
   ECGs.
CT 14th ACM Conference on Bioinformatics, Computational Biology, and Health
   Informatics (ACM-BCB)
CY SEP 03-06, 2023
CL Houston, TX
SP Assoc Comp Machinery; ACM Special Interest Grp Bioinformat, Computat
   Biol, & Biomed Informat
ZS 0
ZA 0
Z8 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2024-03-19
UT WOS:001143941200096
ER

PT J
AU Alessandri-Bonetti, Mario
   Giorgino, Riccardo
   Naegeli, Michelle
   Liu, Hilary Y.
   Egro, Francesco M.
TI Assessing the Soft Tissue Infection Expertise of ChatGPT and Bard
   Compared to IDSA Recommendations
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 6
BP 1551
EP 1553
DI 10.1007/s10439-023-03372-1
EA OCT 2023
DT Letter
PD JUN 2024
PY 2024
AB The aim of the study was to evaluate whether ChatGPT-3.5 and Bard
   provide safe and reliable medical answers to common topics related to
   soft tissue infections and their management according to the guidelines
   provided by the Infectious Disease Society of America (IDSA). IDSA's
   abridged recommendations for soft tissue infections were identified on
   the IDSA official website. Twenty-five queries were entered into the
   LLMs as they appear on the IDSA website. To assess the concordance and
   precision of the LLMs' responses with the IDSA guidelines, two
   infectious disease physicians independently compared and evaluated each
   response. This was done using a 5-point Likert scale, with 1
   representing poor concordance and 5 excellent concordance, as adapted
   from the validated Global Quality Scale. The mean +/- SD score for
   ChatGPT-generated responses was 4.34 +/- 0.74, n = 25. This indicates
   that raters found the answers were good to excellent quality with the
   most important topics covered. Although some topics were not covered,
   the answers were in good concordance with the IDSA guidelines. The mean
   +/- SD score for Bard-generate responses was 3.5 +/- 1.2, n = 25,
   indicating moderate quality. Despite LLMs did not appear to provide
   wrong recommendations and covered most of the topics, the responses were
   often found to be generic, rambling, missing some details, and lacking
   actionability. As AI continues to evolve and researchers feed it with
   more extensive and diverse medical knowledge, it may be inching closer
   to becoming a reliable aid for clinicians, ultimately enhancing the
   accuracy of infectious disease diagnosis and management in the future.
ZR 0
ZS 0
TC 6
ZB 1
ZA 0
Z8 0
Z9 6
DA 2023-11-09
UT WOS:001089653400001
PM 37865615
ER

PT J
AU Amacher, Simon A.
   Baumann, Sira M.
   Berger, Sebastian
   Arpagaus, Armon
   Egli, Simon B.
   Grzonka, Pascale
   Kliem, Paulina S. C.
   Hunziker, Sabina
   Fisch, Urs
   Gebhard, Caroline E.
   Sutter, Raoul
TI Can the large language model ChatGPT-4omni predict outcomes in adult
   patients with status epilepticus?
SO EPILEPSIA
VL 66
IS 3
BP 674
EP 685
DI 10.1111/epi.18215
EA DEC 2024
DT Article
PD MAR 2025
PY 2025
AB ObjectiveLarge language models (LLMs) have recently gained attention for
   clinical decision-making and diagnosis. This study evaluates the
   performance of the recently updated LLM (ChatGPT-4o) in predicting
   clinical outcomes in patients with status epilepticus and compares its
   prognostic performance to the Status Epilepticus Severity Score
   (STESS).MethodsThis retrospective single-center cohort study was
   performed at the University Hospital Basel (tertiary academic medical
   center) from January 2005 to December 2022. It included consecutive
   adult patients (>= 18 years of age) with a diagnosis of status
   epilepticus. The primary outcome was survival at hospital discharge, and
   the secondary outcome was return to premorbid neurological function at
   hospital discharge. The performance characteristics of ChatGPT4-o
   (sensitivity, specificity, Youden Index) were evaluated and compared to
   those of the STESS.ResultsOf 760 patients, 689 patients (90.7%) survived
   to discharge, and 317 survivors (41.7%) regained their premorbid
   neurological function at discharge. ChatGPT-4o predicted survival in 567
   of 760 patients (74.6%), of which 45 died. ChatGPT-4o predicted death in
   193 of 760 patients (25.4%), of which 167 survived, resulting in a
   sensitivity of 75.8% and a specificity of 36.6% (Youden Index 0.12, 95%
   confidence interval [CI] 0-.28) for predicting survival. ChatGPT-4o
   predicted return to premorbid neurologic function in 249 of 760 patients
   (32.8%), of which 112 did not return to their premorbid neurological
   function. ChatGPT-4o predicted no return to premorbid function in 511 of
   760 patients (67.2%), of which 180 returned to their premorbid function,
   resulting in a sensitivity of 43.2% and a specificity of 74.7% (Youden
   Index .12, 95% CI .08-.28) for predicting return to premorbid
   neurological function. There was no difference in the prognostic
   performance of ChatGPT-4o and the STESS. A second round of prompting did
   not increase the predictive performance of ChatGPT-4o.ResultsOf 760
   patients, 689 patients (90.7%) survived to discharge, and 317 survivors
   (41.7%) regained their premorbid neurological function at discharge.
   ChatGPT-4o predicted survival in 567 of 760 patients (74.6%), of which
   45 died. ChatGPT-4o predicted death in 193 of 760 patients (25.4%), of
   which 167 survived, resulting in a sensitivity of 75.8% and a
   specificity of 36.6% (Youden Index 0.12, 95% confidence interval [CI]
   0-.28) for predicting survival. ChatGPT-4o predicted return to premorbid
   neurologic function in 249 of 760 patients (32.8%), of which 112 did not
   return to their premorbid neurological function. ChatGPT-4o predicted no
   return to premorbid function in 511 of 760 patients (67.2%), of which
   180 returned to their premorbid function, resulting in a sensitivity of
   43.2% and a specificity of 74.7% (Youden Index .12, 95% CI .08-.28) for
   predicting return to premorbid neurological function. There was no
   difference in the prognostic performance of ChatGPT-4o and the STESS. A
   second round of prompting did not increase the predictive performance of
   ChatGPT-4o.ResultsOf 760 patients, 689 patients (90.7%) survived to
   discharge, and 317 survivors (41.7%) regained their premorbid
   neurological function at discharge. ChatGPT-4o predicted survival in 567
   of 760 patients (74.6%), of which 45 died. ChatGPT-4o predicted death in
   193 of 760 patients (25.4%), of which 167 survived, resulting in a
   sensitivity of 75.8% and a specificity of 36.6% (Youden Index 0.12, 95%
   confidence interval [CI] 0-.28) for predicting survival.
   ChatGPT-4o predicted return to premorbid neurologic function in 249 of
   760 patients (32.8%), of which 112 did not return to their premorbid
   neurological function. ChatGPT-4o predicted no return to premorbid
   function in 511 of 760 patients (67.2%), of which 180 returned to their
   premorbid function, resulting in a sensitivity of 43.2% and a
   specificity of 74.7% (Youden Index .12, 95% CI .08-.28) for predicting
   return to premorbid neurological function. There was no difference in
   the prognostic performance of ChatGPT-4o and the STESS. A second round
   of prompting did not increase the predictive performance of
   ChatGPT-4o.SignificanceChatGPT-4o unreliably predicts outcomes in
   patients with status epilepticus. Clinicians should refrain from using
   ChatGPT-4o for prognostication in these patients.
ZB 0
ZR 0
TC 0
ZA 0
Z8 0
ZS 0
Z9 0
DA 2024-12-30
UT WOS:001383243100001
PM 39723845
ER

PT J
AU Hong, Soonwook
   Zheng, Henry W.
   Pace, Jordan L.
   Makar, Christian
   Eghbali, Mason
   Limketkai, Berkeley
TI RAPID AND ACCURATE EVALUATION OF DRUG-INDUCED LIVER INJURY CASES WITH A
   CONTEXT-AUGMENTED LARGE LANGUAGE MODEL
SO GASTROENTEROLOGY
VL 166
IS 5
MA Tu2018
BP S1494
EP S1495
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
DA 2024-10-30
UT WOS:001282837706116
ER

PT J
AU Anvari, Sama
   Lee, Yung
   Jin, David S.
   Malone, Sarah
   Collins, Matthew
TI AI IN HEPATOLOGY: A COMPARATIVE ANALYSIS OF CHATGPT-4, BING, AND BARD AT
   ANSWERING CLINICAL QUESTIONS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1976
BP S888
EP S888
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
TC 0
ZR 0
ZS 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2024-10-30
UT WOS:001282837703477
ER

PT J
AU Durmaz, Arda
   Gurnari, Carmelo
   Pagliuca, Simona
   Hercus, Colin
   Bravo-Perez, Carlos
   Guarnera, Luca
   Williams, Nakisha D.
   Dima, Danai
   Nautiyal, Ishani
   Kubota, Yasuo
   Kawashima, Naomi
   Scott, Jacob
   Visconte, Valeria
   Maciejewski, Jaroslaw P.
TI Reverse Engineering of Antigenic Peptides in LGL to Decipher Disease
   Triggers
SO BLOOD
VL 142
DI 10.1182/blood-2023-190381
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
TC 0
Z8 0
ZS 0
ZB 0
ZR 0
ZA 0
Z9 0
DA 2024-02-29
UT WOS:001159306701003
ER

PT J
AU Guo, Edward
   Gupta, Mehul
   Sinha, Sarthak
   Roessler, Karl
   Tatagiba, Marcos
   Akagami, Ryojo
   Al-Mefty, Ossama
   Sugiyama, Taku
   Stieg, Philip E.
   Pickett, Gwynedd E.
   de Lotbiniere-Bassett, Madeleine
   Singh, Rahul
   Lama, Sanju
   Sutherland, Garnette R.
TI neuroGPT-X: toward a clinic-ready large language model
SO JOURNAL OF NEUROSURGERY
VL 140
IS 4
BP 1041
EP 1053
DT Article
PD APR 2024
PY 2024
AB OBJECTIVE The objective was to assess the performance of a
   context-enriched large language model (LLM) compared with international
   neurosurgical experts on questions related to the management of
   vestibular schwannoma. Furthermore, another objective was to develop a
   chat-based platform incorporating in-text citations, references, and
   memory to enable accurate, relevant, and reliable information in real
   time. METHODS The analysis involved 1) creating a data set through web
   scraping, 2) developing a chat-based platform called neuroGPT-X, 3)
   enlisting 8 expert neurosurgeons across international centers to
   independently create questions (n = 1) and to answer (n = 4) and
   evaluate responses (n = 3) while blinded, and 4) analyzing the
   evaluation results on the management of vestibular schwannoma. In the
   blinded phase, all answers were assessed for accuracy, coherence,
   relevance, thoroughness, speed, and overall rating. All experts were
   unblinded and provided their thoughts on the utility and limitations of
   the tool. In the unblinded phase, all neurosurgeons provided answers to
   a Likert scale survey and longanswer questions regarding the clinical
   utility, likelihood of use, and limitations of the tool. The tool was
   then evaluated on the basis of a set of 103 consensus statements on
   vestibular schwannoma care from the 8th Quadrennial International
   Conference on Vestibular Schwannoma. RESULTS Responses from the naive
   and context-enriched Generative Pretrained Transformer (GPT) models were
   consistently rated not significantly different in terms of accuracy,
   coherence, relevance, thoroughness, and overall performance, and they
   were often rated significantly higher than expert responses. Both the
   naive and content-enriched GPT models provided faster responses to the
   standardized question set than expert neurosurgeon respondents (p <
   0.01). The context-enriched GPT model agreed with 98 of the 103 (95%)
   consensus statements. Of interest, all expert surgeons expressed
   concerns about the reliability of GPT in accurately addressing the
   nuances and controversies surrounding the management of vestibular
   schwannoma. Furthermore, the authors developed neuroGPT-X, a chat-based
   platform designed to provide point-of-care clinical support and mitigate
   the limitations of human memory. neuroGPT-X incorporates features such
   as in-text citations and references to enable accurate, relevant, and
   reliable information in real time. CONCLUSIONS The present study, with
   its subspecialist-level performance in generating written responses to
   complex neurosurgical problems for which evidence-based consensus for
   management is lacking, suggests that context-enriched LLMs show promise
   as a point-of-care medical resource. The authors anticipate that this
   work will be a springboard for expansion into more medical specialties,
   incorporating evidence-based clinical information and developing
   expert-level dialogue surrounding LLMs in healthcare.
ZB 2
ZS 0
Z8 1
ZR 0
TC 10
ZA 0
Z9 11
DA 2024-06-30
UT WOS:001251735100004
PM 38564804
ER

PT J
AU Amini, Maziar
   Chang, Patrick
   Nguyen, Denis
   Davis, Rio O.
   Dodge, Jennifer
   Phan, Jennifer
   Buxbaum, James L.
   Sahakian, Ara B.
TI COMPARING CHATGPT3.5 AND BARD IN RECOMMENDING COLONOSCOPY INTERVALS:
   BRIDGING THE GAP IN HEALTHCARE SETTINGS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Tu1991
BP S1482
EP S1482
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2024-10-30
UT WOS:001282837706089
ER

PT J
AU Rahman, Md Mushfiqur
   Irbaz, Mohammad Sabik
   North, Kai
   Williams, Michelle S.
   Zampieri, Marcos
   Lybarger, Kevin
TI Health text simplification: An annotated corpus for digestive cancer
   education and novel strategies for reinforcement learning
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 158
AR 104727
DI 10.1016/j.jbi.2024.104727
EA SEP 2024
DT Article
PD OCT 2024
PY 2024
AB Objective: The reading level of health educational materials
   significantly influences the understandability and accessibility of the
   information, particularly for minoritized populations. Many patient
   educational resources surpass widely accepted standards for reading
   level and complexity. There is a critical need for high-performing text
   simplification models for health information to enhance dissemination
   and literacy. This need is particularly acute in cancer education, where
   effective prevention and screening education can substantially reduce
   morbidity and mortality. Methods: We introduce Simplified Digestive
   Cancer (SimpleDC), a parallel corpus of cancer education materials
   tailored for health text simplification research, comprising educational
   content from the American Cancer Society, Centers for Disease Control
   and Prevention, and National Cancer Institute. The corpus includes 31
   web pages with the corresponding manually simplified versions. It
   consists of 1183 annotated sentence pairs (361 train, 294 development,
   and 528 test). Utilizing SimpleDC and the existing Med-EASi corpus, we
   explore Large Language Model (LLM)-based simplification methods,
   including fine-tuning, reinforcement learning (RL), reinforcement
   learning with human feedback (RLHF), domain adaptation, and prompt-based
   approaches. Our experimentation encompasses Llama 2, Llama 3, and GPT-4.
   We introduce a novel RLHF reward function featuring a lightweight model
   adept at distinguishing between original and simplified texts when
   enables training on unlabeled data. Results: Fine-tuned Llama models
   demonstrated high performance across various metrics. Our RLHF reward
   function outperformed existing RL text simplification reward functions.
   The results underscore that RL/RLHF can achieve performance comparable
   to fine-tuning and improve the performance of fine-tuned models.
   Additionally, these methods effectively adapt out-of-domain text
   simplification models to a target domain. The best-performing
   RL-enhanced Llama models outperformed GPT-4 in both automatic metrics
   and manual evaluation by subject matter experts. Conclusion: The newly
   developed SimpleDC corpus will serve as a valuable asset to the research
   community, particularly in patient education simplification. The RL/RLHF
   methodologies presented herein enable effective training of
   simplification models on unlabeled text and the utilization of
   out-of-domain simplification corpora.
ZR 0
Z8 0
TC 2
ZS 0
ZB 0
ZA 0
Z9 2
DA 2024-09-29
UT WOS:001318940100001
PM 39293643
ER

PT J
AU Schwieger, Arne
   Angst, Katrin
   de Bardeci, Mateo
   Burrer, Achim
   Cathomas, Flurin
   Ferrea, Stefano
   Gratz, Franziska
   Knorr, Marius
   Kronenberg, Golo
   Spiller, Tobias
   Troi, David
   Seifritz, Erich
   Weber, Samantha
   Olbrich, Sebastian
TI Large language models can support generation of standardized discharge
   summaries - A retrospective study utilizing ChatGPT-4 and electronic
   health records
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 192
AR 105654
DI 10.1016/j.ijmedinf.2024.105654
EA OCT 2024
DT Article
PD DEC 2024
PY 2024
AB Objective: To evaluate whether psychiatric discharge summaries (DS)
   generated with ChatGPT-4 from electronic health records (EHR) can match
   the quality of DS written by psychiatric residents. Methods: At a
   psychiatric primary care hospital, we compared 20 inpatient DS, written
   by residents, to those written with ChatGPT-4 from pseudonymized
   residents' notes of the patients' EHRs and a standardized prompt. 8
   blinded psychiatry specialists rated both versions on a custom Likert
   scale from 1 to 5 across 15 quality subcategories. The primary outcome
   was the overall rating difference between the two groups. The secondary
   outcomes were the rating differences at the level of individual
   question, case, and rater. Results: Human-written DS were rated
   significantly higher than AI (mean ratings: human 3.78, AI 3.12, p <
   0.05). They surpassed AI significantly in 12/15 questions and 16/20
   cases and were favored significantly by 7/8 raters. For "low expected
   correction effort", human DS were rated as 67 % favorable, 19 % neutral,
   and 14 % unfavorable, whereas AI-DS were rated as 22 % favorable, 33 %
   neutral, and 45 % unfavorable. Hallucinations were present in 40 % of
   AI-DS, with 37.5 % deemed highly clinically relevant. Minor content
   mistakes were found in 30 % of AI and 10 % of human DS. Raters correctly
   identified AI-DS with 81 % sensitivity and 75 % specificity. Discussion:
   Overall, AI-DS did not match the quality of resident-written DS but
   performed similarly in 20% of cases and were rated as favorable for "low
   expected correction effort" in 22% of cases. AI-DS lacked most in
   content specificity, ability to distill key case information, and
   coherence but performed adequately in conciseness, adherence to
   formalities, relevance of included content, and form. Conclusion:
   LLM-written DS show potential as templates for physicians to finalize,
   potentially saving time in the future.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 1
TC 5
Z9 5
DA 2024-11-07
UT WOS:001343302900001
PM 39437512
ER

PT J
AU Ghalibafan, Seyyedehfatemeh
   Gonzalez, David J. Taylor
   Cai, Louis Z.
   Chou, Brandon Graham
   Panneerselvam, Sugi
   Barrett, Spencer Conrad
   Djulbegovic, Mak B.
   Yannuzzi, Nicolas A.
TI APPLICATIONS OF MULTIMODAL GENERATIVE ARTIFICIAL INTELLIGENCE IN A
   REAL-WORLD RETINA CLINIC SETTING
SO RETINA-THE JOURNAL OF RETINAL AND VITREOUS DISEASES
VL 44
IS 10
BP 1732
EP 1740
DI 10.1097/IAE.0000000000004204
DT Article
PD OCT 2024
PY 2024
AB Supplemental Digital Content is Available in the Text.Generative
   Pre-trained Transformer 4 with vision aids clinical care and medical
   record keeping using standardized multiple-choice questions. Its
   effectiveness in complex, open-ended medical scenarios, especially in
   retina clinics, is limited, highlighting constraints in offering ocular
   health advice.
   Purpose:This study evaluates a large language model, Generative
   Pre-trained Transformer 4 with vision, for diagnosing vitreoretinal
   diseases in real-world ophthalmology settings.Methods:A retrospective
   cross-sectional study at Bascom Palmer Eye Clinic, analyzing patient
   data from January 2010 to March 2023, assesses Generative Pre-trained
   Transformer 4 with vision's performance on retinal image analysis and
   International Classification of Diseases 10th revision coding across 2
   patient groups: simpler cases (Group A) and complex cases (Group B)
   requiring more in-depth analysis. Diagnostic accuracy was assessed
   through open-ended questions and multiple-choice questions independently
   verified by three retina specialists.Results:In 256 eyes from 143
   patients, Generative Pre-trained Transformer 4-V demonstrated a 13.7%
   accuracy for open-ended questions and 31.3% for multiple-choice
   questions, with International Classification of Diseases 10th revision
   code accuracies at 5.5% and 31.3%, respectively. Accurately diagnosed
   posterior vitreous detachment, nonexudative age-related macular
   degeneration, and retinal detachment. International Classification of
   Diseases 10th revision coding was most accurate for nonexudative
   age-related macular degeneration, central retinal vein occlusion, and
   macular hole in OEQs, and for posterior vitreous detachment,
   nonexudative age-related macular degeneration, and retinal detachment in
   multiple-choice questions. No significant difference in diagnostic or
   coding accuracy was found in Groups A and B.Conclusion:Generative
   Pre-trained Transformer 4 with vision has potential in clinical care and
   record keeping, particularly with standardized questions. Its
   effectiveness in open-ended scenarios is limited, indicating a
   significant limitation in providing complex medical advice.
Z8 0
TC 3
ZR 0
ZA 0
ZB 0
ZS 0
Z9 3
DA 2024-10-23
UT WOS:001334163300013
PM 39287535
ER

PT J
AU Giannuzzi, Federico
   Carla, Matteo Mario
   Hu, Lorenzo
   Cestrone, Valentina
   Caputo, Carmela Grazia
   Sammarco, Maria Grazia
   Savino, Gustavo
   Rizzo, Stanislao
   Blasi, Maria Antonietta
   Pagliara, Monica Maria
TI Artificial intelligence with ChatGPT 4: a large language model in
   support of ocular oncology cases
SO INTERNATIONAL OPHTHALMOLOGY
VL 45
IS 1
AR 59
DI 10.1007/s10792-024-03399-w
DT Article
PD FEB 7 2025
PY 2025
AB PurposeTo evaluate ChatGPT's ability to analyze comprehensive case
   descriptions of patients with uveal melanoma and provide recommendations
   for the most appropriate management.DesignRetrospective analysis of
   ocular oncology patients' medical records.Subjects.Forty patients
   treated for uveal melanoma between May 2019 and October
   2023.DesignRetrospective analysis of ocular oncology patients' medical
   records.Subjects.Forty patients treated for uveal melanoma between May
   2019 and October 2023.DesignRetrospective analysis of ocular oncology
   patients' medical records.Subjects.Forty patients treated for uveal
   melanoma between May 2019 and October 2023.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.MethodsWe uploaded each case description into the ChatGPT
   interface (version 4.0) and asked the model to provide realistic
   treatment options by asking the question, "What type of treatment do you
   recommend?" The accuracy of decisions produced by ChatGPT was compared
   to those recorded in patients' files and the treatment recommendations
   provided by three ocular oncologists, each with more than 10 years of
   experience.Main outcome measures.The primary objective of this research
   was to assess the accuracy of ChatGPT replies in ocular oncology cases,
   analyzing its competence in both straightforward and intricate
   situations. Our secondary purpose was to assess the concordance between
   the responses of ChatGPT and those of ocular oncology specialists when
   faced with analogous clinical scenarios.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.ResultsChatGPT's surgical choices matched those in patients'
   files in 55% of cases (22 out of 40). ChatGPT options were agreed upon
   by 50%, 55%, and 57% of the three ocular oncology specialists. The
   investigation revealed significant differences between ChatGPT's
   responses and those of the three cancer specialists when compared to
   patients' files (p = 0.003, p = 0.001, and p = 0.001). ChatGPT's
   surgical responses matched with patient data in 18 out of 24 cases
   (75%), excluding enucleation cases.
   The decisions matched with the three ocular oncology specialists in
   17/24, 18/24, and 18/24 cases, reflecting agreements of 70%, 75%, and
   75%, respectively. The decisions made by ChatGPT were not significantly
   different from those of the three professionals in this cohort (p =
   0.50, p = 0.36, and p = 0.36 for ChatGPT compared to specialists 1, 2,
   and 3).ConclusionChatGPT exhibited a level of proficiency that was
   comparable to that of trained ocular oncology specialists. However, it
   exhibited its limitations when evaluating more complex scenarios, such
   as extrascleral extension or infiltration of the optic nerve, when a
   comprehensive evaluation of the patient is therefore necessary.
ZS 0
Z8 0
ZB 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-04-25
UT WOS:001468330700001
PM 39918656
ER

EF