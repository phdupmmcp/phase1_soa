FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Phillipi, M.
   Cho, H.
   Meraz, J.
   Shu, G.
   Lontoc, J.
   Sun, S.
   Glavis-Bloom, J.
   Houshyar, R.
TI Employing Large Language Models to Assess Physician Rationale for
   Bypassing Clinical Decision Support System Alerts
SO JOURNAL OF INVESTIGATIVE MEDICINE
VL 73
IS 1
MA 594
BP 678
EP 678
DT Meeting Abstract
PD JAN 2025
PY 2025
CT Western Medical Research Conference
CY JAN 16-18, 2025
CL Carmel, CA
ZB 0
TC 0
ZA 0
ZS 0
ZR 0
Z8 0
Z9 0
DA 2025-03-12
UT WOS:001430200800595
ER

PT J
AU Roustan, Dimitri
   Bastardot, Francois
TI The Clinicians' Guide to Large Language Models: A General Perspective
   With a Focus on Hallucinations
SO INTERACTIVE JOURNAL OF MEDICAL RESEARCH
VL 14
AR e59823
DI 10.2196/59823
DT Article
PD 2025
PY 2025
AB Large language models (LLMs) are artificial intelligence tools that have
   the prospect of profoundly changing how we practice all aspects of
   medicine. Considering the incredible potential of LLMs in medicine and
   the interest of many health care stakeholders for implementation into
   routine practice, it is therefore essential that clinicians be aware of
   the basic risks associated with the use of these models. Namely, a
   significant risk associated with the use of LLMs is their potential to
   create hallucinations. Hallucinations (false information) generated by
   LLMs arise from a multitude of causes, including both factors related to
   the training dataset as well as their auto-regressive nature. The
   implications for clinical practice range from the generation of
   inaccurate diagnostic and therapeutic information to the reinforcement
   of flawed diagnostic reasoning pathways, as well as a lack of
   reliability if not used properly. To reduce this risk, we developed a
   general technical framework for approaching LLMs in general clinical
   practice, as well as for implementation on a larger institutional scale.
ZB 0
ZS 0
Z8 0
ZA 0
TC 0
ZR 0
Z9 0
DA 2025-02-14
UT WOS:001415529800001
PM 39874574
ER

PT J
AU Griot, Maxime
   Hemptinne, Coralie
   Vanderdonckt, Jean
   Yuksel, Demet
TI Large Language Models lack essential metacognition for reliable medical
   reasoning
SO NATURE COMMUNICATIONS
VL 16
IS 1
AR 642
DI 10.1038/s41467-024-55628-6
DT Article
PD JAN 14 2025
PY 2025
AB Large Language Models have demonstrated expert-level accuracy on medical
   board examinations, suggesting potential for clinical decision support
   systems. However, their metacognitive abilities, crucial for medical
   decision-making, remain largely unexplored. To address this gap, we
   developed MetaMedQA, a benchmark incorporating confidence scores and
   metacognitive tasks into multiple-choice medical questions. We evaluated
   twelve models on dimensions including confidence-based accuracy, missing
   answer recall, and unknown recall. Despite high accuracy on
   multiple-choice questions, our study revealed significant metacognitive
   deficiencies across all tested models. Models consistently failed to
   recognize their knowledge limitations and provided confident answers
   even when correct options were absent. In this work, we show that
   current models exhibit a critical disconnect between perceived and
   actual capabilities in medical reasoning, posing significant risks in
   clinical settings. Our findings emphasize the need for more robust
   evaluation frameworks that incorporate metacognitive abilities,
   essential for developing reliable Large Language Model enhanced clinical
   decision support systems.
ZR 0
Z8 0
TC 4
ZS 0
ZA 0
ZB 0
Z9 4
DA 2025-01-23
UT WOS:001397956900017
PM 39809759
ER

PT J
AU Cabral, Stephanie
   Restrepo, Daniel
   Kanjee, Zahir
   Wilson, Philip
   Crowe, Byron
   Abdulnour, Raja-Elie
   Rodman, Adam
TI Clinical Reasoning of a Generative Artificial Intelligence Model
   Compared With Physicians
SO JAMA INTERNAL MEDICINE
VL 184
IS 5
BP 581
EP 583
DI 10.1001/jamainternmed.2024.0295
EA MAY 2024
DT Letter
PD MAY 2024
PY 2024
AB This cross-sectional study assesses the ability of a large language
   model to process medical data and display clinical reasoning compared
   with the ability of attending physicians and residents.
ZA 0
ZB 4
Z8 2
ZS 0
ZR 0
TC 42
Z9 42
DA 2024-04-12
UT WOS:001197554900001
PM 38557971
ER

PT J
AU Kainz, Jakob
   Seisl, Philipp
   Grob, Moritz
   Hauptfeld, Leonhard
   Wahringer, Jonas
   Rappelsberger, Andrea
   Adlassnig, Klaus-Peter
TI Fine-Tuning an Existing Large Language Model with Knowledge from the
   Medical Expert System Hepaxpert.
SO Studies in health technology and informatics
VL 327
BP 143
EP 147
DI 10.3233/SHTI250290
DT Journal Article
PD 2025-May-15
PY 2025
AB The analysis and individual interpretation of hepatitis serology test
   results is a complex task in laboratory medicine, requiring either
   experienced physicians or specialized expert systems. This study
   explores fine-tuning a large language model (LLM) for hepatitis serology
   interpretation using a single graphics processing unit (GPU). A custom
   dataset based on the Hepaxpert expert system was used to train the LLM.
   Fine-tuning was performed on an Nvidia RTX 6000 Ada GPU via torchtune.
   The fine-tuned LLM showed significant performance improvements over the
   base model when compared to Hepaxpert using the METEOR algorithm. The
   findings highlight the potential of LLMs in enhancing medical expert
   systems as well as the significance of domain-specific fine-tuning.
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
ZA 0
Z9 0
DA 2025-05-20
UT MEDLINE:40380402
PM 40380402
ER

PT C
AU Mensah, Paulina Boadiwaa
   Quao, Nana Serwaa
   Dagadu, Sesinam
   Mensah, James Kwabena
   Darkwah, Jude Domfeh
CA Project Genie Clinician Evaluation
GP IEEE COMPUTER SOC
TI All You Need Is Context: Clinician Evaluations of various iterations of
   a Large Language Model-Based First Aid Decision Support Tool in Ghana
SO 2024 IEEE 12TH INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS, ICHI
   2024
SE IEEE International Conference on Healthcare Informatics
BP 580
EP 585
DI 10.1109/ICHI61247.2024.00093
DT Proceedings Paper
PD 2024
PY 2024
AB As advancements in research and development expand the capabilities of
   Large Language Models (LLMs), there is a growing focus on their
   applications within the healthcare sector, driven by the large volume of
   data generated in healthcare. There are a few medicine-oriented
   evaluation datasets and benchmarks for assessing the performance of
   various LLMs in clinical scenarios; however, there is a paucity of
   information on the real-world usefulness of LLMs in context-specific
   scenarios in resource-constrained settings. In this work, 5 iterations
   of a decision support tool for medical emergencies using 5 distinct
   generalized LLMs were constructed, alongside a combination of Prompt
   Engineering and Retrieval Augmented Generation techniques. 50 responses
   were generated from the LLMs. Quantitative and qualitative evaluations
   of the LLM responses were provided by 13 physicians (general
   practitioners) with an average of 3 years of practice experience
   managing medical emergencies in resource-constrained settings in Ghana.
   Machine evaluations of the LLM responses were also computed and compared
   with the expert evaluations.
CT 12th IEEE International Conference on Healthcare Informatics (IEEE-ICHI)
CY JUN 03-06, 2024
CL Orlando, FL
SP IEEE; IEEE Comp Soc Tech Community Intelligent Informat; Univ Minnesota,
   Div Computat Hlth Sci; Weill Cornell Med Inst Artificial Intelligence &
   Digital Hlth; Univ Florida Hlth; Yale Univ, Sch Med; Springer; Florida
   State Univ, Coll Commun & Informat
ZB 0
TC 0
ZA 0
ZS 0
Z8 0
ZR 0
Z9 0
DA 2024-11-02
UT WOS:001304501700086
ER

PT J
AU Liao, Zhiqiang
   Wang, Jian
   Shi, Zhuozheng
   Lu, Lintao
   Tabata, Hitoshi
TI Revolutionary Potential of ChatGPT in Constructing Intelligent Clinical
   Decision Support Systems
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 2
BP 125
EP 129
DI 10.1007/s10439-023-03288-w
EA JUN 2023
DT Letter
PD FEB 2024
PY 2024
AB Recently, Chatbot Generative Pre-trained Transformer (ChatGPT) is
   recognized as a promising clinical decision support system (CDSS) in the
   medical field owing to its advanced text analysis capabilities and
   interactive design. However, ChatGPT primarily focuses on learning text
   semantics rather than learning complex data structures and conducting
   real-time data analysis, which typically necessitate the development of
   intelligent CDSS employing specialized machine learning algorithms.
   Although ChatGPT cannot directly execute specific algorithms, it aids in
   algorithm design for intelligent CDSS at the textual level. In this
   study, besides discussing the types of CDSS and their relationship with
   ChatGPT, we mainly investigate the benefits and drawbacks of employing
   ChatGPT as an auxiliary design tool for intelligent CDSS. Our findings
   indicate that by collaborating with human expertise, ChatGPT has the
   potential to revolutionize the development of robust and effective
   intelligent CDSS.
ZR 0
ZS 0
ZB 4
Z8 0
TC 23
ZA 0
Z9 23
DA 2023-07-23
UT WOS:001013401100001
PM 37332008
ER

PT J
AU Shah, Krish
   Xu, Andrew Y.
   Sharma, Yatharth
   Daher, Mohammed
   Mcdonald, Christopher
   Diebo, Bassel G.
   Daniels, Alan H.
TI Large Language Model Prompting Techniques for Advancement in Clinical
   Medicine
SO JOURNAL OF CLINICAL MEDICINE
VL 13
IS 17
AR 5101
DI 10.3390/jcm13175101
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs have the potential to revolutionize clinical
   medicine by enhancing healthcare access, diagnosis, surgical planning,
   and education. However, their utilization requires careful, prompt
   engineering to mitigate challenges like hallucinations and biases.
   Proper utilization of LLMs involves understanding foundational concepts
   such as tokenization, embeddings, and attention mechanisms, alongside
   strategic prompting techniques to ensure accurate outputs. For
   innovative healthcare solutions, it is essential to maintain ongoing
   collaboration between AI technology and medical professionals. Ethical
   considerations, including data security and bias mitigation, are
   critical to their application. By leveraging LLMs as supplementary
   resources in research and education, we can enhance learning and support
   knowledge-based inquiries, ultimately advancing the quality and
   accessibility of medical care. Continued research and development are
   necessary to fully realize the potential of LLMs in transforming
   healthcare.
ZB 1
ZS 0
Z8 0
TC 9
ZA 0
ZR 0
Z9 9
DA 2024-09-21
UT WOS:001311343800001
PM 39274316
ER

PT J
AU Takahashi, Ippei
   Obara, Taku
   Kuriyama, Shinichi
TI An Overarching Framework for the Ethics of Artificial Intelligence in
   Pediatrics
SO JAMA PEDIATRICS
VL 178
IS 3
BP 213
EP 214
DI 10.1001/jamapediatrics.2023.5761.
EA MAR 2024
DT Editorial Material
PD MAR 2024
PY 2024
ZR 0
ZS 0
ZB 2
ZA 0
Z8 0
TC 6
Z9 6
DA 2024-11-07
UT WOS:001136984300001
PM 38165711
ER

PT J
AU Hamed, Ehab
   Sharif, Anna
   Eid, Ahmad
   Alfehaidi, Alanoud
   Alberry, Medhat
TI Advancing Artificial Intelligence for Clinical Knowledge Retrieval: A
   Case Study Using ChatGPT-4 and Link Retrieval Plug-In to Analyze
   Diabetic Ketoacidosis Guidelines
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 15
IS 7
AR e41916
DI 10.7759/cureus.41916
DT Article
PD JUL 15 2023
PY 2023
AB Introduction This case study aimed to enhance the traceability and
   retrieval accuracy of ChatGPT-4 in medical text by employing a
   step-by-step systematic approach. The focus was on retrieving clinical
   answers from three international guidelines on diabetic ketoacidosis
   (DKA). Methods A systematic methodology was developed to guide the
   retrieval process. One question was asked per guideline to ensure
   accuracy and maintain referencing. ChatGPT-4 was utilized to retrieve
   answers, and the 'Link Reader' plug-in was integrated to facilitate
   direct access to webpages containing the guidelines. Subsequently,
   ChatGPT-4 was employed to compile answers while providing citations to
   the sources. This process was iterated 30 times per question to ensure
   consistency. In this report, we present our observations regarding the
   retrieval accuracy, consistency of responses, and the challenges
   encountered during the process. Results Integrating ChatGPT-4 with the
   'Link Reader' plug-in demonstrated notable traceability and retrieval
   accuracy benefits. The AI model successfully provided relevant and
   accurate clinical answers based on the analyzed guidelines. Despite
   occasional challenges with webpage access and minor memory drift, the
   overall performance of the integrated system was promising. The
   compilation of the answers was also impressive and held significant
   promise for further trials. Conclusion The findings of this case study
   contribute to the utilization of AI text-generation models as valuable
   tools for medical professionals and researchers. The systematic approach
   employed in this case study and the integration of the 'Link Reader'
   plug-in offer a framework for automating medical text synthesis, asking
   one question at a time before compilation from different sources, which
   has led to improving AI models' traceability and retrieval accuracy.
   Further advancements and refinement of AI models and integration with
   other software utilities hold promise for enhancing the utility and
   applicability of AI-generated recommendations in medicine and scientific
   academia. These advancements have the potential to drive significant
   improvements in everyday medical practice.
Z8 0
TC 9
ZA 0
ZB 2
ZR 0
ZS 0
Z9 9
DA 2023-09-07
UT WOS:001053897100021
PM 37457604
ER

PT J
AU Shin, Minjeong
   Song, Junho
   Kim, Myung-Gwan
   Yu, Hyeong Won
   Choe, Eun Kyung
   Chai, Young Jun
TI Thyro-GenAI: A Chatbot Using Retrieval-Augmented Generative Models for
   Personalized Thyroid Disease Management
SO JOURNAL OF CLINICAL MEDICINE
VL 14
IS 7
AR 2450
DI 10.3390/jcm14072450
DT Article
PD APR 3 2025
PY 2025
AB Background: Large language models (LLMs) have the potential to enhance
   information processing and clinical reasoning in the healthcare industry
   but are hindered by inaccuracies and hallucinations. The
   retrieval-augmented generation (RAG) technique may address these
   problems by integrating external knowledge sources. Methods: We
   developed a RAG-based chatbot called Thyro-GenAI by integrating a
   database of textbooks and guidelines with LLM. Thyro-GenAI and three
   service LLMs: OpenAI's ChatGPT-4o, Perplexity AI's ChatGPT-4o, and
   Anthropic's Claude 3.5 Sonnet, were asked personalized clinical
   questions about thyroid disease. Three thyroid specialists assessed the
   quality of the generated responses and references without being blinded,
   which allowed them to interact with different chatbot interfaces.
   Results: Thyro-GenAI achieved the highest inverse-weighted mean rank for
   overall response quality. The overall inverse-weighted mean rankings for
   Thyro-GenAI, ChatGPT, Perplexity, and Claude were 3.0, 2.3, 2.8, and
   1.9, respectively. Thyro-GenAI also achieved the second-highest
   inverse-weighted mean rank for overall reference quality. The overall
   inverse-weighted mean rankings for Thyro-GenAI, ChatGPT, Perplexity, and
   Claude were 3.1, 2.3, 3.2, and 1.8, respectively. Conclusions:
   Thyro-GenAI produced patient-specific clinical reasoning output based on
   a vector database, with fewer hallucinations and more reliability,
   compared to service LLMs. This emphasis on evidence-based responses
   ensures its safety and validity, addressing a critical limitation of
   existing LLMs. By integrating RAG with LLMs, it has the potential to
   support frontline clinical decision-making, especially helping
   first-line physicians by offering reliable decision support while
   managing thyroid disease patients.
ZB 0
ZA 0
Z8 0
TC 0
ZS 0
ZR 0
Z9 0
DA 2025-04-18
UT WOS:001463592500001
PM 40217905
ER

PT J
AU Perlis, Roy
TI Large Language Models as Decision Support Tools for Mood Disorder
   Pharmacotherapy
SO NEUROPSYCHOPHARMACOLOGY
VL 49
MA 6.4
BP 7
EP 8
SU 1
DT Meeting Abstract
PD DEC 2024
PY 2024
CT 63rd Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP)
CY DEC 08-11, 2023
CL Phoenix, AZ
SP Amer Coll Neuropsychopharmacol
ZB 0
TC 0
ZS 0
Z8 0
ZA 0
ZR 0
Z9 0
DA 2025-02-23
UT WOS:001421429700018
ER

PT J
AU Liu, Jialin
   Wang, Changyu
   Liu, Siru
TI Utility of ChatGPT in Clinical Practice
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 25
AR e48568
DI 10.2196/48568
DT Article
PD JUN 28 2023
PY 2023
AB ChatGPT is receiving increasing attention and has a variety of
   application scenarios in clinical practice. In clinical decision
   support, ChatGPT has been used to generate accurate differential
   diagnosis lists, support clinical decision-making, optimize clinical
   decision support, and provide insights for cancer screening decisions.
   In addition, ChatGPT has been used for intelligent question-answering to
   provide reliable information about diseases and medical queries. In
   terms of medical documentation, ChatGPT has proven effective in
   generating patient clinical letters, radiology reports, medical notes,
   and discharge summaries, improving efficiency and accuracy for health
   care providers. Future research directions include real-time monitoring
   and predictive analytics, precision medicine and personalized treatment,
   the role of ChatGPT in telemedicine and remote health care, and
   integration with existing health care systems. Overall, ChatGPT is a
   valuable tool that complements the expertise of health care providers
   and improves clinical decision-making and patient care. However, ChatGPT
   is a double-edged sword. We need to carefully consider and study the
   benefits and potential dangers of ChatGPT. In this viewpoint, we discuss
   recent advances in ChatGPT research in clinical practice and suggest
   possible risks and challenges of using ChatGPT in clinical practice. It
   will help guide and support future artificial intelligence research
   similar to ChatGPT in health.
ZS 1
ZR 0
Z8 5
TC 230
ZB 25
ZA 0
Z9 234
DA 2023-08-24
UT WOS:001045687800005
PM 37379067
ER

PT J
AU Wang, Lan
   Tang, Kaiqiang
   Wang, Yan
   Zhang, Peng
   Li, Shao
TI Advancements in Artificial Intelligence-Driven Diagnostic Models for
   Traditional Chinese Medicine
SO AMERICAN JOURNAL OF CHINESE MEDICINE
VL 53
IS 03
BP 647
EP 673
DI 10.1142/S0192415X25500259
DT Article
PD 2025
PY 2025
AB Traditional Chinese medicine (TCM) is an ancient medical system with
   distinctive ethnic characteristics. TCM diagnosis, underpinned by unique
   theoretical frameworks and methodologies, continues to play a
   significant role in contemporary healthcare. The four fundamental
   diagnostic methods, inspection, auscultation-olfaction, inquiry and
   palpation, are inherently subjective, relying on practitioner
   experience. Despite its unique advantages and practical value, TCM must
   still take advantage of modern advancements to enhance its effectiveness
   and accessibility. With the rapid development of computer technology,
   intelligent TCM diagnosis has emerged as a promising frontier.
   Integrating artificial intelligence (AI), particularly through large
   language models (LLMs), offers new avenues for enhancing TCM diagnostic
   practices. However, the systematic review and analysis of these
   technologies remains limited. This paper provides a comprehensive
   overview of the development and recent advancements in TCM diagnostic
   technologies, focusing on the applications of ML across various data
   modalities, and including images, text, and waveforms. Additionally, it
   explores the latest applications of LLMs within the TCM diagnostic
   field. Furthermore, the review discusses the prospects and challenges
   associated with AI-based TCM diagnosis. By systematically summarizing
   the latest research achievements and technological advancements, this
   study aims to provide directional guidance and decision support for
   future research and practical applications in the intersection of AI and
   TCM. Ultimately, this review seeks to foster the continued development
   and integration of intelligent TCM diagnosis into modern healthcare.
ZR 0
Z8 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
DA 2025-05-20
UT WOS:001488594200010
PM 40374369
ER

PT B
AU Shubbar, Safa
Z2  
TI Advancing Autism Spectrum Disorder Diagnosis: A Phenotype-Genotype
   Co-Analysis and Retrieval-Augmented LLM Framework for Clinical Decision
   Support
DT Dissertation/Thesis
PD Jan 01 2025
PY 2025
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
UT PQDT:123210398
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   Croce, Lory
   Shung, Dennis
TI TRANSFORMING HEPATITIS C TREATMENT: THE POWER OF LARGE LANGUAGE MODEL-
   BASED INTELLIGENT AGENTS IN CLINICAL DECISION SUPPORT
SO HEPATOLOGY
VL 80
MA 557
BP S406
EP S407
SU 1
DT Meeting Abstract
PD OCT 2024
PY 2024
CT The Liver Meeting
CY NOV 15-19, 2024
CL San Diego, CA
ZS 0
TC 0
ZR 0
ZA 0
ZB 0
Z8 0
Z9 0
DA 2025-01-07
UT WOS:001366004001049
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Ayoub, Noel F.
   Rameau, Anais
   Brenner, Michael J.
   Bur, Andres M.
   Ator, Gregory A.
   Briggs, Selena E.
   Takashima, Masayoshi
   Stankovic, Konstantina M.
   AAO HNS ArtificialIntelligence Task Force
TI American Academy of Otolaryngology-Head and Neck Surgery (AAO-HNS)
   Report on Artificial Intelligence
SO OTOLARYNGOLOGY-HEAD AND NECK SURGERY
VL 172
IS 2
BP 734
EP 743
DI 10.1002/ohn.1080
EA DEC 2024
DT Editorial Material
PD FEB 2025
PY 2025
AB This report synthesizes the American Academy of Otolaryngology-Head and
   Neck Surgery (AAO-HNS) Task Force's guidance on the integration of
   artificial intelligence (AI) in otolaryngology-head and neck surgery
   (OHNS). A comprehensive literature review was conducted, focusing on the
   applications, benefits, and challenges of AI in OHNS, alongside ethical,
   legal, and social implications. The Task Force, formulated by
   otolaryngologist experts in AI, used an iterative approach, adapted from
   the Delphi method, to prioritize topics for inclusion and to reach a
   consensus on guiding principles. The Task Force's findings highlight
   AI's transformative potential for OHNS, offering potential advancements
   in precision medicine, clinical decision support, operational
   efficiency, research, and education. However, challenges such as data
   quality, health equity, privacy concerns, transparency, regulatory gaps,
   and ethical dilemmas necessitate careful navigation. Incorporating AI
   into otolaryngology practice in a safe, equitable, and patient-centered
   manner requires clinician judgment, transparent AI systems, and
   adherence to ethical and legal standards. The Task Force principles
   underscore the importance of otolaryngologists' involvement in AI's
   ethical development, implementation, and regulation to harness benefits
   while mitigating risks. The proposed principles inform the integration
   of AI in otolaryngology, aiming to enhance patient outcomes, clinician
   well-being, and efficiency of health care delivery.
ZS 0
TC 1
ZA 0
Z8 0
ZR 0
ZB 0
Z9 1
DA 2024-12-19
UT WOS:001376682000001
PM 39666770
ER

PT J
AU Bhattacharya, Kaushik
   Bhattacharya, Surajit
   Bhattacharya, Neeta
   Bhattacharya, Neela
TI DeepSeek Versus ChatGPT in Surgical Practice
SO INDIAN JOURNAL OF SURGERY
DI 10.1007/s12262-025-04368-y
EA MAY 2025
DT Review; Early Access
PY 2025
AB Artificial intelligence (AI) is revolutionizing medicine and surgery by
   enhancing diagnostic accuracy, decision-making, and patient care. Among
   the most promising AI-driven tools are ChatGPT and DeepSeek, each
   playing a distinct yet complementary role in clinical practice. ChatGPT,
   a large language model, serves as an intelligent assistant for medical
   professionals, aiding in clinical decision support, medical education,
   documentation, and patient communication. Its ability to process vast
   medical literature, generate differential diagnoses, and provide
   real-time guidance improves efficiency and accessibility in healthcare.
   DeepSeek, an artificial intelligence technology, is being explored for
   surgical training, patient education, and preoperative planning. By
   generating realistic simulations and personalized surgical
   reconstructions, DeepSeek enhances skill acquisition, facilitates
   virtual surgical rehearsals, and improves patient understanding of
   procedures. Together, these AI tools have the potential to transform
   modern healthcare, reducing cognitive workload for clinicians and
   improving patient outcomes. However, ethical concerns, data security,
   and regulatory oversight must be addressed to ensure their safe and
   effective integration into medical practice. As AI continues to evolve,
   ChatGPT and DeepSeeK will likely play an increasingly vital role in
   advancing the fields of medicine and surgery.
Z8 0
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z9 0
DA 2025-05-16
UT WOS:001485543000001
ER

PT J
AU Shin, Euibeom
   Hartman, Maggie
   Ramanathan, Murali
TI Performance of the ChatGPT large language model for decision support in
   community pharmacy
SO BRITISH JOURNAL OF CLINICAL PHARMACOLOGY
VL 90
IS 12
BP 3320
EP 3333
DI 10.1111/bcp.16215
EA AUG 2024
DT Article
PD DEC 2024
PY 2024
AB AimsThe aim of this study was to assess the ChatGPT-4 (ChatGPT) large
   language model (LLM) on tasks relevant to community
   pharmacy.MethodsChatGPT was assessed with community pharmacy-relevant
   test cases involving drug information retrieval, identifying labelling
   errors, prescription interpretation, decision-making under uncertainty
   and multidisciplinary consults. Drug information on rituximab, warfarin,
   and St. John's wort was queried. The decision-support scenarios
   consisted of a subject with swollen eyelids and a maculopapular rash in
   a subject on lisinopril and ferrous sulfate. The multidisciplinary
   scenarios required the integration of medication management with
   recommendations for healthy eating and physical
   activity/exercise.ResultsThe responses from ChatGPT for rituximab,
   warfarin, and St. John's wort were satisfactory and cited drug databases
   and drug-specific monographs. ChatGPT identified labeling errors related
   to incorrect medication strength, form, route of administration, unit
   conversion, and directions. For the patient with inflamed eyelids, the
   course of action developed by ChatGPT was comparable to the pharmacist's
   approach. For the patient with the maculopapular rash, both the
   pharmacist and ChatGPT placed a drug reaction to either lisinopril or
   ferrous sulfate at the top of the differential. ChatGPT provided
   customized vaccination requirements for travel to Brazil, guidance on
   management of drug allergies and recovery from a knee injury. ChatGPT
   provided satisfactory medication management and wellness information for
   a diabetic on metformin and semaglutide.ConclusionsLLMs have the
   potential to become a powerful tool in community pharmacy. However,
   rigorous validation studies across diverse pharmacist queries, drug
   classes and populations, and engineering to secure patient privacy will
   be needed to enhance LLM utility.
TC 1
ZR 0
Z8 0
ZB 1
ZS 0
ZA 0
Z9 1
DA 2024-09-01
UT WOS:001298523500001
PM 39191671
ER

PT J
AU Hao, Jie
   Yao, Zixuan
   Tang, Yaogeng
   Remis, Andreas
   Wu, Kangchao
   Yu, Xin
TI Artificial Intelligence in Physical Therapy: Evaluating ChatGPT's Role
   in Clinical Decision Support for Musculoskeletal Care
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 53
IS 1
BP 9
EP 13
DI 10.1007/s10439-025-03676-4
EA JAN 2025
DT Letter
PD JAN 2025
PY 2025
AB Background The integration of artificial intelligence into medicine has
   attracted increasing attention in recent years. ChatGPT has emerged as a
   promising tool for delivering evidence-based recommendations in various
   clinical domains. However, the application of ChatGPT to physical
   therapy for musculoskeletal conditions has yet to be investigated.
   Methods Thirty clinical questions related to spinal, lower extremity,
   and upper extremity conditions were quired to ChatGPT-4. Responses were
   assessed for accuracy against clinical practice guidelines by two
   reviewers. Intra- and inter-rater reliability were measured using
   Fleiss' kappa (k). Results ChatGPT's responses were consistent with CPG
   recommendations for 80% of the questions. Performance was highest for
   upper extremity conditions (100%) and lowest for spinal conditions
   (60%), with a moderate performance for lower extremity conditions (87%).
   Intra-rater reliability was good (k = 0.698 and k = 0.631 for the two
   reviewers), and inter-rater reliability was very good (k = 0.847).
   Conclusion ChatGPT demonstrates promise as a supplementary
   decision-making support tool for physical therapy, with good accuracy
   and reliability in aligning with clinical practice guideline
   recommendations. Further research is needed to evaluate its performance
   across broader scenarios and refine its clinical applicability.
ZR 0
ZB 0
ZA 0
ZS 0
TC 3
Z8 0
Z9 3
DA 2025-01-11
UT WOS:001390982400001
PM 39760952
ER

PT J
AU Wada, Akihiko
   Akashi, Toshiaki
   Shih, George
   Hagiwara, Akifumi
   Nishizawa, Mitsuo
   Hayakawa, Yayoi
   Kikuta, Junko
   Shimoji, Keigo
   Sano, Katsuhiro
   Kamagata, Koji
   Nakanishi, Atsushi
   Aoki, Shigeki
TI Optimizing GPT-4 Turbo Diagnostic Accuracy in Neuroradiology through
   Prompt Engineering and Confidence Thresholds
SO DIAGNOSTICS
VL 14
IS 14
AR 1541
DI 10.3390/diagnostics14141541
DT Article
PD JUL 2024
PY 2024
AB Background and Objectives: Integrating large language models (LLMs) such
   as GPT-4 Turbo into diagnostic imaging faces a significant challenge,
   with current misdiagnosis rates ranging from 30-50%. This study
   evaluates how prompt engineering and confidence thresholds can improve
   diagnostic accuracy in neuroradiology. Methods: We analyze 751
   neuroradiology cases from the American Journal of Neuroradiology using
   GPT-4 Turbo with customized prompts to improve diagnostic precision.
   Results: Initially, GPT-4 Turbo achieved a baseline diagnostic accuracy
   of 55.1%. By reformatting responses to list five diagnostic candidates
   and applying a 90% confidence threshold, the highest precision of the
   diagnosis increased to 72.9%, with the candidate list providing the
   correct diagnosis at 85.9%, reducing the misdiagnosis rate to 14.1%.
   However, this threshold reduced the number of cases that responded.
   Conclusions: Strategic prompt engineering and high confidence thresholds
   significantly reduce misdiagnoses and improve the precision of the LLM
   diagnostic in neuroradiology. More research is needed to optimize these
   approaches for broader clinical implementation, balancing accuracy and
   utility.
Z8 0
ZS 0
ZR 0
ZA 0
TC 5
ZB 0
Z9 5
DA 2024-08-01
UT WOS:001276606000001
PM 39061677
ER

PT J
AU Sarma, Karthik
   Hanss, Kaitlin
   Glowinski, Anne
   Halls, Andrew
   Krystal, Andrew
   Butte, Atul
TI Can Large Language Model-Based AI Reason About Behavioral Health?
   Preliminary Evaluation of a Decision Tree-Based LLM Algorithm for
   Psychiatric Case Diagnosis
SO NEUROPSYCHOPHARMACOLOGY
VL 49
MA P44
BP 90
EP 91
SU 1
DT Meeting Abstract
PD DEC 2024
PY 2024
CT 63rd Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP)
CY DEC 08-11, 2023
CL Phoenix, AZ
SP Amer Coll Neuropsychopharmacol
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
ZA 0
Z9 0
DA 2025-02-23
UT WOS:001421429700202
ER

PT J
AU Neha, Fnu
   Bhati, Deepshikha
   Shukla, Deepak Kumar
   Amiruzzaman, Md
TI ChatGPT: Transforming Healthcare with AI
SO AI
VL 5
IS 4
BP 2618
EP 2650
DI 10.3390/ai5040126
DT Article
PD DEC 2024
PY 2024
AB ChatGPT, developed by OpenAI, is a large language model (LLM) that
   leverages artificial intelligence (AI) and deep learning (DL) to
   generate human-like responses. This paper provides a broad, systematic
   review of ChatGPT's applications in healthcare, particularly in
   enhancing patient engagement through medical history collection, symptom
   assessment, and decision support for improved diagnostic accuracy. It
   assesses ChatGPT's potential across multiple organ systems and
   specialties, highlighting its value in clinical, educational, and
   administrative contexts. This analysis reveals both the benefits and
   limitations of ChatGPT, including health literacy promotion and support
   for clinical decision-making, alongside challenges such as the risk of
   inaccuracies, ethical considerations around informed consent, and
   regulatory hurdles. A quantified summary of key findings shows ChatGPT's
   promise in various applications while underscoring the risks associated
   with its integration in medical practice. Through this comprehensive
   approach, this review aims to provide healthcare professionals,
   researchers, and policymakers with a balanced view of ChatGPT's
   potential and limitations, emphasizing the need for ongoing updates to
   keep pace with evolving medical knowledge.
Z8 0
ZS 0
TC 8
ZB 0
ZR 0
ZA 0
Z9 8
DA 2024-12-31
UT WOS:001384069000001
ER

PT J
AU Cohen, I. Glenn
TI What Should ChatGPT Mean for Bioethics?
SO AMERICAN JOURNAL OF BIOETHICS
VL 23
IS 10
BP 8
EP 16
DI 10.1080/15265161.2023.2233357
EA JUL 2023
DT Article
PD OCT 3 2023
PY 2023
AB In the last several months, several major disciplines have started their
   initial reckoning with what ChatGPT and other Large Language Models
   (LLMs) mean for them - law, medicine, business among other professions.
   With a heavy dose of humility, given how fast the technology is moving
   and how uncertain its social implications are, this article attempts to
   give some early tentative thoughts on what ChatGPT might mean for
   bioethics. I will first argue that many bioethics issues raised by
   ChatGPT are similar to those raised by current medical AI - built into
   devices, decision support tools, data analytics, etc. These include
   issues of data ownership, consent for data use, data representativeness
   and bias, and privacy. I describe how these familiar issues appear
   somewhat differently in the ChatGPT context, but much of the existing
   bioethical thinking on these issues provides a strong starting point.
   There are, however, a few "new-ish" issues I highlight - by new-ish I
   mean issues that while perhaps not truly new seem much more important
   for it than other forms of medical AI. These include issues about
   informed consent and the right to know we are dealing with an AI, the
   problem of medical deepfakes, the risk of oligopoly and inequitable
   access related to foundational models, environmental effects, and on the
   positive side opportunities for the democratization of knowledge and
   empowering patients. I also discuss how races towards dominance (between
   large companies and between the U.S. and geopolitical rivals like China)
   risk sidelining ethics.
ZB 4
ZS 0
Z8 1
ZR 0
TC 58
ZA 0
Z9 59
DA 2023-07-31
UT WOS:001029754900001
PM 37440696
ER

PT J
AU Mykhalko, Yaroslav
   Kish, Pavlo
   Rubtsova, Yelyzaveta
   Kutsyn, Oleksandr
   Koval, Valentyna
TI FROM TEXT TO DIAGNOSE: CHATGPT'S EFFICACY IN MEDICAL DECISION-MAKING.
SO Wiadomosci lekarskie (Warsaw, Poland : 1960)
VL 76
IS 11
BP 2345
EP 2350
DI 10.36740/WLek202311101
DT Journal Article
PD 2023
PY 2023
AB OBJECTIVE: The aim: Evaluate the diagnostic capabilities of the ChatGPT
   in the field of medical diagnosis.
   PATIENTS AND METHODS: Materials and methods: We utilized 50 clinical
   cases, employing Large Language Model ChatGPT-3.5. The experiment had
   three phases, each with a new chat setup. In the initial phase, ChatGPT
   received detailed clinical case descriptions, guided by a "Persona
   Pattern" prompt. In the second phase, cases with diagnostic errors were
   addressed by providing potential diagnoses for ChatGPT to choose from.
   The final phase assessed artificial intelligence's ability to mimic a
   medical practitioner's diagnostic process, with prompts limiting initial
   information to symptoms and history.
   RESULTS: Results: In the initial phase, ChatGPT showed a 66.00%
   diagnostic accuracy, surpassing physicians by nearly 50%. Notably, in 11
   cases requiring image interpretation, ChatGPT struggled initially but
   achieved a correct diagnosis for four without added interpretations. In
   the second phase, ChatGPT demonstrated a remarkable 70.59% diagnostic
   accuracy, while physicians averaged 41.47%. Furthermore, the overall
   accuracy of Large Language Model in first and second phases together was
   90.00%. In the third phase emulating real doctor decision-making,
   ChatGPT achieved a 46.00% success rate.
   CONCLUSION: Conclusions: Our research underscores ChatGPT's strong
   potential in clinical medicine as a diagnostic tool, especially in
   structured scenarios. It emphasizes the need for supplementary data and
   the complexity of medical diagnosis. This contributes valuable insights
   to AI-driven clinical diagnostics, with a nod to the importance of
   prompt engineering techniques in ChatGPT's interaction with doctors.
TC 6
ZR 0
ZB 1
Z8 0
ZS 0
ZA 0
Z9 6
DA 2023-12-21
UT MEDLINE:38112347
PM 38112347
ER

PT J
AU Inojosa, Hernan
   Voigt, Isabel
   Wenk, Judith
   Ferber, Dyke
   Wiest, Isabella
   Antweiler, Dario
   Weicken, Eva
   Gilbert, Stephen
   Kather, Jakob Nikolas
   Akguen, Katja
   Ziemssen, Tjalf
TI Integrating large language models in care, research, and education in
   multiple sclerosis management
SO MULTIPLE SCLEROSIS JOURNAL
VL 30
IS 11-12
BP 1392
EP 1401
DI 10.1177/13524585241277376
EA SEP 2024
DT Review
PD OCT 2024
PY 2024
AB Use of techniques derived from generative artificial intelligence (AI),
   specifically large language models (LLMs), offer a transformative
   potential on the management of multiple sclerosis (MS). Recent LLMs have
   exhibited remarkable skills in producing and understanding human-like
   texts. The integration of AI in imaging applications and the deployment
   of foundation models for the classification and prognosis of disease
   course, including disability progression and even therapy response, have
   received considerable attention. However, the use of LLMs within the
   context of MS remains relatively underexplored. LLMs have the potential
   to support several activities related to MS management. Clinical
   decision support systems could help selecting proper disease-modifying
   therapies; AI-based tools could leverage unstructured real-world data
   for research or virtual tutors may provide adaptive education materials
   for neurologists and people with MS in the foreseeable future. In this
   focused review, we explore practical applications of LLMs across the
   continuum of MS management as an initial scope for future analyses,
   reflecting on regulatory hurdles and the indispensable role of human
   supervision.
ZA 0
Z8 1
ZS 0
ZR 0
TC 4
ZB 0
Z9 4
DA 2024-09-29
UT WOS:001318637000001
PM 39308156
ER

PT J
AU Chung, Sunny
   Rajashekar, Niroop
   Pu, Yuan
   Shin, Yeo Eun
   Giuffre, Mauro
   Chan, Colleen
   You, Kisung
   Saarinen, Theo
   Hsiao, Allen
   Sekhon, Jasjeet
   Wong, Ambrose
   Evans, Leigh
   McCall, Terika
   Kizilcec, Rene F.
   Laine, Loren
   Shung, Dennis
TI IMPACT OF ARTIFICIAL INTELLIGENCE SYSTEMS FOR UPPER GASTROINTESTINAL
   BLEEDING ON CLINICIAN TRUST AND LEARNING USING LARGE LANGUAGE MODELS: A
   RANDOMIZED PILOT SIMULATION STUDY
SO GASTROENTEROLOGY
VL 166
IS 5
MA 407
BP S95
EP S96
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZB 0
Z8 0
TC 0
ZA 0
ZR 0
ZS 0
Z9 0
DA 2024-10-30
UT WOS:001282837700239
ER

PT J
AU Wu, Jie
   Ma, Yingzhuo
   Wang, Jun
   Xiao, Mingzhao
TI The Application of ChatGPT in Medicine: A Scoping Review and
   Bibliometric Analysis
SO JOURNAL OF MULTIDISCIPLINARY HEALTHCARE
VL 17
BP 1681
EP 1692
DI 10.2147/JMDH.S463128
DT Review
PD 2024
PY 2024
AB Purpose: ChatGPT has a wide range of applications in the medical field.
   Therefore, this review aims to define the key issues and provide a
   comprehensive view of the literature based on the application of ChatGPT
   in medicine. Methods: This scope follows Arksey and O'Malley's
   five-stage framework. A comprehensive literature search of publications
   (30 November 2022 to 16 August 2023) was conducted. Six databases were
   searched and relevant references were systematically catalogued.
   Attention was focused on the general characteristics of the articles,
   their fields of application, and the advantages and disadvantages of
   using ChatGPT. Descriptive statistics and narrative synthesis methods
   were used for data analysis. Results: Of the 3426 studies, 247 met the
   criteria for inclusion in this review. The majority of articles (31.17%)
   were from the United States. Editorials (43.32%) ranked first, followed
   by experimental studys (11.74%). The potential applications of ChatGPT
   in medicine are varied, with the largest number of studies (45.75%)
   exploring clinical practice, including assisting with clinical decision
   support and providing disease information and medical advice. This was
   followed by medical education (27.13%) and scientific research (16.19%).
   Particularly noteworthy in the discipline statistics were radiology,
   surgery and dentistry at the top of the list. However, ChatGPT in
   medicine also faces issues of data privacy, inaccuracy and plagiarism.
   Conclusion: The application of ChatGPT in medicine focuses on different
   disciplines and general application scenarios. ChatGPT has a paradoxical
   nature: it offers significant advantages, but at the same time raises
   great concerns about its application in healthcare settings. Therefore,
   it is imperative to develop theoretical frameworks that not only address
   its widespread use in healthcare but also facilitate a comprehensive
   assessment. In addition, these frameworks should contribute to the
   development of strict and effective guidelines and regulatory measures.
Z8 0
ZR 0
TC 9
ZA 0
ZB 0
ZS 0
Z9 9
DA 2024-05-02
UT WOS:001208117100001
PM 38650670
ER

PT J
AU Griewing, Sebastian
   Lechner, Fabian
   Gremke, Niklas
   Lukac, Stefan
   Janni, Wolfgang
   Wallwiener, Markus
   Wagner, Uwe
   Hirsch, Martin
   Kuhn, Sebastian
TI Proof-of-concept study of a small language model chatbot for breast
   cancer decision support - a transparent, source-controlled, explainable
   and data-secure approach
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 10
AR 451
DI 10.1007/s00432-024-05964-3
DT Article
PD OCT 9 2024
PY 2024
AB Purpose Large language models (LLM) show potential for decision support
   in breast cancer care. Their use in clinical care is currently
   prohibited by lack of control over sources used for decision-making,
   explainability of the decision-making process and health data security
   issues. Recent development of Small Language Models (SLM) is discussed
   to address these challenges. This preclinical proof-of-concept study
   tailors an open-source SLM to the German breast cancer guideline
   (BC-SLM) to evaluate initial clinical accuracy and technical
   functionality in a preclinical simulation. Methods A multidisciplinary
   tumor board (MTB) is used as the gold-standard to assess the initial
   clinical accuracy in terms of concordance of the BC-SLM with MTB and
   comparing it to two publicly available LLM, ChatGPT3.5 and 4. The study
   includes 20 fictional patient profiles and recommendations for 5
   treatment modalities, resulting in 100 binary treatment recommendations
   (recommended or not recommended). Statistical evaluation includes
   concordance with MTB in % including Cohen's Kappa statistic (kappa).
   Technical functionality is assessed qualitatively in terms of local
   hosting, adherence to the guideline and information retrieval. Results
   The overall concordance amounts to 86% for BC-SLM (kappa = 0.721, p <
   0.001), 90% for ChatGPT4 (kappa = 0.820, p < 0.001) and 83% for
   ChatGPT3.5 (kappa = 0.661, p < 0.001). Specific concordance for each
   treatment modality ranges from 65 to 100% for BC-SLM, 85-100% for
   ChatGPT4, and 55-95% for ChatGPT3.5. The BC-SLM is locally functional,
   adheres to the standards of the German breast cancer guideline and
   provides referenced sections for its decision-making. Conclusion The
   tailored BC-SLM shows initial clinical accuracy and technical
   functionality, with concordance to the MTB that is comparable to
   publicly-available LLMs like ChatGPT4 and 3.5. This serves as a
   proof-of-concept for adapting a SLM to an oncological disease and its
   guideline to address prevailing issues with LLM by ensuring decision
   transparency, explainability, source control, and data security, which
   represents a necessary step towards clinical validation and safe use of
   language models in clinical oncology.
ZR 0
ZA 0
Z8 0
TC 1
ZB 1
ZS 0
Z9 1
DA 2024-10-24
UT WOS:001335902900001
PM 39382778
ER

PT J
AU Perlis, Roy H.
   Goldberg, Joseph F.
   Ostacher, Michael J.
   Schneck, Christopher D.
TI Clinical decision support for bipolar depression using large language
   models
SO NEUROPSYCHOPHARMACOLOGY
VL 49
IS 9
BP 1412
EP 1416
DI 10.1038/s41386-024-01841-2
EA MAR 2024
DT Article
PD AUG 2024
PY 2024
AB Management of depressive episodes in bipolar disorder remains
   challenging for clinicians despite the availability of treatment
   guidelines. In other contexts, large language models have yielded
   promising results for supporting clinical decisionmaking. We developed
   50 sets of clinical vignettes reflecting bipolar depression and
   presented them to experts in bipolar disorder, who were asked to
   identify 5 optimal next-step pharmacotherapies and 5 poor or
   contraindicated choices. The same vignettes were then presented to a
   large language model (GPT4-turbo; gpt-4-1106-preview), with or without
   augmentation by prompting with recent bipolar treatment guidelines, and
   asked to identify the optimal next-step pharmacotherapy. Overlap between
   model output and gold standard was estimated. The augmented model
   prioritized the expert-designated optimal choice for 508/1000 vignettes
   (50.8%, 95% CI 47.7-53.9%; Cohen's kappa = 0.31, 95% CI 0.28-0.35). For
   120 vignettes (12.0%), at least one model choice was among the poor or
   contraindicated treatments. Results were not meaningfully different when
   gender or race of the vignette was permuted to examine risk for bias. By
   comparison, an un-augmented model identified the optimal treatment for
   234 (23.0%, 95% CI 20.8-26.0%; McNemar's p < 0.001 versus augmented
   model) of the vignettes. A sample of community clinicians scoring the
   same vignettes identified the optimal choice for 23.1% (95% CI
   15.7-30.5%) of vignettes, on average; McNemar's p < 0.001 versus
   augmented model. Large language models prompted with evidence-based
   guidelines represent a promising, scalable strategy for clinical
   decision support. In addition to prospective studies of efficacy,
   strategies to avoid clinician overreliance on such models, and address
   the possibility of bias, will be needed.
TC 10
ZB 1
Z8 0
ZS 0
ZR 0
ZA 0
Z9 10
DA 2024-03-28
UT WOS:001182357900004
PM 38480911
ER

PT J
AU Maharjan, Jenish
   Garikipati, Anurag
   Singh, Navan Preet
   Cyrus, Leo
   Sharma, Mayank
   Ciobanu, Madalina
   Barnes, Gina
   Thapa, Rahul
   Mao, Qingqing
   Das, Ritankar
TI OpenMedLM: prompt engineering can out-perform fine-tuning in medical
   question-answering with open-source large language models
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 14156
DI 10.1038/s41598-024-64827-6
DT Article
PD JUN 2024
PY 2024
AB LLMs can accomplish specialized medical knowledge tasks, however,
   equitable access is hindered by the extensive fine-tuning, specialized
   medical data requirement, and limited access to proprietary models.
   Open-source (OS) medical LLMs show performance improvements and provide
   the transparency and compliance required in healthcare. We present
   OpenMedLM, a prompting platform delivering state-of-the-art (SOTA)
   performance for OS LLMs on medical benchmarks. We evaluated OS
   foundation LLMs (7B-70B) on medical benchmarks (MedQA, MedMCQA,
   PubMedQA, MMLU medical-subset) and selected Yi34B for developing
   OpenMedLM. Prompting strategies included zero-shot, few-shot,
   chain-of-thought, and ensemble/self-consistency voting. OpenMedLM
   delivered OS SOTA results on three medical LLM benchmarks, surpassing
   previous best-performing OS models that leveraged costly and extensive
   fine-tuning. OpenMedLM displays the first results to date demonstrating
   the ability of OS foundation models to optimize performance, absent
   specialized fine-tuning. The model achieved 72.6% accuracy on MedQA,
   outperforming the previous SOTA by 2.4%, and 81.7% accuracy on MMLU
   medical-subset, establishing itself as the first OS LLM to surpass 80%
   accuracy on this benchmark. Our results highlight medical-specific
   emergent properties in OS LLMs not documented elsewhere to date and
   validate the ability of OS models to accomplish healthcare tasks,
   highlighting the benefits of prompt engineering to improve performance
   of accessible LLMs for medical applications.
ZR 0
Z8 0
TC 16
ZS 0
ZA 0
ZB 2
Z9 16
DA 2024-08-07
UT WOS:001275958700048
PM 38898116
ER

PT J
AU Zace, Drieda
   Semeraro, Federico
   Schnaubelt, Sebastian
   Montomoli, Jonathan
   Ristagno, Giuseppe
   Fijacko, Nino
   Gamberini, Lorenzo
   Bignami, Elena G.
   Greif, Robert
   Monsieurs, Koenraad G.
   Scapigliati, Andrea
TI Artificial intelligence in resuscitation: a scoping review
SO RESUSCITATION PLUS
VL 24
AR 100973
DI 10.1016/j.resplu.2025.100973
EA MAY 2025
DT Review
PD JUL 2025
PY 2025
AB Background: Artificial intelligence (AI) is increasingly applied in
   medicine, with growing interest in its potential to improve outcomes in
   cardiac arrest (CA). However, the scope and characteristics of current
   AI applications in resuscitation remain unclear. Methods: This scoping
   review aims to map the existing literature on AI applications in CA and
   resuscitation and identify research gaps for further investigation.
   PRISMA-ScR framework and ILCOR guidelines were followed. A systematic
   literature search across PubMed, EMBASE, and Cochrane identified AI
   applications in resuscitation. Articles were screened and classified by
   AI methodology, study design, outcomes, and implementation settings.
   AI-assisted data extraction was manually validated for accuracy.
   Results: Out of 4046 records, 197 studies met inclusion criteria. Most
   were retrospective (90%), with only 16 prospective studies and 2
   randomised controlled trials. AI was predominantly applied in prediction
   of CA, rhythm classification, and post-resuscitation outcome
   prognostication. Machine learning was the most commonly used method (50%
   of studies), followed by deep learning and, less frequently, natural
   language processing. Reported performance was generally high, with AUROC
   values often exceeding 0.85; however, external validation was rare and
   real-world implementation limited. Conclusions: While AI applications in
   resuscitation demonstrate encouraging performance in prediction and
   decision support tasks, clear evidence of improved patient outcomes or
   routine clinical use remains limited. Future research should focus on
   prospective validation, equity in data sources, explainability, and
   seamless integration of AI tools into clinical workflows.
ZS 0
ZB 0
Z8 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-05-25
UT WOS:001492234400003
PM 40486106
ER

PT J
AU Gwon, Yong Nam
   Kim, Jae Heon
   Chung, Hyun Soo
   Jung, Eun Jee
   Chun, Joey
   Lee, Serin
   Shim, Sung Ryul
TI The Use of Generative AI for Scientific Literature Searches for
   Systematic Reviews: ChatGPT and Microsoft Bing AI Performance Evaluation
SO JMIR MEDICAL INFORMATICS
VL 12
AR e51187
DI 10.2196/51187
DT Article
PD 2024
PY 2024
AB Background: A large language model is a type of artificial intelligence
   (AI) model that opens up great possibilities for health care practice,
   research, and education, although scholars have emphasized the need to
   proactively address the issue of unvalidated and inaccurate information
   regarding its use. One of the best-known large language models is
   ChatGPT (OpenAI). It is believed to be of great help to medical
   research, as it facilitates more efficient data set analysis, code
   generation, and literature review, allowing researchers to focus on
   experimental design as well as drug discovery and development.
   Objective: This study aims to explore the potential of ChatGPT as a
   real-time literature search tool for systematic reviews and clinical
   decision support systems, to enhance their efficiency and accuracy in
   health care settings. Methods: The search results of a published
   systematic review by human experts on the treatment of Peyronie disease
   were selected as a benchmark, and the literature search formula of the
   study was applied to ChatGPT and Microsoft Bing AI as a comparison to
   human researchers. Peyronie disease typically presents with discomfort,
   curvature, or deformity of the penis in association with palpable
   plaques and erectile dysfunction. To evaluate the quality of individual
   studies derived from AI answers, we created a structured rating system
   based on bibliographic information related to the publications. We
   classified its answers into 4 grades if the title existed: A, B, C, and
   F. No grade was given for a fake title or no answer. Results: From
   ChatGPT, 7 (0.5%) out of 1287 identified studies were directly relevant,
   whereas Bing AI resulted in 19 (40%) relevant studies out of 48,
   compared to the human benchmark of 24 studies. In the qualitative
   evaluation, ChatGPT had 7 grade A, 18 grade B, 167 grade C, and 211
   grade F studies, and Bing AI had 19 grade A and 28 grade C studies.
   Conclusions: This is the first study to compare AI and conventional
   human systematic review methods as a real-time literature collection
   tool for evidence -based medicine. The results suggest that the use of
   ChatGPT as a tool for real-time evidence generation is not yet accurate
   and feasible. Therefore, researchers should be cautious about using such
   AI. The limitations of this study using the generative pre -trained
   transformer model are that the search for research topics was not
   diverse and that it did not prevent the hallucination of generative AI.
   However, this study will serve as a standard for future studies by
   providing an index to verify the reliability and consistency of
   generative AI from a user's point of view. If the reliability and
   consistency of AI literature search services are verified, then the use
   of these technologies will help medical research greatly.
Z8 0
ZS 0
TC 12
ZA 0
ZR 0
ZB 2
Z9 12
DA 2024-06-07
UT WOS:001233902800001
PM 38771247
ER

PT B
AU Rajashekar, Niroop
Z2  
TI Generative Artificial Intelligence in Clinical Decision Support -
   Quantitative and Qualitative Analyses
DT Dissertation/Thesis
PD Jan 01 2025
PY 2025
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
UT PQDT:123384289
ER

PT J
AU Thirunavukarasu, Arun James
   Hassan, Refaat
   Mahmood, Shathar
   Sanghera, Rohan
   Barzangi, Kara
   El Mukashfi, Mohanned
   Shah, Sachin
TI Trialling a Large Language Model (ChatGPT) in General Practice With the
   Applied Knowledge Test: Observational Study Demonstrating Opportunities
   and Limitations in Primary Care
SO JMIR MEDICAL EDUCATION
VL 9
AR e46599
DI 10.2196/46599
DT Article
PD 2023
PY 2023
AB Background: Large language models exhibiting human-level performance in
   specialized tasks are emerging; examples include Generative Pretrained
   Transformer 3.5, which underlies the processing of ChatGPT. Rigorous
   trials are required to understand the capabilitiesof emerging
   technology, so that innovation can be directed to benefit patients and
   practitioners. Objective: Here, we evaluated the strengths and
   weaknesses of ChatGPT in primary care using the Membership of the Royal
   College of General Practitioners Applied Knowledge Test (AKT) as a
   medium. Methods: AKT questions were sourced from a web-based question
   bank and 2 AKT practice papers. In total, 674 unique AKT questions were
   inputted to ChatGPT, with the model's answers recorded and compared to
   correct answers provided by the Royal College of General Practitioners.
   Each question was inputted twice in separate ChatGPT sessions, with
   answers on repeated trials compared to gauge consistency. Subject
   difficulty was gauged by referring to examiners' reports from 2018 to
   2022. Novel explanations from ChatGPT-defined as information provided
   that was not inputted within the question or multiple answer
   choices-were recorded. Performance was analyzed with respect to subject,
   difficulty, question source, and novel model outputs to explore
   ChatGPT's strengths and weaknesses. Results: Average overall performance
   of ChatGPT was 60.17%, which is below the mean passing mark in the last
   2 years (70.42%). Accuracy differed between sources (P=.04 and .06).
   ChatGPT's performance varied with subject category (P=.02 and .02), but
   variation did not correlatewith difficulty (Spearman rho=-0.241 and
   -0.238; P=.19 and .20). The proclivity of ChatGPT to provide novel
   explanations did not affect accuracy (P>.99 and .23). Conclusions:Large
   language models are approaching human expert-level performance, although
   further development is required to match the performance of qualified
   primary care physicians in the AKT. Validated high-performance models
   may serve as assistants or autonomous clinical tools to ameliorate the
   general practice workforce crisis.
ZR 0
Z8 2
ZB 14
TC 94
ZS 0
ZA 0
Z9 96
DA 2023-01-01
UT WOS:001424929400003
PM 37083633
ER

PT J
AU Padovan, Martina
   Palla, Alessandro
   Marino, Riccardo
   Porciatti, Francesco
   Cosci, Bianca
   Carlucci, Francesco
   Nerli, Gianluca
   Petillo, Armando
   Necciari, Gabriele
   Dell'Amico, Letizia
   Lucisano, Vincenzo Carmelo
   Scarinci, Sergio
   Foddis, Rudy
TI ChatGPT-4 vs. Google Bard: Which Chatbot Better Understands the Italian
   Legislative Framework for Worker Health and Safety?
SO APPLIED SCIENCES-BASEL
VL 15
IS 3
AR 1508
DI 10.3390/app15031508
DT Article
PD FEB 2025
PY 2025
AB Large language models, such as ChatGPT-4 and Google Bard, have
   demonstrated potential in healthcare. This study explores their utility
   in occupational medicine, a field where decisions rely on compliance
   with specific workplace health and safety regulations. A dataset of
   questions encompassing key occupational health topics derived from the
   Italian Legislative Decree 81/08, which governs workplace health and
   safety, was utilized. Responses from ChatGPT-4 with contextual
   information (ChatGPT-4+context) and Google Bard were evaluated for
   accuracy and completeness, with error categorization used to identify
   common issues. Subcategories of the topics of the regulations were
   analyzed as well. In total, 433 questions were included in our analysis.
   ChatGPT-4+context surpasses Bard in terms of accuracy and completeness
   in responses, with a lower error rate in the categories analyzed, except
   for the percentage of missed responses. In the subcategories analyzed,
   Bard is superior to ChatGPT-4+context only in the areas of the manual
   handling of loads and physical hazards. ChatGPT-4+context outperformed
   Bard in providing answers about Italian regulations on health and safety
   at work. This study highlights the potential and limitations of large
   language models as decision-support tools in occupational medicine and
   underscores the importance of regulatory context in enhancing their
   reliability.
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
DA 2025-02-17
UT WOS:001418463500001
ER

PT J
AU Shool, Sina
   Adimi, Sara
   Amleshi, Reza Saboori
   Bitaraf, Ehsan
   Golpira, Reza
   Tara, Mahmood
TI A systematic review of large language model (LLM) evaluations in
   clinical medicine
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
VL 25
IS 1
AR 117
DI 10.1186/s12911-025-02954-4
DT Review
PD MAR 7 2025
PY 2025
AB BackgroundLarge Language Models (LLMs), advanced AI tools based on
   transformer architectures, demonstrate significant potential in clinical
   medicine by enhancing decision support, diagnostics, and medical
   education. However, their integration into clinical workflows requires
   rigorous evaluation to ensure reliability, safety, and ethical
   alignment.ObjectiveThis systematic review examines the evaluation
   parameters and methodologies applied to LLMs in clinical medicine,
   highlighting their capabilities, limitations, and application
   trends.MethodsA comprehensive review of the literature was conducted
   across PubMed, Scopus, Web of Science, IEEE Xplore, and arXiv databases,
   encompassing both peer-reviewed and preprint studies. Studies were
   screened against predefined inclusion and exclusion criteria to identify
   original research evaluating LLM performance in medical
   contexts.ResultsThe results reveal a growing interest in leveraging LLM
   tools in clinical settings, with 761 studies meeting the inclusion
   criteria. While general-domain LLMs, particularly ChatGPT and GPT-4,
   dominated evaluations (93.55%), medical-domain LLMs accounted for only
   6.45%. Accuracy emerged as the most commonly assessed parameter
   (21.78%). Despite these advancements, the evidence base highlights
   certain limitations and biases across the included studies, emphasizing
   the need for careful interpretation and robust evaluation
   frameworks.ConclusionsThe exponential growth in LLM research underscores
   their transformative potential in healthcare. However, addressing
   challenges such as ethical risks, evaluation variability, and
   underrepresentation of critical specialties will be essential. Future
   efforts should prioritize standardized frameworks to ensure safe,
   effective, and equitable LLM integration in clinical practice.
ZR 0
ZB 0
ZS 0
ZA 0
Z8 0
TC 6
Z9 6
DA 2025-04-13
UT WOS:001461570300001
PM 40055694
ER

PT J
AU Gwon, Yong Nam
   Kim, Jae Heon
   Chung, Hyun Soo
   Jung, Eun Jee
   Chun, Joey
   Lee, Serin
   Shim, Sung Ryul
TI The Use of Generative AI for Scientific Literature Searches for
   Systematic Reviews: ChatGPT and Microsoft Bing AI Performance Evaluation
SO JMIR MEDICAL INFORMATICS
VL 12
AR e51187
DI 10.2024/1/e51187
DT Article
PD 2024
PY 2024
AB Background: A large language model is a type of artificial intelligence
   (AI) model that opens up great possibilities for health care practice,
   research, and education, although scholars have emphasized the need to
   proactively address the issue of unvalidated and inaccurate information
   regarding its use. One of the best-known large language models is
   ChatGPT (OpenAI). It is believed to be of great help to medical
   research, as it facilitates more efficient data set analysis, code
   generation, and literature review, allowing researchers to focus on
   experimental design as well as drug discovery and development.
   Objective: This study aims to explore the potential of ChatGPT as a real
   -time literature search tool for systematic reviews and clinical
   decision support systems, to enhance their efficiency and accuracy in
   health care settings. Methods: The search results of a published
   systematic review by human experts on the treatment of Peyronie disease
   were selected as a benchmark, and the literature search formula of the
   study was applied to ChatGPT and Microsoft Bing AI as a comparison to
   human researchers. Peyronie disease typically presents with discomfort,
   curvature, or deformity of the penis in association with palpable
   plaques and erectile dysfunction. To evaluate the quality of individual
   studies derived from AI answers, we created a structured rating system
   based on bibliographic information related to the publications. We
   classified its answers into 4 grades if the title existed: A, B, C, and
   F. No grade was given for a fake title or no answer. Results: From
   ChatGPT, 7 (0.5%) out of 1287 identified studies were directly relevant,
   whereas Bing AI resulted in 19 (40%) relevant studies out of 48,
   compared to the human benchmark of 24 studies. In the qualitative
   evaluation, ChatGPT had 7 grade A, 18 grade B, 167 grade C, and 211
   grade F studies, and Bing AI had 19 grade A and 28 grade C studies.
   Conclusions: This is the first study to compare AI and conventional
   human systematic review methods as a real -time literature collection
   tool for evidence-based medicine. The results suggest that the use of
   ChatGPT as a tool for real -time evidence generation is not yet accurate
   and feasible. Therefore, researchers should be cautious about using such
   AI. The limitations of this study using the generative pre-trained
   transformer model are that the search for research topics was not
   diverse and that it did not prevent the hallucination of generative AI.
   However, this study will serve as a standard for future studies by
   providing an index to verify the reliability and consistency of
   generative AI from a user's point of view. If the reliability and
   consistency of AI literature search services are verified, then the use
   of these technologies will help medical research greatly.
ZR 0
TC 0
ZA 0
ZB 0
ZS 0
Z8 0
Z9 0
DA 2024-06-07
UT WOS:001226395600002
ER

PT J
AU Yang, Kuo
   Dong, Xin
   Zhang, Shuhan
   Yu, Haibin
   Zhong, Liqun
   Zhang, Lei
   Zhao, He
   Hou, Yutong
   Song, Xinpeng
   Zhou, Xuezhong
TI PresRecRF: Herbal prescription recommendation via the representation
   fusion of large TCM semantics and molecular knowledge
SO PHYTOMEDICINE
VL 135
AR 156116
DI 10.1016/j.phymed.2024.156116
EA OCT 2024
DT Article
PD DEC 2024
PY 2024
AB Background: Herbal prescription recommendation (HPR) is a hotspot in the
   research of clinical intelligent decision support. Recently plentiful
   HPR models based on deep neural networks have been proposed. Owing to
   insufficient data, e.g., lack of knowledge of molecular, TCM theory, and
   herbal dosage in HPR modeling, the existing models suffer from
   challenges, e.g., plain prediction precision, and are far from
   real-world clinics. Purpose: To address these problems, we proposed a
   novel herbal prescription recommendation model with the representation
   fusion of large TCM semantics and molecular knowledge (termed
   PresRecRF). Study Design and Methods: PresRecRF comprises three key
   modules. The representation learning module consists of two key
   components: a molecular knowledge representation component, integrating
   molecular knowledge into the herbsymptom-protein knowledge graph to
   enhance representations for herbs and symptoms; and a TCM knowledge
   representation component, leveraging BERT and ChatGPT to acquire TCM
   knowledge-enriched semantic representations. We introduced a
   representation fusion module to effectively merge molecular and TCM
   semantic representations. In the herb recommendation module, a
   multi-task objective loss is implemented to predict both herbs and
   dosages simultaneously. Results: The experimental results on two
   clinical datasets show that PresRecRF can achieve the optimal
   performance. Further analysis of ablation, hyper-parameters, and case
   studies indicate the effectiveness and reliability of the proposed
   model, suggesting that it can help precision medicine and treatment
   recommendations. Conclusion: The entire process of the proposed
   PresRecRF model closely mirrors the actual diagnosis and treatment
   procedures carried out by doctors, which are better applied in real
   clinical scenarios. The source codes of PresRecRF is available at
   https://github.com/2020MEAI/PresRecRF.
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
TC 0
Z9 0
DA 2024-12-07
UT WOS:001368283600001
PM 39396402
ER

PT J
AU Giuffre, Mauro
   Shung, Dennis
TI INTERACTIVE CLINICAL GUIDELINES WITH LARGE LANGUAGE MODELS: THE GUTGPT
   SERIES ON AMERICAN GASTROENTEROLOGY ASSOCIATION GUIDELINES
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1987
BP S892
EP S893
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
Z8 0
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z9 0
DA 2024-10-30
UT WOS:001282837703488
ER

PT J
AU Mccaffrey, Peter
   Jackups, Ronald
   Seheult, Jansen
   Zaydman, Mark A.
   Balis, Ulysses
   Thaker, Harshwardhan M.
   Rashidi, Hooman
   Gullapalli, Rama R.
TI Evaluating Use of Generative Artificial Intelligence in Clinical
   Pathology Practice Opportunities and the Way Forward
SO ARCHIVES OF PATHOLOGY & LABORATORY MEDICINE
VL 149
IS 2
BP 130
EP 141
DI 10.5858/arpa.2024-0208-RA
DT Article
PD FEB 2025
PY 2025
AB Context.-Generative artificial intelligence (GAI) technologies are
   likely to dramatically impact health care workflows in clinical
   pathology (CP). Applications in CP include education, data mining,
   decision support, result summaries, and patient trend assessments.
   Objective.-To review use cases of GAI in CP, with a particular focus on
   large language models. Specific examples are provided for the
   applications of GAI in the subspecialties of clinical chemistry,
   microbiology, hematopathology, and molecular diagnostics. Additionally,
   the review addresses potential pitfalls of GAI paradigms. Data
   Sources.-Current literature on GAI in health care was reviewed broadly.
   The use case scenarios for each CP subspecialty review common data
   sources generated in each subspecialty. The potential for utilization of
   CP data in the GAI context was subsequently assessed, focusing on issues
   such as future reporting paradigms, impact on quality metrics, and
   potential for translational research activities. Conclusions.-GAI is a
   powerful tool with the potential to revolutionize health care for
   patients and practitioners alike. However, GAI must be implemented with
   much caution considering various shortcomings of the technology such as
   biases, hallucinations, practical challenges of implementing GAI in
   existing CP workflows, and end-user acceptance. Human-in-the-loop models
   of GAI implementation have the potential to revolutionize CP by
   delivering deeper, meaningful insights into patient outcomes both at an
   individual and a population level.
Z8 0
ZS 0
ZR 0
ZA 0
TC 0
ZB 0
Z9 0
DA 2025-02-14
UT WOS:001416363100006
PM 39384182
ER

PT J
AU Yang, Xintian
   Li, Tongxin
   Su, Qin
   Liu, Yaling
   Kang, Chenxi
   Lyu, Yong
   Zhao, Lina
   Nie, Yongzhan
   Pan, Yanglin
TI Application of large language models in disease diagnosis and treatment
SO CHINESE MEDICAL JOURNAL
VL 138
IS 2
BP 130
EP 142
DI 10.1097/CM9.0000000000003456
DT Review
PD JAN 20 2025
PY 2025
AB Large language models (LLMs) such as ChatGPT, Claude, Llama, and Qwen
   are emerging as transformative technologies for the diagnosis and
   treatment of various diseases. With their exceptional long-context
   reasoning capabilities, LLMs are proficient in clinically relevant
   tasks, particularly in medical text analysis and interactive dialogue.
   They can enhance diagnostic accuracy by processing vast amounts of
   patient data and medical literature and have demonstrated their utility
   in diagnosing common diseases and facilitating the identification of
   rare diseases by recognizing subtle patterns in symptoms and test
   results. Building on their image-recognition abilities, multimodal LLMs
   (MLLMs) show promising potential for diagnosis based on radiography,
   chest computed tomography (CT), electrocardiography (ECG), and common
   pathological images. These models can also assist in treatment planning
   by suggesting evidence-based interventions and improving clinical
   decision support systems through integrated analysis of patient records.
   Despite these promising developments, significant challenges persist
   regarding the use of LLMs in medicine, including concerns regarding
   algorithmic bias, the potential for hallucinations, and the need for
   rigorous clinical validation. Ethical considerations also underscore the
   importance of maintaining the function of supervision in clinical
   practice. This paper highlights the rapid advancements in research on
   the diagnostic and therapeutic applications of LLMs across different
   medical disciplines and emphasizes the importance of policymaking,
   ethical supervision, and multidisciplinary collaboration in promoting
   more effective and safer clinical applications of LLMs. Future
   directions include the integration of proprietary clinical knowledge,
   the investigation of open-source and customized models, and the
   evaluation of real-time effects in clinical diagnosis and treatment
   practices.
TC 2
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
Z9 2
DA 2025-01-25
UT WOS:001400214400011
PM 39722188
ER

PT J
AU Liu, Siru
   Wright, Aileen P.
   Mccoy, Allison B.
   Huang, Sean S.
   Genkins, Julian Z.
   Peterson, Josh F.
   Kumah-Crystal, Yaa A.
   Martinez, William
   Carew, Babatunde
   Mize, Dara
   Steitz, Bryan
   Wright, Adam
TI Using large language model to guide patients to create efficient and
   comprehensive clinical care message
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 8
DI 10.1093/jamia/ocae142
EA JUN 2024
DT Article
PD JUN 25 2024
PY 2024
AB Objective This study aims to investigate the feasibility of using Large
   Language Models (LLMs) to engage with patients at the time they are
   drafting a question to their healthcare providers, and generate
   pertinent follow-up questions that the patient can answer before sending
   their message, with the goal of ensuring that their healthcare provider
   receives all the information they need to safely and accurately answer
   the patient's question, eliminating back-and-forth messaging, and the
   associated delays and frustrations.Methods We collected a dataset of
   patient messages sent between January 1, 2022 to March 7, 2023 at
   Vanderbilt University Medical Center. Two internal medicine physicians
   identified 7 common scenarios. We used 3 LLMs to generate follow-up
   questions: (1) Comprehensive LLM Artificial Intelligence Responder
   (CLAIR): a locally fine-tuned LLM, (2) GPT4 with a simple prompt, and
   (3) GPT4 with a complex prompt. Five physicians rated them with the
   actual follow-ups written by healthcare providers on clarity,
   completeness, conciseness, and utility.Results For five scenarios, our
   CLAIR model had the best performance. The GPT4 model received higher
   scores for utility and completeness but lower scores for clarity and
   conciseness. CLAIR generated follow-up questions with similar clarity
   and conciseness as the actual follow-ups written by healthcare
   providers, with higher utility than healthcare providers and GPT4, and
   lower completeness than GPT4, but better than healthcare
   providers.Conclusion LLMs can generate follow-up patient messages
   designed to clarify a medical question that compares favorably to those
   generated by healthcare providers.
ZS 0
ZB 1
ZA 0
TC 6
ZR 0
Z8 0
Z9 6
DA 2024-07-02
UT WOS:001253441200001
PM 38917441
ER

PT J
AU Mondal, Agnibho
   Naskar, Arindam
   Roy Choudhury, Bhaskar
   Chakraborty, Sambudhya
   Biswas, Tanmay
   Sinha, Sumanta
   Roy, Sasmit
TI Evaluating the Performance and Safety of Large Language Models in
   Generating Type 2 Diabetes Mellitus Management Plans: A Comparative
   Study With Physicians Using Real Patient Records.
SO Cureus
VL 17
IS 3
BP e80737
EP e80737
DI 10.7759/cureus.80737
DT Journal Article
PD 2025-Mar
PY 2025
AB Background The integration of large language models (LLMs) such as GPT-4
   into healthcare presents potential benefits and challenges. While LLMs
   show promise in applications ranging from scientific writing to
   personalized medicine, their practical utility and safety in clinical
   settings remain under scrutiny. Concerns about accuracy, ethical
   considerations, and bias necessitate rigorous evaluation of these
   technologies against established medical standards. Methods This study
   involved a comparative analysis using anonymized patient records from a
   healthcare setting in the state of West Bengal, India. Management plans
   for 50 patients with type 2 diabetes mellitus were generated by GPT-4
   and three physicians, who were blinded to each other's responses. These
   plans were evaluated against a reference management plan based on
   American Diabetes Society guidelines. Completeness, necessity, and
   dosage accuracy were quantified and a Prescribing Error Score was
   devised to assess the quality of the generated management plans. The
   safety of the management plans generated by GPT-4 was also assessed.
   Results Results indicated that physicians' management plans had fewer
   missing medications compared to those generated by GPT-4 (p=0.008).
   However, GPT-4-generated management plans included fewer unnecessary
   medications (p=0.003). No significant difference was observed in the
   accuracy of drug dosages (p=0.975). The overall error scores were
   comparable between physicians and GPT-4 (p=0.301). Safety issues were
   noted in 16% of the plans generated by GPT-4, highlighting potential
   risks associated with AI-generated management plans. Conclusion The
   study demonstrates that while GPT-4 can effectively reduce unnecessary
   drug prescriptions, it does not yet match the performance of physicians
   in terms of plan completeness. The findings support the use of LLMs as
   supplementary tools in healthcare, highlighting the need for enhanced
   algorithms and continuous human oversight to ensure the efficacy and
   safety of artificial intelligence in clinical settings.
ZS 0
TC 0
ZB 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2025-04-20
UT MEDLINE:40248538
PM 40248538
ER

PT J
AU Cheungpasitporn, Wisit
   Thongprayoon, Charat
   Ronco, Claudio
   Kashani, Kianoush B.
TI Generative AI in Critical Care Nephrology: Applications and Future
   Prospects
SO BLOOD PURIFICATION
VL 53
IS 11-12
BP 871
EP 883
DI 10.1159/000541168
EA AUG 2024
DT Review
PD DEC 2024
PY 2024
AB Background: Generative artificial intelligence (AI) is rapidly
   transforming various aspects of healthcare, including critical care
   nephrology. Large language models (LLMs), a key technology in generative
   AI, show promise in enhancing patient care, streamlining workflows, and
   advancing research in this field. Summary: This review analyzes the
   current applications and future prospects of generative AI in critical
   care nephrology. Recent studies demonstrate the capabilities of LLMs in
   diagnostic accuracy, clinical reasoning, and continuous renal
   replacement therapy (CRRT) alarm troubleshooting. As we enter an era of
   multiagent models and automation, the integration of generative AI into
   critical care nephrology holds promise for improving patient care,
   optimizing clinical processes, and accelerating research. However,
   careful consideration of ethical implications and continued refinement
   of these technologies are essential for their responsible implementation
   in clinical practice. This review explores the current and potential
   applications of generative AI in nephrology, focusing on clinical
   decision support, patient education, research, and medical education.
   Additionally, we examine the challenges and limitations of AI
   implementation, such as privacy concerns, potential bias, and the
   necessity for human oversight. Key Messages: (i) LLMs have shown
   potential in enhancing diagnostic accuracy, clinical reasoning, and CRRT
   alarm troubleshooting in critical care nephrology. (ii) Generative AI
   offers promising applications in patient education, literature review,
   and academic writing within the field of nephrology. (iii) The
   integration of AI into electronic health records and clinical workflows
   presents both opportunities and challenges for improving patient care
   and research. (iv) Addressing ethical concerns, ensuring data privacy,
   and maintaining human oversight are crucial for the responsible
   implementation of AI in critical care nephrology.
ZA 0
ZS 0
ZR 0
TC 2
ZB 1
Z8 0
Z9 2
DA 2024-09-30
UT WOS:001319695700001
PM 39217985
ER

PT J
AU Williams, Christopher Y. K.
   Miao, Brenda Y.
   Kornblith, Aaron E.
   Butte, Atul J.
TI Evaluating the use of large language models to provide clinical
   recommendations in the Emergency Department
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 8236
DI 10.1038/s41467-024-52415-1
DT Article
PD OCT 8 2024
PY 2024
AB The release of GPT-4 and other large language models (LLMs) has the
   potential to transform healthcare. However, existing research evaluating
   LLM performance on real-world clinical notes is limited. Here, we
   conduct a highly-powered study to determine whether LLMs can provide
   clinical recommendations for three tasks (admission status, radiological
   investigation(s) request status, and antibiotic prescription status)
   using clinical notes from the Emergency Department. We randomly selected
   10,000 Emergency Department visits to evaluate the accuracy of
   zero-shot, GPT-3.5-turbo- and GPT-4-turbo-generated clinical
   recommendations across four different prompting strategies. We found
   that both GPT-4-turbo and GPT-3.5-turbo performed poorly compared to a
   resident physician, with accuracy scores 8% and 24%, respectively, lower
   than physician on average. Both LLMs tended to be overly cautious in its
   recommendations, with high sensitivity at the cost of specificity. Our
   findings demonstrate that, while early evaluations of the clinical use
   of LLMs are promising, LLM performance must be significantly improved
   before their deployment as decision support systems for clinical
   recommendations and other complex tasks.
   The emergence of large language models has the potential to transform
   healthcare. Here, the authors show that, when providing clinical
   recommendations, these models perform poorly compared to physicians and
   are overly cautious in their decisions.
ZA 0
TC 13
ZR 0
ZS 0
ZB 2
Z8 0
Z9 13
DA 2024-10-25
UT WOS:001331421200021
PM 39379357
ER

PT J
AU Huang, Yixing
   Gomaa, Ahmed
   Semrau, Sabine
   Haderlein, Marlen
   Lettmaier, Sebastian
   Weissmann, Thomas
   Grigo, Johanna
   Tkhayat, Hassen Ben
   Frey, Benjamin
   Gaipl, Udo
   Distel, Luitpold
   Maier, Andreas
   Fietkau, Rainer
   Bert, Christoph
   Putz, Florian
TI Benchmarking ChatGPT-4 on a radiation oncology in-training exam and Red
   Journal Gray Zone cases: potentials and challenges for ai-assisted
   medical education and decision making in radiation oncology
SO FRONTIERS IN ONCOLOGY
VL 13
AR 1265024
DI 10.3389/fonc.2023.1265024
DT Article
PD SEP 14 2023
PY 2023
AB PurposeThe potential of large language models in medicine for education
   and decision-making purposes has been demonstrated as they have achieved
   decent scores on medical exams such as the United States Medical
   Licensing Exam (USMLE) and the MedQA exam. This work aims to evaluate
   the performance of ChatGPT-4 in the specialized field of radiation
   oncology.MethodsThe 38th American College of Radiology (ACR) radiation
   oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone
   cases are used to benchmark the performance of ChatGPT-4. The TXIT exam
   contains 300 questions covering various topics of radiation oncology.
   The 2022 Gray Zone collection contains 15 complex clinical
   cases.ResultsFor the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved
   the scores of 62.05% and 78.77%, respectively, highlighting the
   advantage of the latest ChatGPT-4 model. Based on the TXIT exam,
   ChatGPT-4's strong and weak areas in radiation oncology are identified
   to some extent. Specifically, ChatGPT-4 demonstrates better knowledge of
   statistics, CNS & eye, pediatrics, biology, and physics than knowledge
   of bone & soft tissue and gynecology, as per the ACR knowledge domain.
   Regarding clinical care paths, ChatGPT-4 performs better in diagnosis,
   prognosis, and toxicity than brachytherapy and dosimetry. It lacks
   proficiency in in-depth details of clinical trials. For the Gray Zone
   cases, ChatGPT-4 is able to suggest a personalized treatment approach to
   each case with high correctness and comprehensiveness. Importantly, it
   provides novel treatment aspects for many cases, which are not suggested
   by any human experts.ConclusionBoth evaluations demonstrate the
   potential of ChatGPT-4 in medical education for the general public and
   cancer patients, as well as the potential to aid clinical
   decision-making, while acknowledging its limitations in certain domains.
   Owing to the risk of hallucinations, it is essential to verify the
   content generated by models such as ChatGPT for accuracy.
ZA 0
ZR 0
TC 56
ZB 10
Z8 0
ZS 1
Z9 56
DA 2023-12-23
UT WOS:001119288400001
PM 37790756
ER

PT J
AU McLean, Aaron Lawson
   Wu, Yonghui
   McLean, Anna C. Lawson
   Hristidis, Vagelis
TI Large language models as decision aids in neuro-oncology: a review of
   shared decision-making applications
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 3
AR 139
DI 10.1007/s00432-024-05673-x
DT Review
PD MAR 19 2024
PY 2024
AB Shared decision-making (SDM) is crucial in neuro-oncology, fostering
   collaborations between patients and healthcare professionals to navigate
   treatment options. However, the complexity of neuro-oncological
   conditions and the cognitive and emotional burdens on patients present
   significant barriers to achieving effective SDM. This discussion
   explores the potential of large language models (LLMs) such as OpenAI's
   ChatGPT and Google's Bard to overcome these barriers, offering a means
   to enhance patient understanding and engagement in their care. LLMs, by
   providing accessible, personalized information, could support but not
   supplant the critical insights of healthcare professionals. The
   hypothesis suggests that patients, better informed through LLMs, may
   participate more actively in their treatment choices. Integrating LLMs
   into neuro-oncology requires navigating ethical considerations,
   including safeguarding patient data and ensuring informed consent,
   alongside the judicious use of AI technologies. Future efforts should
   focus on establishing ethical guidelines, adapting healthcare workflows,
   promoting patient-oriented research, and developing training programs
   for clinicians on the use of LLMs. Continuous evaluation of LLM
   applications will be vital to maintain their effectiveness and alignment
   with patient needs. Ultimately, this exploration contends that the
   thoughtful integration of LLMs into SDM processes could significantly
   enhance patient involvement and strengthen the patient-physician
   relationship in neuro-oncology care.
ZR 0
ZB 1
ZA 0
ZS 0
TC 8
Z8 1
Z9 8
DA 2024-04-01
UT WOS:001187667700003
PM 38503921
ER

PT J
AU Balla, Yashaswini
   Tirunagari, Santosh
   Windridge, David
TI Pediatrics in Artificial Intelligence Era: A Systematic Review on
   Challenges, Opportunities, and Explainability
SO INDIAN PEDIATRICS
VL 60
IS 7
BP 561
EP 569
DI 10.1007/s13312-023-2936-8
DT Review
PD JUL 2023
PY 2023
AB BackgroundThe emergence of artificial intelligence (AI) tools such as
   ChatGPT and Bard is disrupting a broad swathe of fields, including
   medicine. In pediatric medicine, AI is also increasingly being used
   across multiple subspecialties. However, the practical application of AI
   still faces a number of key challenges. Consequently, there is a
   requirement for a concise overview of the roles of AI across the
   multiple domains of pediatric medicine, which the current study seeks to
   address.AimTo systematically assess the challenges, opportunities, and
   explainability of AI in pediatric medicine.MethodologyA systematic
   search was carried out on peer-reviewed databases, PubMed Central,
   Europe PubMed Central, and grey literature using search terms related to
   machine learning (ML) and AI for the years 2016 to 2022 in the English
   language. A total of 210 articles were retrieved that were screened with
   PRISMA for abstract, year, language, context, and proximal relevance to
   research aims. A thematic analysis was carried out to extract findings
   from the included studies.ResultsTwenty articles were selected for data
   abstraction and analysis, with three consistent themes emerging from
   these articles. In particular, eleven articles address the current
   state-of-the-art application of AI in diagnosing and predicting health
   conditions such as behavioral and mental health, cancer, syndromic and
   metabolic diseases. Five articles highlight the specific challenges of
   AI deployment in pediatric medicines: data security, handling,
   authentication, and validation. Four articles set out future
   opportunities for AI to be adapted: the incorporation of Big Data, cloud
   computing, precision medicine, and clinical decision support systems.
   These studies collectively critically evaluate the potential of AI in
   overcoming current barriers to adoption.ConclusionAI is proving
   disruptive within pediatric medicine and is presently associated with
   challenges, opportunities, and the need for explainability. AI should be
   viewed as a tool to enhance and support clinical decision-making rather
   than a substitute for human judgement and expertise. Future research
   should consequently focus on obtaining comprehensive data to ensure the
   generalizability of research findings.
ZB 2
ZR 0
ZS 0
ZA 0
TC 11
Z8 0
Z9 11
DA 2023-08-19
UT WOS:001034797100014
PM 37424120
ER

PT J
AU Giuffre, Mauro
   You, Kisung
   Chung, Sunny
   Kresevic, Simone
   Chan, Colleen
   Saarinen, Theo
   Nakamura, Shinpei
   Laine, Loren
   Sung, Joseph J. Y.
   Garcia-Tsao, Guadalupe
   Gralnek, Ian
   Barkun, Alan N.
   Sekhon, Jasjeet
   Shung, Dennis
TI GUTGPT: NOVEL LARGE LANGUAGE MODEL PIPELINE OUTPERFORMS OTHER LARGE
   LANGUAGE MODELS IN ACCURACY AND SIMILARITY TO INTERNATIONAL EXPERTS FOR
   GUIDELINE RECOMMENDED MANAGEMENT OF PATIENTS WITH UPPER GASTROINTESTINAL
   BLEEDING
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1979
BP S889
EP S890
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZR 0
TC 0
Z8 0
ZS 0
ZA 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837703480
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Mizuta, Kazuya
   Sakamoto, Tetsu
   Tokumasu, Kazuki
   Shimizu, Taro
TI Evaluating ChatGPT-4's Accuracy in Identifying Final Diagnoses Within
   Differential Diagnoses Compared With Those of Physicians: Experimental
   Study for Diagnostic Cases
SO JMIR FORMATIVE RESEARCH
VL 8
AR e59267
DI 10.2196/59267
DT Article
PD 2024
PY 2024
AB Background: The potential of artificial intelligence (AI) chatbots,
   particularly ChatGPT with GPT-4 (OpenAI), in assistingwith medical
   diagnosis is an emerging research area. However, it is not yet clear how
   well AI chatbots can evaluate whether thefinal diagnosis is included in
   differential diagnosis lists. Objective: This study aims to assess the
   capability of GPT-4 in identifying the final diagnosis from
   differential-diagnosis listsand to compare its performance with that of
   physicians for case report series. Methods: We used a database of
   differential-diagnosis lists from case reports in the American Journal
   of Case Reports,corresponding to final diagnoses. These lists were
   generated by 3 AI systems: GPT-4, Google Bard (currently Google
   Gemini),and Large Language Models by Meta AI 2 (LLaMA2). The primary
   outcome was focused on whether GPT-4's evaluationsidentified the final
   diagnosis within these lists. None of these AIs received additional
   medical training or reinforcement. Forcomparison, 2 independent
   physicians also evaluated the lists, with any inconsistencies resolved
   by another physician. Results: The 3 AIs generated a total of 1176
   differential diagnosis lists from 392 case descriptions. GPT-4's
   evaluations concurredwith those of the physicians in 966 out of 1176
   lists (82.1%). The Cohen kappa coefficient was 0.63 (95% CI 0.56-0.69),
   indicatinga fair to good agreement between GPT-4 and the physicians'
   evaluations. Conclusions: GPT-4 demonstrated a fair to good agreement in
   identifying the final diagnosis from differential-diagnosis
   lists,comparable to physicians for case report series. Its ability to
   compare differential diagnosis lists with final diagnoses suggests
   itspotential to aid clinical decision-making support through diagnostic
   feedback. While GPT-4 showed a fair to good agreement forevaluation, its
   application in real-world scenarios and further validation in diverse
   clinical environments are essential to fullyunderstand its utility in
   the diagnostic process.
ZS 0
ZB 0
TC 5
ZA 0
ZR 0
Z8 0
Z9 5
DA 2024-09-21
UT WOS:001303612400011
PM 38924784
ER

PT J
AU Marchi, Filippo
   Bellini, Elisa
   Iandelli, Andrea
   Sampieri, Claudio
   Peretti, Giorgio
TI Exploring the landscape of AI-assisted decision-making in head and neck
   cancer treatment: a comparative analysis of NCCN guidelines and ChatGPT
   responses
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 2123
EP 2136
DI 10.1007/s00405-024-08525-z
EA FEB 2024
DT Article
PD APR 2024
PY 2024
AB PurposeRecent breakthroughs in natural language processing and machine
   learning, exemplified by ChatGPT, have spurred a paradigm shift in
   healthcare. Released by OpenAI in November 2022, ChatGPT rapidly gained
   global attention. Trained on massive text datasets, this large language
   model holds immense potential to revolutionize healthcare. However,
   existing literature often overlooks the need for rigorous validation and
   real-world applicability.MethodsThis head-to-head comparative study
   assesses ChatGPT's capabilities in providing therapeutic recommendations
   for head and neck cancers. Simulating every NCCN Guidelines scenarios.
   ChatGPT is queried on primary treatments, adjuvant treatment, and
   follow-up, with responses compared to the NCCN Guidelines. Performance
   metrics, including sensitivity, specificity, and F1 score, are employed
   for assessment.ResultsThe study includes 68 hypothetical cases and 204
   clinical scenarios. ChatGPT exhibits promising capabilities in
   addressing NCCN-related queries, achieving high sensitivity and overall
   accuracy across primary treatment, adjuvant treatment, and follow-up.
   The study's metrics showcase robustness in providing relevant
   suggestions. However, a few inaccuracies are noted, especially in
   primary treatment scenarios.ConclusionOur study highlights the
   proficiency of ChatGPT in providing treatment suggestions. The model's
   alignment with the NCCN Guidelines sets the stage for a nuanced
   exploration of AI's evolving role in oncological decision support.
   However, challenges related to the interpretability of AI in clinical
   decision-making and the importance of clinicians understanding the
   underlying principles of AI models remain unexplored. As AI continues to
   advance, collaborative efforts between models and medical experts are
   deemed essential for unlocking new frontiers in personalized cancer
   care.
ZB 4
ZA 0
TC 18
Z8 0
ZR 0
ZS 0
Z9 18
DA 2024-04-24
UT WOS:001172712200001
PM 38421392
ER

PT B
AU Evans, Parker Timothy
Z2  
TI Data Driven Order Set Design in Pediatric Appendicitis
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
ZB 0
ZA 0
ZR 0
Z8 0
ZS 0
TC 0
Z9 0
UT PQDT:91785236
ER

PT J
AU Brown, Ethan D L
   Shah, Harshal A
   Donnelly, Brianna M
   Ward, Max
   Vojnic, Morana
   D'Amico, Randy S
TI Precision Oncology in Non-small Cell Lung Cancer: A Comparative Study of
   Contextualized ChatGPT Models.
SO Cureus
VL 17
IS 3
BP e81097
EP e81097
DI 10.7759/cureus.81097
DT Journal Article
PD 2025-Mar
PY 2025
AB OBJECTIVES: The growing adoption of Large Language Models (LLMs) in
   medicine has raised important questions about theirpotential utility for
   clinical decision support within oncology. This study aimed to evaluate
   the effects of various contextualization methods on ChatGPT's ability to
   provide National Comprehensive Cancer Network (NCCN) guideline-aligned
   recommendations on managing non-small cell lung cancer (NSCLC).
   METHODOLOGY: GPT-4o, base GPT-4, and GPT-4 models contextualized with
   prompts and PDF documents were asked to identify preferred
   chemotherapies for twelve advanced lung cancers given molecular profiles
   derived from the 2024 NCCN Clinical Practice Guidelines in Oncology for
   NSCLC. GPT responses were subsequently compared to NCCN guidelines using
   readability scores and qualitative reviewer assessments of (1)
   recommendation of specific targeted therapy, (2) agreement with
   NCCN-guideline-preferred therapies, (3) recommendation of guideline
   non-concordant therapies, and (4) provision of supplementary
   information.
   RESULTS: The PDF+Prompt contextualized model demonstrated elevated
   agreement scores of 23/24 versus 17/24 for GPT-4 (P= 0.040) and 18/24
   for GPT-4o (P= 0.089). No PDF+Prompt model responses contained guideline
   non-concordant therapies in contrast to 4/12 responses for GPT4 (P=
   0.093) and 5/12 responses for GPT4o (P= 0.037). Comparison of response
   readability between the PDF+Prompt model and GPT-4 or GPT-4o showed a
   lower mean word count (bothP< 0.001), Simple Measure of Gobbledygook
   (SMOG) score (bothP< 0.001), and Gunning Fog readability score (P< 0.001
   for GPT-4,P= 0.002 for GPT-4o). Prompting alone did not significantly
   improve agreement or reduce the rate of non-concordant therapy
   recommendations.
   CONCLUSIONS: The performance gains observed following contextualization
   suggest that broader applications of LLMs in oncology may exist than
   current literature indicates. This study provides proof of concept for
   the use of contextualized GPT models in oncology and showcases their
   accessibility. Future studies validating this application within
   additional cancer types or real-life patient encounters could provide an
   important bridge to eventual adoption.
TC 0
ZS 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 0
DA 2025-04-26
UT MEDLINE:40271313
PM 40271313
ER

PT J
AU Li, Yiming
   Peng, Xueqing
   Li, Jianfu
   Zuo, Xu
   Peng, Suyuan
   Pei, Donghong
   Tao, Cui
   Xu, Hua
   Hong, Na
TI Relation extraction using large language models: a case study on
   acupuncture point locations
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 11
BP 2622
EP 2631
DI 10.1093/jamia/ocae233
EA AUG 2024
DT Article
PD AUG 29 2024
PY 2024
AB Objective In acupuncture therapy, the accurate location of acupoints is
   essential for its effectiveness. The advanced language understanding
   capabilities of large language models (LLMs) like Generative Pre-trained
   Transformers (GPTs) and Llama present a significant opportunity for
   extracting relations related to acupoint locations from textual
   knowledge sources. This study aims to explore the performance of LLMs in
   extracting acupoint-related location relations and assess the impact of
   fine-tuning on GPT's performance.Materials and Methods We utilized the
   World Health Organization Standard Acupuncture Point Locations in the
   Western Pacific Region (WHO Standard) as our corpus, which consists of
   descriptions of 361 acupoints. Five types of relations ("direction_of",
   "distance_of", "part_of", "near_acupoint", and "located_near") (n =
   3174) between acupoints were annotated. Four models were compared:
   pre-trained GPT-3.5, fine-tuned GPT-3.5, pre-trained GPT-4, as well as
   pretrained Llama 3. Performance metrics included micro-average exact
   match precision, recall, and F1 scores.Results Our results demonstrate
   that fine-tuned GPT-3.5 consistently outperformed other models in F1
   scores across all relation types. Overall, it achieved the highest
   micro-average F1 score of 0.92.Discussion The superior performance of
   the fine-tuned GPT-3.5 model, as shown by its F1 scores, underscores the
   importance of domain-specific fine-tuning in enhancing relation
   extraction capabilities for acupuncture-related tasks. In light of the
   findings from this study, it offers valuable insights into leveraging
   LLMs for developing clinical decision support and creating educational
   modules in acupuncture.Conclusion This study underscores the
   effectiveness of LLMs like GPT and Llama in extracting relations related
   to acupoint locations, with implications for accurately modeling
   acupuncture knowledge and promoting standard implementation in
   acupuncture training and practice. The findings also contribute to
   advancing informatics applications in traditional and complementary
   medicine, showcasing the potential of LLMs in natural language
   processing.
ZS 0
ZR 0
TC 5
ZB 2
Z8 0
ZA 0
Z9 5
DA 2024-09-02
UT WOS:001300170700001
PM 39208311
ER

PT J
AU Sandmann, Sarah
   Riepenhausen, Sarah
   Plagwitz, Lucas
   Varghese, Julian
TI Systematic analysis of ChatGPT, Google search and Llama 2 for clinical
   decision support tasks
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 2050
DI 10.1038/s41467-024-46411-8
DT Article
PD MAR 6 2024
PY 2024
AB It is likely that individuals are turning to Large Language Models
   (LLMs) to seek health advice, much like searching for diagnoses on
   Google. We evaluate clinical accuracy of GPT-3 center dot 5 and GPT-4
   for suggesting initial diagnosis, examination steps and treatment of 110
   medical cases across diverse clinical disciplines. Moreover, two model
   configurations of the Llama 2 open source LLMs are assessed in a
   sub-study. For benchmarking the diagnostic task, we conduct a naive
   Google search for comparison. Overall, GPT-4 performed best with
   superior performances over GPT-3 center dot 5 considering diagnosis and
   examination and superior performance over Google for diagnosis. Except
   for treatment, better performance on frequent vs rare diseases is
   evident for all three approaches. The sub-study indicates slightly lower
   performances for Llama models. In conclusion, the commercial LLMs show
   growing potential for medical question answering in two successive major
   releases. However, some weaknesses underscore the need for robust and
   regulated AI models in health care. Open source LLMs can be a viable
   option to address specific needs regarding data privacy and transparency
   of training.
   People will likely use ChatGPT to seek health advice. Here, the authors
   show promising performance of ChatGPT and open source models, but a lack
   of high accuracy considering medical question answering. Improvements
   are expected over time via domain-specific finetuning and integration of
   regulations.
ZS 0
ZR 0
Z8 3
ZB 11
TC 56
ZA 0
Z9 59
DA 2024-04-03
UT WOS:001180826600013
PM 38448475
ER

PT J
AU Robinson, Jamie R.
   Stey, Anne
   Schneider, David F.
   Kothari, Anai N.
   Lindeman, Brenessa
   Kaafarani, Haytham M.
   Haines, Krista L.
TI Generative Artificial Intelligence in Academic Surgery: Ethical
   Implications and Transformative Potential
SO JOURNAL OF SURGICAL RESEARCH
VL 307
BP 212
EP 220
DI 10.1016/j.jss.2024.12.059
EA APR 2025
DT Article
PD MAR 2025
PY 2025
AB Artificial intelligence (AI) is rapidly being used in medicine due to
   its advanced capabilities in image and video recognition, clinical
   decision support, surgical education, and administrative task
   automation. Large language models such as OpenAI's Generative Pretrained
   Transformer (GPT)-4 and Google's Bard have particularly revolutionized
   text generation, offering substantial benefits for the academic surgeon,
   including aiding in manuscript and grant writing. However, integrating
   AI into academic surgery necessitates addressing ethical concerns such
   as bias, transparency, and intellectual property. This paper provides
   guidelines and recommendations based on current literature around the
   opportunities and ethical challenges of AI in academic surgery. We
   discuss the underlying mechanisms of large language models, their
   potential biases, and the importance of responsible usage. Furthermore,
   we explore the ethical implications of AI in clinical documentation,
   highlighting improved efficiency and necessary privacy concerns. This
   review also addresses the critical issue of intellectual property
   dilemmas posed by AI-generated innovations in university settings.
   Finally, we propose guidelines for the responsible adoption of AI in
   academic and clinical environments, stressing the need for transparency,
   ethical training,and robust governance frameworks to ensure AI enhances,
   rather than undermines, academic integrity and patient care. (c) 2025
   The Author(s). Published by Elsevier Inc. This is an open access article
   under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZA 0
TC 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 0
DA 2025-04-17
UT WOS:001462940700001
PM 39934059
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Kresevic, Simone
   Giuffre, Mauro
   Shung, Dennis
TI ENHANCING CLINICAL DECISION SUPPORT WITH LARGE LANGUAGE MODELS: A
   TAILORED PIPELINE FOR ACCURATE INTERPRETATION OF HEPATITIS C MANAGEMENT
   GUIDELINES
SO GASTROENTEROLOGY
VL 166
IS 5
MA 1059
BP S1564
EP S1564
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZB 0
ZS 0
ZA 0
Z8 0
ZR 0
TC 0
Z9 0
DA 2024-10-30
UT WOS:001282837706291
ER

PT J
AU Feldman, Mitchell J.
   Hoffer, Edward P.
   Conley, Jared J.
   Chang, Jaime
   Chung, Jeanhee A.
   Jernigan, Michael C.
   Lester, William T.
   Strasser, Zachary H.
   Chueh, Henry C.
TI Dedicated AI Expert System vs Generative AI With Large Language Model
   for Clinical Diagnoses
SO JAMA NETWORK OPEN
VL 8
IS 5
AR e2512994
DI 10.1001/jamanetworkopen.2025.12994
DT Article
PD MAY 29 2025
PY 2025
AB Importance Large language models (LLMs) have not yet been compared with
   traditional diagnostic decision support systems (DDSSs) on unpublished
   clinical cases. Objective To compare the performance of 2 widely used
   LLMs (ChatGPT, version 4 [hereafter, LLM1] and Gemini, version 1.5
   [hereafter, LLM2]) with a DDSS (DXplain [hereafter, DDSS]) on 36
   unpublished general medicine cases. Design, Setting, and Participants
   This diagnostic study, conducted from October 6, 2023, to November 22,
   2024, looked for the presence of the known case diagnosis in the
   differential diagnoses of the LLMs and DDSS after data from previously
   unpublished clinical cases from 3 academic medical centers were entered.
   The systems' performance was assessed both with and without laboratory
   test data. Each case was reviewed by 3 physicians blinded to the case
   diagnosis. Physicians identified all clinical findings as well as the
   subset deemed relevant to making the diagnosis for mapping to the DDSS's
   controlled vocabulary. Two other physicians, also blinded to the
   diagnoses, entered the data from these cases into the DDSS, LLM1, and
   LLM2. Exposures All cases were entered into each LLM twice, with and
   without laboratory test results. For the DDSS, each case was entered 4
   times: for all findings and for findings relevant to the diagnosis, each
   with and without laboratory test results. The top 25 diagnoses in each
   resulting differential diagnosis were reviewed. Main Outcomes and
   Measures Presence or absence of the case diagnosis in the system's
   differential diagnosis and, when present, in which quintile it appeared
   in the top 25 diagnoses. Results Among 36 patient cases of various races
   and ethnicities, genders, and ages (mean [SD] age, 51.4 [16.4] years),
   in the version with all findings but no laboratory test results, the
   DDSS listed the case diagnosis in its differential diagnosis more often
   (56% [20 of 36]) than LLM1 (42% [15 of 36]) and LLM2 (39% [14 of 36]),
   although this difference did not reach statistical significance (DDSS vs
   LLMI, P = .09; DDSS vs LLM2, P = .08). All 3 systems listed the case
   diagnosis in most cases if laboratory test results were included (all
   findings DDSS, 72% [26 of 36]; LLM1, 64% [23 of 36]; and LLM2, 58% [21
   of 36]). Conclusions and Relevance In this diagnostic study comparing
   the performance of a traditional DDSS and current LLMs on unpublished
   clinical cases, in most cases, every system listed the case diagnosis in
   their top 25 diagnoses if laboratory test results were included. A
   hybrid approach that combines the parsing and expository linguistic
   capabilities of LLMs with the deterministic and explanatory capabilities
   of traditional DDSSs may produce synergistic benefits.
ZA 0
Z8 0
TC 0
ZR 0
ZB 0
ZS 0
Z9 0
DA 2025-06-05
UT WOS:001499415200009
PM 40440012
ER

PT J
AU Afshar, Majid
   Gao, Yanjun
   Gupta, Deepak
   Croxford, Emma
   Demner-Fushman, Dina
TI On the role of the UMLS in supporting diagnosis generation proposed by
   Large Language Models
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 157
AR 104707
DI 10.1016/j.jbi.2024.104707
EA AUG 2024
DT Article
PD SEP 2024
PY 2024
AB Objective: Traditional knowledge-based and machine learning diagnostic
   decision support systems have benefited from integrating the medical
   domain knowledge encoded in the Unified Medical Language System (UMLS).
   The emergence of Large Language Models (LLMs) to supplant traditional
   systems poses questions of the quality and extent of the medical
   knowledge in the models' internal knowledge representations and the need
   for external knowledge sources. The objective of this study is
   three-fold: to probe the diagnosis-related medical knowledge of popular
   LLMs, to examine the benefit of providing the UMLS knowledge to LLMs
   (grounding the diagnosis predictions), and to evaluate the correlations
   between human judgments and the UMLS-based metrics for generations by
   LLMs. Methods: We evaluated diagnoses generated by LLMs from consumer
   health questions and daily care notes in the electronic health records
   using the ConsumerQA and Problem Summarization datasets. Probing LLMs
   for the UMLS knowledge was performed by prompting the LLM to complete
   the diagnosis-related UMLS knowledge paths. Grounding the predictions
   was examined in an approach that integrated the UMLS graph paths and
   clinical notes in prompting the LLMs. The results were compared to
   prompting without the UMLS paths. The final experiments examined the
   alignment of different evaluation metrics, UMLS-based and non-UMLS, with
   human expert evaluation. Results: In probing the UMLS knowledge, GPT-3.5
   significantly outperformed Llama2 and a simple baseline yielding an F1
   score of 10.9% in completing one-hop UMLS paths for a given concept.
   Grounding diagnosis predictions with the UMLS paths improved the results
   for both models on both tasks, with the highest improvement (4%) in
   SapBERT score. There was a weak correlation between the widely used
   evaluation metrics (ROUGE and SapBERT) and human judgments. Conclusion:
   We found that while popular LLMs contain some medical knowledge in their
   internal representations, augmentation with the UMLS knowledge provides
   performance gains around diagnosis generation. The UMLS needs to be
   tailored for the task to improve the LLMs predictions. Finding
   evaluation metrics that are aligned with human judgments better than the
   traditional ROUGE and BERT-based scores remains an open research
   question.
ZA 0
ZR 0
ZS 0
TC 2
ZB 0
Z8 0
Z9 2
DA 2024-09-02
UT WOS:001300508200001
PM 39142598
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Shi, Boqun
   Chen, Liangguo
   Pang, Shuo
   Wang, Yue
   Wang, Shen
   Li, Fadong
   Zhao, Wenxin
   Guo, Pengrong
   Zhang, Leli
   Fan, Chu
   Zou, Yi
   Wu, Xiaofan
TI Large Language Models and Artificial Neural Networks for Assessing
   1-Year Mortality in Patients With Myocardial Infarction: Analysis From
   the Medical Information Mart for Intensive Care IV (MIMIC-IV) Database
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e67253
DI 10.2196/67253
DT Article
PD MAY 12 2025
PY 2025
AB Background:Accurate mortality risk prediction is crucial for effective
   cardiovascular risk management. Recent advancements in artificial
   intelligence (AI) have demonstrated potential in this specific medical
   field. Qwen-2 and Llama-3 are high-performance, open-source large
   language models (LLMs) available online. An artificial neural network
   (ANN) algorithm derived from the SWEDEHEART (Swedish Web System for
   Enhancement and Development of Evidence-Based Care in Heart Disease
   Evaluated According to Recommended Therapies) registry, termed
   SWEDEHEART-AI, can predict patient prognosis following acute myocardial
   infarction (AMI). Objective:This study aims to evaluate the 3 models
   mentioned above in predicting 1-year all-cause mortality in critically
   ill patients with AMI. Methods:The Medical Information Mart for
   Intensive Care IV (MIMIC-IV) database is a publicly available data set
   in critical care medicine. We included 2758 patients who were first
   admitted for AMI and discharged alive. SWEDEHEART-AI calculated the
   mortality rate based on each patient's 21 clinical variables. Qwen-2 and
   Llama-3 analyzed the content of patients' discharge records and directly
   provided a 1-decimal value between 0 and 1 to represent 1-year death
   risk probabilities. The patients' actual mortality was verified using
   follow-up data. The predictive performance of the 3 models was assessed
   and compared using the Harrell C-statistic (C-index), the area under the
   receiver operating characteristic curve (AUROC), calibration plots,
   Kaplan-Meier curves, and decision curve analysis. Results:SWEDEHEART-AI
   demonstrated strong discrimination in predicting 1-year all-cause
   mortality in patients with AMI, with a higher C-index than Qwen-2 and
   Llama-3 (C-index 0.72, 95% CI 0.69-0.74 vs C-index 0.65, 0.62-0.67 vs
   C-index 0.56, 95% CI 0.53-0.58, respectively; all P<.001 for both
   comparisons). SWEDEHEART-AI also showed high and consistent AUROC in the
   time-dependent ROC curve. The death rates calculated by SWEDEHEART-AI
   were positively correlated with actual mortality, and the 3 risk classes
   derived from this model showed clear differentiation in the Kaplan-Meier
   curve (P<.001). Calibration plots indicated that SWEDEHEART-AI tended to
   overestimate mortality risk, with an observed-to-expected ratio of
   0.478. Compared with the LLMs, SWEDEHEART-AI demonstrated positive and
   greater net benefits at risk thresholds below 19%.
   Conclusions:SWEDEHEART-AI, a trained ANN model, demonstrated the best
   performance, with strong discrimination and clinical utility in
   predicting 1-year all-cause mortality in patients with AMI from an
   intensive care cohort. Among the LLMs, Qwen-2 outperformed Llama-3 and
   showed moderate predictive value. Qwen-2 and SWEDEHEART-AI exhibited
   comparable classification effectiveness. The future integration of LLMs
   into clinical decision support systems holds promise for accurate risk
   stratification in patients with AMI; however, further research is needed
   to optimize LLM performance and address calibration issues across
   diverse patient populations.
ZA 0
ZB 0
ZR 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2025-06-06
UT WOS:001495317500003
PM 40354652
ER

PT J
AU Shaheen, Abdulla
   Afflitto, Gabriele Gallo
   Swaminathan, Swarup S.
TI ChatGPT-Assisted Classification fi cation of Postoperative Bleeding
   Following Microinvasive Glaucoma Surgery Using Electronic Health Record
   Data
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100602
DI 10.1016/j.xops.2024.100602
EA SEP 2024
DT Article
PD FEB 2025
PY 2025
AB Purpose: To evaluate the performance of a large language model (LLM) in
   classifying electronic health record (EHR) text, and to use this
   classification to evaluate the type and resolution of hemorrhagic events
   (HEs) after microinvasive glaucoma surgery (MIGS). Design: Retrospective
   cohort study. Participants: Eyes from the Bascom Palmer Glaucoma
   Repository. Methods: Eyes that underwent MIGS between July 1, 2014 and
   February 1, 2022 were analyzed. Chat Generative Pre-trained Transformer
   (ChatGPT) was used to classify deidentified EHR anterior chamber
   examination text into HE categories (no hyphema, microhyphema, clot, and
   hyphema). Agreement between classifications by ChatGPT and a glaucoma
   specialist was evaluated using Cohen's Kappa and precision-recall (PR)
   curve. Time to resolution of HEs was assessed using Cox
   proportional-hazards models. Goniotomy HE resolution was evaluated by
   degree of angle treatment (90 degrees-179 degrees,180 degrees-269
   degrees, 270 degrees-360 degrees). degrees-360 degrees ). Logistic
   regression was used to identify HE risk factors. Main Outcome Measures:
   Accuracy of ChatGPT HE classification and incidence and resolution of
   HEs. Results: The study included 434 goniotomy eyes (368 patients) and
   528 Schlemm's canal stent (SCS) eyes (390 patients). Chat Generative
   Pre-trained Transformer facilitated excellent HE classification (Cohen's
   kappa 0.93, area under PR curve 0.968). Using ChatGPT classifications,
   at postoperative day 1, HEs occurred in 67.8% of goniotomy and 25.2% of
   SCS eyes (P < 0.001). The 270 degrees degrees to 360 degrees degrees
   goniotomy group had the highest HE rate (84.0%, P < 0.001). At
   postoperative week 1, HEs were observed in 43.4% and 11.3% of goniotomy
   and SCS eyes, respectively (P < 0.001). By postoperative month 1, HE
   rates were 13.3% and 1.3% among goniotomy and SCS eyes, respectively (P
   < 0.001). Time to HE resolution differed between the goniotomy angle
   groups (log-rank P = 0.034); median time to resolution was 10, 10, and
   15 days for the 90 degrees degrees to 179 degrees, 180 degrees to 269
   degrees, and 270 degrees to 360 degrees groups, respectively. Risk
   factor analysis demonstrated greater goniotomy angle was the only
   significant predictor of HEs (odds ratio for 270 degrees-360 degrees:
   360 degrees : 4.08, P < 0.001). Conclusions: Large language models can
   be effectively used to classify longitudinal EHR free-text examination
   data with high accuracy, highlighting a promising direction for future
   LLM-assisted research and clinical decision support. Hemorrhagic events
   are relatively common self-resolving complications that occur more often
   in goniotomy cases and with larger goniotomy treatments. Time to HE
   resolution differs significantly between goniotomy groups. Financial
   Disclosure(s):Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100602<feminine ordinal indicator>2024 by the American
   Academy of Ophthalmology. This is an open access article under the CC
   BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
DA 2024-10-05
UT WOS:001321792000001
PM 39380881
ER

PT J
AU Hager, Paul
   Jungmann, Friederike
   Holland, Robbie
   Bhagat, Kunal
   Hubrecht, Inga
   Knauer, Manuel
   Vielhauer, Jakob
   Makowski, Marcus
   Braren, Rickmer
   Kaissis, Georgios
   Rueckert, Daniel
TI Evaluation and mitigation of the limitations of large language models in
   clinical decision-making
SO NATURE MEDICINE
VL 30
IS 9
DI 10.1038/s41591-024-03097-1
EA JUL 2024
DT Article
PD SEP 2024
PY 2024
AB Clinical decision-making is one of the most impactful parts of a
   physician's responsibilities and stands to benefit greatly from
   artificial intelligence solutions and large language models (LLMs) in
   particular. However, while LLMs have achieved excellent performance on
   medical licensing exams, these tests fail to assess many skills
   necessary for deployment in a realistic clinical decision-making
   environment, including gathering information, adhering to guidelines,
   and integrating into clinical workflows. Here we have created a curated
   dataset based on the Medical Information Mart for Intensive Care
   database spanning 2,400 real patient cases and four common abdominal
   pathologies as well as a framework to simulate a realistic clinical
   setting. We show that current state-of-the-art LLMs do not accurately
   diagnose patients across all pathologies (performing significantly worse
   than physicians), follow neither diagnostic nor treatment guidelines,
   and cannot interpret laboratory results, thus posing a serious risk to
   the health of patients. Furthermore, we move beyond diagnostic accuracy
   and demonstrate that they cannot be easily integrated into existing
   workflows because they often fail to follow instructions and are
   sensitive to both the quantity and order of information. Overall, our
   analysis reveals that LLMs are currently not ready for autonomous
   clinical decision-making while providing a dataset and framework to
   guide future studies.
   Using a curated dataset of 2,400 cases and a framework to simulate a
   realistic clinical setting, current large language models are shown to
   incur substantial pitfalls when used for autonomous clinical
   decision-making.
ZA 0
TC 80
Z8 0
ZR 0
ZB 13
ZS 0
Z9 80
DA 2024-07-12
UT WOS:001262233500004
PM 38965432
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Tokumasu, Kazuki
   Ito, Takahiro
   Suzuki, Tomoharu
   Shimizu, Taro
TI Evaluating ChatGPT-4's Diagnostic Accuracy: Impact of Visual Data
   Integration
SO JMIR MEDICAL INFORMATICS
VL 12
AR e55627
DI 10.2196/55627
DT Article
PD 2024
PY 2024
AB Background: In the evolving field of health care, multimodal generative
   artificial intelligence (AI) systems, such as ChatGPT-4 with vision
   (ChatGPT-4V), represent a significant advancement, as they integrate
   visual data with text data. This integration has the potential to
   revolutionize clinical diagnostics by offering more comprehensive
   analysis capabilities. However, the impact on diagnostic accuracy of
   using image data to augment ChatGPT-4 remains unclear. Objective: This
   study aims to assess the impact of adding image data on ChatGPT-4's
   diagnostic accuracy and provide insights into how image data integration
   can enhance the accuracy of multimodal AI in medical diagnostics.
   Specifically, this study endeavored to compare the diagnostic accuracy
   between ChatGPT-4V, which processed both text and image data, and its
   counterpart, ChatGPT-4, which only uses text data. Methods: We
   identified a total of 557 case reports published in the American Journal
   of Case Reports from January 2022 to March 2023. After excluding cases
   that were nondiagnostic, pediatric, and lacking image data, we included
   363 case descriptions with their final diagnoses and associated images.
   We compared the diagnostic accuracy of ChatGPT-4V and ChatGPT-4 without
   vision based on their ability to include the final diagnoses within
   differential diagnosis lists. Two independent physicians evaluated their
   accuracy, with a third resolving any discrepancies, ensuring a rigorous
   and objective analysis. Results: The integration of image data into
   ChatGPT-4V did not significantly enhance diagnostic accuracy, showing
   that final diagnoses were included in the top 10 differential diagnosis
   lists at a rate of 85.1% (n=309), comparable to the rate of 87.9%
   (n=319) for the text -only version ( P =.33). Notably, ChatGPT-4V's
   performance in correctly identifying the top diagnosis was inferior, at
   44.4% (n=161), compared with 55.9% (n=203) for the text -only version (
   P =.002, chi 2 test). Additionally, ChatGPT-4's self -reports showed
   that image data accounted for 30% of the weight in developing the
   differential diagnosis lists in more than half of cases. Conclusions:
   Our findings reveal that currently, ChatGPT-4V predominantly relies on
   textual data, limiting its ability to fully use the diagnostic potential
   of visual information. This study underscores the need for further
   development of multimodal generative AI systems to effectively integrate
   and use clinical image data. Enhancing the diagnostic performance of
   such AI systems through improved multimodal data integration could
   significantly benefit patient care by providing more accurate and
   comprehensive diagnostic insights. Future research should focus on
   overcoming these limitations, paving the way for the practical
   application of advanced AI in medicine.
ZB 2
Z8 1
TC 11
ZA 0
ZR 0
ZS 0
Z9 11
DA 2024-05-16
UT WOS:001217446200001
PM 38592758
ER

PT J
AU Preiksaitis, Carl
   Ashenburg, Nicholas
   Bunney, Gabrielle
   Chu, Andrew
   Kabeer, Rana
   Riley, Fran
   Ribeira, Ryan
   Rose, Christian
TI The Role of Large Language Models in Transforming Emergency Medicine:
   Scoping Review
SO JMIR MEDICAL INFORMATICS
VL 12
AR e53787
DI 10.2196/53787
DT Review
PD 2024
PY 2024
AB Background: Artificial intelligence (AI), more specifically large
   language models (LLMs), holds significant potential in revolutionizing
   emergency care delivery by optimizing clinical workflows and enhancing
   the quality of decision-making. Although enthusiasm for integrating LLMs
   into emergency medicine (EM) is growing, the existing literature is
   characterized by a disparate collection of individual studies,
   conceptual analyses, and preliminary implementations. Given these
   complexities and gaps in understanding, a cohesive framework is needed
   to comprehend the existing body of knowledge on the application of LLMs
   in Objective: Given the absence of a comprehensive framework for
   exploring the roles of LLMs in EM, this scoping review aims to
   systematically map the existing literature on LLMs' potential
   applications within EM and identify directions for future research.
   Addressing this gap will allow for informed advancements in the field.
   Methods: Using PRISMA-ScR (Preferred Reporting Items for Systematic
   Reviews and Meta-Analyses extension for Scoping Reviews) criteria, we
   searched Ovid MEDLINE, Embase, Web of Science, and Google Scholar for
   papers published between January 2018 and August 2023 that discussed
   LLMs' use in EM. We excluded other forms of AI. A total of 1994 unique
   titles and abstracts were screened, and each full-text paper was
   independently reviewed by 2 authors. Data were abstracted independently,
   and 5 authors performed a collaborative quantitative and qualitative
   synthesis of the data. Results: A total of 43 papers were included.
   Studies were predominantly from 2022 to 2023 and conducted in the United
   States and China. We uncovered four major themes: (1) clinical
   decision-making and support was highlighted as a pivotal area, with LLMs
   playing a substantial role in enhancing patient care, notably through
   their application in real-time triage, allowing early recognition of
   patient urgency; (2) efficiency, workflow, and information management
   demonstrated the capacity of LLMs to significantly boost operational
   efficiency, particularly through the automation of patient record
   synthesis, which could reduce administrative burden and enhance
   patient-centric care; (3) risks, ethics, and transparency were
   identified as areas of concern, especially regarding the reliability of
   LLMs' outputs, and specific studies highlighted the challenges of
   ensuring unbiased decision-making amidst potentially flawed training
   data sets, stressing the importance of thorough validation and ethical
   oversight; and (4) education and communication possibilities included
   LLMs' capacity to enrich medical training, such as through using
   simulated patient interactions that enhance communication skills.
   Conclusions: LLMs have the potential to fundamentally transform EM,
   enhancing clinical decision-making, optimizing workflows, and improving
   patient outcomes. This review sets the stage for future advancements by
   identifying key research areas: prospective validation of LLM
   applications, establishing standards for responsible use, understanding
   provider and patient perceptions, and improving physicians' AI literacy.
   Effective integration of LLMs into EM will require collaborative efforts
   and thorough evaluation to ensure these technologies can be safely and
   effectively applied.
ZA 0
ZR 0
TC 25
ZB 2
ZS 0
Z8 0
Z9 25
DA 2024-05-25
UT WOS:001226121400001
PM 38728687
ER

PT J
AU Griewing, Sebastian
   Knitza, Johannes
   Boekhoff, Jelena
   Hillen, Christoph
   Lechner, Fabian
   Wagner, Uwe
   Wallwiener, Markus
   Kuhn, Sebastian
TI Evolution of publicly available large language models for complex
   decision-making in breast cancer care
SO ARCHIVES OF GYNECOLOGY AND OBSTETRICS
VL 310
IS 1
BP 537
EP 550
DI 10.1007/s00404-024-07565-4
EA MAY 2024
DT Article
PD JUL 2024
PY 2024
AB Purpose This study investigated the concordance of five different
   publicly available Large Language Models (LLM) with the recommendations
   of a multidisciplinary tumor board regarding treatment recommendations
   for complex breast cancer patient profiles.Methods Five LLM, including
   three versions of ChatGPT (version 4 and 3.5, with data access until
   September 3021 and January 2022), Llama2, and Bard were prompted to
   produce treatment recommendations for 20 complex breast cancer patient
   profiles. LLM recommendations were compared to the recommendations of a
   multidisciplinary tumor board (gold standard), including surgical,
   endocrine and systemic treatment, radiotherapy, and genetic testing
   therapy options.Results GPT4 demonstrated the highest concordance
   (70.6%) for invasive breast cancer patient profiles, followed by GPT3.5
   September 2021 (58.8%), GPT3.5 January 2022 (41.2%), Llama2 (35.3%) and
   Bard (23.5%). Including precancerous lesions of ductal carcinoma in
   situ, the identical ranking was reached with lower overall concordance
   for each LLM (GPT4 60.0%, GPT3.5 September 2021 50.0%, GPT3.5 January
   2022 35.0%, Llama2 30.0%, Bard 20.0%). GPT4 achieved full concordance
   (100%) for radiotherapy. Lowest alignment was reached in recommending
   genetic testing, demonstrating a varying concordance (55.0% for GPT3.5
   January 2022, Llama2 and Bard up to 85.0% for GPT4).Conclusion This
   early feasibility study is the first to compare different LLM in breast
   cancer care with regard to changes in accuracy over time, i.e., with
   access to more data or through technological upgrades. Methodological
   advancement, i.e., the optimization of prompting techniques, and
   technological development, i.e., enabling data input control and secure
   data processing, are necessary in the preparation of large-scale and
   multicenter studies to provide evidence on their safe and reliable
   clinical application. At present, safe and evidenced use of LLM in
   clinical breast cancer care is not yet feasible.
ZB 3
Z8 0
ZA 0
ZR 0
ZS 0
TC 14
Z9 14
DA 2024-06-04
UT WOS:001233695900001
PM 38806945
ER

EF