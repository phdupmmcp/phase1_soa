FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Geevarghese, Ruben
   Solomon, Stephen B.
   Alexander, Erica S.
   Marinelli, Brett
   Chatterjee, Subrata
   Jain, Pulkit
   Cadley, John
   Hollingsworth, Alex
   Chatterjee, Avijit
   Ziv, Etay
TI Utility of a Large Language Model for Extraction of Clinical Findings
   from Healthcare Data following Lung Ablation: A Feasibility Study
SO JOURNAL OF VASCULAR AND INTERVENTIONAL RADIOLOGY
VL 36
IS 4
DI 10.1016/j.jvir.2024.11.029
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB To assess the feasibility of utilizing a large language model (LLM) in
   extracting clinically relevant information from healthcare data in
   patients who have undergone microwave ablation for lung tumors. In this
   single-center retrospective study, radiology reports and clinic notes of
   20 patients were extracted, up to 12 months after treatment. Utilizing
   an LLM (generative pretrained transformer 3.5 Turbo 16k), a zero-shot
   prompt strategy was employed to identify 4 key outcomes from relevant
   healthcare data: (a) recurrence at ablation site, (b) pneumothorax, (c)
   hemoptysis, and (d) hemothorax following ablation. This was validated
   with ground-truth labels obtained through manual chart review. Analysis
   of 104 radiology reports and 37 clinic notes was undertaken. The LLM
   output demonstrated high accuracy (85%-100%) across the 4 outcomes. An
   LLM approach appears to have utility in extraction of clinically
   relevant information from healthcare data. This method may be beneficial
   in facilitating data analysis for future interventional radiology
   studies.
Z8 0
ZB 0
ZA 0
ZR 0
TC 0
ZS 0
Z9 0
DA 2025-04-04
UT WOS:001453244100001
PM 39662619
ER

PT J
AU Kang, Yan
   Yang, Mingjian
   Peng, Yue
   Cai, Jingwen
   Zhao, Lei
   Gao, Zhan
   Li, Ningshu
   Pu, Bin
TI LLM-DG: Leveraging large language model for enhanced disease prediction
   via inter-patient and intra-patient modeling
SO INFORMATION FUSION
VL 121
AR 103145
DI 10.1016/j.inffus.2025.103145
EA APR 2025
DT Article
PD SEP 2025
PY 2025
AB Existing methods play a crucial role in clinical decision support by
   enabling disease prediction and personalizing healthcare based on
   swiftly accumulated electronic Health Records (EHRs). However, these
   methods often overlook multi-source data integration by relying solely
   on specific domain knowledge and fail to model intricate relationships
   among patients as focusing on inter or intra-patient relationships,
   respectively. To address these limitations, we propose LLM-DG, a
   multi-level health event prediction framework enhanced by large language
   models (LLMs). Specifically, LLM performs semantic enhancement for
   patient and discharge summary representations and injects domain
   knowledge into disease modeling, improving prediction accuracy and
   robustness. Moreover, LLM-DG synchronously models inter-patient and
   intra-patient relationships by capturing high-order patient correlations
   and fusing dynamic and static patient features. At the inter-patient
   level, LLM-DG clusters patients based on LLM-enhanced features,
   identifying similar health trajectories. At the intra-patient level, it
   models disease evolution characteristics through a dynamic graph and
   extracts textual information from LLM-enhanced discharge summaries using
   a text encoder. Experiments on MIMIC-III and MIMIC-IV datasets
   demonstrate that LLM-DG significantly outperforms state-of-the-art
   models, achieving a 12.39% improvement in w-F1 on the diagnosis
   prediction task of the MIMIC-IV dataset. Overall, LLM-DG demonstrates
   strong potential in complex healthcare environments by integrating
   patient histories and cross-patient health patterns, highlighting its
   applicability in clinical decision support and personalized treatment
   planning.
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001464997000001
ER

PT C
AU James, Lorenzo J.
   Genga, Laura
   Montagne, Barbara
   Hagenaars, Muriel A.
   Van Gorp, Pieter M. E.
GP ASSOC COMPUTING MACHINERY
TI Caregiver's Evaluation of LLM-Generated Treatment Goals for Patients
   with SMI
SO 17TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO
   ASSISTIVE ENVIRONMENTS, PETRA 2024
BP 187
EP 190
DI 10.1145/3652037.3663955
DT Proceedings Paper
PD 2024
PY 2024
AB The potential of LLMs to generate context-specific content for
   psychiatric patients could possibly be used to support treatment.
   Patients diagnosed with Severe Mental Illnesses face a significant
   challenge in the realm of goal setting. Caregivers work closely with
   patients with SMI to establish treatment goals. However, most goals are
   often immeasurable, hindering their integration into mHealth. This is a
   missed opportunity since mHealth has the potential to aid healthcare
   professionals in tracking a patient's progress and help motivate
   patients to work on their goals using behavior change concepts like
   personalization and gamification. Recognizing the time-consuming nature
   of creating measurable goals. This study validates an LLM-powered goal
   system aiming to provide a time-efficient way of goal creation for
   patients with SMI, on the quality of the goals it generates in
   collaboration with caregivers.
CT 17th International Conference on PErvasive Technologies Related to
   Assistive Environments (PETRA)
CY JUN 26-28, 2024
CL Crete, GREECE
SP ACM
TC 0
ZA 0
ZB 0
ZS 0
Z8 0
ZR 0
Z9 0
DA 2024-09-04
UT WOS:001281996200027
ER

PT J
AU Lammert, Jacqueline
   Dreyer, Tobias
   Mathes, Sonja
   Kuligin, Leonid
   Borm, Kai J.
   Schatz, Ulrich A.
   Kiechle, Marion
   Loersch, Alisa M.
   Jung, Johannes
   Lange, Sebastian
   Pfarr, Nicole
   Durner, Anna
   Schwamborn, Kristina
   Winter, Christof
   Ferber, Dyke
   Kather, Jakob Nikolas
   Mogler, Carolin
   Illert, Anna L.
   Tschochohei, Maximilian
TI Expert-Guided Large Language Models for Clinical Decision Support in
   Precision Oncology
SO JCO PRECISION ONCOLOGY
VL 8
AR e2400478
DI 10.1200/PO-24-00478
DT Article
PD OCT 2024
PY 2024
AB PURPOSE Rapidly expanding medical literature challenges oncologists
   seeking targeted cancer therapies. General-purpose large language models
   (LLMs) lack domain-specific knowledge, limiting their clinical utility.
   This study introduces the LLM system Medical Evidence Retrieval and Data
   Integration for Tailored Healthcare (MEREDITH), designed to support
   treatment recommendations in precision oncology. Built on Google's
   Gemini Pro LLM, MEREDITH uses retrieval-augmented generation and chain
   of thought.
   METHODS We evaluated MEREDITH on 10 publicly available fictional
   oncology cases with iterative feedback from a molecular tumor board
   (MTB) at a major German cancer center. Initially limited to
   PubMed-indexed literature (draft system), MEREDITH was enhanced to
   incorporate clinical studies on drug response within the specific tumor
   type, trial databases, drug approval status, and oncologic guidelines.
   The MTB provided a benchmark with manually curated treatment
   recommendations and assessed the clinical relevance of LLM-generated
   options (qualitative assessment). We measured semantic cosine similarity
   between LLM suggestions and clinician responses (quantitative
   assessment).
   RESULTS MEREDITH identified a broader range of treatment options (median
   4) compared with MTB experts (median 2). These options included
   therapies on the basis of preclinical data and combination treatments,
   expanding the treatment possibilities for consideration by the MTB. This
   broader approach was achieved by incorporating a curated medical data
   set that contextualized molecular targetability. Mirroring the approach
   MTB experts use to evaluate MTB cases improved the LLM's ability to
   generate relevant suggestions. This is supported by high concordance
   between LLM suggestions and expert recommendations (94.7% for the
   enhanced system) and a significant increase in semantic similarity from
   the draft to the enhanced system (from 0.71 to 0.76, P = .01).
   CONCLUSION Expert feedback and domain-specific data augment LLM
   performance. Future research should investigate responsible LLM
   integration into real-world clinical workflows.
ZA 0
ZB 0
TC 4
Z8 0
ZS 0
ZR 0
Z9 4
DA 2025-01-13
UT WOS:001376907800001
PM 39475661
ER

PT J
AU Ho, Cindy N.
   Tian, Tiffany
   Ayers, Alessandra T.
   Aaron, Rachel E.
   Phillips, Vidith
   Wolf, Risa M.
   Mathioudakis, Nestoras
   Dai, Tinglong
   Klonoff, David C.
TI Qualitative metrics from the biomedical literature for evaluating large
   language models in clinical decision-making: a narrative review
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
VL 24
IS 1
AR 357
DI 10.1186/s12911-024-02757-z
DT Article
PD NOV 26 2024
PY 2024
AB BackgroundThe large language models (LLMs), most notably ChatGPT,
   released since November 30, 2022, have prompted shifting attention to
   their use in medicine, particularly for supporting clinical
   decision-making. However, there is little consensus in the medical
   community on how LLM performance in clinical contexts should be
   evaluated.MethodsWe performed a literature review of PubMed to identify
   publications between December 1, 2022, and April 1, 2024, that discussed
   assessments of LLM-generated diagnoses or treatment plans.ResultsWe
   selected 108 relevant articles from PubMed for analysis. The most
   frequently used LLMs were GPT-3.5, GPT-4, Bard, LLaMa/Alpaca-based
   models, and Bing Chat. The five most frequently used criteria for
   scoring LLM outputs were "accuracy", "completeness", "appropriateness",
   "insight", and "consistency".ConclusionsThe most frequently used
   criteria for defining high-quality LLMs have been consistently selected
   by researchers over the past 1.5 years. We identified a high degree of
   variation in how studies reported their findings and assessed LLM
   performance. Standardized reporting of qualitative evaluation metrics
   that assess the quality of LLM outputs can be developed to facilitate
   research studies on LLMs in healthcare.
ZS 0
TC 4
ZA 0
ZB 0
Z8 0
ZR 0
Z9 4
DA 2024-12-03
UT WOS:001364059400003
PM 39593074
ER

PT J
AU Miletic, Marko
   Sariyar, Murat
TI Large Language Models for Synthetic Tabular Health Data: A Benchmark
   Study.
SO Studies in health technology and informatics
VL 316
BP 963
EP 967
DI 10.3233/SHTI240571
DT Journal Article
PD 2024-Aug-22
PY 2024
AB Synthetic tabular health data plays a crucial role in healthcare
   research, addressing privacy regulations and the scarcity of publicly
   available datasets. This is essential for diagnostic and treatment
   advancements. Among the most promising models are transformer-based
   Large Language Models (LLMs) and Generative Adversarial Networks (GANs).
   In this paper, we compare LLM models of the Pythia LLM Scaling Suite
   with varying model sizes ranging from 14M to 1B, against a reference GAN
   model (CTGAN). The generated synthetic data are used to train random
   forest estimators for classification tasks to make predictions on the
   real-world data. Our findings indicate that as the number of parameters
   increases, LLM models outperform the reference GAN model. Even the
   smallest 14M parameter models perform comparably to GANs. Moreover, we
   observe a positive correlation between the size of the training dataset
   and model performance. We discuss implications, challenges, and
   considerations for the real-world usage of LLM models for synthetic
   tabular data generation.
ZR 0
ZA 0
TC 1
Z8 0
ZB 0
ZS 0
Z9 1
DA 2024-08-24
UT MEDLINE:39176952
PM 39176952
ER

PT J
AU Gencer, Gulcan
   Gencer, Kerem
TI Large Language Models in Healthcare: A Bibliometric Analysis and
   Examination of Research Trends
SO JOURNAL OF MULTIDISCIPLINARY HEALTHCARE
VL 18
BP 223
EP 238
DI 10.2147/JMDH.S502351
DT Article
PD 2025
PY 2025
AB Background: The integration of large language models (LLMs) in
   healthcare has generated significant interest due to their potential to
   improve diagnostic accuracy, personalization of treatment, and patient
   care efficiency. Objective: This study aims to conduct a comprehensive
   bibliometric analysis to identify current research trends, main themes
   and future directions regarding applications in the healthcare sector.
   Methods: A systematic scan of publications until 08.05.2024 was carried
   out from an important database such as Web of Science.Using bibliometric
   tools such as VOSviewer and CiteSpace, we analyzed data covering
   publication counts, citation analysis, co-authorship, co- occurrence of
   keywords and thematic development to map the intellectual landscape and
   collaborative networks in this field. Results: The analysis included
   more than 500 articles published between 2021 and 2024. The United
   States, Germany and the United Kingdom were the top contributors to this
   field. The study highlights that neural network applications in
   diagnostic imaging, natural language processing for clinical
   documentation, and patient data in the field of general internal
   medicine, radiology, medical informatics, health care services, surgery,
   oncology, ophthalmology, neurology, orthopedics and psychiatry have seen
   significant growth in publications over the past two years. Keyword
   trend analysis revealed emerging sub-themes such as clinical research,
   artificial intelligence, ChatGPT, education, natural language
   processing, clinical management, virtual reality, chatbot, indicating a
   shift towards addressing the broader implications of LLM application in
   healthcare. Conclusion: The use of LLM in healthcare is an expanding
   field with significant academic and clinical interest. This bibliometric
   analysis not only maps the current state of the research, but also
   identifies important areas that require further research and
   development. Continued advances in this field are expected to
   significantly impact future healthcare applications, with a focus on
   increasing the accuracy and personalization of patient care through
   advanced data analytics.
ZR 0
Z8 0
ZS 0
ZA 0
TC 3
ZB 0
Z9 3
DA 2025-01-25
UT WOS:001400829200001
PM 39844924
ER

PT J
AU Mohanty, Prasant Kumar
   Francis, Sharmila Anand John
   Barik, Rabindra Kumar
   Reddy, K. Hemant Kumar
   Roy, Diptendu Sinha
   Saikia, Manob Jyoti
TI IMPACT: an interactive multi-disease prevention and counterfactual
   treatment system using explainable AI and a multimodal LLM
SO PEERJ COMPUTER SCIENCE
VL 11
AR e2839
DI 10.7717/peerj-cs.2839
DT Article
PD APR 29 2025
PY 2025
AB Multi-disease conditions strain the body's defenses, complicating
   recovery and increasing mortality risk. Therefore, effective concurrent
   prevention of multiple diseases is essential for mitigating
   complications and improving overall well-being. Explainable artificial
   intelligence (XAI) with an advanced multimodal large language model
   (LLM) can create an interactive system enabling the general public to
   engage in natural language without any specialized knowledge
   prerequisites. Counterfactual explanation, an XAI method, offers
   valuable insights by suggesting adjustments to patient features to
   minimize disease risks. However, addressing multiple diseases
   simultaneously poses challenging barriers. This article proposes an
   interactive multi-disease prevention system that uses Google Gemini Pro,
   a multimodal LLM, and a non-dominated sorting genetic algorithm, namely
   NSGA-II, to overcome such problems. This system recommends changes in
   feature values to concurrently minimize the risk of diseases such as
   heart attacks and diabetes. The system facilitates personalized feature
   value selection, significantly reducing disease attack probabilities to
   as low as possible. Such an approach holds the potential to
   simultaneously address the unresolved issue of preventing and managing
   multiple diseases for the general public.
ZR 0
ZA 0
ZB 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2025-05-10
UT WOS:001480517000001
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Truhn, Daniel
   Weber, Christian D.
   Braun, Benedikt J.
   Bressem, Keno
   Kather, Jakob N.
   Kuhl, Christiane
   Nebelung, Sven
TI A pilot study on the efficacy of GPT-4 in providing orthopedic treatment
   recommendations from MRI reports
SO SCIENTIFIC REPORTS
VL 13
IS 1
AR 20159
DI 10.1038/s41598-023-47500-2
DT Article
PD NOV 17 2023
PY 2023
AB Large language models (LLMs) have shown potential in various
   applications, including clinical practice. However, their accuracy and
   utility in providing treatment recommendations for orthopedic conditions
   remain to be investigated. Thus, this pilot study aims to evaluate the
   validity of treatment recommendations generated by GPT-4 for common knee
   and shoulder orthopedic conditions using anonymized clinical MRI
   reports. A retrospective analysis was conducted using 20 anonymized
   clinical MRI reports, with varying severity and complexity. Treatment
   recommendations were elicited from GPT-4 and evaluated by two
   board-certified specialty-trained senior orthopedic surgeons. Their
   evaluation focused on semiquantitative gradings of accuracy and clinical
   utility and potential limitations of the LLM-generated recommendations.
   GPT-4 provided treatment recommendations for 20 patients (mean age, 50
   years +/- 19 [standard deviation]; 12 men) with acute and chronic knee
   and shoulder conditions. The LLM produced largely accurate and
   clinically useful recommendations. However, limited awareness of a
   patient's overall situation, a tendency to incorrectly appreciate
   treatment urgency, and largely schematic and unspecific treatment
   recommendations were observed and may reduce its clinical usefulness. In
   conclusion, LLM-based treatment recommendations are largely adequate and
   not prone to 'hallucinations', yet inadequate in particular situations.
   Critical guidance by healthcare professionals is obligatory, and
   independent use by patients is discouraged, given the dependency on
   precise data input.
ZB 9
ZA 0
ZR 0
Z8 2
ZS 0
TC 33
Z9 33
DA 2024-04-05
UT WOS:001125371600058
PM 37978240
ER

PT C
AU Chang, Chia-Hsuan
   Lucas, Mary M.
   Lee, Yeawon
   Yang, Christopher C.
   Lu-Yao, Grace
BE Finkelstein, J
   Moskovitch, R
   Parimbelli, E
TI Beyond Self-consistency: Ensemble Reasoning Boosts Consistency and
   Accuracy of LLMs in Cancer Staging
SO ARTIFICIAL INTELLIGENCE IN MEDICINE, PT I, AIME 2024
SE Lecture Notes in Artificial Intelligence
VL 14844
BP 224
EP 228
DI 10.1007/978-3-031-66538-7_23
DT Proceedings Paper
PD 2024
PY 2024
AB Pathologic cancer stage, crucial for treatment decisions, is often
   buried in unstructured pathology reports. This study investigates using
   pre-trained clinical LLMs for stage extraction, leveraging prompting
   techniques like chain-of-thought to enhance model transparency. While
   self-consistency methods further improve LLM performance, they can
   introduce inconsistencies in reasoning paths and predictions. We propose
   an ensemble reasoning approach, aiming for reliable cancer stage
   extraction. Utilizing an open-source clinical LLM on real-world reports,
   we demonstrate that the ensemble approach improves consistency and
   boosts performance, paving the way for utilizing LLMs in healthcare
   settings where reliability and interpretability are paramount.
CT 22nd International Conference on Artificial Intelligence in Medicine
   (AIME)
CY JUL 09-12, 2024
CL Salt Lake City, UT
ZB 1
TC 1
ZR 0
ZA 0
Z8 0
ZS 0
Z9 1
DA 2024-09-29
UT WOS:001295129500023
ER

PT C
AU Alshehri, Basma Mohammed J.
   Kraiem, Naoufel
   Sakly, Houneida
   Alasbali, Nada
GP IEEE
TI Enhancing Medication Safety with Large Language Models: Advanced
   Detection and Prediction of Drug-Drug Interactions
SO 2024 IEEE 7TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES, SIGNAL
   AND IMAGE PROCESSING, ATSIP 2024
SE International Conference on Advanced Technologies for Signal and Image
   Processing ATSIP
BP 547
EP 552
DI 10.1109/ATSIP62566.2024.10638993
DT Proceedings Paper
PD 2024
PY 2024
AB Poly-pharmacy means the use of multiple medications for multiple
   Diseases, with impact to the increases of the risk of drug-drug
   interactions (DDIs), and it may cause a threat to patient safety.
   Traditional DDI detection methods are often manual and leads to errors.
   This study investigates the potential of large language models (LLMs) to
   improve the efficiency of personalized DDI prediction and to use the AI
   advancements. By using LLMs' natural language processing capabilities,
   we will develop a system that analyzes comprehensive patient data,
   including medical history, and individual characteristics. The system
   aims to enabling healthcare providers to make informed decisions and
   improve the treatment plans. Initial results, while promising, highlight
   the need for further refinement and larger datasets to improve
   prediction accuracy. However, this research demonstrates the significant
   potential of LLM-based systems in transforming medication safety,
   optimizing treatment regimens, and ultimately enhancing patient care and
   treatment process.
CT IEEE 7th International Conference on Advanced Technologies, Signal and
   Image Processing (ATSIP)
CY JUL 11-13, 2024
CL Sousse, TUNISIA
SP IEEE; IEEE Tunisia Sect; IEEE Signal Proc Soc; IEEE Control Syst Soc;
   Adv Technologies Med & Signals; ATSI; Telecom Paris; Telecom SudParis;
   Telecom ParisTech; SUPCOM; ANST; ENST; SYS; Technopole SFAX; CRNS; ENET
   COM; ATISP; ENIG; MACS; ENIS
ZS 0
TC 1
Z8 0
ZR 0
ZA 0
ZB 0
Z9 1
DA 2024-12-13
UT WOS:001315771700097
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU John, Annette
   Alhajj, Reda
   Rokne, Jon
TI A systematic review of AI as a digital twin for prostate cancer care
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 268
AR 108804
DI 10.1016/j.cmpb.2025.108804
EA MAY 2025
DT Review
PD AUG 2025
PY 2025
AB Artificial Intelligence (AI) and Digital Twin (DT) technologies are
   rapidly transforming healthcare, offering the potential for
   personalized, accurate, and efficient medical care. This systematic
   review focuses on the intersection of AI-based digital twins and their
   applications in prostate cancer pathology. A digital twin, when applied
   to healthcare, creates a dynamic, data-driven virtual model that
   simulates a patient's biological systems in real-time. By incorporating
   AI techniques such as Machine Learning (ML) and Deep Learning (DL),
   these systems enhance predictive accuracy, enable early diagnosis, and
   facilitate individualized treatment strategies for prostate cancer. This
   review systematically examines recent advances (2020-2025) in AI-driven
   digital twins for prostate cancer, highlighting key methodologies,
   algorithms, and data integration strategies. The literature analysis
   also reveals substantial progress in image processing, predictive
   modeling, and clinical decision support systems, which are the basic
   tools used when implementing digital twins for prostate cancer care. Our
   survey also critically evaluates the strengths and limitations of
   current approaches, identifying gaps such as the need for real-time data
   integration, improved explainability in AI models, and more robust
   clinical validation. It concludes with a discussion of future research
   directions, emphasizing the importance of integrating multi-modal data
   with Large Language Models (LLMs) and Vision-Language Models (VLMs),
   scalability, and ethical considerations in advancing AI-driven digital
   twins for prostate cancer diagnosis and treatment. This paper provides a
   comprehensive resource for researchers and clinicians, offering insights
   into how AI-based digital twins can enhance precision medicine and
   improve patient outcomes in prostate cancer care.
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
DA 2025-05-23
UT WOS:001490802200002
PM 40347618
ER

PT B
AU Gu, Zhanzhong
Z2  
TI Automatic Quantitative Stroke Severity Assessment from Chinese
   Electronic Health Records Based on Advanced Large Language Models
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
UT PQDT:121107541
ER

PT J
AU Macaluso, Joseph N Jr
TI Hospital, Catheter, Peritoneal Dialysis Acquired Infections: Visible
   Light as a New Solution to Reduce Risk and Incidence.
SO Cureus
VL 15
IS 8
BP e43043
EP e43043
DI 10.7759/cureus.43043
DT Journal Article; Review
PD 2023-Aug
PY 2023
AB Healthcare-associated infections, often identified as hospital-acquired
   infections (HAIs), are typically not present during patient contact or
   admission. Healthcare-associated infections cause longer lengths of
   stay, increasing costs and mortality. HAI occurring in trauma patients
   increases the risk for length of stay and higher inpatient costs. Many
   HAIs are preventable. Antibiotic resistance has increased to a high
   level making proper treatment increasingly difficult due to organisms
   resistant to common antibiotics. Therefore, there is a need for
   alternate forms of attack against these pathogens. Currently, the
   application of light for the treatment of topical infections has been
   used. Ultraviolet (UV) light has well-documented antimicrobial
   properties. UV is damaging to DNA and causes the degradation of
   plastics, etc., so its use for medical purposes is limited. Using
   visible light may be more promising. 405-nm light sterilization has been
   shown to be highly efficacious in reducing bacteria. Light Line Medical,
   Inc.'s (LLM) patented visible-light platform technology for infection
   prevention may create a global shift in the prevention of
   healthcare-associated infections. LLM has developed a proprietary method
   of delivering light to prevent catheter-associated infections. This
   technology uses non-UV visible light and can kill both bacteria and
   prevent biofilm inside and outside a luminal catheter. This is
   significant as prevention is key. Independent analysis of the prototype
   system showed the application of the device met the acceptance criterion
   of 4 x 109-10 reduction in Candida albicans, Staphylococcus aureus,
   Pseudomonas aeruginosa, and other bacteria and fungal species. Further
   design evolution for this technology continues, and the FDA submission
   process is underway.
ZR 0
ZB 0
ZS 0
Z8 0
TC 2
ZA 0
Z9 2
DA 2023-08-10
UT MEDLINE:37554377
PM 37554377
ER

PT C
AU Calle, Paul
   Shao, Ruosi
   Liu, Yunlong
   Hebert, Emily T.
   Kendzor, Darla
   Neil, Jordan
   Businelle, Michael
   Pan, Chongle
GP ACM
TI Towards AI-Driven Healthcare: Systematic Optimization, Linguistic
   Analysis, and Clinicians' Evaluation of Large Language Models for
   Smoking Cessation Interventions
SO PROCEEDINGS OF THE 2024 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYTEMS, CHI 2024
DI 10.1145/3613904.3641965
DT Proceedings Paper
PD 2024
PY 2024
AB Creating intervention messages for smoking cessation is a
   labor-intensive process. Advances in Large Language Models (LLMs) offer
   a promising alternative for automated message generation. Two critical
   questions remain: 1) How to optimize LLMs to mimic human expert writing,
   and 2) Do LLM-generated messages meet clinical standards? We
   systematically examined the message generation and evaluation processes
   through three studies investigating prompt engineering (Study 1),
   decoding optimization (Study 2), and expert review (Study 3). We
   employed computational linguistic analysis in LLM assessment and
   established a comprehensive evaluation framework, incorporating
   automated metrics, linguistic attributes, and expert evaluations.
   Certified tobacco treatment specialists assessed the quality, accuracy,
   credibility, and persuasiveness of LLM-generated messages, using
   expert-written messages as the benchmark. Results indicate that larger
   LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate
   expert writing to generate well-written, accurate, and persuasive
   messages, thereby demonstrating the capability of LLMs in augmenting
   clinical practices of smoking cessation interventions.
CT CHI Conference on Human Factors in Computing Sytems (CHI)
CY MAY 11-16, 2024
CL Honolulu, HI
SP Assoc Comp Machinery; ACM SIGCHI; Apple; Google; NSF; Tianqiao & Chrissy
   Chen Inst
ZB 0
ZS 0
ZR 0
ZA 0
TC 2
Z8 0
Z9 2
DA 2024-10-05
UT WOS:001255317901034
PM 38912297
ER

PT J
AU Ding, Sirui
   Ye, Jiancheng
   Hu, Xia
   Zou, Na
TI Distilling the knowledge from large-language model for health event
   prediction
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30675
DI 10.1038/s41598-024-75331-2
DT Article
PD DEC 28 2024
PY 2024
AB Health event prediction is empowered by the rapid and wide application
   of electronic health records (EHR). In the Intensive Care Unit (ICU),
   precisely predicting the health related events in advance is essential
   for providing treatment and intervention to improve the patients
   outcomes. EHR is a kind of multi-modal data containing clinical text,
   time series, structured data, etc. Most health event prediction works
   focus on a single modality, e.g., text or tabular EHR. How to
   effectively learn from the multi-modal EHR for health event prediction
   remains a challenge. Inspired by the strong capability in text
   processing of large language model (LLM), we propose the framework CKLE
   for health event prediction by distilling the knowledge from LLM and
   learning from multi-modal EHR. There are two challenges of applying LLM
   in the health event prediction, the first one is most LLM can only
   handle text data rather than other modalities, e.g., structured data.
   The second challenge is the privacy issue of health applications
   requires the LLM to be locally deployed, which may be limited by the
   computational resource. CKLE solves the challenges of LLM scalability
   and portability in the healthcare domain by distilling the
   cross-modality knowledge from LLM into the health event predictive
   model. To fully take advantage of the strong power of LLM, the raw
   clinical text is refined and augmented with prompt learning. The
   embedding of clinical text are generated by LLM. To effectively distill
   the knowledge of LLM into the predictive model, we design a
   cross-modality knowledge distillation (KD) method. A specially designed
   training objective will be used for the KD process with the
   consideration of multiple modality and patient similarity. The KD loss
   function consists of two parts. The first one is cross-modality
   contrastive loss function, which models the correlation of different
   modalities from the same patient. The second one is patient similarity
   learning loss function to model the correlations between similar
   patients. The cross-modality knowledge distillation can distill the rich
   information in clinical text and the knowledge of LLM into the
   predictive model on structured EHR data. To demonstrate the
   effectiveness of CKLE, we evaluate CKLE on two health event prediction
   tasks in the field of cardiology, heart failure prediction and
   hypertension prediction. We select the 7125 patients from MIMIC-III
   dataset and split them into train/validation/test sets. We can achieve a
   maximum 4.48% improvement in accuracy compared to state-of-the-art
   predictive model designed for health event prediction. The results
   demonstrate CKLE can surpass the baseline prediction models
   significantly on both normal and limited label settings. We also conduct
   the case study on cardiology disease analysis in the heart failure and
   hypertension prediction. Through the feature importance calculation, we
   analyse the salient features related to the cardiology disease which
   corresponds to the medical domain knowledge. The superior performance
   and interpretability of CKLE pave a promising way to leverage the power
   and knowledge of LLM in the health event prediction in real-world
   clinical settings.
Z8 0
ZA 0
TC 2
ZS 0
ZB 0
ZR 0
Z9 2
DA 2025-01-09
UT WOS:001386137300038
PM 39730390
ER

PT J
AU Vrdoljak, Josip
   Boban, Zvonimir
   Vilovic, Marino
   Kumric, Marko
   Bozic, Josko
TI A Review of Large Language Models in Medical Education, Clinical
   Decision Support, and Healthcare Administration
SO HEALTHCARE
VL 13
IS 6
AR 603
DI 10.3390/healthcare13060603
DT Review
PD MAR 10 2025
PY 2025
AB Background/Objectives: Large language models (LLMs) have shown
   significant potential to transform various aspects of healthcare. This
   review aims to explore the current applications, challenges, and future
   prospects of LLMs in medical education, clinical decision support, and
   healthcare administration. Methods: A comprehensive literature review
   was conducted, examining the applications of LLMs across the three key
   domains. The analysis included their performance, challenges, and
   advancements, with a focus on techniques like retrieval-augmented
   generation (RAG). Results: In medical education, LLMs show promise as
   virtual patients, personalized tutors, and tools for generating study
   materials. Some models have outperformed junior trainees in specific
   medical knowledge assessments. Concerning clinical decision support,
   LLMs exhibit potential in diagnostic assistance, treatment
   recommendations, and medical knowledge retrieval, though performance
   varies across specialties and tasks. In healthcare administration, LLMs
   effectively automate tasks like clinical note summarization, data
   extraction, and report generation, potentially reducing administrative
   burdens on healthcare professionals. Despite their promise, challenges
   persist, including hallucination mitigation, addressing biases, and
   ensuring patient privacy and data security. Conclusions: LLMs have
   transformative potential in medicine but require careful integration
   into healthcare settings. Ethical considerations, regulatory challenges,
   and interdisciplinary collaboration between AI developers and healthcare
   professionals are essential. Future advancements in LLM performance and
   reliability through techniques such as RAG, fine-tuning, and
   reinforcement learning will be critical to ensuring patient safety and
   improving healthcare delivery.
TC 1
ZA 0
ZS 0
ZR 0
ZB 0
Z8 0
Z9 1
DA 2025-03-31
UT WOS:001452063500001
PM 40150453
ER

PT J
AU Goh, Ethan
   Bunning, Bryan
   Khoong, Elaine
   Gallo, Robert
   Milstein, Arnold
   Centola, Damon
   Chen, Jonathan H
TI ChatGPT Influence on Medical Decision-Making, Bias, and Equity: A
   Randomized Study of Clinicians Evaluating Clinical Vignettes.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2023.11.24.23298844
DT Preprint
PD 2023 Nov 27
PY 2023
AB In a randomized, pre-post intervention study, we evaluated the influence
   of a large language model (LLM) generative AI system on accuracy of
   physician decision-making and bias in healthcare. 50 US-licensed
   physicians reviewed a video clinical vignette, featuring actors
   representing different demographics (a White male or a Black female)
   with chest pain. Participants were asked to answer clinical questions
   around triage, risk, and treatment based on these vignettes, then asked
   to reconsider after receiving advice generated by ChatGPT+ (GPT4). The
   primary outcome was the accuracy of clinical decisions based on
   pre-established evidence-based guidelines. Results showed that
   physicians are willing to change their initial clinical impressions
   given AI assistance, and that this led to a significant improvement in
   clinical decision-making accuracy in a chest pain evaluation scenario
   without introducing or exacerbating existing race or gender biases. A
   survey of physician participants indicates that the majority expect LLM
   tools to play a significant role in clinical decision making.
ZS 0
ZB 0
ZR 0
Z8 0
ZA 0
TC 1
Z9 1
DA 2023-12-16
UT MEDLINE:38076944
PM 38076944
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Sai, Siva
   Gaur, Aanchal
   Sai, Revant
   Chamola, Vinay
   Guizani, Mohsen
   Rodrigues, Joel J. P. C.
TI Generative AI for Transformative Healthcare: A Comprehensive Study of
   Emerging Models, Applications, Case Studies, and Limitations
SO IEEE ACCESS
VL 12
BP 31078
EP 31106
DI 10.1109/ACCESS.2024.3367715
DT Article
PD 2024
PY 2024
AB Generative artificial intelligence (GAI) can be broadly described as an
   artificial intelligence system capable of generating images, text, and
   other media types with human prompts. GAI models like ChatGPT, DALL-E,
   and Bard have recently caught the attention of industry and academia
   equally. GAI applications span various industries like art, gaming,
   fashion, and healthcare. In healthcare, GAI shows promise in medical
   research, diagnosis, treatment, and patient care and is already making
   strides in real-world deployments. There has yet to be any detailed
   study concerning the applications and scope of GAI in healthcare.
   Addressing this research gap, we explore several applications,
   real-world scenarios, and limitations of GAI in healthcare. We examine
   how GAI models like ChatGPT and DALL-E can be leveraged to aid in the
   applications of medical imaging, drug discovery, personalized patient
   treatment, medical simulation and training, clinical trial optimization,
   mental health support, healthcare operations and research, medical
   chatbots, human movement simulation, and a few more applications. Along
   with applications, we cover four real-world healthcare scenarios that
   employ GAI: visual snow syndrome diagnosis, molecular drug optimization,
   medical education, and dentistry. We also provide an elaborate
   discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT,
   DeepHealth, etc.,Since GAI is still evolving, it poses challenges like
   the lack of professional expertise in decision making, risk of patient
   data privacy, issues in integrating with existing healthcare systems,
   and the problem of data bias which are elaborated on in this work along
   with several other challenges. We also put forward multiple directions
   for future research in GAI for healthcare.
ZS 0
ZA 0
Z8 0
ZR 0
ZB 5
TC 39
Z9 40
DA 2024-03-21
UT WOS:001176001000001
ER

PT C
AU Bandara, Eranga
   Foytik, Peter
   Shetty, Sachin
   Mukkamala, Ravi
   Rahman, Abdul
   Liang, Xueping
   Keon, Ng Wee
   De Zoysa, Kasun
GP IEEE
TI WedaGPT - Generative-AI (with Custom-Trained Meta's Llama2 LLM),
   Blockchain, Self Sovereign Identity, NFT and Model Card Enabled
   Indigenous Medicine Platform
SO 2024 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, ISCC 2024
SE IEEE Symposium on Computers and Communications ISCC
DI 10.1109/ISCC61673.2024.10733674
DT Proceedings Paper
PD 2024
PY 2024
AB Traditional and indigenous medicine, deeply rooted in ancient traditions
   and wisdom, plays a crucial role in global healthcare and cultural
   identity. These practices provide treatments for illnesses such as
   cancer and bone injuries, which often lack effective remedies in Western
   medicine. However, these valuable systems face challenges like potential
   knowledge loss, undervaluation of practitioners' expertise, and the risk
   of fraud due to the absence of credential verification mechanisms. In
   this research, we introduce "WedaGPT," a Generative AI-enabled platform
   that utilizes a custom-trained Meta's Llama2 Large Language Model (LLM),
   Blockchain, self-sovereign identity (SSI), Non-Fungible Tokens (NFTs),
   and model cards to share traditional medical knowledge and address these
   issues. WedaGPT creates a collaborative ecosystem connecting doctors,
   medicine providers, therapists, patients, and technology experts, all
   committed to preserving and advancing traditional healing practices.
   This platform enables secure and transparent contributions from all
   stakeholders to patient well-being. Ancient medical recipe books are
   translated into English and digitized into PDF formats to enrich the
   platform's knowledge base. These texts are used to fine-tune the Llama2
   LLM, which has been quantized and optimized with Qlora for performance
   on consumer-grade hardware. Through a chat-based interface in the
   SSI-enabled mobile wallet, users can interact with the LLM and access
   detailed information on treatments, recipes, prescriptions, and healing
   methods. Additionally, users can consult remotely with doctors who
   prescribe treatments through this wallet. A key feature of WedaGPT is
   transforming ancient medicinal recipes into NFT tokens for sale on NFT
   marketplaces, giving traditional knowledge digital authenticity and
   economic value. Revenue from these sales is distributed among platform
   contributors, promoting equitable ownership and recognition. Medical
   recipe data, including treatment histories and physician details, are
   encapsulated in Model Cards and securely stored on the blockchain. This
   system offers mechanisms to verify doctors and treatments in a
   privacy-preserving way, potentially reducing fraud and medication
   errors.
CT 29th IEEE Symposium on Computers and Communications (IEEE ISCC)
CY JUN 26-29, 2024
CL Paris, FRANCE
SP IEEE
Z8 0
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-01-03
UT WOS:001363176200111
ER

PT J
AU Pan, Jie
   Lee, Seungwon
   Cheligeer, Cheligeer
   Martin, Elliot A
   Riazi, Kiarash
   Quan, Hude
   Li, Na
TI Integrating large language models with human expertise for disease
   detection in electronic health records.
SO Computers in biology and medicine
VL 191
BP 110161
EP 110161
DI 10.1016/j.compbiomed.2025.110161
DT Journal Article
PD 2025-Jun
PY 2025
AB OBJECTIVE: Electronic health records (EHR) are widely available to
   complement administrative data-based disease surveillance and healthcare
   performance evaluation. Defining conditions from EHR is labour-intensive
   and requires extensive manual labelling of disease outcomes. This study
   developed an efficient strategy based on advanced large language models
   to identify multiple conditions from EHR clinical notes.
   METHODS: We linked a cardiac registry cohort in 2015 with an EHR system
   in Alberta, Canada. We developed a pipeline that leveraged a generative
   large language model (LLM) to analyze, understand, and interpret EHR
   notes by prompts based on specific diagnosis, treatment management, and
   clinical guidelines. The pipeline was applied to detect acute myocardial
   infarction (AMI), diabetes, and hypertension. The performance was
   compared against clinician-validated diagnoses as the reference standard
   and widely adopted International Classification of Diseases (ICD)
   codes-based methods.
   RESULTS: The study cohort accounted for 3088 patients and 551,095
   clinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI,
   diabetes, and hypertension, respectively. The performance of the
   LLM-based pipeline for detecting conditions varied: AMI had 88%
   sensitivity, 63% specificity, and 77% positive predictive value (PPV);
   diabetes had 91% sensitivity, 86% specificity, and 71% PPV; and
   hypertension had 94% sensitivity, 32% specificity, and 72% PPV. Compared
   with ICD codes, the LLM-based method demonstrated improved sensitivity
   and negative predictive value across all conditions. The monthly
   percentage trends from the detected cases by LLM and reference standard
   showed consistent patterns.
   CONCLUSION: The proposed LLM-based pipeline demonstrated reasonable
   accuracy and high efficiency in disease detection for multiple
   conditions. Human expert knowledge can be integrated into the pipeline
   to guide EHR note analysis without manually curated labels. The method
   could enable comprehensive real-time disease surveillance using EHRs.
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-04-11
UT MEDLINE:40198990
PM 40198990
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Assessing the use of the novel tool Claude 3 in comparison to ChatGPT
   4.0 as an artificial intelligence tool in the diagnosis and therapy of
   primary head and neck cancer cases
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6099
EP 6109
DI 10.1007/s00405-024-08828-1
EA AUG 2024
DT Article
PD NOV 2024
PY 2024
AB ObjectivesHead and neck squamous cell carcinoma (HNSCC) is a complex
   malignancy that requires a multidisciplinary tumor board approach for
   individual treatment planning. In recent years, artificial intelligence
   tools have emerged to assist healthcare professionals in making informed
   treatment decisions. This study investigates the application of the
   newly published LLM Claude 3 Opus compared to the currently most
   advanced LLM ChatGPT 4.0 for the diagnosis and therapy planning of
   primary HNSCC. The results were compared to that of a conventional
   multidisciplinary tumor board; (2) Materials and Methods: We conducted a
   study in March 2024 on 50 consecutive primary head and neck cancer
   cases. The diagnostics and MDT recommendations were compared to the
   Claude 3 Opus and ChatGPT 4.0 recommendations for each patient and rated
   by two independent reviewers for the following parameters: clinical
   recommendation, explanation, and summarization in addition to the
   Artificial Intelligence Performance Instrument (AIPI); (3) Results: In
   this study, Claude 3 achieved better scores for the diagnostic workup of
   patients than ChatGPT 4.0 and provided treatment recommendations
   involving surgery, chemotherapy, and radiation therapy. In terms of
   clinical recommendations, explanation and summarization Claude 3 scored
   similar to ChatGPT 4.0, listing treatment recommendations which were
   congruent with the MDT, but failed to cite the source of the
   information; (4) Conclusion: This study is the first analysis of Claude
   3 for primary head and neck cancer cases and demonstrates a superior
   performance in the diagnosis of HNSCC than ChatGPT 4.0 and similar
   results for therapy recommendations. This marks the advent of a newly
   launched advanced AI model that may be superior to ChatGPT 4.0 for the
   assessment of primary head and neck cancer cases and may assist in the
   clinical diagnostic and MDT setting.
   Claude 3 OpusHNSCCMultidisciplinary TumorboardArtificial IntelligenceLLM
ZA 0
ZS 0
ZB 4
TC 17
Z8 0
ZR 0
Z9 17
DA 2024-08-13
UT WOS:001285919100001
PM 39112556
ER

PT J
AU Choudhury, Avishek
   Chaudhry, Zaira
TI Large Language Models and User Trust: Consequence of Self-Referential
   Learning Loop and the Deskilling of Health Care Professionals
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 26
AR e56764
DI 10.2196/56764
DT Article
PD APR 25 2024
PY 2024
AB As the health care industry increasingly embraces large language models
   (LLMs), understanding the consequence of this integration becomes
   crucial for maximizing benefits while mitigating potential pitfalls.
   This paper explores the evolving relationship among clinician trust in
   LLMs, the transition of data sources from predominantly human -generated
   to artificial intelligence (AI)-generated content, and the subsequent
   impact on the performance of LLMs and clinician competence. One of the
   primary concerns identified in this paper is the LLMs' self -referential
   learning loops, where AI -generated content feeds into the learning
   algorithms, threatening the diversity of the data pool, potentially
   entrenching biases, and reducing the efficacy of LLMs. While theoretical
   at this stage, this feedback loop poses a significant challenge as the
   integration of LLMs in health care deepens, emphasizing the need for
   proactive dialogue and strategic measures to ensure the safe and
   effective use of LLM technology. Another key takeaway from our
   investigation is the role of user expertise and the necessity for a
   discerning approach to trusting and validating LLM outputs. The paper
   highlights how expert users, particularly clinicians, can leverage LLMs
   to enhance productivity by off-loading routine tasks while maintaining a
   critical oversight to identify and correct potential inaccuracies in AI
   -generated content. This balance of trust and skepticism is vital for
   ensuring that LLMs augment rather than undermine the quality of patient
   care. We also discuss the risks associated with the deskilling of health
   care professionals. Frequent reliance on LLMs for critical tasks could
   result in a decline in health care providers' diagnostic and thinking
   skills, particularly affecting the training and development of future
   professionals. The legal and ethical considerations surrounding the
   deployment of LLMs in health care are also examined. We discuss the
   medicolegal challenges, including liability in cases of erroneous
   diagnoses or treatment advice generated by LLMs. The paper references
   recent legislative efforts, such as The Algorithmic Accountability Act
   of 2023, as crucial steps toward establishing a framework for the
   ethical and responsible use of AI -based technologies in health care. In
   conclusion, this paper advocates for a strategic approach to integrating
   LLMs into health care. By emphasizing the importance of maintaining
   clinician expertise, fostering critical engagement with LLM outputs, and
   navigating the legal and ethical landscape, we can ensure that LLMs
   serve as valuable tools in enhancing patient care and supporting health
   care professionals. This approach addresses the immediate challenges
   posed by integrating LLMs and sets a foundation for their maintainable
   and responsible use in the future.
ZA 0
Z8 0
ZB 1
ZR 0
ZS 0
TC 23
Z9 23
DA 2024-05-23
UT WOS:001223117600002
PM 38662419
ER

PT C
AU Kumi, Sandra
   Ray, Madhurima
   Walia, Sanskriti
   Lomotey, Richard K.
   Deters, Ralph
BE Paul, R
   Kundu, A
   Bhattacharyya, R
TI Digital Twins for Stress Management Utilizing Synthetic Data
SO 2024 IEEE 5TH ANNUAL WORLD AI IOT CONGRESS, AIIOT 2024
BP 0329
EP 0335
DI 10.1109/AIIoT61789.2024.10579038
DT Proceedings Paper
PD 2024
PY 2024
AB In the era of Medical 4.0, technologies such as big data, wearables, and
   Machine Learning (ML) are being deployed for predictive healthcare
   delivery. In this regard, digital twins have been adopted in healthcare
   to enhance diagnosis and personalized treatment. Health Digital Twins
   (HDTs) are virtual representations of patients' data, mirroring the
   health state of patients to provide insights. Despite its promise, the
   existing works on HDTs relied on large historical data to train ML
   models. These historical data may be difficult to obtain due to privacy
   concerns of data fiduciaries and subjects. In this paper, we propose a
   Digital Twin for Stress Management (DTSM) that employs generative models
   to learn the distribution of patients' data retrieved from a wearable
   device for stress management score prediction. To obtain a virtual
   replica of a patient's data, we used synthetic data generative models
   such as Conditional Tabular Generative Adversarial Network (CTGAN),
   Tabular Variational Autoencoder (TVAE), Gaussian Copula, and Large
   Language Models (LLM) (REaLTabFormer and GReaT). The best result came
   from REaLTabFormer which accurately learns the distributions of the real
   data with a data quality score of approximately 93%. Furthermore, four
   wellknown ML models trained on the synthetic data obtained a mean
   absolute error (MAE) of less than 5% in the prediction of stress score.
   Our experimental results show that the proposed DTSM can be used for the
   prediction of stress management scores.
CT IEEE 5th Annual World AI IoT Congress (AIIoT)
CY MAY 29-31, 2024
CL WA
SP IEEE; SMART; IEEE USA; Inst Engn & Management; Univ Engn & Management
ZR 0
ZA 0
Z8 0
ZB 0
TC 1
ZS 0
Z9 1
DA 2024-10-10
UT WOS:001289206000048
ER

PT J
AU Roumie, Christianne L.
   Huizinga, Mary Margaret
   Liu, Xulei
   Greevy, Robert A.
   Grijalva, Carlos G.
   Murff, Harvey J.
   Hung, Adriana M.
   Griffin, Marie R.
TI The effect of incident antidiabetic regimens on lipid profiles in
   veterans with type 2 diabetes: a retrospective cohort
SO PHARMACOEPIDEMIOLOGY AND DRUG SAFETY
VL 20
IS 1
BP 36
EP 44
DI 10.1002/pds.2029
DT Article
PD JAN 2011
PY 2011
AB Objective Effects of oral antidiabetic drugs (OADs) on lipids may
   influence cardiovascular outcomes. Our aim was to compare time to
   initiation of lipid lowering medication (LLM) and 12-month lipid
   profiles among new OAD users.
   Methods We identified a retrospective cohort of 17 774 veterans who
   received care at Veterans Administration (VA) Mid-South Network with a
   first OAD from 1 January 2000 to 31 December 2007. There were 6917
   patients (38.9%) not on a LLM at baseline, and 3871 (56%) had complete
   covariates. Incident users of sulfonylurea and combination
   metformin+sulfonylurea were compared to metformin users for time to LLM
   initiation. Incident users of these OADs and thiazolidendiones were
   included in comparison of 12-month low-density lipoprotein (LDL),
   high-density lipoprotein (HDL), triglycerides (TGs), and total
   cholesterol. All analyses adjusted for demographics, lipids, HbA1C,
   healthcare utilization, and cardiovascular disease at baseline.
   Results The median time to starting LLM was 2.35 years (interquartile
   range 0.96, 4.6) following metformin initiation and not statistically
   different for users of sulfonylureas, or combination OADs. Compared to
   metformin users, 12-month HDL was 1.35 mg/dl (95%CI: -2.01, -0.72) lower
   and TGs were 5.7% higher (95%CI: 1.5%, 10.0%) for sulfonylurea users;
   TGs were 24.8% (95%CI: 0.7%, 54.5%) higher for thiazolidinedione users.
   Statin users had LDL and total cholesterol 16.7 mg/dl (95%CI: -19.9,
   -13.5) and 18.6 mg/dl (95%CI: -22.1, -15.1) lower than non-statin users,
   respectively.
   Conclusions Time to LLM initiation was similar between OADs. Metformin
   use resulted in more favorable lipids at 12 months compared to
   sulfonylureas or thiazolidinediones. Copyright (C) 2010 John Wiley &
   Sons, Ltd.
ZS 0
ZR 0
ZB 7
Z8 0
ZA 0
TC 11
Z9 11
DA 2011-01-01
UT WOS:000286071700005
PM 21182152
ER

PT J
AU Fisch, Urs
   Kliem, Paulina
   Grzonka, Pascale
   Sutter, Raoul
TI Performance of large language models on advocating the management of
   meningitis: a comparative qualitative stud
SO BMJ HEALTH & CARE INFORMATICS
VL 31
IS 1
AR e100978
DI 10.1136/bmjhci-2023-100978
DT Article
PD FEB 2024
PY 2024
AB Objectives We aimed to examine the adherence of large language models
   (LLMs) to bacterial meningitis guidelines using a hypothetical medical
   case, highlighting their utility and limitations in healthcare.Methods A
   simulated clinical scenario of a patient with bacterial meningitis
   secondary to mastoiditis was presented in three independent sessions to
   seven publicly accessible LLMs (Bard, Bing, Claude-2, GTP-3.5, GTP-4,
   Llama, PaLM). Responses were evaluated for adherence to good clinical
   practice and two international meningitis guidelines.Results A central
   nervous system infection was identified in 90% of LLM sessions. All
   recommended imaging, while 81% suggested lumbar puncture. Blood cultures
   and specific mastoiditis work-up were proposed in only 62% and 38%
   sessions, respectively. Only 38% of sessions provided the correct
   empirical antibiotic treatment, while antiviral treatment and
   dexamethasone were advised in 33% and 24%, respectively. Misleading
   statements were generated in 52%. No significant correlation was found
   between LLMs' text length and performance (r=0.29, p=0.20). Among all
   LLMs, GTP-4 demonstrated the best performance.Discussion Latest LLMs
   provide valuable advice on differential diagnosis and diagnostic
   procedures but significantly vary in treatment-specific information for
   bacterial meningitis when introduced to a realistic clinical scenario.
   Misleading statements were common, with performance differences
   attributed to each LLM's unique algorithm rather than output
   length.Conclusions Users must be aware of such limitations and
   performance variability when considering LLMs as a support tool for
   medical decision-making. Further research is needed to refine these
   models' comprehension of complex medical scenarios and their ability to
   provide reliable information.
TC 7
Z8 0
ZS 0
ZR 0
ZB 1
ZA 0
Z9 7
DA 2024-02-12
UT WOS:001156524500002
PM 38307617
ER

PT J
AU Wong, Matthew
   Lim, Zhi Wei
   Pushpanathan, Krithi
   Cheung, Carol Y.
   Wang, Ya Xing
   Chen, David
   Tham, Yih Chung
TI Review of emerging trends and projection of future developments in large
   language models research in ophthalmology
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1362
EP 1370
DI 10.1136/bjo-2023-324734
EA DEC 2023
DT Review
PD OCT 2024
PY 2024
AB Background Large language models (LLMs) are fast emerging as potent
   tools in healthcare, including ophthalmology. This systematic review
   offers a twofold contribution: it summarises current trends in
   ophthalmology-related LLM research and projects future directions for
   this burgeoning field.
   Methods We systematically searched across various databases (PubMed,
   Europe PMC, Scopus and Web of Science) for articles related to LLM use
   in ophthalmology, published between 1 January 2022 and 31 July 2023.
   Selected articles were summarised, and categorised by type (editorial,
   commentary, original research, etc) and their research focus (eg,
   evaluating ChatGPT's performance in ophthalmology examinations or
   clinical tasks).
   Findings We identified 32 articles meeting our criteria, published
   between January and July 2023, with a peak in June (n=12). Most were
   original research evaluating LLMs' proficiency in clinically related
   tasks (n=9). Studies demonstrated that ChatGPT-4.0 outperformed its
   predecessor, ChatGPT-3.5, in ophthalmology exams. Furthermore, ChatGPT
   excelled in constructing discharge notes (n=2), evaluating diagnoses
   (n=2) and answering general medical queries (n=6). However, it struggled
   with generating scientific articles or abstracts (n=3) and answering
   specific subdomain questions, especially those regarding specific
   treatment options (n=2). ChatGPT's performance relative to other LLMs
   (Google's Bard, Microsoft's Bing) varied by study design. Ethical
   concerns such as data hallucination (n=27), authorship (n=5) and data
   privacy (n=2) were frequently cited.
   Interpretation While LLMs hold transformative potential for healthcare
   and ophthalmology, concerns over accountability, accuracy and data
   security remain. Future research should focus on application programming
   interface integration, comparative assessments of popular LLMs, their
   ability to interpret image-based data and the establishment of
   standardised evaluation frameworks.
ZB 2
ZA 0
ZS 0
TC 14
Z8 0
ZR 0
Z9 14
DA 2024-01-06
UT WOS:001129050700001
PM 38164563
ER

PT J
AU Huo, Bright
   Calabrese, Elisa
   Sylla, Patricia
   Kumar, Sunjay
   Ignacio, Romeo C.
   Oviedo, Rodolfo
   Hassan, Imran
   Slater, Bethany J.
   Kaiser, Andreas
   Walsh, Danielle S.
   Vosburg, Wesley
TI The performance of artificial intelligence large language model-linked
   chatbots in surgical decision-making for gastroesophageal reflux disease
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
VL 38
IS 5
BP 2320
EP 2330
DI 10.1007/s00464-024-10807-w
EA APR 2024
DT Article
PD MAY 2024
PY 2024
AB BackgroundLarge language model (LLM)-linked chatbots may be an efficient
   source of clinical recommendations for healthcare providers and
   patients. This study evaluated the performance of LLM-linked chatbots in
   providing recommendations for the surgical management of
   gastroesophageal reflux disease (GERD).MethodsNine patient cases were
   created based on key questions addressed by the Society of American
   Gastrointestinal and Endoscopic Surgeons (SAGES) guidelines for the
   surgical treatment of GERD. ChatGPT-3.5, ChatGPT-4, Copilot, Google
   Bard, and Perplexity AI were queried on November 16th, 2023, for
   recommendations regarding the surgical management of GERD. Accurate
   chatbot performance was defined as the number of responses aligning with
   SAGES guideline recommendations. Outcomes were reported with counts and
   percentages.ResultsSurgeons were given accurate recommendations for the
   surgical management of GERD in an adult patient for 5/7 (71.4%) KQs by
   ChatGPT-4, 3/7 (42.9%) KQs by Copilot, 6/7 (85.7%) KQs by Google Bard,
   and 3/7 (42.9%) KQs by Perplexity according to the SAGES guidelines.
   Patients were given accurate recommendations for 3/5 (60.0%) KQs by
   ChatGPT-4, 2/5 (40.0%) KQs by Copilot, 4/5 (80.0%) KQs by Google Bard,
   and 1/5 (20.0%) KQs by Perplexity, respectively. In a pediatric patient,
   surgeons were given accurate recommendations for 2/3 (66.7%) KQs by
   ChatGPT-4, 3/3 (100.0%) KQs by Copilot, 3/3 (100.0%) KQs by Google Bard,
   and 2/3 (66.7%) KQs by Perplexity. Patients were given appropriate
   guidance for 2/2 (100.0%) KQs by ChatGPT-4, 2/2 (100.0%) KQs by Copilot,
   1/2 (50.0%) KQs by Google Bard, and 1/2 (50.0%) KQs by
   Perplexity.ConclusionsGastrointestinal surgeons, gastroenterologists,
   and patients should recognize both the promise and pitfalls of LLM's
   when utilized for advice on surgical management of GERD. Additional
   training of LLM's using evidence-based health information is needed.
ZA 0
ZR 0
Z8 0
ZB 0
TC 8
ZS 0
Z9 8
DA 2024-05-15
UT WOS:001204657100004
PM 38630178
ER

PT J
AU Delleani, Mattia
   D'Amico, Saverio
   Sauta, Elisabetta
   Asti, Gianluca
   Zazzetti, Elena
   Campagna, Alessia
   Lanino, Luca
   Maggioni, Giulia
   Grondelli, Maria Chiara
   Barrero, Alessandro Forcina
   Morandini, Pierandrea
   Ubezio, Marta
   Todisco, Gabriele
   Russo, Antonio
   Tentori, Cristina Astrid
   Buizza, Alessandro
   Bonometti, Arturo
   Lancellotti, Cesare
   Di Tommaso, Luca
   Rahal, Daoud
   Bicchieri, Marilena
   Savevski, Victor
   Santoro, Armando
   Santini, Valeria
   Sole, Francesc
   Platzbecker, Uwe
   Fenaux, Pierre
   Diez-Campelo, Maria
   Komrokji, Rami S.
   Garcia-Manero, Guillermo
   Haferlach, Torsten
   Kordasti, Shahram
   Zeidan, Amer M.
   Castellani, Gastone
   Della Porta, Matteo Giovanni
TI The "David Vs Goliath" Study: Application of Large
   Language Models (LLM) for Automatic Medical Information Retrieval from
   Multiple Data Sources to Accelerate Clinical and Translational Research
   in Hematology
SO BLOOD
VL 144
BP 3597
EP 3599
DI 10.1182/blood-2024-205621
SU 1
DT Meeting Abstract
PD NOV 5 2024
PY 2024
ZR 0
ZA 0
Z8 0
ZB 0
TC 0
ZS 0
Z9 0
DA 2025-02-20
UT WOS:001412307500014
ER

PT C
AU Panagoulias, Dimitrios P.
   Palamidas, Filippos A.
   Virvou, Maria
   Tsihrintzis, George A.
GP IEEE
TI Evaluation of ChatGPT-supported diagnosis, staging and treatment
   planning for the case of lung cancer
SO 2023 20TH ACS/IEEE INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS, AICCSA
SE International Conference on Computer Systems and Applications
DI 10.1109/AICCSA59173.2023.10479348
DT Proceedings Paper
PD 2023
PY 2023
AB In this paper, we evaluate the validity, accuracy, usefulness, and
   specificity of medical diagnoses related to lung cancer and its staging
   provided by ChatGPT based on symptoms described by humans. The
   evaluation is grounded on three main pillars: the validity and accuracy
   of answers in relation to context and associated references. The
   specificity and usefulness of the information for both doctors and
   patients. The economic value added to the healthcare system, determined
   by several weighted factors derived from the provided answers. The
   system's responses are expected to return proposed diagnoses and
   diagnostic steps, ranked by probability and importance. A specialist
   conducts the review process.
CT 20th ACS/IEEE International Conference on Computer Systems and
   Applications (AICCSA)
CY DEC 04-07, 2023
CL Giza, EGYPT
SP IEEE; ACS
ZB 0
ZS 0
ZR 0
TC 1
ZA 0
Z8 0
Z9 1
DA 2024-07-06
UT WOS:001222477900114
ER

PT J
AU Xie, Kevin
   Ojemann, William K. S.
   Gallagher, Ryan S.
   Shinohara, Russell T.
   Lucas, Alfredo
   Hill, Chloe E.
   Hamilton, Roy H.
   Johnson, Kevin B.
   Roth, Dan
   Litt, Brian
   Ellis, Colin A.
TI Disparities in seizure outcomes revealed by large language models
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 6
BP 1348
EP 1355
DI 10.1093/jamia/ocae047
EA MAR 2024
DT Article
PD MAY 20 2024
PY 2024
AB Objective Large-language models (LLMs) can potentially revolutionize
   health care delivery and research, but risk propagating existing biases
   or introducing new ones. In epilepsy, social determinants of health are
   associated with disparities in care access, but their impact on seizure
   outcomes among those with access remains unclear. Here we (1) evaluated
   our validated, epilepsy-specific LLM for intrinsic bias, and (2) used
   LLM-extracted seizure outcomes to determine if different demographic
   groups have different seizure outcomes.Materials and Methods We tested
   our LLM for differences and equivalences in prediction accuracy and
   confidence across demographic groups defined by race, ethnicity, sex,
   income, and health insurance, using manually annotated notes. Next, we
   used LLM-classified seizure freedom at each office visit to test for
   demographic outcome disparities, using univariable and multivariable
   analyses.Results We analyzed 84 675 clinic visits from 25 612 unique
   patients seen at our epilepsy center. We found little evidence of bias
   in the prediction accuracy or confidence of outcome classifications
   across demographic groups. Multivariable analysis indicated worse
   seizure outcomes for female patients (OR 1.33, P <= .001), those with
   public insurance (OR 1.53, P <= .001), and those from lower-income zip
   codes (OR >= 1.22, P <= .007). Black patients had worse outcomes than
   White patients in univariable but not multivariable analysis (OR 1.03, P
   = .66).Conclusion We found little evidence that our LLM was
   intrinsically biased against any demographic group. Seizure freedom
   extracted by LLM revealed disparities in seizure outcomes across several
   demographic groups. These findings quantify the critical need to reduce
   disparities in the care of people with epilepsy.
ZB 1
Z8 0
ZA 0
ZS 0
TC 5
ZR 0
Z9 5
DA 2024-03-29
UT WOS:001184502000001
PM 38481027
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   Pugliese, Nicola
   You, Kisung
   Shung, Dennis L.
TI Optimizing large language models in digestive disease: strategies and
   challenges to improve clinical outcomes
SO LIVER INTERNATIONAL
VL 44
IS 9
BP 2114
EP 2124
DI 10.1111/liv.15974
EA MAY 2024
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs) are transformer-based neural networks with
   billions of parameters trained on very large text corpora from diverse
   sources. LLMs have the potential to improve healthcare due to their
   capability to parse complex concepts and generate context-based
   responses. The interest in LLMs has not spared digestive disease
   academics, who have mainly investigated foundational LLM accuracy, which
   ranges from 25% to 90% and is influenced by the lack of standardized
   rules to report methodologies and results for LLM-oriented research. In
   addition, a critical issue is the absence of a universally accepted
   definition of accuracy, varying from binary to scalar interpretations,
   often tied to grader expertise without reference to clinical guidelines.
   We address strategies and challenges to increase accuracy. In
   particular, LLMs can be infused with domain knowledge using Retrieval
   Augmented Generation (RAG) or Supervised Fine-Tuning (SFT) with
   reinforcement learning from human feedback (RLHF). RAG faces challenges
   with in-context window limits and accurate information retrieval from
   the provided context. SFT, a deeper adaptation method, is
   computationally demanding and requires specialized knowledge. LLMs may
   increase patient quality of care across the field of digestive diseases,
   where physicians are often engaged in screening, treatment and
   surveillance for a broad range of pathologies for which in-context
   learning or SFT with RLHF could improve clinical decision-making and
   patient outcomes. However, despite their potential, the safe deployment
   of LLMs in healthcare still needs to overcome hurdles in accuracy,
   suggesting a need for strategies that integrate human feedback with
   advanced model training.
ZR 0
TC 16
ZA 0
Z8 2
ZS 0
ZB 3
Z9 16
DA 2024-06-06
UT WOS:001235783300001
PM 38819632
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Assessing the role of advanced artificial intelligence as a tool in
   multidisciplinary tumor board decision-making for recurrent/metastatic
   head and neck cancer cases - the first study on ChatGPT 4o and a
   comparison to ChatGPT 4.0
SO FRONTIERS IN ONCOLOGY
VL 14
AR 1455413
DI 10.3389/fonc.2024.1455413
DT Article
PD SEP 5 2024
PY 2024
AB Background Recurrent and metastatic head and neck squamous cell
   carcinoma (HNSCC) is characterized by a complex therapeutic management
   that needs to be discussed in multidisciplinary tumor boards (MDT).
   While artificial intelligence (AI) improved significantly to assist
   healthcare professionals in making informed treatment decisions for
   primary cases, an application in the even more complex
   recurrent/metastatic setting has not been evaluated yet. This study also
   represents the first evaluation of the recently published LLM ChatGPT
   4o, compared to ChatGPT 4.0 for providing therapy
   recommendations.Methods The therapy recommendations for 100 HNSCC cases
   generated by each LLM, 50 cases of recurrence and 50 cases of distant
   metastasis were evaluated by two independent reviewers. The primary
   outcome measured was the quality of the therapy recommendations measured
   by the following parameters: clinical recommendation, explanation, and
   summarization.Results In this study, ChatGPT 4o and 4.0 provided mostly
   general answers for surgery, palliative care, or systemic therapy.
   ChatGPT 4o proved to be 48.5% faster than ChatGPT 4.0. For clinical
   recommendation, explanation, and summarization both LLMs obtained high
   scores in terms of performance of therapy recommendations, with no
   significant differences between both LLMs, but demonstrated to be mostly
   an assisting tool, requiring validation by an experienced clinician due
   to a lack of transparency and sometimes recommending treatment
   modalities that are not part of the current treatment
   guidelines.Conclusion This research demonstrates that ChatGPT 4o and 4.0
   share a similar performance, while ChatGPT 4o is significantly faster.
   Since the current versions cannot tailor therapy recommendations, and
   sometimes recommend incorrect treatment options and lack information on
   the source material, advanced AI models at the moment can merely assist
   in the MDT setting for recurrent/metastatic HNSCC.
ZS 0
Z8 0
ZB 2
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-09-23
UT WOS:001315310200001
PM 39301542
ER

PT J
AU CHEN, QINGYU 
TI Addressing Factual Inaccuracy and Unfaithful Reasoning of Large Language
   Models in Biomedicine and Healthcare
DT Awarded Grant
PD Aug 29 2024
PY 2024
AB PROJECT SUMMARY/ABSTRACTLarge Language Models (LLMs) represent the
   latest advancement in Natural Language Processing (NLP) andArtificial
   Intelligence (AI), holding tremendous potential to revolutionize
   biomedical and healthcare applications.Extensive research has
   demonstrated the effectiveness of LLMs in a range of biomedical and
   healthapplications, ranging from medical question answering to
   summarizing systematic reviews and AI-assisteddisease diagnosis.
   However, the major barriers to applying LLMs in biomedical and health
   applications arefactual incorrectness – where LLM-generated responses
   are inaccurate or incomplete – and unfaithfulreasoning – where
   LLM-generated responses lack supporting evidence, contradict existing
   evidence, or evenrely on hallucinated evidence. Such issues further pose
   the risk of propagating misinformation, potentiallyleading to
   misdiagnosis or incorrect treatment recommendations. Addressing these
   issues has beenchallenging, primarily due to three fundamental
   obstacles: (1) from the data perspective, LLMs may capturemisinformation
   from lower-quality or unauthorized sources in the general domain data
   during pretraining, lackaccess to accurate and up-to-date biomedical
   knowledge, and consequently generate inaccurate, outdated, orunfaithful
   results; (2) from the methods perspective, there is a lack of mechanisms
   for fact-checking andevidence attribution throughout the lifecycle of
   LLMs when applied to biomedical and health studies, spanningfrom
   training/fine-tuning to inference and post-hoc analysis; (3) from the
   accountability perspective, fewapproaches have evaluated their
   effectiveness in biomedical and health downstream applications. Our
   overallobjective in this proposal is to systematically address the issue
   of factuality and unfaithful reasoning of LLMs inbiomedicine and
   healthcare. The specific aims include (1) from the data perspective,
   establishing a self-augmentation framework to teach LLMs to
   automatically select and use relevant biomedical digital resources
   toaugment their responses; (2) from the methods perspective, developing
   an LLM curator by stimulating fact-checking and evidence attribution
   performed in biocuration via a multi-stage, multi-task instruction
   tuningpipeline; (3) from the methods perspective, introducing a
   step-level automated feedback-guided paradigm forLLMs to reflect and
   improve from its intermediate responses via fact-checking and evidence
   attribution; and (4)from the accountability perspective, evaluating the
   methods in downstream use cases. The proposed work isexpected to address
   factual incorrectness and unfaithful reasoning of LLMs – the key barrier
   to their use inbiomedical and health domains – and make LLMs generate
   accurate and trustworthy responses to advancebiomedical discovery and
   healthcare. It is also expected to refine the current development and
   evaluationpipelines of LLMs in biomedical and health domains by making
   fact-checking and evidence attribution essentialcomponents and providing
   related benchmarks, methods, and tools to facilitate the implementation.
ZA 0
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
Z9 0
G1 10946218; 1R01LM014604-01; R01LM014604
DA 2024-09-29
UT GRANTS:17811425
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT C
AU Panagoulias, Dimitrios P.
   Palamidas, Filippos A.
   Virvou, Maria
   Tsihrintzis, George A.
GP IEEE
TI Rule-Augmented Artificial Intelligence-empowered Systems for Medical
   Diagnosis using Large Language Models
SO 2023 IEEE 35TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE, ICTAI
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
BP 70
EP 77
DI 10.1109/ICTAI59109.2023.00018
DT Proceedings Paper
PD 2023
PY 2023
AB In this paper, we investigate the enhancement of Artificial Intelligence
   (AI) technologies in healthcare and the better understanding of medical
   literature with the use of Large Language Models (LLMs) and Natural
   Language Processing (NLP). Specifically, we introduce a rule-augmented
   AI-empowered system which incorporates a rule-based decision system, the
   ChatGPT application programming interface (API), and other external
   machine learning and analytical APIs to offer diagnostic suggestions to
   patients. The complexities of patient healthcare experiences, including
   doctor-patient interactions, understanding levels, treatment procedures,
   and preventive care, are considered. We illustrate how a diagnostic
   process typically integrates various strategies depending on various
   factors. To digitize the greatest portion of the process, we propose and
   illustrate the use of LLMs for humanizing the communication process and
   investigating ways to reduce burdens and costs in primary healthcare. We
   also outline a theoretical decision model for evaluating the use of
   technological components from external sources versus building them from
   scratch. The paper is structured into sections detailing background
   theories and context, our proposed and implemented rule-augmented
   AI-empowered system, as well as a system test in a corresponding use
   case. Finally, the paper key findings are presented, which contribute
   valuable insights for future work in this field.
CT 35th IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 06-08, 2023
CL Atlanta, GA
SP IEEE; IEEE Comp Soc; Biol & Artificial Intelligence Fdn
Z8 0
ZA 0
TC 5
ZR 0
ZB 0
ZS 0
Z9 5
DA 2024-02-28
UT WOS:001139095400010
ER

PT J
AU Pawana, I Wayan Adi Juliawan
   Astillo, Philip Virgil
   You, Ilsun
TI Lightweight LLM-Based Anomaly Detection Framework for Securing IoTMD
   Enabled Diabetes Management Control Systems.
SO IEEE journal of biomedical and health informatics
VL PP
DI 10.1109/JBHI.2025.3577604
DT Journal Article
PD 2025-Jun-09
PY 2025
AB The adoption of Implantable Internet of Things Medical Devices (IoTMD)
   has revolutionized chronic disease management by enabling continuous
   monitoring and real-time data transmission, allowing patients to
   optimize treatment strategies. However, these advancements come with
   significant security risks, as IoTMD systems remain vulnerable to cyber
   threats that could compromise patient data and device functionality.
   Addressing this challenge, this study evaluates the fine-tuning
   performance of various lightweight Large Language Models (LLMs) for
   anomaly detection in IoTMD-enabled diabetes management control systems
   (DMCS). Among the evaluated models, LLaMA 3.2 1B-Instruct, fine-tuned
   with Low-Rank Adaptation (LoRA), achieves the highest performance, with
   99.91% accuracy, perfect precision (100.00%), and a false positive rate
   of 0%. Comparative analysis against other lightweight LLMs-GPT-2, Phi-1
   (1.3B), and Gemma 2B-Instruct-as well as traditional deep learning
   models such as IL-MLP, IL-CNN, FL-MLP, and FL-CNN, highlights the
   superior adaptability and robustness of transformer-based architectures
   in anomaly detection. These findings demonstrate the effectiveness of
   LLMs in securing IoTMD systems, providing a powerful solution for
   mitigating cyber threats while ensuring system reliability. The results
   underscore the potential of LLM-based anomaly detection in strengthening
   IoTMD cybersecurity, paving the way for safer and more reliable
   implantable medical devices in modern healthcare settings.
ZA 0
Z8 0
TC 0
ZS 0
ZR 0
ZB 0
Z9 0
DA 2025-06-12
UT MEDLINE:40489281
PM 40489281
ER

PT J
AU McLean, Aaron Lawson
   Wu, Yonghui
   McLean, Anna C. Lawson
   Hristidis, Vagelis
TI Large language models as decision aids in neuro-oncology: a review of
   shared decision-making applications
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 3
AR 139
DI 10.1007/s00432-024-05673-x
DT Review
PD MAR 19 2024
PY 2024
AB Shared decision-making (SDM) is crucial in neuro-oncology, fostering
   collaborations between patients and healthcare professionals to navigate
   treatment options. However, the complexity of neuro-oncological
   conditions and the cognitive and emotional burdens on patients present
   significant barriers to achieving effective SDM. This discussion
   explores the potential of large language models (LLMs) such as OpenAI's
   ChatGPT and Google's Bard to overcome these barriers, offering a means
   to enhance patient understanding and engagement in their care. LLMs, by
   providing accessible, personalized information, could support but not
   supplant the critical insights of healthcare professionals. The
   hypothesis suggests that patients, better informed through LLMs, may
   participate more actively in their treatment choices. Integrating LLMs
   into neuro-oncology requires navigating ethical considerations,
   including safeguarding patient data and ensuring informed consent,
   alongside the judicious use of AI technologies. Future efforts should
   focus on establishing ethical guidelines, adapting healthcare workflows,
   promoting patient-oriented research, and developing training programs
   for clinicians on the use of LLMs. Continuous evaluation of LLM
   applications will be vital to maintain their effectiveness and alignment
   with patient needs. Ultimately, this exploration contends that the
   thoughtful integration of LLMs into SDM processes could significantly
   enhance patient involvement and strengthen the patient-physician
   relationship in neuro-oncology care.
ZR 0
ZB 1
ZA 0
ZS 0
TC 8
Z8 1
Z9 8
DA 2024-04-01
UT WOS:001187667700003
PM 38503921
ER

PT J
AU Agrawal, Anjali
TI Fairness in AI-Driven Oncology: Investigating Racial and Gender Biases
   in Large Language Models
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 9
AR e69541
DI 10.7759/cureus.69541
DT Article
PD SEP 16 2024
PY 2024
AB Introduction: Large language model (LLM) chatbots have many applications
   in medical settings. However, these tools can potentially perpetuate
   racial and gender biases through their responses, worsening disparities
   in healthcare. With the ongoing discussion of LLM chatbots in oncology
   and the widespread goal of addressing cancer disparities, this study
   focuses on biases propagated by LLM chatbots in oncology. Methods: Chat
   Generative Pre-trained Transformer (Chat GPT; OpenAI, San Francisco, CA,
   USA) was asked to determine what occupation a generic description of
   "assesses cancer patients" would correspond to for different
   demographics. Chat GPT, Gemini (Alphabet Inc., Mountain View, CA, USA),
   and Bing Chat (Microsoft Corp., Redmond, WA, USA) were prompted to
   provide oncologist recommendations in the top U.S. cities and
   demographic information (race, gender) of recommendations was compared
   against national distributions. Chat GPT was also asked to generate a
   job description for oncologists with different demographic backgrounds.
   Finally, Chat GPT, Gemini, and Bing Chat were asked to generate
   hypothetical cancer patients with race, smoking, and drinking histories.
   Results: LLM chatbots are about two times more likely to predict Blacks
   and Native Americans as oncology nurses than oncologists, compared to
   Asians (p < 0.01 and < 0.001, respectively). Similarly, they are also
   significantly more likely to predict females than males as oncology
   nurses (p < 0.001). Chat GPT's real-world oncologist recommendations
   overrepresent Asians by almost double and underrepresent Blacks by
   double and Hispanics by seven times. Chatbots also generate different
   job descriptions based on demographics, including cultural competency
   and advocacy and excluding treatment administration for underrepresented
   backgrounds. AI-generated cancer cases are not fully representative of
   real-world demographic distributions and encode stereotypes on substance
   abuse, such as Hispanics having a greater proportion of smokers than
   Whites by about 20% in Chat GPT breast cancer cases. Conclusion: To our
   knowledge, this is the first study of its kind to investigate racial and
   gender biases of such a diverse set of AI chatbots, and that too, within
   oncology. The methodology presented in this study provides a framework
   for targeted bias evaluation of LLMs in various fields across medicine.
ZB 0
Z8 0
ZA 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2024-09-29
UT WOS:001318056600011
PM 39416584
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT C
AU Almeida, Ruben
   Sousa, Hugo
   Cunha, Luis F.
   Guimaraes, Nuno
   Campos, Ricardo
   Jorge, Alipio
BE Goharian, N
   Tonellotto, N
   He, Y
   Lipani, A
   McDonald, G
   Macdonald, C
   Ounis, I
TI Physio: An LLM-Based Physiotherapy Advisor
SO ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT V
SE Lecture Notes in Computer Science
VL 14612
BP 189
EP 193
DI 10.1007/978-3-031-56069-9_16
DT Proceedings Paper
PD 2024
PY 2024
AB The capabilities of the most recent language models have increased the
   interest in integrating them into real-world applications. However, the
   fact that these models generate plausible, yet incorrect text poses a
   constraint when considering their use in several domains. Healthcare is
   a prime example of a domain where text-generative trustworthiness is a
   hard requirement to safeguard patient well-being. In this paper, we
   present Physio, a chat-based application for physical rehabilitation.
   Physio is capable of making an initial diagnosis while citing reliable
   health sources to support the information provided. Furthermore, drawing
   upon external knowledge databases, Physio can recommend rehabilitation
   exercises and over-the-counter medication for symptom relief. By
   combining these features, Physio can leverage the power of generative
   models for language processing while also conditioning its response on
   dependable and verifiable sources. A live demo of Physio is available at
   https://physio.inesctec.pt.
CT 46th European Conference on Information Retrieval (ECIR)
CY MAR 24-28, 2024
CL Glasgow, SCOTLAND
SP Univ Glasgow; British Comp Soc, Informat Retrieval Specialist Grp
ZB 0
ZR 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-05-31
UT WOS:001211835200016
ER

PT J
AU McClelland, Robyn L.
   Jorgensen, Neal W.
   Post, Wendy S.
   Szklo, Moyses
   Kronmal, Richard A.
TI Methods for estimation of disparities in medication use in an
   observational cohort study: results from the Multi-Ethnic Study of
   Atherosclerosis
SO PHARMACOEPIDEMIOLOGY AND DRUG SAFETY
VL 22
IS 5
BP 533
EP 541
DI 10.1002/pds.3406
DT Article
PD MAY 2013
PY 2013
AB Purpose Evaluating disparities in health care is an important aspect of
   understanding differences in disease risk. The purpose of this study is
   to describe the methodology for estimating such disparities, with
   application to a large multi-ethnic cohort study. Methods The
   Multi-Ethnic Study of Atherosclerosis includes 6814 participants aged
   4584years free of cardiovascular disease. Prevalence ratio (PR)
   regression was used to model baseline lipid lowering medication (LLM) or
   anti-hypertensive medication use at baseline as a function of gender,
   race, risk factors, and estimated pre-treatment biomarker values.
   Results Hispanics and African Americans had lower prevalence of
   medication use than did non-Hispanic whites, even at the same risk
   factor profile. This became non-significant after adjusting for
   socioeconomic status. Although gender did not influence the prevalence
   of LLM use (PR=1.09, 95%CI 0.951.25), there were differences in the
   association of diabetes and HDL with LLM use by gender. Men were
   significantly less likely to be on anti-hypertensive medications than
   women (PR=0.86, 95%CI 0.800.92, p<0.001), and this was not explained by
   risk factors or socioeconomic status. Lack of health insurance strongly
   influenced medication use, controlling for risk factors and other
   markers of socioeconomic status. Conclusions Disparities exist in the
   treatment of cholesterol and hypertension. Hispanics and African
   Americans had less use of LLM; men had less use of anti-hypertensives.
   Risk factors have differential associations with medication use
   depending on gender. Methods described in this paper can provide
   improved disparity estimation in observational cohort studies. Copyright
   (c) 2013 John Wiley & Sons, Ltd.
ZS 0
Z8 0
ZR 0
ZB 6
ZA 0
TC 9
Z9 11
DA 2013-06-05
UT WOS:000318439500011
PM 23382107
ER

PT J
AU Frosolini, Andrea
   Catarzi, Lisa
   Benedetti, Simone
   Latini, Linda
   Chisci, Glauco
   Franz, Leonardo
   Gennaro, Paolo
   Gabriele, Guido
TI The Role of Large Language Models (LLMs) in Providing Triage for
   Maxillofacial Trauma Cases: A Preliminary Study
SO DIAGNOSTICS
VL 14
IS 8
AR 839
DI 10.3390/diagnostics14080839
DT Article
PD APR 2024
PY 2024
AB Background: In the evolving field of maxillofacial surgery, integrating
   advanced technologies like Large Language Models (LLMs) into medical
   practices, especially for trauma triage, presents a promising yet
   largely unexplored potential. This study aimed to evaluate the
   feasibility of using LLMs for triaging complex maxillofacial trauma
   cases by comparing their performance against the expertise of a tertiary
   referral center. Methods: Utilizing a comprehensive review of patient
   records in a tertiary referral center over a year-long period,
   standardized prompts detailing patient demographics, injury
   characteristics, and medical histories were created. These prompts were
   used to assess the triage suggestions of ChatGPT 4.0 and Google GEMINI
   against the center's recommendations, supplemented by evaluating the
   AI's performance using the QAMAI and AIPI questionnaires. Results: The
   results in 10 cases of major maxillofacial trauma indicated moderate
   agreement rates between LLM recommendations and the referral center,
   with some variances in the suggestion of appropriate examinations (70%
   ChatGPT and 50% GEMINI) and treatment plans (60% ChatGPT and 45%
   GEMINI). Notably, the study found no statistically significant
   differences in several areas of the questionnaires, except in the
   diagnosis accuracy (GEMINI: 3.30, ChatGPT: 2.30; p = 0.032) and
   relevance of the recommendations (GEMINI: 2.90, ChatGPT: 3.50; p =
   0.021). A Spearman correlation analysis highlighted significant
   correlations within the two questionnaires, specifically between the
   QAMAI total score and AIPI treatment scores (rho = 0.767, p = 0.010).
   Conclusions: This exploratory investigation underscores the potential of
   LLMs in enhancing clinical decision making for maxillofacial trauma
   cases, indicating a need for further research to refine their
   application in healthcare settings.
TC 17
ZB 2
ZS 0
ZR 0
Z8 0
ZA 0
Z9 17
DA 2024-05-05
UT WOS:001210140800001
PM 38667484
ER

PT J
AU Gu, Zhanzhong
   He, Xiangjian
   Yu, Ping
   Jia, Wenjing
   Yang, Xiguang
   Peng, Gang
   Hu, Penghui
   Chen, Shiyan
   Chen, Hongjie
   Lin, Yiguang
TI Automatic quantitative stroke severity assessment based on Chinese
   clinical named entity recognition with domain-adaptive pre-trained large
   language model
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
VL 150
AR 102822
DI 10.1016/j.artmed.2024.102822
EA FEB 2024
DT Article
PD APR 2024
PY 2024
AB Background: Stroke is a prevalent disease with a significant global
   impact. Effective assessment of stroke severity is vital for an accurate
   diagnosis, appropriate treatment, and optimal clinical outcomes. The
   National Institutes of Health Stroke Scale (NIHSS) is a widely used
   scale for quantitatively assessing stroke severity. However, the current
   manual scoring of NIHSS is labor-intensive, time-consuming, and
   sometimes unreliable. Applying artificial intelligence (AI) techniques
   to automate the quantitative assessment of stroke on vast amounts of
   electronic health records (EHRs) has attracted much interest. Objective:
   This study aims to develop an automatic, quantitative stroke severity
   assessment framework through automating the entire NIHSS scoring process
   on Chinese clinical EHRs. Methods: Our approach consists of two major
   parts: Chinese clinical named entity recognition (CNER) with a domain
   -adaptive pre -trained large language model (LLM) and automated NIHSS
   scoring. To build a highperforming CNER model, we first construct a
   stroke -specific, densely annotated dataset "Chinese Stroke Clinical
   Records"(CSCR) from EHRs provided by our partner hospital, based on a
   stroke ontology that defines semantically related entities for stroke
   assessment. We then pre -train a Chinese clinical LLM coined
   "CliRoberta"through domain -adaptive transfer learning and construct a
   deep learning -based CNER model that can accurately extract entities
   directly from Chinese EHRs. Finally, an automated, end -to -end NIHSS
   scoring pipeline is proposed by mapping the extracted entities to
   relevant NIHSS items and values, to quantitatively assess the stroke
   severity. Results: Results obtained on a benchmark dataset CCKS2019 and
   our newly created CSCR dataset demonstrate the superior performance of
   our domain -adaptive pre -trained LLM and the CNER model, compared with
   the existing benchmark LLMs and CNER models. The high F1 score of 0.990
   ensures the reliability of our model in accurately extracting the
   entities for the subsequent automatic NIHSS scoring. Subsequently, our
   automated, end -to -end NIHSS scoring approach achieved excellent inter
   -rater agreement (0.823) and intraclass consistency (0.986) with the
   ground truth and significantly reduced the processing time from minutes
   to a few seconds. Conclusion: Our proposed automatic and quantitative
   framework for assessing stroke severity demonstrates exceptional
   performance and reliability through directly scoring the NIHSS from
   diagnostic notes in Chinese clinical EHRs. Moreover, this study also
   contributes a new clinical dataset, a pre -trained clinical LLM, and an
   effective deep learning -based CNER model. The deployment of these
   advanced algorithms can improve the accuracy and efficiency of clinical
   assessment, and help improve the quality, affordability and productivity
   of healthcare services.
ZS 0
TC 7
ZA 0
Z8 0
ZR 0
ZB 1
Z9 7
DA 2024-04-13
UT WOS:001197568100001
PM 38553162
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT J
AU Alkhnbashi, Omer S.
   Mohammad, Rasheed
   Hammoudeh, Mohammad
TI Aspect-Based Sentiment Analysis of Patient Feedback Using Large Language
   Models
SO BIG DATA AND COGNITIVE COMPUTING
VL 8
IS 12
AR 167
DI 10.3390/bdcc8120167
DT Article
PD DEC 2024
PY 2024
AB Online medical forums have emerged as vital platforms for patients to
   share their experiences and seek advice, providing a valuable,
   cost-effective source of feedback for medical service management. This
   feedback not only measures patient satisfaction and improves health
   service quality but also offers crucial insights into the effectiveness
   of medical treatments, pain management strategies, and alternative
   therapies. This study systematically identifies and categorizes key
   aspects of patient experiences, emphasizing both positive and negative
   sentiments expressed in their narratives. We collected a dataset of
   approximately 15,000 entries from various sections of the widely used
   medical forum, patient.info. Our innovative approach integrates content
   analysis with aspect-based sentiment analysis, deep learning techniques,
   and a large language model (LLM) to analyze these data. Our methodology
   is designed to uncover a wide range of aspect types reflected in patient
   feedback. The analysis revealed seven distinct aspect types prevalent in
   the feedback, demonstrating that deep learning models can effectively
   predict these aspect types and their corresponding sentiment values.
   Notably, the LLM with few-shot learning outperformed other models. Our
   findings enhance the understanding of patient experiences in online
   forums and underscore the utility of advanced analytical techniques in
   extracting meaningful insights from unstructured patient feedback,
   offering valuable implications for healthcare providers and medical
   service management.
ZR 0
ZB 0
TC 1
ZA 0
Z8 0
ZS 0
Z9 1
DA 2025-01-09
UT WOS:001389594900001
ER

PT J
AU Mathis, Walter S.
   Zhao, Sophia
   Pratt, Nicholas
   Weleff, Jeremy
   De Paoli, Stefano
TI Inductive thematic analysis of healthcare qualitative interviews using
   open-source large language models: How does it compare to traditional
   methods?
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 255
AR 108356
DI 10.1016/j.cmpb.2024.108356
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background: Large language models (LLMs) are generative artificial
   intelligence that have ignited much interest and discussion about their
   utility in clinical and research settings. Despite this interest there
   is sparse analysis of their use in qualitative thematic analysis
   comparing their current ability to that of human coding and analysis. In
   addition, there has been no published analysis of their use in
   real-world, protected health information. Objective: Here we fill that
   gap in the literature by comparing an LLM to standard human thematic
   analysis in real-world, semi-structured interviews of both patients and
   clinicians within a psychiatric setting. Methods: Using a 70 billion
   parameter open-source LLM running on local hardware and advanced prompt
   engineering techniques, we produced themes that summarized a full corpus
   of interviews in minutes. Subsequently we used three different
   evaluation methods for quantifying similarity between themes produced by
   the LLM and those produced by humans. Results: These revealed
   similarities ranging from moderate to substantial (Jaccard similarity
   coefficients 0.44-0.69), which are promising preliminary results.
   Conclusion: Our study demonstrates that open-source LLMs can effectively
   generate robust themes from qualitative data, achieving substantial
   similarity to human-generated themes. The validation of LLMs in thematic
   analysis, coupled with evaluation methodologies, highlights their
   potential to enhance and democratize qualitative research across diverse
   fields.
TC 7
ZS 0
ZR 0
ZB 0
Z8 0
ZA 0
Z9 7
DA 2024-08-10
UT WOS:001283539000001
PM 39067136
ER

PT J
AU Benedetti, Simone
   Frosolini, Andrea
   Catarzi, Lisa
   Vaira, Luigi Angelo
   Consorti, Giuseppe
   Paglianiti, Mariagrazia
   Gennaro, Paolo
   Gabriele, Guido
TI Large Language Models and Surgical Decision-Making: Evaluation of
   Generative Unimodal AI in Facial Traumatology Practice
SO JOURNAL OF MAXILLOFACIAL & ORAL SURGERY
DI 10.1007/s12663-025-02556-7
EA MAY 2025
DT Article; Early Access
PY 2025
AB IntroductionLarge language models (LLMs) offer remarkable potential in
   assisting healthcare professionals with diagnostic and therapeutic
   decision-making processes. However, the integration of LLMs into
   healthcare decision-making processes also introduces several doubts in
   the field of usefulness, reliability and ethical implications.Materials
   and MethodsTo assess the potential of LLMs in managing intricate
   surgical situations, a cross-sectional study with 30 real-world cases of
   maxillofacial traumatology was designed. The cases were presented to
   ChatGPT-4, Google Bard, and maxillofacial surgery residents in a
   standardized manner, and the results of the subjects were evaluated by
   an expert surgeon panel of reviewers using the AIPI and QAMAI
   tools.ResultsChatGPT-4 and Bard showed comparable performances in
   patient feature consideration but differed significantly in their
   ability to suggest differential diagnoses. ChatGPT-4 outperformed Bard
   in proposing additional examinations and treatment plans. Compared to
   LLMs, human surgery residents consistently scored higher across all
   parameters of the QAMAI tool, indicating superior accuracy, clarity,
   relevance, completeness, quality of references, and overall
   usefulness.DiscussionBoth LLMs demonstrated their potential to support
   clinical decision-making in facial traumatology, but they require
   further development to be sufficiently reliable for real-world clinical
   use.ConclusionsAIPI and QAMAI proved their utility as evaluation tools
   but highlighted the need for standardization in LLM-generated responses
   assessment.
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2025-06-08
UT WOS:001501234200001
ER

PT J
AU Lorge, Isabelle
   Joyce, Dan W
   Taylor, Niall
   Nevado-Holgado, Alejo
   Cipriani, Andrea
   Kormilitzin, Andrey
TI Detecting the clinical features of difficult-to-treat depression using
   synthetic data from large language models.
SO Computers in biology and medicine
VL 194
BP 110246
EP 110246
DI 10.1016/j.compbiomed.2025.110246
DT Journal Article
PD 2025-Jun-10
PY 2025
AB Difficult-to-treat depression (DTD) has been proposed as a broader and
   more clinically comprehensive perspective on a person's depressive
   disorder where, despite treatment, they continue to experience
   significant burden. We sought to develop a tool capable of interrogating
   routinely-collected narrative (free-text) electronic health record (EHR)
   data to locate known prognostic factors identified from the scientific
   literature that capture the clinical syndrome of DTD. Thus, we aim to
   address the upstream aspect of DTD detection, that is the identification
   of relevant factors. In this work, we use Large Language Model
   (LLM)-generated synthetic data (GPT3.5) and a Non-Maximum Suppression
   (NMS) algorithm to train a BERT-based span extraction model. The model
   is trained to extract and label spans related to a variety of relevant
   positive and negative factors (i.e. spans of text that increase or
   decrease the likelihood of a patient matching the DTD syndrome). We test
   the model on both a synthetic and a clinical test set. We obtain good
   overall performance (0.70 F1 across polarity) on clinical data from EHRs
   for extracting as many as 20 different factors considered as predictors
   of DTD and high performance (0.85 F1 with 0.95 precision) on a subset of
   important DTD factors such as history of abuse, family history of
   affective disorder, illness severity and suicidality. We show it is
   possible to train a model exclusively on synthetic data to extract
   prognostic factors in clinical data. Our results show promise for future
   healthcare applications especially in applications where traditionally,
   highly confidential medical data and costly human-expert annotations
   would normally be required.
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
TC 0
Z9 0
DA 2025-06-14
UT MEDLINE:40499374
PM 40499374
ER

PT J
AU Liu, Xiaohong
   Liu, Hao
   Yang, Guoxing
   Jiang, Zeyu
   Cui, Shuguang
   Zhang, Zhaoze
   Wang, Huan
   Tao, Liyuan
   Sun, Yongchang
   Song, Zhu
   Hong, Tianpei
   Yang, Jin
   Gao, Tianrun
   Zhang, Jiangjiang
   Li, Xiaohu
   Zhang, Jing
   Sang, Ye
   Yang, Zhao
   Xue, Kanmin
   Wu, Song
   Zhang, Ping
   Yang, Jian
   Song, Chunli
   Wang, Guangyu
TI A generalist medical language model for disease diagnosis assistance
SO NATURE MEDICINE
VL 31
IS 3
DI 10.1038/s41591-024-03416-6
EA JAN 2025
DT Article
PD MAR 2025
PY 2025
AB The delivery of accurate diagnoses is crucial in healthcare and
   represents the gateway to appropriate and timely treatment. Although
   recent large language models (LLMs) have demonstrated impressive
   capabilities in few-shot or zero-shot learning, their effectiveness in
   clinical diagnosis remains unproven. Here we present MedFound, a
   generalist medical language model with 176 billion parameters,
   pre-trained on a large-scale corpus derived from diverse medical text
   and real-world clinical records. We further fine-tuned MedFound to learn
   physicians' inferential diagnosis with a self-bootstrapping
   strategy-based chain-of-thought approach and introduced a unified
   preference alignment framework to align it with standard clinical
   practice. Extensive experiments demonstrate that our medical LLM
   outperforms other baseline LLMs and specialized models in
   in-distribution (common diseases), out-of-distribution (external
   validation) and long-tailed distribution (rare diseases) scenarios
   across eight specialties. Further ablation studies indicate the
   effectiveness of key components in our medical LLM training approach. We
   conducted a comprehensive evaluation of the clinical applicability of
   LLMs for diagnosis involving artificial intelligence (AI) versus
   physician comparison, AI-assistance study and human evaluation
   framework. Our proposed framework incorporates eight clinical evaluation
   metrics, covering capabilities such as medical record summarization,
   diagnostic reasoning and risk management. Our findings demonstrate the
   model's feasibility in assisting physicians with disease diagnosis as
   part of the clinical workflow.
Z8 0
ZB 0
ZA 0
ZS 0
TC 3
ZR 0
Z9 3
DA 2025-01-13
UT WOS:001391696700001
PM 39779927
ER

PT J
AU Pagano, Stefano
   Strumolo, Luigi
   Michalk, Katrin
   Schiegl, Julia
   Pulido, Loreto C.
   Reinhard, Jan
   Maderbacher, Guenther
   Renkawitz, Tobias
   Schuster, Marie
TI Evaluating ChatGPT, Gemini and other Large Language Models (LLMs) in
   orthopaedic diagnostics: A prospective clinical study
SO COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL
VL 28
BP 9
EP 15
DI 10.1016/j.csbj.2024.12.013
EA JAN 2025
DT Article
PD 2025
PY 2025
AB Background: Large Language Models (LLMs) such as ChatGPT are gaining
   attention for their potential applications in healthcare. This study
   aimed to evaluate the diagnostic sensitivity of various LLMs in
   detecting hip or knee osteoarthritis (OA) using only patient-reported
   data collected via a structured questionnaire, without prior medical
   consultation. Methods: A prospective observational study was conducted
   at an orthopaedic outpatient clinic specialized in hip and knee OA
   treatment. A total of 115 patients completed a paper-based questionnaire
   covering symptoms, medical history, and demographic information. The
   diagnostic performance of five different LLMs-including four versions of
   ChatGPT, two of Gemini, Llama, Gemma 2, and Mistral-Nemo-was analysed.
   Model-generated diagnoses were compared against those provided by
   experienced orthopaedic clinicians, which served as the reference
   standard. Results: GPT-4o achieved the highest diagnostic sensitivity at
   92.3 %, significantly outperforming other LLMs. The completeness of
   patient responses to symptom-related questions was the strongest
   predictor of accuracy for GPT-4o (p < 0.001). Inter-model agreement was
   moderate among GPT-4 versions, whereas models such as Llama-3.1
   demonstrated notably lower accuracy and concordance. Conclusions: GPT-4o
   demonstrated high accuracy and consistency in diagnosing OA based solely
   on patient- reported questionnaires, underscoring its potential as a
   supplementary diagnostic tool in clinical settings. Nevertheless, the
   reliance on patient-reported data without direct physician involvement
   highlights the critical need for medical oversight to ensure diagnostic
   accuracy. Further research is needed to refine LLM capabilities and
   expand their utility in broader diagnostic applications.
ZR 0
ZS 0
Z8 0
ZA 0
TC 2
ZB 0
Z9 2
DA 2025-01-28
UT WOS:001401486200001
PM 39850460
ER

PT J
AU Javid, Mohamed
   Reddiboina, Madhu
   Bhandari, Mahendra
TI Emergence of artificial generative intelligence and its potential impact
   on urology
SO CANADIAN JOURNAL OF UROLOGY
VL 30
IS 4
BP 11588
EP 11598
DT Review
PD AUG 2023
PY 2023
AB Introduction: Artificial generative intelligence (AGI) and large
   language models (LLMs) have gained significant attention in healthcare
   and hold enormous promise for transforming every aspect of our life and
   urology is no exception.
   Materials and methods: We conducted a comprehensive literature search of
   electronic databases and included articles discussing AGI and LLMs in
   healthcare. Additionally, we have incorporated our experiences
   interacting with the ChatGPT and GPT-4 in different situations with real
   case reports and case constructs.
   Results: Our review highlights the potential applications and likely
   impact of these technologies in urology, for differential diagnosis,
   prioritizing treatment options, and facilitating research, surgeon, and
   patient education. At their current developmental stage, we have
   recognized the need for concurrent validation and continuous human
   interaction necessary to induce inverse reinforced learning with human
   feedback to mature them to authenticity. We need to consciously adjust
   to the hallucinations and guard patients' confidentiality before their
   extensive implementations in clinical practice. We propose possible
   remedies for these shortcomings and emphasize the critical role of human
   interaction in their evolution.
   Conclusion: The integration of these tools has the potential to
   revolutionize urology, but it also presents several challenges needing
   attention. To harness the full potential of these models, urologists
   must consistently engage in training these tools with their clinical
   sense and experience. We urge the urology community to actively
   participate in AGI and LLM development to address potential challenges.
   These models could help us in unleashing our full potential and help us
   achieve a better work-life balance.
Z8 0
ZS 0
ZA 0
ZR 0
TC 14
ZB 4
Z9 14
DA 2023-11-10
UT WOS:001087939300004
PM 37633285
ER

PT J
AU Busch, Felix
   Hoffmann, Lena
   Rueger, Christopher
   van Dijk, Elon H. C.
   Kader, Rawen
   Ortiz-Prado, Esteban
   Makowski, Marcus R.
   Saba, Luca
   Hadamitzky, Martin
   Kather, Jakob Nikolas
   Truhn, Daniel
   Cuocolo, Renato
   Adams, Lisa C.
   Bressem, Keno K.
TI Current applications and challenges in large language models for patient
   care: a systematic review
SO COMMUNICATIONS MEDICINE
VL 5
IS 1
AR 26
DI 10.1038/s43856-024-00717-2
DT Article
PD JAN 21 2025
PY 2025
AB BackgroundThe introduction of large language models (LLMs) into clinical
   practice promises to improve patient education and empowerment, thereby
   personalizing medical care and broadening access to medical knowledge.
   Despite the popularity of LLMs, there is a significant gap in
   systematized information on their use in patient care. Therefore, this
   systematic review aims to synthesize current applications and
   limitations of LLMs in patient care.MethodsWe systematically searched 5
   databases for qualitative, quantitative, and mixed methods articles on
   LLMs in patient care published between 2022 and 2023. From 4349 initial
   records, 89 studies across 29 medical specialties were included. Quality
   assessment was performed using the Mixed Methods Appraisal Tool 2018. A
   data-driven convergent synthesis approach was applied for thematic
   syntheses of LLM applications and limitations using free line-by-line
   coding in Dedoose.ResultsWe show that most studies investigate
   Generative Pre-trained Transformers (GPT)-3.5 (53.2%, n = 66 of 124
   different LLMs examined) and GPT-4 (26.6%, n = 33/124) in answering
   medical questions, followed by patient information generation, including
   medical text summarization or translation, and clinical documentation.
   Our analysis delineates two primary domains of LLM limitations: design
   and output. Design limitations include 6 second-order and 12 third-order
   codes, such as lack of medical domain optimization, data transparency,
   and accessibility issues, while output limitations include 9
   second-order and 32 third-order codes, for example, non-reproducibility,
   non-comprehensiveness, incorrectness, unsafety, and bias.ConclusionsThis
   review systematically maps LLM applications and limitations in patient
   care, providing a foundational framework and taxonomy for their
   implementation and evaluation in healthcare settings.
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 8
Z9 8
DA 2025-01-29
UT WOS:001402540700001
PM 39838160
ER

PT B
AU Xue, Bing
Z2  
TI Deep Representation Learning for Clinical Predictive Models
DT Dissertation/Thesis
PD Jan 01 2023
PY 2023
ZR 0
ZB 0
ZA 0
Z8 0
TC 0
ZS 0
Z9 0
UT PQDT:86901685
ER

PT J
AU Karakas, Cemal
   Brock, Dylan
   Lakhotia, Arpita
TI Leveraging ChatGPT in the Pediatric Neurology Clinic: Practical
   Considerations for Use to Improve Efficiency and Outcomes
SO PEDIATRIC NEUROLOGY
VL 148
BP 157
EP 163
DI 10.1016/j.pediatrneurol.2023.08.035
EA SEP 2023
DT Article
PD NOV 2023
PY 2023
AB Background: Artificial intelligence (AI) is progressively influencing
   healthcare sectors, including pediatric neurology. This paper aims to
   investigate the potential and limitations of using ChatGPT, a large
   language model (LLM) developed by OpenAI, in an outpatient pediatric
   neurology clinic. The analysis focuses on the tool's capabilities in
   enhancing clinical efficiency, productivity, and patient education.
   Method: This is an opinion-based exploration supplemented with practical
   examples. We assessed ChatGPT's utility in administrative and
   educational tasks such as drafting medical necessity letters and
   creating patient educational materials. Results: ChatGPT showed efficacy
   in streamlining administrative work, particularly in drafting
   administrative letters and formulating personalized patient education
   materials. However, the model has limitations in performing higher-order
   tasks like formulating nuanced differential diagnoses. Additionally,
   ethical and legal concerns, including data privacy and the potential
   dissemination of misinformation, warrant cautious implementation.
   Conclusions: The integration of AI tools like ChatGPT in pediatric
   neurology clinics has demonstrated promising results in boosting
   efficiency and patient education, despite present limitations and
   ethical concerns. As technology advances, we anticipate future
   applications may extend to more complex clinical tasks like precise
   differential diagnoses and treatment strategy guidance. Careful,
   patient-centered implementation is essential for leveraging the
   potential benefits of AI in pediatric neurology effectively. (c) 2023
   Elsevier Inc. All rights reserved.
Z8 1
ZB 1
ZS 0
TC 5
ZR 0
ZA 0
Z9 6
DA 2023-10-28
UT WOS:001082330800001
PM 37725885
ER

PT C
AU Sharif, Omar
   Basak, Madhusudan
   Parvin, Tanzia
   Scharfstein, Ava
   Bradham, Alphonso
   Borodovsky, Jacob T.
   Lord, Sarah E.
   Preum, Sarah M.
BE Wooldridge, M
   Dy, J
   Natarajan, S
TI Characterizing Information Seeking Events in Health-Related Social
   Discourse
SO THIRTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOL 38 NO 20
SE AAAI Conference on Artificial Intelligence
BP 22350
EP 22358
DT Proceedings Paper
PD 2024
PY 2024
AB Social media sites have become a popular platform for individuals to
   seek and share health information. Despite the progress in natural
   language processing for social media mining, a gap remains in analyzing
   health-related texts on social discourse in the context of events.
   Event-driven analysis can offer insights into different facets of
   healthcare at an individual and collective level, including treatment
   options, misconceptions, knowledge gaps, etc. This paper presents a
   paradigm to characterize health-related information-seeking in social
   discourse through the lens of events. Events here are board categories
   defined with domain experts that capture the trajectory of the
   treatment/medication. To illustrate the value of this approach, we
   analyze Reddit posts regarding medications for OPIOID USE DISORDER
   (OUD), a critical global health concern. To the best of our knowledge,
   this is the first attempt to define event categories for characterizing
   information-seeking in OUD social discourse. Guided by domain experts,
   we develop TREAT-ISE, a novel multilabel treatment information-seeking
   event dataset to analyze online discourse on an event-based framework.
   This dataset contains Reddit posts on information-seeking events related
   to recovery from OUD, where each post is annotated based on the type of
   events. We also establish a strong performance benchmark (77.4% F1
   score) for the task by employing several machine learning and deep
   learning classifiers. Finally, we thoroughly investigate the performance
   and errors of ChatGPT on this task, providing valuable insights into the
   LLM's capabilities and ongoing characterization efforts.
CT 38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference
   on Innovative Applications of Artificial Intelligence / 14th Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 20-27, 2024
CL Vancouver, CANADA
SP Assoc Advancement Artificial Intelligence
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
TC 1
Z9 1
DA 2024-08-23
UT WOS:001239985800053
ER

PT J
AU Xu, Peng
TI Multi-layered data framework for enhancing postoperative outcomes and
   anaesthesia management through natural language processing
SO SLAS TECHNOLOGY
VL 32
AR 100294
DI 10.1016/j.slast.2025.100294
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Anaesthesia management is a critical aspect of perioperative care,
   directly influencing postoperative recovery, pain management, and
   patient outcomes. Despite advancements in anaesthesia techniques,
   variability in patient responses and unexpected postoperative
   complications remain significant challenges. The research proposes a
   multi-layered architecture named Anaesthesia CareNet for analyzing data
   from diverse sources to enhance personalized anaesthesia management and
   postoperative outcome prediction. The architecture is structured into
   two primary layers: Data processing and Predictive Modeling. In the Data
   processing layer, advanced Natural Language Processing (NLP) techniques
   such as Named Entity Recognition (NER), normalization, lemmatization,
   and stemming are applied to clean and standardize the unstructured
   clinical data. Generative Pre-trained Transformer 3 (GPT-3), a Large
   Language Model (LLM) is employed as a feature extraction method,
   allowing the system to process and analyze complex clinical narratives
   and unstructured textual data from patient records. This enables more
   precise and personalized predictions, not only improving anaesthesia
   management but also laying the groundwork for broader applications in
   life sciences. The extracted data is passed into the predictive modeling
   layer, where the Intelligent Golden Eagle Fine-Tuned Logistic Regression
   (IGE-LR) model is applied. By analyzing correlations between patient
   characteristics, surgical details, and postoperative recovery patterns,
   IGELR enables the prediction of complications, pain management
   requirements, and recovery trajectories beyond anaesthesia; the
   methodology has potential applications in diverse areas such as
   diagnostics, drug discovery, and personalized medicine, where
   large-scale data analysis, predictive modeling, and real-time
   adaptability are crucial for improving patient outcomes. The proposed
   IGE-LR method achieves higher performance with 91.7 % accuracy, 90.6 %
   specificity, and 90 % AUC, with a recall of 91.3 %, precision of 90.1 %,
   and an F1-Score of 90.4 %. By leveraging advanced NLP and predictive
   analytics, Anaesthesia CareNet exemplifies how AI-driven frameworks can
   transform life sciences, advancing personalized healthcare and creating
   a more precise, efficient, and dynamic approach to treatment management.
ZR 0
ZS 0
TC 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-10
UT WOS:001479823100001
PM 40252977
ER

PT C
AU Nath, Shantanu
   Samin, Ahnaf Mozib
BE Ojha, AK
   Dogruoz, AS
   Madabushi, HT
   Martino, GD
   Rosenthal, S
   Rosa, A
TI BD-NLP at SemEval-2024 Task 2: Investigating Generative and
   Discriminative Models for Clinical Inference with Knowledge Augmentation
SO PROCEEDINGS OF THE 18TH INTERNATIONAL WORKSHOP ON SEMANTIC EVALUATION,
   SEMEVAL-2024
BP 1302
EP 1308
DT Proceedings Paper
PD 2024
PY 2024
AB Healthcare professionals rely on evidence from Clinical Trial Records
   (CTRs) to devise treatment plans. However, the increasing quantity of
   CTRs poses challenges in efficiently assimilating the latest evidence to
   provide personalized evidence-based care. In this paper, we present our
   solution to the SemEval-2024 Task 2 titled "Safe Biomedical Natural
   Language Inference for Clinical Trials". Given a statement and one/two
   CTRs as inputs, the task is to determine whether or not the statement
   entails or contradicts the CTRs. We explore both generative and
   discriminative large language models (LLM) to investigate their
   performance for clinical inference. Moreover, we contrast the
   general-purpose LLMs with the ones specifically tailored for the
   clinical domain to study the potential advantage in mitigating
   distributional shifts. Furthermore, the benefit of augmenting additional
   knowledge within the prompt is examined in this work. Our empirical
   study suggests that DeBERTa-lg, a discriminative task-specific natural
   language inference model, obtains the highest F1 score of 0.77 and
   consistency score of 0.76 on the test set, securing the fourth rank on
   the leaderboard. Intriguingly, the augmentation of knowledge yields
   subpar results across most cases.
CT 18th International Workshop on Semantic Evaluation (SemEval)
CY JUN 20-21, 2024
CL Mexico City, MEXICO
SP ACL Special Interest Grp Lexicon
ZA 0
TC 0
ZB 0
ZR 0
Z8 0
ZS 0
Z9 0
DA 2024-12-11
UT WOS:001356736800188
ER

PT C
AU Balakrishna, Chinnala
   Yadav, Ankit
   Singh, Jagendra
   Saba, Masarath
   Shashikant
   Shrivastava, Vineet
GP IEEE
TI Smart Drug Delivery Systems using Large Language Models for Real-Time
   Treatment Personalization
SO 2024 2ND WORLD CONFERENCE ON COMMUNICATION & COMPUTING, WCONF 2024
AR 2593
DI 10.1109/WCONF61366.2024.10692060
DT Proceedings Paper
PD 2024
PY 2024
AB This research explores the use of large language models, such as BERT
   and GPT, in developing a smart drug delivery system utilizing real-time
   personalized treatments. The research aims to utilize large datasets
   with advanced natural language processing to recommend the appropriate
   drug for a patient based on their health record with enhanced accuracy
   and efficiency. The research, which evaluates and compares BERT and GPT,
   achieves the goal of predicting a drug with high accuracy, and GPT
   delivers the best results compared to BERT. Specifically, GPT achieved
   an accuracy of 97.95%, while BERT's accuracy was 95.50%. Additionally,
   the research emphasizes the essential aspect of a model's time response
   since these are real-time clinical decision systems. GPT took 110
   milliseconds to predict the drug while the BERT took 120 milliseconds.
   It is clear from the results of this work that LLM has the potential of
   changing personalized medicine's approach by recommending drugs in
   real-time and according to the patient's health record within no time.
   The proposed system for smart drug delivery is promising to improve
   healthcare services, patient outcomes, and reduce drug administration
   errors. Apart from predicting the drug, these research findings can be
   simulated to the health sectors and integrated with AI technologies to
   improve decision support systems.
CT 2nd IEEE World Conference on Communication and Computing (WCONF)
CY JUL 12-14, 2024
CL Kalinga Univ, Raipur, INDIA
HO Kalinga Univ
SP IEEE; Govt India, Dept Sci & Technol, Sci & Engn Res Board; IEEE Tech
   Comm; IEEE MP Sect
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
ZA 0
Z9 0
DA 2025-02-14
UT WOS:001339364000090
ER

PT J
TI Assist GP <> Medwise AI. Improving patient care pathways with LLM
   technology
DT Awarded Grant
PD Apr 30 2024
PY 2024
AB There is an increasing need for healthcare professionals to quickly and
   accurately access information during patient care consultations. Doctors
   and other clinicians typically rely on written guidelines from various
   authorities for decision-making. These guidelines, encompassing
   everything from diagnosis to treatment, present challenges during
   patient care episodes due to their complexity (length, depth or
   presentation). Moreover, discrepancies between these guidelines and
   other online resources, along with local healthcare policies and funding
   protocols, can lead to variations in patient care and outcomes if the
   information - or its whereabouts- is not known to the clinician. 
   Responding to this challenge, Medwise AI is developing a solution to
   assist clinicians in swiftly finding the information they need.
   Utilising advanced technology, the company aims to streamline the
   process of information retrieval, thus enhancing efficiency and the
   consistency of care that this information enables. The solution is
   intended to reduce the time healthcare professionals spend navigating
   extensive guidelines, allowing a greater focus on direct patient care,
   and adherence to best practice.  The project builds upon existing
   technologies already used by GPs in West Yorkshire. It includes the
   development of a tool that provides immediate access to the required
   evidence-based information. This tool is particularly useful for
   navigating lengthy clinical guidelines and ensuring healthcare
   professionals stay abreast of the latest best practices when the
   information is needed.  The next stage of the project involves
   leveraging insights from previous user interactions to develop an
   improved search tool. This tool will provide rapid and precise responses
   to clinical queries, guiding healthcare professionals through various
   patient care options. Advanced technological features are planned to
   enhance the tool's accuracy and response speed, ensuring clinicians have
   timely access to necessary information.  The initiative is focused on
   providing healthcare professionals with accessible, consistent, and
   standardised care information. The goal is to minimise variations in
   treatment approaches and mitigate disparities in patient care. Medwise
   AI is committed to supporting healthcare professionals in delivering
   uniform, high-quality care to all patients. By equipping clinicians with
   more effective tools, the aim is to improve the overall quality of
   patient care and meet the challenges posed by the complex nature of
   current medical guidelines, making these documents more useful and
   usable in the delivery of best practice patient care.
ZR 0
ZS 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
G1 10108507
DA 2024-08-04
UT GRANTS:17771413
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT J
AU Li, Ang
   Wang, Yunxin
   Chen, Hongxu
TI AI driven cardiovascular risk prediction using NLP and Large Language
   Models for personalized medicine in athletes
SO SLAS TECHNOLOGY
VL 32
AR 100286
DI 10.1016/j.slast.2025.100286
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB The performance and long-term health of athletes are significantly
   influenced by their cardiovascular resilience and associated risk
   factors. This study explores the innovative applications of Natural
   Language Processing (NLP) and Large Language Models (LLMs) in biomedical
   diagnostics, particularly for AI-driven arrhythmia detection,
   hypertrophic cardiomyopathy (HCM) in athletes, and personalized
   medicine. The complexity of analysing diverse biomedical datasets, such
   as electrocardiograms (ECG), clinical records, genetic screening
   reports, and imaging results, poses challenges in obtaining precise
   early diagnoses. To address these issues, we introduce a hybrid machine
   learning (ML) framework that integrates the Wolf Pack Search Algorithm
   Dynamic Random Forest (WPSA-DRF) with a RoBERTa-based LLM to enhance the
   accuracy of cardiovascular disease predictions. Using advanced NLP
   techniques, including biomedical text mining, entity recognition, and
   feature extraction, the system processes structured and unstructured
   clinical data to detect abnormalities associated with sudden cardiac
   arrest (SCA), arrhythmias, and genetic cardiomyopathies. The proposed
   system achieves a diagnostic accuracy of 92.5 %, precision of 92.7 %,
   recall of 99.23 %, and F1-score of 95.6 %, outperforming traditional
   diagnostic methodologies. Furthermore, the research underscores the role
   of LLMs in personalized medicine, identifying patient-specific risk
   factors and optimizing treatment pathways for cardiac patients. This
   work highlights how NLP-driven AI solutions are transforming biomedical
   research, accelerating early disease detection, and improving clinical
   decision-making for both athletes and the general population.
ZR 0
TC 0
ZA 0
ZS 0
Z8 0
ZB 0
Z9 0
DA 2025-05-08
UT WOS:001478484900001
PM 40216258
ER

PT B
AU Neehal, Nafis
Z2  
TI Enhancing Treatment Effect Estimation Using Machine Learning and Large
   Language Models
DT Dissertation/Thesis
PD Jan 01 2025
PY 2025
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
ZS 0
Z9 0
UT PQDT:123728600
ER

PT J
AU Azurmendi, Iker
   Gonzalez, Manuel
   Garcia, Gustavo
   Zulueta, Ekaitz
   Martin, Elena
TI Deep Learning-Based Postural Asymmetry Detection Through Pressure Mat
SO APPLIED SCIENCES-BASEL
VL 14
IS 24
AR 12050
DI 10.3390/app142412050
DT Article
PD DEC 2024
PY 2024
AB Deep learning, a subfield of artificial intelligence that uses neural
   networks with multiple layers, is rapidly changing healthcare. Its
   ability to analyze large datasets and extract relevant information makes
   it a powerful tool for improving diagnosis, treatment, and disease
   management. The integration of DL with pressure mats-which are devices
   that use pressure sensors to continuously and non-invasively monitor the
   interaction between patients and the contact surface-is a promising
   application. These pressure platforms generate data that can be very
   useful for detecting postural anomalies. In this paper we will discuss
   the application of deep learning algorithms in the analysis of pressure
   data for the detection of postural asymmetries in 139 patients aged 3 to
   20 years. We investigated several main tasks: patient classification,
   hemibody segmentation, recognition of specific body parts, and
   generation of automated clinical reports. For this purpose,
   convolutional neural networks in their classification and regression
   modalities, the object detection algorithm YOLOv8, and the open language
   model LLaMa3 were used. Our results demonstrated high accuracy in all
   tasks: classification achieved 100% accuracy; hemibody division obtained
   an MAE of approximately 7; and object detection had an average accuracy
   of 70%. These results demonstrate the potential of this approach for
   monitoring postural and motor disabilities. By enabling personalized
   patient care, our methodology contributes to improved clinical outcomes
   and healthcare delivery. To our best knowledge, this is the first study
   that combines pressure images with multiple deep learning algorithms for
   the detection and assessment of postural disorders and motor
   disabilities in this group of patients.
ZR 0
ZB 0
ZA 0
TC 1
ZS 0
Z8 0
Z9 1
DA 2024-12-31
UT WOS:001384060100001
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT C
AU Wei, Qizhi
   Chen, Xuanyu
   Ni, Yifei
   Cao, Cong
GP ASSOC COMPUTING MACHINERY
TI A Technical Framework for Recognizing and Interpreting Complex Medical
   Records: Based on Multimodal Large Language Model
SO 2024 THE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND TEACHER
   EDUCATION, ICAITE 2024
BP 76
EP 83
DI 10.1145/3702386.3702396
DT Proceedings Paper
PD 2024
PY 2024
AB This paper brings up a technical framework for Interpreting medical
   documentation that integrates multi-modal large language modals, aiming
   to provide patients and doctors with the ability to read nonstandard
   medical documentation in complex environments and to obtain text
   interpretation based on generative AI. The framework proposes a
   three-stage solution, namely Recognition, Formatting, and AI-Processing,
   involving technologies such as OCR, medical multi-modal models, and
   large language models, abbreviated as the RF-AI framework. This paper
   focuses on explaining the potential issues encountered when applying the
   framework and describes the resolution within the framework. In
   addition, this paper conducts experiments on two key stages of the
   framework, recognition and AI-processing, which effectively demonstrate
   the feasibility of the framework. This framework can significantly
   reduce the difficulty for patients in understanding medical records and
   provides necessary resolution for situations where paper records might
   be used. It helps patients better understand their conditions and
   enhances the efficiency of diagnosis and treatment between doctors and
   patients. Benefiting from a large language model, this framework allows
   developers to expand based on actual needs and can be integrated into
   existing electronic healthcare systems to achieve more comprehensive
   functionality.
CT 2024 International Conference on Artificial Intelligence and Teacher
   Education
CY OCT 12-14, 2024
CL Beijing, PEOPLES R CHINA
Z8 0
ZR 0
ZA 0
TC 0
ZS 0
ZB 0
Z9 0
DA 2025-04-04
UT WOS:001443289300012
ER

PT J
AU de Arriba-Perez, Francisco
   Garcia-Mendez, Silvia
TI Leveraging large language models through natural language processing to
   provide interpretable machine learning predictions of mental
   deterioration in real time
SO ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING
DI 10.1007/s13369-024-09508-2
EA AUG 2024
DT Article; Early Access
PY 2024
AB Based on official estimates, 50 million people worldwide are affected by
   dementia, and this number increases by 10 million new patients every
   year. Without a cure, clinical prognostication and early intervention
   represent the most effective ways to delay its progression. To this end,
   artificial intelligence and computational linguistics can be exploited
   for natural language analysis, personalized assessment, monitoring, and
   treatment. However, traditional approaches need more semantic knowledge
   management and explicability capabilities. Moreover, using large
   language models (llms) for cognitive decline diagnosis is still scarce,
   even though these models represent the most advanced way for
   clinical-patient communication using intelligent systems. Consequently,
   we leverage an llm using the latest natural language processing (nlp)
   techniques in a chatbot solution to provide interpretable machine
   learning prediction of cognitive decline in real-time.
   Linguistic-conceptual features are exploited for appropriate natural
   language analysis. Through explainability, we aim to fight potential
   biases of the models and improve their potential to help clinical
   workers in their diagnosis decisions. More in detail, the proposed
   pipeline is composed of (i) data extraction employing nlp-based prompt
   engineering; (ii) stream-based data processing including feature
   engineering, analysis, and selection; (iii) real-time classification;
   and (iv) the explainability dashboard to provide visual and natural
   language descriptions of the prediction outcome. Classification results
   exceed 80% in all evaluation metrics, with a recall value for the mental
   deterioration class about 85%. To sum up, we contribute with an
   affordable, flexible, non-invasive, personalized diagnostic system to
   this work.
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
ZR 0
Z9 0
DA 2024-09-01
UT WOS:001298762700003
ER

PT J
AU Saxena, Sarah
   Barreto Chang, Odmara L
   Suppan, Melanie
   Meco, Basak Ceyda
   Vacas, Susana
   Radtke, Finn
   Matot, Idit
   Devos, Arnout
   Maze, Mervyn
   Gisselbaek, Mia
   Berger-Estilita, Joana
TI A comparison of large language model-generated and published
   perioperative neurocognitive disorder recommendations: a cross-sectional
   web-based analysis.
SO British journal of anaesthesia
DI 10.1016/j.bja.2025.01.001
DT Journal Article
PD 2025-Feb-07
PY 2025
AB BACKGROUND: Perioperative neurocognitive disorders (PNDs) are common
   complications after surgery and anaesthesia, particularly in older
   adults, leading to increased morbidity, mortality, and healthcare costs.
   Therefore, major medical societies have developed recommendations for
   the prevention and treatment of PNDs. Our study evaluated the
   reliability of large language models, specifically ChatGPT-4 and Gemini,
   in generating recommendations for PND management and comparing them with
   published guidelines.
   METHODS: We conducted an online cross-sectional web-based analysis over
   48 h in June 2024. Artificial intelligence (AI)-generated
   recommendations were produced in six different locations across five
   countries (Switzerland, Belgium, Turkey, Canada, and the East and West
   Coasts of the USA). The English prompt 'a table of a bundle of care for
   perioperative neurocognitive disorders' was entered into ChatGPT-4 and
   Gemini, generating tables evaluated by independent reviewers. The
   primary outcomes were the Total Disagreement Score (TDS) and Quality
   Assessment of Medical Artificial Intelligence (QAMAI), which compared
   AI-generated recommendations with published guidelines.
   RESULTS: The study generated 14 tables, with TDS and QAMAI scores
   showing similar results for ChatGPT-4 and Gemini (2 [1-3] vs 2 [2-3],
   P=0.636 and 4 [4-4] vs 4 [3-4], P=0.424, respectively). AI-generated
   recommendations aligned well with published guidelines, with the highest
   alignment observed in ChatGPT-4-generated recommendations. No complete
   agreement with guidelines was achieved, and lack of cited sources was a
   noted limitation.
   CONCLUSIONS: Large language models can generate perioperative
   neurocognitive disorder recommendations that align closely with
   published guidelines. However, further validation and integration of
   clinician feedback are required before clinical application.
ZS 0
Z8 0
ZR 0
ZB 0
TC 0
ZA 0
Z9 0
DA 2025-02-10
UT MEDLINE:39922789
PM 39922789
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU Cohen, Natalie D.
   Ho, Milan
   Mcintire, Donald
   Smith, Katherine
   Kho, Kimberly A.
TI A comparative analysis of generative artificial intelligence responses
   from leading chatbots to questions about endometriosis
SO AJOG GLOBAL REPORTS
VL 5
IS 1
AR 100405
DI 10.1016/j.xagr.2024.100405
EA DEC 2024
DT Article
PD FEB 2025
PY 2025
AB INTRODUCTION: The use of generative artificial intelligence (AI) has
   begun to permeate most industries, including medicine, and patients will
   inevitably start using these large language model (LLM) chatbots as a
   modality for education. As healthcare information technology evolves, it
   is imperative to evaluate chatbots and the accuracy of the information
   they provide to patients and to determine if there is variability
   between them. OBJECTIVE: This study aimed to evaluate the accuracy and
   comprehensiveness of three chatbots in addressing questions related to
   endometriosis and determine the level of variability between them. STUDY
   DESIGN: Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic),
   and Bard (Google) were asked to generate answers to 10 commonly asked
   questions about endometriosis. The responses were qualitatively compared
   to current guidelines and expert opinion on endometriosis and rated on a
   scale by nine gynecologists. The grading scale included the following:
   (1) Completely incorrect, (2) mostly incorrect and some correct, (3)
   mostly correct and some incorrect, (4) correct but inadequate, (5)
   correct and comprehensive. Final scores were averaged between the nine
   reviewers. Kendall's Wand the related chi-square test were used to
   evaluate the reviewers' strength of agreement in ranking the LLMs'
   responses for each item. RESULTS: Average scores for the 10 answers
   amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7,
   respectively. Two questions showed significant disagreement between the
   nine reviewers. There were no questions the models could answer
   comprehensively or correctly across the reviewers. The model most
   associated with comprehensive and correct responses was ChatGPT.
   Chatbots showed an improved ability to accurately answer questions about
   symptoms and pathophysiology over treatment and risk of recurrence.
   CONCLUSION: The analysis of LLMs revealed that, on average, they mainly
   provided correct but inadequate responses to commonly asked patient
   questions about endometriosis. While chatbot responses can serve as
   valuable supplements to information provided by licensed medical
   professionals, it is crucial to maintain a thorough ongoing evaluation
   process for outputs to provide the most comprehensive and accurate
   information to patients. Further research into this technology and its
   role in patient education and treatment is crucial as generative AI
   becomes more embedded in the medical field.
ZA 0
Z8 0
TC 1
ZS 0
ZB 0
ZR 0
Z9 1
DA 2025-05-06
UT WOS:001476609200001
PM 39810943
ER

PT J
AU HOLLY A SWARTZ; Diyi  Yang; ZHU, HAIYI 
TI SCH: Training Mental Health Supporters with Virtual Patients and
   Automated Feedback
DT Awarded Grant
PD Aug 01 2024
PY 2024
AB Under-treatment of mental health problems remains a major issue in the
   US, especially for youth, peopleof color, and individuals with low
   incomes. Technology may help reduce disparities in and expand thereach
   of mental health services. However, the newest technologies, such as
   generative AI, remain fraughtwith perils such as hallucinations.
   Therefore, rather than using AI to directly interact with clients, we
   willharness generative AI to provide training to mental health support
   providers, with the ultimate goal ofincreasing accessibility of mental
   health services and improving mental health outcomes for thosereceiving
   care. The goal of this research project is to develop and evaluate an
   automated, scalablesystem for delivering experiential training to mental
   healthcare providers. Specifically, we propose todevelop a multi-agent
   training environment to provide interactive and experiential training on
   the micro-skills and underlying common factors for both lay counselors
   and paraprofessionals. Our trainingenvironment consists of three
   components: Virtual Patient, Assessor Agents, and Trainer Agents.
   Ourproposal has four aims. During Aim 1, we will develop and evaluate a
   set of LLM-based Virtual Patients(VPs) that (a) realistically depict a
   wide range of common clinical problems (e.g., depression,
   job-relatedstress, ADHD, and suicidality), (b) engage in coherent
   conversations with trainees, and (c) present typicalcounseling
   challenges, such as addressing resistance to sharing problems in depth.
   During Aim 2, we willdevelop an Assessor Agent capable of automatically
   assessing the micro-skills used by the trainee, aswell as how the
   trainee accomplishes higher-level segment goals (common factors). During
   Aim 3, we willdevelop a Trainer Agent capable of interacting with
   trainees, the Assessor Agent module, and the VirtualPatient module to
   achieve optimal training goals. During Aim 4, we will recruit 7Cups
   supporters to useour multi-agent training environment to evaluate its
   impacts on the training outcomes.
Z8 0
ZR 0
ZS 0
TC 0
ZB 0
ZA 0
Z9 0
G1 11062823; 1R01MH139114-01; R01MH139114
DA 2024-09-16
UT GRANTS:17807793
ER

PT J
AU Han, B.
   Chen, Y.
   Buyyounouski, M. K.
   Gensheimer, M. F.
   Xing, L.
TI RadAlonc: Enhancing Decision-Making in Radiation Oncology with a
   GPT-4-Based Prompt-Driven Large Language Model
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 2297
BP E134
EP E134
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892300029
ER

PT J
AU Yan, Chunyi
   Li, Zexi
   Liang, Yongzhou
   Shao, Shuran
   Ma, Fan
   Zhang, Nanjun
   Li, Bowen
   Wang, Chuan
   Zhou, Kaiyu
TI Assessing large language models as assistive tools in medical
   consultations for Kawasaki disease
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
VL 8
AR 1571503
DI 10.3389/frai.2025.1571503
DT Article
PD MAR 31 2025
PY 2025
AB Background Kawasaki disease (KD) presents complex clinical challenges in
   diagnosis, treatment, and long-term management, requiring a
   comprehensive understanding by both parents and healthcare providers.
   With advancements in artificial intelligence (AI), large language models
   (LLMs) have shown promise in supporting medical practice. This study
   aims to evaluate and compare the appropriateness and comprehensibility
   of different LLMs in answering clinically relevant questions about KD
   and assess the impact of different prompting strategies. Methods
   Twenty-five questions were formulated, incorporating three prompting
   strategies: No prompting (NO), Parent-friendly (PF), and Doctor-level
   (DL). These questions were input into three LLMs: ChatGPT-4o, Claude 3.5
   Sonnet, and Gemini 1.5 Pro. Responses were evaluated based on
   appropriateness, educational quality, comprehensibility, cautionary
   statements, references, and potential misinformation, using Information
   Quality Grade, Global Quality Scale (GQS), Flesch Reading Ease (FRE)
   score, and word count. Results Significant differences were found among
   the LLMs in terms of response educational quality, accuracy, and
   comprehensibility (p < 0.001). Claude 3.5 provided the highest
   proportion of completely correct responses (51.1%) and achieved the
   highest median GQS score (5.0), outperforming GPT-4o (4.0) and Gemini
   1.5 (3.0) significantly. Gemini 1.5 achieved the highest FRE score
   (31.5) and provided highest proportion of responses assessed as
   comprehensible (80.4%). Prompting strategies significantly affected LLM
   responses. Claude 3.5 Sonnet with DL prompting had the highest
   completely correct rate (81.3%), while PF prompting yielded the most
   acceptable responses (97.3%). Gemini 1.5 Pro showed minimal variation
   across prompts but excelled in comprehensibility (98.7% under PF
   prompting). Conclusion This study indicates that LLMs have great
   potential in providing information about KD, but their use requires
   caution due to quality inconsistencies and misinformation risks.
   Significant discrepancies existed across LLMs and prompting strategies.
   Claude 3.5 Sonnet offered the best response quality and accuracy, while
   Gemini 1.5 Pro excelled in comprehensibility. PF prompting with Claude
   3.5 Sonnet is most recommended for parents seeking KD information. As AI
   evolves, expanding research and refining models is crucial to ensure
   reliable, high-quality information.
Z8 0
ZR 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-04-20
UT WOS:001466146900001
PM 40231209
ER

PT J
AU Johnston, Carolyn
Z2  
TI Divergence in healthcare decision-making: seeking a consensus on the
   meaning and application of 'best interests'
DT Dissertation/Thesis
PD Jan 01 2011
PY 2011
ZR 0
TC 0
ZA 0
Z8 0
ZB 0
ZS 0
Z9 0
UT PQDT:67862891
ER

PT J
AU TOKEDE, OLUWABUNMI 
TI FullMouth: Enhancing Dental Clinical Data and Reducing Disparities
   through Innovative ML Approaches.
DT Awarded Grant
PD Sep 01 2024
PY 2024
AB Project Abstract/SummaryThe vast amount of health data created in the
   United States may hold the key to understanding disease,improving
   quality, and lowering healthcare costs. Electronic health records
   (EHRs), digital collections of patienthealthcare events and
   observations, are now ubiquitous in medicine and critical to healthcare
   delivery,operations, and research. EHR data is often classified as
   structured or unstructured. Structured EHR datainclude standardized
   diagnoses, medications, and laboratory values in fixed numerical or
   categorical fields. Forstructured data, challenges such as missing,
   incomplete, and inconsistent data are very prevalent.Unstructured data,
   in contrast, refer to free-form text written by healthcare providers,
   such as clinical notes anddischarge summaries. Dental care providers
   often write detailed findings, diagnoses, treatment plans andprognostic
   factors in free-text format for clinical care purposes. While this
   information is easily accessible duringpatient care, extracting it for
   generating meaningful insights for secondary analysis can be
   challenging. Utilizingthese records requires manual review by domain
   experts, which can be time-consuming and costly, particularlywhen
   dealing with a large number of patient records. Unstructured data
   represents about 60% of total EHR data.Recently, Large Language Models
   (LLMs) and newer deep learning approaches to Natural Language
   Processing(NLP) have made considerable advances, outperforming
   traditional statistical and rule-based systems on avariety of tasks.To
   fully realize the promise of health information technology in dentistry,
   it is important to address datamissingness and disparity in missingness.
   Through a periodontal use-case, this proposal will tackle the
   challengeof missing structured, and ‘technically’ inaccessible,
   unstructured clinical data. Periodontal (advanced gumdisease) problems
   are very pervasive, and unlike caries (whose prevalence has steadily
   declined over the pastfour decades), disease burden and tooth loss
   secondary to periodontal disease remain intractable. In preliminarywork
   at two dental institutions, we observed that most patients seen for a
   comprehensive oral evaluation hadmissing or incomplete documentation
   with respect to clinical periodontal indices/diagnosis, demographic,
   andhealth-related behavior information – all of which are critical in
   diagnosing and treating periodontal disease. Thissignificantly limits
   our ability to learn and improve. Aim 1 will focus on using LLM-based
   NLP approaches for theconversion of unstructured note entries into
   structured and machine-readable information. In Aim 2, we will
   useimputation techniques to fill in missing structured clinical data
   entries. Aim 3 will then evaluate the impact ofreduction in clinical
   data missingness for both clinical and research applications. This work
   builds on our priorwork in developing the BigMouth Dental Data
   Repository (which contains regularly updated structured data on4.6
   million patients). We will be supported by the collective strength of
   the 11 core BigMouth, and other allieddental institutions that currently
   share and/or contribute data to the repository.
TC 0
ZA 0
Z8 0
ZR 0
ZS 0
ZB 0
Z9 0
G1 11137246; 1R56DE034086-01; R56DE034086
DA 2024-09-29
UT GRANTS:17810133
ER

PT J
AU Rasool, Abdur
   Aslam, Saba
   Hussain, Naeem
   Imtiaz, Sharjeel
   Riaz, Waqar
TI nBERT: Harnessing NLP for Emotion Recognition in Psychotherapy to
   Transform Mental Health Care
SO INFORMATION
VL 16
IS 4
AR 301
DI 10.3390/info16040301
DT Article
PD APR 9 2025
PY 2025
AB The rising prevalence of mental health disorders, particularly
   depression, highlights the need for improved approaches in therapeutic
   interventions. Traditional psychotherapy relies on subjective
   assessments, which can vary across therapists and sessions, making it
   challenging to track emotional progression and therapy effectiveness
   objectively. Leveraging the advancements in Natural Language Processing
   (NLP) and domain-specific Large Language Models (LLMs), this study
   introduces nBERT, a fine-tuned Bidirectional Encoder Representations
   from the Transformers (BERT) model integrated with the NRC Emotion
   Lexicon, to elevate emotion recognition in psychotherapy transcripts.
   The goal of this study is to provide a computational framework that aids
   in identifying emotional patterns, tracking patient-therapist emotional
   alignment, and assessing therapy outcomes. Addressing the challenge of
   emotion classification in text-based therapy sessions, where non-verbal
   cues are absent, nBERT demonstrates its ability to extract nuanced
   emotional insights from unstructured textual data, providing a
   data-driven approach to enhance mental health assessments. Trained on a
   dataset of 2021 psychotherapy transcripts, the model achieves an average
   precision of 91.53%, significantly outperforming baseline models. This
   capability not only improves diagnostic accuracy but also supports the
   customization of therapeutic strategies. By automating the
   interpretation of complex emotional dynamics in psychotherapy, nBERT
   exemplifies the transformative potential of NLP and LLMs in
   revolutionizing mental health care. Beyond psychotherapy, the framework
   enables broader LLM applications in the life sciences, including
   personalized medicine and precision healthcare.
TC 0
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
Z9 0
DA 2025-05-04
UT WOS:001475220100001
ER

PT J
AU Bentzen, S. M.
TI Artificial Intelligence in Health Care: A Rallying Cry for Critical
   Clinical Research and Ethical Thinking
SO CLINICAL ONCOLOGY
VL 41
AR 103798
DI 10.1016/j.clon.2025.103798
EA APR 2025
DT Article
PD MAY 2025
PY 2025
AB Artificial intelligence (AI) will impact a large proportion of jobs in
   the short to medium term, especially in the developed countries. The
   consequences will be felt across many sectors including health care, a
   critical sector for implementation of AI tools because glitches in
   algorithms or biases in training datasets may lead to suboptimal
   treatment that may negatively affect the health of an individual. The
   stakes are obviously higher in case of potentially life-threatening
   diseases such as cancer and therapies with a potential for causing
   severe or even fatal adverse events. Over the last two decades, much of
   the research on AI in health care has focussed on diagnostic radiology
   and digital pathology, but a solid body of research is emerging on AI
   tools in the radiation oncology workflow. Many of these applications are
   relatively uncontroversial, although there is still a lack of evidence
   regarding effectiveness rather than efficiency, and-the ultimate
   bar-evidence of clinical utility. Proponents of AI will argue that these
   algorithms should be implemented with robust human supervision. One
   challenge here is the deskilling effect associated with new
   technologies. We will become increasingly dependent on the AI tools over
   time, and we will become less capable of assessing the quality of the AI
   output. Much of this research appears almost old-fashioned in view of
   the rapid advances in Generative artificial intelligence (GenAI). GenAI
   can draw from multiple types of data and produce output that is
   personalised and appears relevant in the given context. Especially the
   rapid progress in large language models (LLMs) has opened a wide field
   of potential applications that were out of bounds just a few years ago.
   One LLM, Generative Pre-trained Transformer 4 (GPT-4), has been made
   widely accessible to end-users as ChatGPT-4, which passed a rigorous
   Turing test in a recent study. In this viewpoint, I argue for the
   necessity of independent academic research to establish evidence-based
   applications of AI in medicine. Algorithmic medicine is an intervention
   similar to a new drug or a new medical device. We should be especially
   concerned about under-represented minorities and rare/atypical clinical
   cases that may drown in the petabyte-sized training sets. A huge
   educational push is needed to ensure that the end-users of AI in health
   care understand the strengths and weaknesses of algorithmic medicine.
   Finally, we need to address the ethical boundaries for where and when
   GenAI can replace humans in the relation between patients and healthcare
   providers. (c) 2025 The Royal College of Radiologists. Published by
   Elsevier Ltd. All rights are reserved, including those for text and data
   mining, AI training, and similar technologies.
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2025-04-17
UT WOS:001463027500001
PM 40184826
ER

PT J
AU Toiv, Avi
   Saleh, Zachary
   Alsheik, Eva
   Venkat, Deepak
   Nandi, Neilanjan
   Zuchelli, Tobias
TI STARTING THE CONVERSATION: THE RELIABILITY OF ARTIFICIAL INTELLIGENCE
   GENERATED MEDICAL INFORMATION IN GASTROENTEROLOGY
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1972
BP S887
EP S887
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZR 0
ZB 0
ZS 0
ZA 0
Z8 0
TC 0
Z9 0
DA 2024-10-30
UT WOS:001282837703473
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

EF