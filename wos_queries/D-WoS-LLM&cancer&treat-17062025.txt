FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Singh, Krishna B.
   Hahm, Eun-Ryeong
   Singh, Shivendra V.
TI Leelamine suppresses cMyc expression in prostate cancer cells in
   vitro and inhibits prostate carcinogenesis in vivo
SO JOURNAL OF CANCER METASTASIS AND TREATMENT
VL 7
AR 16
DI 10.20517/2394-4722.2021.08
DT Article
PD 2021
PY 2021
AB Aim: Leelamine (LLM) inhibits the growth of human prostate cancer cells
   but the underlying mechanism is not fully understood. The present study
   was undertaken to determine the effect of LLM on cMyc, which is
   overexpressed in a subset of human prostate cancers.
   Methods: The effect of LLM on cMyc expression and activity was
   determined by western blotting/confocal microscopy and luciferase
   reporter assay, respectively. A transgenic mouse model of prostate
   cancer (Hi-Myc) was used to determine the chemopreventive efficacy of
   LLM.
   Results: Exposure of androgen-sensitive (LNCaP) and castration-resistant
   (22Rv1) human prostate cancer cells to LLM resulted in downregulation of
   protein and mRNA levels of cMyc. Overexpression of cMyc partially
   attenuated LLM-mediated inhibition of colony formation, cell viability,
   and cell migration in 22Rv1 and/ or PC-3 cells. LLM treatment decreased
   protein levels of cMyc targets ( e. g., lactate dehydrogenase), however,
   overexpression of cMyc did not attenuate these effects. A trend for a
   decrease in the expression level of cMyc protein was discernible in
   22Rv1 xenografts from LLM-treated mice compared with control mice. LLM
   treatment (10 mg/kg body weight, 5 times/week) was well-tolerated by
   Hi-Myc transgenic mice. The incidence of high-grade prostatic
   intraepithelial neoplasia, adenocarcinoma in situ, and microinvasion
   were lower in LLM-treated Hi-Myc mice but the difference was not
   statistically significant.
   Conclusion: The present study reveals that LLM inhibits cMyc expression
   in human prostate cancer cells in vitro but concentrations higher than
   10 mg/kg may be required to achieve chemoprevention of prostate cancer.
TC 4
ZB 2
ZS 0
ZA 0
Z8 0
ZR 0
Z9 4
DA 2021-01-01
UT WOS:000911213000016
PM 34660908
ER

PT J
AU Bibault, Jean-Emmanuel
   Wu, David J. H.
TI A web-based, LLM-powered AI symptom summarization tool (ASST) for
   monitoring of breast cancer treatment toxicity.
SO JOURNAL OF CLINICAL ONCOLOGY
VL 42
IS 16
MA e13622
SU S
DT Meeting Abstract
PD JUN 1 2024
PY 2024
CT Special Clinical Science Symposia
CY MAY 29-29, 2024
CL ELECTR NETWORK
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2024-08-18
UT WOS:001275557403390
ER

PT J
AU Verda, Damiano
   Parodi, Stefano
   Ferrari, Enrico
   Muselli, Marco
TI Analyzing gene expression data for pediatric and adult cancer diagnosis
   using logic learning machine and standard supervised methods
SO BMC BIOINFORMATICS
VL 20
AR 390
DI 10.1186/s12859-019-2953-8
SU 9
DT Article
PD NOV 22 2019
PY 2019
AB Background: Logic Learning Machine (LLM) is an innovative method of
   supervised analysis capable of constructing models based on simple and
   intelligible rules.
   In this investigation the performance of LLM in classifying patients
   with cancer was evaluated using a set of eight publicly available gene
   expression databases for cancer diagnosis.
   LLM accuracy was assessed by summary ROC curve (sROC) analysis and
   estimated by the area under an sROC curve (sAUC). Its performance was
   compared in cross validation with that of standard supervised methods,
   namely: decision tree, artificial neural network, support vector machine
   (SVM) and k-nearest neighbor classifier.
   Results: LLM showed an excellent accuracy (sAUC = 0.99, 95%CI: 0.98-1.0)
   and outperformed any other method except SVM.
   Conclusions: LLM is a new powerful tool for the analysis of gene
   expression data for cancer diagnosis. Simple rules generated by LLM
   could contribute to a better understanding of cancer biology,
   potentially addressing therapeutic approaches.
ZR 0
Z8 0
TC 13
ZS 0
ZA 0
ZB 4
Z9 13
DA 2020-01-03
UT WOS:000503868200007
PM 31757200
ER

PT J
AU Lammert, Jacqueline
   Dreyer, Tobias
   Mathes, Sonja
   Kuligin, Leonid
   Borm, Kai J.
   Schatz, Ulrich A.
   Kiechle, Marion
   Loersch, Alisa M.
   Jung, Johannes
   Lange, Sebastian
   Pfarr, Nicole
   Durner, Anna
   Schwamborn, Kristina
   Winter, Christof
   Ferber, Dyke
   Kather, Jakob Nikolas
   Mogler, Carolin
   Illert, Anna L.
   Tschochohei, Maximilian
TI Expert-Guided Large Language Models for Clinical Decision Support in
   Precision Oncology
SO JCO PRECISION ONCOLOGY
VL 8
AR e2400478
DI 10.1200/PO-24-00478
DT Article
PD OCT 2024
PY 2024
AB PURPOSE Rapidly expanding medical literature challenges oncologists
   seeking targeted cancer therapies. General-purpose large language models
   (LLMs) lack domain-specific knowledge, limiting their clinical utility.
   This study introduces the LLM system Medical Evidence Retrieval and Data
   Integration for Tailored Healthcare (MEREDITH), designed to support
   treatment recommendations in precision oncology. Built on Google's
   Gemini Pro LLM, MEREDITH uses retrieval-augmented generation and chain
   of thought.
   METHODS We evaluated MEREDITH on 10 publicly available fictional
   oncology cases with iterative feedback from a molecular tumor board
   (MTB) at a major German cancer center. Initially limited to
   PubMed-indexed literature (draft system), MEREDITH was enhanced to
   incorporate clinical studies on drug response within the specific tumor
   type, trial databases, drug approval status, and oncologic guidelines.
   The MTB provided a benchmark with manually curated treatment
   recommendations and assessed the clinical relevance of LLM-generated
   options (qualitative assessment). We measured semantic cosine similarity
   between LLM suggestions and clinician responses (quantitative
   assessment).
   RESULTS MEREDITH identified a broader range of treatment options (median
   4) compared with MTB experts (median 2). These options included
   therapies on the basis of preclinical data and combination treatments,
   expanding the treatment possibilities for consideration by the MTB. This
   broader approach was achieved by incorporating a curated medical data
   set that contextualized molecular targetability. Mirroring the approach
   MTB experts use to evaluate MTB cases improved the LLM's ability to
   generate relevant suggestions. This is supported by high concordance
   between LLM suggestions and expert recommendations (94.7% for the
   enhanced system) and a significant increase in semantic similarity from
   the draft to the enhanced system (from 0.71 to 0.76, P = .01).
   CONCLUSION Expert feedback and domain-specific data augment LLM
   performance. Future research should investigate responsible LLM
   integration into real-world clinical workflows.
ZA 0
ZB 0
TC 4
Z8 0
ZS 0
ZR 0
Z9 4
DA 2025-01-13
UT WOS:001376907800001
PM 39475661
ER

PT C
AU Chang, Chia-Hsuan
   Lucas, Mary M.
   Lee, Yeawon
   Yang, Christopher C.
   Lu-Yao, Grace
BE Finkelstein, J
   Moskovitch, R
   Parimbelli, E
TI Beyond Self-consistency: Ensemble Reasoning Boosts Consistency and
   Accuracy of LLMs in Cancer Staging
SO ARTIFICIAL INTELLIGENCE IN MEDICINE, PT I, AIME 2024
SE Lecture Notes in Artificial Intelligence
VL 14844
BP 224
EP 228
DI 10.1007/978-3-031-66538-7_23
DT Proceedings Paper
PD 2024
PY 2024
AB Pathologic cancer stage, crucial for treatment decisions, is often
   buried in unstructured pathology reports. This study investigates using
   pre-trained clinical LLMs for stage extraction, leveraging prompting
   techniques like chain-of-thought to enhance model transparency. While
   self-consistency methods further improve LLM performance, they can
   introduce inconsistencies in reasoning paths and predictions. We propose
   an ensemble reasoning approach, aiming for reliable cancer stage
   extraction. Utilizing an open-source clinical LLM on real-world reports,
   we demonstrate that the ensemble approach improves consistency and
   boosts performance, paving the way for utilizing LLMs in healthcare
   settings where reliability and interpretability are paramount.
CT 22nd International Conference on Artificial Intelligence in Medicine
   (AIME)
CY JUL 09-12, 2024
CL Salt Lake City, UT
ZB 1
TC 1
ZR 0
ZA 0
Z8 0
ZS 0
Z9 1
DA 2024-09-29
UT WOS:001295129500023
ER

PT J
AU Griewing, Sebastian
   Knitza, Johannes
   Boekhoff, Jelena
   Hillen, Christoph
   Lechner, Fabian
   Wagner, Uwe
   Wallwiener, Markus
   Kuhn, Sebastian
TI Evolution of publicly available large language models for complex
   decision-making in breast cancer care
SO ARCHIVES OF GYNECOLOGY AND OBSTETRICS
VL 310
IS 1
BP 537
EP 550
DI 10.1007/s00404-024-07565-4
EA MAY 2024
DT Article
PD JUL 2024
PY 2024
AB Purpose This study investigated the concordance of five different
   publicly available Large Language Models (LLM) with the recommendations
   of a multidisciplinary tumor board regarding treatment recommendations
   for complex breast cancer patient profiles.Methods Five LLM, including
   three versions of ChatGPT (version 4 and 3.5, with data access until
   September 3021 and January 2022), Llama2, and Bard were prompted to
   produce treatment recommendations for 20 complex breast cancer patient
   profiles. LLM recommendations were compared to the recommendations of a
   multidisciplinary tumor board (gold standard), including surgical,
   endocrine and systemic treatment, radiotherapy, and genetic testing
   therapy options.Results GPT4 demonstrated the highest concordance
   (70.6%) for invasive breast cancer patient profiles, followed by GPT3.5
   September 2021 (58.8%), GPT3.5 January 2022 (41.2%), Llama2 (35.3%) and
   Bard (23.5%). Including precancerous lesions of ductal carcinoma in
   situ, the identical ranking was reached with lower overall concordance
   for each LLM (GPT4 60.0%, GPT3.5 September 2021 50.0%, GPT3.5 January
   2022 35.0%, Llama2 30.0%, Bard 20.0%). GPT4 achieved full concordance
   (100%) for radiotherapy. Lowest alignment was reached in recommending
   genetic testing, demonstrating a varying concordance (55.0% for GPT3.5
   January 2022, Llama2 and Bard up to 85.0% for GPT4).Conclusion This
   early feasibility study is the first to compare different LLM in breast
   cancer care with regard to changes in accuracy over time, i.e., with
   access to more data or through technological upgrades. Methodological
   advancement, i.e., the optimization of prompting techniques, and
   technological development, i.e., enabling data input control and secure
   data processing, are necessary in the preparation of large-scale and
   multicenter studies to provide evidence on their safe and reliable
   clinical application. At present, safe and evidenced use of LLM in
   clinical breast cancer care is not yet feasible.
ZB 3
Z8 0
ZA 0
ZR 0
ZS 0
TC 14
Z9 14
DA 2024-06-04
UT WOS:001233695900001
PM 38806945
ER

PT J
AU Shirasu, Hiromichi
   Tsushima, Takahiro
   Kawahira, Masahiro
   Kawai, Sadayuki
   Kawakami, Takeshi
   Kito, Yosuke
   Yoshida, Yukio
   Hamauchi, Satoshi
   Todaka, Akiko
   Yokota, Tomoya
   Machida, Nozomu
   Yamazaki, Kentaro
   Fukutomi, Akira
   Onozawa, Yusuke
   Terashima, Masanori
   Uesaka, Katsuhiko
   Yasui, Hirofumi
TI Role of hepatectomy in gastric cancer with multiple liver-limited
   metastases
SO GASTRIC CANCER
VL 21
IS 2
BP 338
EP 344
DI 10.1007/s10120-017-0730-9
DT Article
PD MAR 2018
PY 2018
AB Background Several studies have demonstrated the benefit of hepatectomy
   for treating gastric cancer (GC) with liver-limited metastases (LLM).
   The survival benefit of hepatectomy compared with that of systemic
   chemotherapy is unknown, particularly in patients with multiple LLM.
   This study investigated the survival benefit of hepatectomy compared
   with that of systemic chemotherapy administered to patients with GC with
   multiple LLM.
   Methods We retrospectively reviewed the data of consecutive patients
   with GC with two or three LLM who underwent hepatectomy or received
   systemic chemotherapy as initial treatment at the Shizuoka Cancer Center
   between December 2004 and December 2015.
   Results Nine of 24 patients who met the inclusion criteria underwent
   hepatectomy, and 15 received chemotherapy. In the hepatectomy group, all
   patients achieved R0 resection and none died during hospitalization.
   Three patients received adjuvant chemotherapy. Disease recurred in eight
   patients (88.9%). In the chemotherapy group, three patients underwent
   hepatectomy following initial chemotherapy and did not experience
   recurrence or death during follow-up. Median follow-up was 47.9 months
   and median overall survival (OS) was 38.1 and 24.8 months in the
   chemotherapy and hepatectomy groups, respectively. Multivariate analysis
   of OS, including initial treatment, revealed that unilobar liver
   metastasis was the only independent favorable prognostic factor.
   Conclusions Although hepatectomy for patients with GC with multiple LLM
   is not recommended as the initial therapy, it prolonged the survival of
   patients with tumors controlled using systemic chemotherapy.
Z8 3
ZB 9
ZR 0
ZA 0
TC 29
ZS 0
Z9 32
DA 2018-03-22
UT WOS:000426564700016
PM 28577228
ER

PT C
AU Gubanov, Michael
   Pyayt, Anna
   Karolak, Aleksandra
GP ACM
TI CancerKG.ORG-A Web-scale, Interactive, Verifiable Knowledge Graph-LLM
   Hybrid for Assisting with Optimal Cancer Treatment and Care
SO PROCEEDINGS OF THE 33RD ACM INTERNATIONAL CONFERENCE ON INFORMATION AND
   KNOWLEDGE MANAGEMENT, CIKM 2024
BP 4497
EP 4505
DI 10.1145/3627673.3680094
DT Proceedings Paper
PD 2024
PY 2024
AB Here, we describe one of the first Web-scale hybrid Knowledge Graph
   (KG)-Large Language Model (LLM), populated with the latest peer-reviewed
   medical knowledge on colorectal Cancer. It is currently being evaluated
   to assist with both medical research and clinical information retrieval
   tasks at Moffitt Cancer Center, which is one of the top Cancer centers
   in the U.S. and in the world. Our hybrid is remarkable as it serves the
   user needs better than just an LLM, KG or a search-engine in isolation.
   LLMs as is are known to exhibit hallucinations and catastrophic
   forgetting as well as are trained on outdated corpora. The state of the
   art KGs, such as PrimeKG, cBioPortal, ChEMBL, NCBI, and other require
   manual curation, hence are quickly getting stale. CancerKG is
   unsupervised and is capable of automatically ingesting and organizing
   the latest medical findings. To alleviate the LLMs shortcomings, the
   verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
   CancerKG exhibits 5 different advanced user interfaces, each tailored to
   serve different data modalities better and more convenient for the user.
   We evaluated CancerKG on real user queries and report a high NDCG score
   on a large-scale corpora of approximately 44K publications.
CT 33rd ACM International Conference on Information and Knowledge
   Management (CIKM)
CY OCT 21-25, 2024
CL Boise, ID
SP Assoc Comp Machinery; ACM SIGIR; ACM SIGWEB
TC 2
ZS 0
ZR 0
ZA 0
ZB 2
Z8 0
Z9 2
DA 2025-03-05
UT WOS:001349579604110
ER

PT J
AU Singh, Krishna B.
   Ji, Xinhua
   Singh, Shivendra V.
TI Therapeutic Potential of Leelamine, a Novel Inhibitor of Androgen
   Receptor and Castration-Resistant Prostate Cancer
SO MOLECULAR CANCER THERAPEUTICS
VL 17
IS 10
BP 2079
EP 2090
DI 10.1158/1535-7163.MCT-18-0117
DT Article
PD OCT 2018
PY 2018
AB Clinical management of castration-resistant prostate cancer (CRPC)
   resulting from androgen deprivation therapy remains challenging. CRPC is
   driven by aberrant activation of androgen receptor (AR) through
   mechanisms ranging from its amplification, mutation, post-translational
   modification, and expression of splice variants (e.g., AR-V7). Herein,
   we present experimental evidence for therapeutic vulnerability of CRPC
   to a novel phytochemical, leelamine (LLM), derived from pine tree bark.
   Exposure of human prostate cancer cell lines LNCaP (an
   androgen-responsive cell line with mutant AR), C4-2B (an
   androgen-insensitive variant of LNCaP), and 22Rv1 (a CRPC cell line with
   expression of AR-Vs), and a murine prostate cancer cell line Myc-CaP to
   plasma achievable concentrations of LLM resulted in ligand-dependent
   (LNCaP) and ligand-independent (22Rv1) growth inhibition in vitro that
   was accompanied by downregulation of mRNA and/or protein levels of
   full-length AR as well as its splice variants, including AR-V7. LLM
   treatment resulted in apoptosis induction in the absence and presence of
   R1881. In silico modeling followed by luciferase reporter assay revealed
   a critical role for noncovalent interaction of LLM with Y739 in AR
   activity inhibition. Substitution of the amine group with an
   isothiocyanate functional moiety abolished AR and cell viability
   inhibition by LLM. Administration of LLM resulted in 22Rv1 xenograft
   growth suppression that was statistically insignificant but was
   associated with a significant decrease in Ki-67 expression, mitotic
   activity, expression of fulllength AR and AR-V7 proteins, and secretion
   of PSA. This study identifies a novel chemical scaffold for the
   treatment of CRPC. (C) 2018 AACR.
Z8 0
ZS 0
TC 18
ZB 11
ZR 0
ZA 0
Z9 18
DA 2019-01-30
UT WOS:000456145700001
PM 30030299
ER

PT J
AU Yasaka, Koichiro
   Kanzawa, Jun
   Kanemaru, Noriko
   Koshino, Saori
   Abe, Osamu
TI Fine-Tuned Large Language Model for Extracting Patients on Pretreatment
   for Lung Cancer from a Picture Archiving and Communication System Based
   on Radiological Reports
SO JOURNAL OF IMAGING INFORMATICS IN MEDICINE
VL 38
IS 1
BP 327
EP 334
DI 10.1007/s10278-024-01186-8
EA JUL 2024
DT Article
PD FEB 2025
PY 2025
AB This study aimed to investigate the performance of a fine-tuned large
   language model (LLM) in extracting patients on pretreatment for lung
   cancer from picture archiving and communication systems (PACS) and
   comparing it with that of radiologists. Patients whose radiological
   reports contained the term lung cancer (3111 for training, 124 for
   validation, and 288 for test) were included in this retrospective study.
   Based on clinical indication and diagnosis sections of the radiological
   report (used as input data), they were classified into four groups (used
   as reference data): group 0 (no lung cancer), group 1 (pretreatment lung
   cancer present), group 2 (after treatment for lung cancer), and group 3
   (planning radiation therapy). Using the training and validation
   datasets, fine-tuning of the pretrained LLM was conducted ten times. Due
   to group imbalance, group 2 data were undersampled in the training. The
   performance of the best-performing model in the validation dataset was
   assessed in the independent test dataset. For testing purposes, two
   other radiologists (readers 1 and 2) were also involved in classifying
   radiological reports. The overall accuracy of the fine-tuned LLM, reader
   1, and reader 2 was 0.983, 0.969, and 0.969, respectively. The
   sensitivity for differentiating group 0/1/2/3 by LLM, reader 1, and
   reader 2 was 1.000/0.948/0.991/1.000, 0.750/0.879/0.996/1.000, and
   1.000/0.931/0.978/1.000, respectively. The time required for
   classification by LLM, reader 1, and reader 2 was 46s/2539s/1538s,
   respectively. Fine-tuned LLM effectively extracted patients on
   pretreatment for lung cancer from PACS with comparable performance to
   radiologists in a shorter time.
ZA 0
ZB 0
TC 6
ZS 0
ZR 0
Z8 0
Z9 6
DA 2024-07-10
UT WOS:001261213000001
PM 38955964
ER

PT J
AU Liu, Rozee Junhan
   Forsythe, Anna
   Rege, Jessicca Martin
   Kaufman, Peter
TI BIO25-024: Real-Time Clinical Trial Data Library in Non-Small Cell Lung
   (NSCLC), Prostate (PC), and Breast Cancer (BC) to Support Informed
   Treatment Decisions: Now a Reality With a Fine-Tuned Large Language
   Model (LLM).
SO Journal of the National Comprehensive Cancer Network : JNCCN
VL 23
IS 3.5
DI 10.6004/jnccn.2024.7156
DT Journal Article
PD 2025 Mar 28
PY 2025
Z8 0
ZA 0
ZS 0
ZR 0
TC 0
ZB 0
Z9 0
DA 2025-04-02
UT MEDLINE:40157350
PM 40157350
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Singh, Krishna B.
   Hahm, Eun-Ryeong
   Pore, Subrata K.
   Singh, Shivendra, V
TI Leelamine Is a Novel Lipogenesis Inhibitor in Prostate Cancer Cells
   In Vitro and In Vivo
SO MOLECULAR CANCER THERAPEUTICS
VL 18
IS 10
BP 1800
EP 1810
DI 10.1158/1535-7163.MCT-19-0046
DT Article
PD OCT 2019
PY 2019
AB Increased de novo synthesis of fatty acids is implicated in the
   pathogenesis of human prostate cancer, but a safe and effective clinical
   inhibitor of this metabolic pathway is still lacking. We have shown
   previously that leelamine (LLM) suppresses transcriptional activity of
   androgen receptor, which is known to regulate fatty acid synthesis.
   Therefore, the current study was designed to investigate the effect of
   LLM on fatty add synthesis. Exposure of 22Rv1, LNCaP, and PC-3 prostate
   cancer cells, but not RWPE- I normal prostate epithelial cell line, to
   LLM resulted in a decrease in intracellular levels of neutral lipids or
   total free fatty adds. LLM was superior to another fatty acid synthesis
   inhibitor (cerulenin) for suppression of total free fatty acid levels.
   LLM treatment downregulated protein and/or mRNA expression of key fatty
   acid synthesis enzymes, including ATP citrate lyase, acetyl-CoA
   carboxylase 1, fatty acid synthase, and sterol regulatory
   element-binding protein 1 (SREBP1) in each cell line. Consistent with
   these in vitro findings, we also observed a significant decrease in ATP
   citrate lyase and SREBP1 protein expression as well as number of neutral
   lipid droplets in vivo in 22Rv1 tumor sections of LLM-treated mice when
   compared with that of controls. LLM-mediated suppression of
   intracellular levels of total free fatty acids and neutral lipids was
   partly attenuated by overexpression of SREBP1. In conclusion, these
   results indicate that LLM is a novel inhibitor of SREBP1-regulated fatty
   acid/lipid synthesis in prostate cancer cells that is not affected by
   androgen receptor status.
Z8 1
ZA 0
TC 19
ZB 17
ZS 0
ZR 0
Z9 19
DA 2019-10-22
UT WOS:000489688400013
PM 31395683
ER

PT J
AU Benary, Manuela
   Wang, Xing David
   Schmidt, Max
   Soll, Dominik
   Hilfenhaus, Georg
   Nassir, Mani
   Sigler, Christian
   Knoedler, Maren
   Keller, Ulrich
   Beule, Dieter
   Keilholz, Ulrich
   Leser, Ulf
   Rieke, Damian T.
TI Leveraging Large Language Models for Decision Support in Personalized
   Oncology
SO JAMA NETWORK OPEN
VL 6
IS 11
AR e2343689
DI 10.1001/jamanetworkopen.2023.43689
DT Article
PD NOV 17 2023
PY 2023
AB Importance Clinical interpretation of complex biomarkers for precision
   oncology currently requires manual investigations of previous studies
   and databases. Conversational large language models (LLMs) might be
   beneficial as automated tools for assisting clinical
   decision-making.Objective To assess performance and define their role
   using 4 recent LLMs as support tools for precision oncology.Design,
   Setting, and Participants This diagnostic study examined 10 fictional
   cases of patients with advanced cancer with genetic alterations. Each
   case was submitted to 4 different LLMs (ChatGPT, Galactica, Perplexity,
   and BioMedLM) and 1 expert physician to identify personalized treatment
   options in 2023. Treatment options were masked and presented to a
   molecular tumor board (MTB), whose members rated the likelihood of a
   treatment option coming from an LLM on a scale from 0 to 10 (0,
   extremely unlikely; 10, extremely likely) and decided whether the
   treatment option was clinically useful.Main Outcomes and Measures Number
   of treatment options, precision, recall, F1 score of LLMs compared with
   human experts, recognizability, and usefulness of
   recommendations.Results For 10 fictional cancer patients (4 with lung
   cancer, 6 with other; median [IQR] 3.5 [3.0-4.8] molecular alterations
   per patient), a median (IQR) number of 4.0 (4.0-4.0) compared with 3.0
   (3.0-5.0), 7.5 (4.3-9.8), 11.5 (7.8-13.0), and 13.0 (11.3-21.5)
   treatment options each was identified by the human expert and 4 LLMs,
   respectively. When considering the expert as a criterion standard,
   LLM-proposed treatment options reached F1 scores of 0.04, 0.17, 0.14,
   and 0.19 across all patients combined. Combining treatment options from
   different LLMs allowed a precision of 0.29 and a recall of 0.29 for an
   F1 score of 0.29. LLM-generated treatment options were recognized as
   AI-generated with a median (IQR) 7.5 (5.3-9.0) points in contrast to 2.0
   (1.0-3.0) points for manually annotated cases. A crucial reason for
   identifying AI-generated treatment options was insufficient accompanying
   evidence. For each patient, at least 1 LLM generated a treatment option
   that was considered helpful by MTB members. Two unique useful treatment
   options (including 1 unique treatment strategy) were identified only by
   LLM.Conclusions and Relevance In this diagnostic study, treatment
   options of LLMs in precision oncology did not reach the quality and
   credibility of human experts; however, they generated helpful ideas that
   might have complemented established procedures. Considering
   technological progress, LLMs could play an increasingly important role
   in assisting with screening and selecting relevant biomedical literature
   to support evidence-based, personalized treatment decisions.
ZB 23
ZR 0
ZA 0
Z8 3
TC 91
ZS 0
Z9 95
DA 2024-01-11
UT WOS:001124127500011
PM 37976064
ER

PT J
AU Naik, Himani R.
   Prather, Andrew D.
   Gurda, Grzegorz T.
TI Synchronous Bilateral Breast Cancer: A Case Report Piloting and
   Evaluating the Implementation of the AI-Powered Large Language Model
   (LLM) ChatGPT
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 15
IS 4
AR e37587
DI 10.7759/cureus.37587
DT Article
PD APR 14 2023
PY 2023
AB Primary breast carcinoma is the most common cancer type in women, and
   although bilateral synchronous breast cancers (s-BBC) remain quite rare,
   the reported incidence may increase with the adoption of more sensitive
   imaging modalities. Here, we present a case of histomorphological and
   clinically distinct s-BBC, together with a discussion of clinical
   management decisions, prognosis, and treatment standards and how these
   relate to outcomes vis-a-vis more established standards in unifocal
   breast carcinoma. The case report also constitutes a pilot and formal
   evaluation of a large language model (LLM) of ChatGPT as a tool to aid
   in generating a single patient case report.
ZB 4
Z8 1
ZR 0
ZA 0
TC 8
ZS 0
Z9 9
DA 2023-11-05
UT WOS:001082835600036
PM 37193434
ER

PT J
AU Tang, Tengjie
   Li, Angkai
   Tan, Xingye
   Ji, Qingli
   Si, Lu
   Bao, Le
TI Bridging Data Gaps in Oncology: Large Language Models and Collaborative
   Filtering for Cancer Treatment Recommendations.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2025.04.07.25325243
DT Journal Article; Preprint
PD 2025 Apr 07
PY 2025
AB Background: Patients with rare cancers face substantial challenges due
   to limited evidence-based treatment options, resulting from sparse
   clinical trials. Advances in large language models (LLMs) and
   recommendation algorithms offer new opportunities to utilize all
   clinical trial information to improve clinical decisions.
   Methods: We used LLM to systematically extract and standardize more than
   100,000 cancer trials from ClinicalTrials.gov. Each trial was annotated
   using a customized scoring system reflecting cancer-treatment
   interactions based on clinical outcomes and trial attributes. Using this
   structured data set, we implemented three state-of-the-art collaborative
   filtering algorithms to recommend potentially effective treatments
   across different cancer types.
   Results: The LLM-driven data extraction process successfully generated a
   comprehensive and rigorously curated database from fragmented clinical
   trial information, covering 78 cancer types and 5,315 distinct
   interventions. Recommendation models demonstrated high predictive
   accuracy (cross-validated RMSE: 0.49-0.62) and identified clinically
   meaningful new treatments for melanoma, independently validated by
   oncology experts.
   Conclusions: Our study establishes a proof of concept demonstrating that
   the combination of LLMs with sophisticated recommendation algorithms can
   systematically identify novel and clinically plausible cancer
   treatments. This integrated approach may accelerate the identification
   of effective therapies for rare cancers, ultimately improving patient
   outcomes by generating evidence-based treatment recommendations where
   traditional data sources remain limited.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
DA 2025-05-01
UT MEDLINE:40297440
PM 40297440
ER

PT J
AU Wang, Qingxin
   Wang, Zhongqiu
   Li, Minghua
   Ni, Xinye
   Tan, Rong
   Zhang, Wenwen
   Wubulaishan, Maitudi
   Wang, Wei
   Yuan, Zhiyong
   Zhang, Zhen
   Liu, Cong
TI A feasibility study of automating radiotherapy planning with large
   language model agents
SO PHYSICS IN MEDICINE AND BIOLOGY
VL 70
IS 7
AR 075007
DI 10.1088/1361-6560/adbff1
DT Article
PD APR 6 2025
PY 2025
AB Objective. Radiotherapy planning requires significant expertise to
   balance tumor control and organ-at-risk (OAR) sparing. Automated
   planning can improve both efficiency and quality. This study introduces
   GPT-Plan, a novel multi-agent system powered by the GPT-4 family of
   large language models (LLMs), for automating the iterative radiotherapy
   plan optimization. Approach. GPT-Plan uses LLM-driven agents, mimicking
   the collaborative clinical workflow of a dosimetrist and physicist, to
   iteratively generate and evaluate text-based radiotherapy plans based on
   predefined criteria. Supporting tools assist the agents by leveraging
   historical plans, mitigating LLM hallucinations, and balancing
   exploration and exploitation. Performance was evaluated on 12 lung
   (IMRT) and 5 cervical (VMAT) cancer cases, benchmarked against the ECHO
   auto-planning method and manual plans. The impact of historical plan
   retrieval on efficiency was also assessed. Results. For IMRT lung cancer
   cases, GPT-Plan generated high-quality plans, demonstrating superior
   target coverage and homogeneity compared to ECHO while maintaining
   comparable or better OAR sparing. For VMAT cervical cancer cases, plan
   quality was comparable to a senior physicist and consistently superior
   to a junior physicist, particularly for OAR sparing. Retrieving
   historical plans significantly reduced the number of required
   optimization iterations for lung cases (p < 0.01) and yielded iteration
   counts comparable to those of the senior physicist for cervical cases (p
   = 0.313). Occasional LLM hallucinations have been mitigated by
   self-reflection mechanisms. One limitation was the inaccuracy of
   vision-based LLMs in interpreting dose images. Significance. This
   pioneering study demonstrates the feasibility of automating radiotherapy
   planning using LLM-powered agents for complex treatment decision-making
   tasks. While challenges remain in addressing LLM limitations, ongoing
   advancements hold potential for further refining and expanding
   GPT-Plan's capabilities.
ZS 0
TC 1
ZB 0
ZA 0
ZR 0
Z8 0
Z9 1
DA 2025-04-26
UT WOS:001469440600001
PM 40073507
ER

PT J
AU Griewing, Sebastian
   Gremke, Niklas
   Wagner, Uwe
   Lingenfelder, Michael
   Kuhn, Sebastian
   Boekhoff, Jelena
TI Challenging ChatGPT 3.5 in Senology-An Assessment of Concordance with
   Breast Cancer Tumor Board Decision Making
SO JOURNAL OF PERSONALIZED MEDICINE
VL 13
IS 10
AR 1502
DI 10.3390/jpm13101502
DT Article
PD OCT 2023
PY 2023
AB With the recent diffusion of access to publicly available large language
   models (LLMs), common interest in generative
   artificial-intelligence-based applications for medical purposes has
   skyrocketed. The increased use of these models by tech-savvy patients
   for personal health issues calls for a scientific evaluation of whether
   LLMs provide a satisfactory level of accuracy for treatment decisions.
   This observational study compares the concordance of treatment
   recommendations from the popular LLM ChatGPT 3.5 with those of a
   multidisciplinary tumor board for breast cancer (MTB). The study design
   builds on previous findings by combining an extended input model with
   patient profiles reflecting patho- and immunomorphological diversity of
   primary breast cancer, including primary metastasis and precancerous
   tumor stages. Overall concordance between the LLM and MTB is reached for
   half of the patient profiles, including precancerous lesions. In the
   assessment of invasive breast cancer profiles, the concordance amounts
   to 58.8%. Nevertheless, as the LLM makes considerably fraudulent
   decisions at times, we do not identify the current development status of
   publicly available LLMs to be adequate as a support tool for tumor
   boards. Gynecological oncologists should familiarize themselves with the
   capabilities of LLMs in order to understand and utilize their potential
   while keeping in mind potential risks and limitations.
ZR 0
ZA 0
ZS 0
ZB 13
TC 40
Z8 1
Z9 40
DA 2023-11-05
UT WOS:001090005600001
PM 37888113
ER

PT J
AU Agaronnik, Nicole D.
   Davis, Joshua
   Manz, Christopher R.
   Tulsky, James A.
   Lindvall, Charlotta
TI Large Language Models to Identify Advance Care Planning in Patients With
   Advanced Cancer
SO JOURNAL OF PAIN AND SYMPTOM MANAGEMENT
VL 69
IS 3
DI 10.1016/j.jpainsymman.2024.11.016
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
AB Context. Efficiently tracking Advance Care Planning (ACP) documentation
   in electronic heath records (EHRs) is essential for quality improvement
   and research efforts. The use of large language models (LLMs) offers a
   novel approach to this task. Objectives. To evaluate the ability of LLMs
   to identify ACP in EHRs for patients with advanced cancer and compare
   performance to gold-standard manual chart review and natural language
   processing (NLP). Methods. EHRs from patients with advanced cancer
   followed at seven Dana Farber Cancer Center (DFCI) clinics in June 2024.
   We utilized GPT-4o-2024-05-13 within DFCI's HIPAA-secure digital
   infrastructure. We designed LLM prompts to identify ACP domains: goals
   of care, limitation of life-sustaining treatment, hospice, and
   palliative care. We developed a novel hallucination index to measure
   production of factually-incorrect evidence by the LLM. Performance was
   compared to gold-standard manual chart review and NLP. Results. 60
   unique patients associated with 528 notes were used to construct the
   gold-standard data set. LLM prompts had sensitivity ranging from 0.85 to
   1.0, specificity ranging from 0.80 to 0.91, and accuracy ranging from
   0.81 to 0.91 across domains. The LLM had better sensitivity than NLP for
   identifying complex topics such as goals of care. Average hallucination
   index for notes identified by LLM was less than 0.5, indicating a low
   probability of hallucination. Despite lower precision compared to NLP,
   false positive documentation identified by LLMs was clinically-relevant
   and useful for guiding management. Conclusion. LLMs can capture ACP
   domains from EHRs, with sensitivity exceeding NLP methods for complex
   domains such as goals of care. Future studies should explore approaches
   for scaling this methodology. J Pain Symptom Manage 2025;69:243-250. (c)
   2024 American Academy of Hospice and Palliative Medicine. Published by
   Elsevier Inc. All rights are reserved, including those for text and data
   mining, AI training, and similar technologies.
Z8 0
ZR 0
ZB 0
ZA 0
TC 2
ZS 0
Z9 2
DA 2025-02-23
UT WOS:001422708600001
PM 39586429
ER

PT J
AU Berman, Eliza
   Malek, Holly Sundberg
   Bitzer, Michael
   Malek, Nisar
   Eickhoff, Carsten
TI Retrieval Augmented Therapy Suggestion for Molecular Tumor Boards:
   Algorithmic Development and Validation Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e64364
DI 10.2196/64364
DT Article
PD MAR 5 2025
PY 2025
AB Background: Molecular tumor boards (MTBs) require intensive manual
   investigation to generate optimal treatment recommendations for
   patients. Large language models (LLMs) can catalyze MTB recommendations,
   decrease human error, improve accessibility to care, and enhance the
   efficiency of precision oncology. Objective: In this study, we aimed to
   investigate the efficacy of LLM-generated treatments for MTB patients.
   We specifically investigate the LLMs' ability to generate evidence-based
   treatment recommendations using PubMed references. Methods: We built a
   retrieval augmented generation pipeline using PubMed data. We prompted
   the resulting LLM to generate treatment recommendations with PubMed
   references using a test set of patients from an MTB conference at a
   large comprehensive cancer center at a tertiary care institution.
   Members of the MTB manually assessed the relevancy and correctness of
   the generated responses. Results: A total of 75% of the referenced
   articles were properly cited from PubMed, while 17% of the referenced
   articles were hallucinations, and the remaining were not properly cited
   from PubMed. Clinician-generated LLM queries achieved higher accuracy
   through clinician evaluation than automated queries, with clinicians
   labeling 25% of LLM responses as equal to their recommendations and
   37.5% as alternative plausible treatments. Conclusions:This study
   demonstrates how retrieval augmented generation-enhanced LLMscan bea
   powerful tool in accelerating MTB conferences, as LLMs are sometimes
   capable of achieving clinician-equal treatment recommendations. However,
   further investigation is required to achieve stable results with zero
   hallucinations. LLMs signify a scalable solution to the time-intensive
   process of MTB investigations. However, LLM performance demonstrates
   that they must be used with heavy clinician supervision, and cannot yet
   fully automate the MTB pipeline.
ZS 0
ZR 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
DA 2025-04-19
UT WOS:001467624400010
PM 40053768
ER

PT J
AU Ghorbian, Mohsen
   Ghobaei-Arani, Mostafa
   Ghorbian, Saied
TI Transforming breast cancer diagnosis and treatment with large language
   Models: A comprehensive survey
SO METHODS
VL 239
BP 85
EP 110
DI 10.1016/j.ymeth.2025.04.001
EA APR 2025
DT Article
PD JUL 2025
PY 2025
AB Breast cancer (BrCa), being one of the most prevalent forms of cancer in
   women, poses many challenges in the field of treatment and diagnosis due
   to its complex biological mechanisms. Early and accurate diagnosis plays
   a fundamental role in improving survival rates, but the limitations of
   existing imaging methods and clinical data interpretation often prevent
   optimal results. Large Language Models (LLMs), which are developed based
   on advanced architectures such as transformers, have brought about a
   significant revolution in data processing and medical decision-making.
   By analyzing a large volume of medical and clinical data, these models
   enable early diagnosis by identifying patterns in images and medical
   records and provide personalized treatment strategies by integrating
   genetic markers and clinical guidelines. Despite the transformative
   potential of these models, their use in BrCa management faces challenges
   such as data sensitivity, algorithm transparency, ethical
   considerations, and model compatibility with the details of medical
   applications that need to be addressed to achieve reliable results. This
   review systematically reviews the impact of LLMs on BrCa treatment and
   diagnosis. This study's objectives include analyzing the role of LLM
   technology in diagnosing and treating this disease. The findings
   indicate that the application of LLMs has resulted in significant
   improvements in various aspects of BrCa management, such as a 35%
   increase in the Efficiency of Diagnosis and BrCa Treatment (EDBC), a 30%
   enhancement in the System's Clinical Trust and Reliability (SCTR), and a
   20% improvement in the quality of patient education and information
   (IPEI). Ultimately, this study demonstrates the importance of LLMs in
   advancing precision medicine for BrCa and paves the way for effective
   patient-centered care solutions.
ZS 0
ZR 0
TC 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001466448900001
PM 40199412
ER

PT J
AU Mora, J.
   Chen, S.
   Mak, R. H.
   Bitterman, D. S.
TI Cancer Treatment Information Differences by Bilingual Prompting in Large
   Language Model Chatbots
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3415
BP E645
EP E646
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001325892302096
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Assessing the use of the novel tool Claude 3 in comparison to ChatGPT
   4.0 as an artificial intelligence tool in the diagnosis and therapy of
   primary head and neck cancer cases
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6099
EP 6109
DI 10.1007/s00405-024-08828-1
EA AUG 2024
DT Article
PD NOV 2024
PY 2024
AB ObjectivesHead and neck squamous cell carcinoma (HNSCC) is a complex
   malignancy that requires a multidisciplinary tumor board approach for
   individual treatment planning. In recent years, artificial intelligence
   tools have emerged to assist healthcare professionals in making informed
   treatment decisions. This study investigates the application of the
   newly published LLM Claude 3 Opus compared to the currently most
   advanced LLM ChatGPT 4.0 for the diagnosis and therapy planning of
   primary HNSCC. The results were compared to that of a conventional
   multidisciplinary tumor board; (2) Materials and Methods: We conducted a
   study in March 2024 on 50 consecutive primary head and neck cancer
   cases. The diagnostics and MDT recommendations were compared to the
   Claude 3 Opus and ChatGPT 4.0 recommendations for each patient and rated
   by two independent reviewers for the following parameters: clinical
   recommendation, explanation, and summarization in addition to the
   Artificial Intelligence Performance Instrument (AIPI); (3) Results: In
   this study, Claude 3 achieved better scores for the diagnostic workup of
   patients than ChatGPT 4.0 and provided treatment recommendations
   involving surgery, chemotherapy, and radiation therapy. In terms of
   clinical recommendations, explanation and summarization Claude 3 scored
   similar to ChatGPT 4.0, listing treatment recommendations which were
   congruent with the MDT, but failed to cite the source of the
   information; (4) Conclusion: This study is the first analysis of Claude
   3 for primary head and neck cancer cases and demonstrates a superior
   performance in the diagnosis of HNSCC than ChatGPT 4.0 and similar
   results for therapy recommendations. This marks the advent of a newly
   launched advanced AI model that may be superior to ChatGPT 4.0 for the
   assessment of primary head and neck cancer cases and may assist in the
   clinical diagnostic and MDT setting.
   Claude 3 OpusHNSCCMultidisciplinary TumorboardArtificial IntelligenceLLM
ZA 0
ZS 0
ZB 4
TC 17
Z8 0
ZR 0
Z9 17
DA 2024-08-13
UT WOS:001285919100001
PM 39112556
ER

PT J
AU Ye, Liu-Fang
   Ji, Xiao-Meng
   Ren, Chao
   Wang, Zhi-Qiang
   Lin, Chun-Ping
   Chen, Dong-Liang
   Cai, Yan-Qing
   Jin, Ying
   Qiu, Miao-Zhen
   Du, Zi-Ming
   Xi, Shao-Yan
   Zhang, Dong-Sheng
   Wang, Feng
   Wang, Feng-Hua
   Xu, Rui-Hua
   Li, Yu-Hong
   Wang, De-Shen
TI The Prognostic Value of Locoregional Interventions for BRAF V600E
   Metastatic Colorectal Cancer: A Retrospective Cohort Analysis
SO BIOMOLECULES
VL 11
IS 9
AR 1268
DI 10.3390/biom11091268
DT Article
PD SEP 2021
PY 2021
AB The prognostic heterogeneity in patients with BRAF V600E metastatic
   colorectal cancer (mCRC) remains poorly defined. Real-world data of 93
   BRAF V600E mCRC patients from Sun Yat-sen University Cancer Center were
   evaluated using the prognostic factors affecting overall survival (OS).
   Treatment of metastases served as an independent prognosticator, where
   curative locoregional interventions (LRIs) were associated with superior
   clinical outcomes (adjusted hazard ratio (HR): 0.46, 95% confidence
   interval (CI): 0.22-0.98; p = 0.044). The LRIs group showed an improved
   median OS of 49.4 months versus 18.3 months for the palliative
   treatments (PTs) group. The median OS of patients with colorectal liver
   metastasis (CRLM) was significantly prolonged after undergoing LRIs
   (42.4 vs. 23.7 months; HR: 0.11, 95% CI: 0.01-1.22; p = 0.030), and
   patients in the LRIs plus liver-limited or lung-limited metastasis (LLM)
   group benefited more than those in the LRIs plus non-LLM group when
   compared to the PTs group (LLM from LRIs vs. PTs, HR: 0.16, 95% CI:
   0.04-0.68; p = 0.006. Non-LLM from LRIs vs. PTs, HR: 0.47, 95% CI:
   0.21-1.05; p = 0.074). In conclusion, we confirmed the positive
   prognostic value of LRIs in BRAF V600E mCRC, particularly in patients
   with CRLM or LLM.
ZS 0
ZA 0
ZB 1
Z8 0
TC 4
ZR 0
Z9 4
DA 2021-10-02
UT WOS:000699229600001
PM 34572480
ER

PT J
AU Zhu, Libing
   Rong, Yi
   Mcgee, Lisa A.
   Rwigema, Jean-Claude M.
   Patel, Samir H.
TI Testing and Validation of a Custom Retrained Large Language Model for
   the Supportive Care of HN Patients with External Knowledge Base
SO CANCERS
VL 16
IS 13
AR 2311
DI 10.3390/cancers16132311
DT Article
PD JUL 2024
PY 2024
AB Simple Summary Cancer patients, especially long-distance patients, often
   struggle to receive timely and precise medical information and support
   for their symptom management and survivorship care. ChatGPT-4's
   responses to queries concerning head and neck (HN) cancer remain
   questionable. The purpose of this study was to develop and validate a
   retrained large language model (LLM) for HN cancer patients. In this
   cross-sectional study, the presented LLM was retrained with a
   high-quality user-defined knowledge base. The responses from the LLM to
   patients' questions were validated against human responses, and the
   model showed a superior performance, with average scores of 4.25 for
   accuracy, 4.35 for clarity, 4.22 for completeness, and 4.32 for
   relevance, on a 5-point scale. The confined-trained LLM with a
   high-quality user-defined knowledge base demonstrates high accuracy,
   clarity, completeness, and relevance in offering evidence-based
   information and guidance on the symptom management and survivorship care
   for head and neck cancer patients.Abstract Purpose: This study aimed to
   develop a retrained large language model (LLM) tailored to the needs of
   HN cancer patients treated with radiotherapy, with emphasis on symptom
   management and survivorship care. Methods: A comprehensive external
   database was curated for training ChatGPT-4, integrating
   expert-identified consensus guidelines on supportive care for HN
   patients and correspondences from physicians and nurses within our
   institution's electronic medical records for 90 HN patients. The
   performance of our model was evaluated using 20 patient post-treatment
   inquiries that were then assessed by three Board certified radiation
   oncologists (RadOncs). The rating of the model was assessed on a scale
   of 1 (strongly disagree) to 5 (strongly agree) based on accuracy,
   clarity of response, completeness s, and relevance. Results: The average
   scores for the 20 tested questions were 4.25 for accuracy, 4.35 for
   clarity, 4.22 for completeness, and 4.32 for relevance, on a 5-point
   scale. Overall, 91.67% (220 out of 240) of assessments received scores
   of 3 or higher, and 83.33% (200 out of 240) received scores of 4 or
   higher. Conclusion: The custom-trained model demonstrates high accuracy
   in providing support to HN patients offering evidence-based information
   and guidance on their symptom management and survivorship care.
ZA 0
ZS 0
Z8 0
ZR 0
TC 1
ZB 1
Z9 1
DA 2024-07-22
UT WOS:001269842700001
PM 39001375
ER

PT J
AU Parent, Nicolas
   Scherer, Max
   Liebisch, Gerhard
   Schmitz, Gerd
   Bertrand, Richard
TI Protein kinase C-δ isoform mediates lysosome labilization in DNA
   damage-induced apoptosis
SO INTERNATIONAL JOURNAL OF ONCOLOGY
VL 38
IS 2
BP 313
EP 324
DI 10.3892/ijo.2010.881
DT Article
PD FEB 2011
PY 2011
AB A lysosomal pathway, characterized by the partial rupture or
   labilization of lysosomal membranes (LLM) and cathepsin release into the
   cytosol, is evoked during the early events of 20-S-camptothecin lactone
   (CPT)-induced apoptosis in human cancer cells, including human
   histiocytic lymphoma U-937 cells. These lysosomal events begin rapidly
   and simultaneously with mitochondrial permeabilization and caspase
   activation within 3 h after drug treatment. Recently, in a comparative
   proteomics analysis performed on highly-enriched lysosomal extracts, we
   identified proteins whose translocation to lysosomes correlated with LLM
   induction after CPT treatment, including protein kinase C-delta
   (PKC-delta). In this study, we show that the PKC-delta translocation to
   lysosomes is required for LLM, as silencing its expression with RNA
   interference or suppressing its activity with the inhibitor, rottlerin,
   prevents CPT-induced LLM. PKC-delta translocation to lysosomes is
   associated with lysosomal acidic sphingomyelinase (ASM) phosphorylation
   and activation, which in turn leads to an increase in ceramide (CER)
   content in lysosomes. The accumulation of endogenous CER in lysosomes is
   a critical event for CPT-induced LLM as suppressing PKC-delta or ASM
   activity reduces both the CPT-mediated CER generation in lysosomes and
   CPT-induced LLM. These findings reveal a novel mechanism by which
   PKC-delta mediates ASM phosphorylation/activation and CER accumulation
   in lysosomes in CPT-induced LLM, rapidly activating the lysosomal
   pathway of apoptosis after CPT treatment.
TC 12
ZA 0
Z8 0
ZS 0
ZR 0
ZB 9
Z9 13
DA 2011-02-01
UT WOS:000286702600003
PM 21174057
ER

PT J
AU Kaiser, Kristen N.
   Hughes, Alexa J.
   Yang, Anthony D.
   Turk, Anita A.
   Mohanty, Sanjay
   Gonzalez, Andrew A.
   Patzer, Rachel E.
   Bilimoria, Karl Y.
   Ellis, Ryan J.
TI Accuracy and consistency of publicly available Large Language Models as
   clinical decision support tools for the management of colon cancer
SO JOURNAL OF SURGICAL ONCOLOGY
VL 130
IS 5
BP 1104
EP 1110
DI 10.1002/jso.27821
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB Background: Large Language Models (LLM; e.g., ChatGPT) may be used to
   assist clinicians and form the basis of future clinical decision support
   (CDS) for colon cancer. The objectives of this study were to (1)
   evaluate the response accuracy of two LLM-powered interfaces in
   identifying guideline-based care in simulated clinical scenarios and (2)
   define response variation between and within LLMs. Methods: Clinical
   scenarios with "next steps in management" queries were developed based
   on National Comprehensive Cancer Network guidelines. Prompts were
   entered into OpenAI ChatGPT and Microsoft Copilot in independent
   sessions, yielding four responses per scenario. Responses were compared
   to clinician-developed responses and assessed for accuracy, consistency,
   and verbosity. Results: Across 108 responses to 27 prompts, both
   platforms yielded completely correct responses to 36% of scenarios (n =
   39). For ChatGPT, 39% (n = 21) were missing information and 24% (n = 14)
   contained inaccurate/misleading information. Copilot performed
   similarly, with 37% (n = 20) having missing information and 28% (n = 15)
   containing inaccurate/misleading information (p = 0.96). Clinician
   responses were significantly shorter (34 +/- 15.5 words) than both
   ChatGPT (251 +/- 86 words) and Copilot (271 +/- 67 words; both p <
   0.01). Conclusions: Publicly available LLM applications often provide
   verbose responses with vague or inaccurate information regarding colon
   cancer management. Significant optimization is required before use in
   formal CDS.
Z8 0
ZA 0
ZR 0
ZS 0
TC 6
ZB 0
Z9 6
DA 2024-08-23
UT WOS:001293197900001
PM 39155667
ER

PT J
AU Agrawal, Anjali
TI Fairness in AI-Driven Oncology: Investigating Racial and Gender Biases
   in Large Language Models
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 9
AR e69541
DI 10.7759/cureus.69541
DT Article
PD SEP 16 2024
PY 2024
AB Introduction: Large language model (LLM) chatbots have many applications
   in medical settings. However, these tools can potentially perpetuate
   racial and gender biases through their responses, worsening disparities
   in healthcare. With the ongoing discussion of LLM chatbots in oncology
   and the widespread goal of addressing cancer disparities, this study
   focuses on biases propagated by LLM chatbots in oncology. Methods: Chat
   Generative Pre-trained Transformer (Chat GPT; OpenAI, San Francisco, CA,
   USA) was asked to determine what occupation a generic description of
   "assesses cancer patients" would correspond to for different
   demographics. Chat GPT, Gemini (Alphabet Inc., Mountain View, CA, USA),
   and Bing Chat (Microsoft Corp., Redmond, WA, USA) were prompted to
   provide oncologist recommendations in the top U.S. cities and
   demographic information (race, gender) of recommendations was compared
   against national distributions. Chat GPT was also asked to generate a
   job description for oncologists with different demographic backgrounds.
   Finally, Chat GPT, Gemini, and Bing Chat were asked to generate
   hypothetical cancer patients with race, smoking, and drinking histories.
   Results: LLM chatbots are about two times more likely to predict Blacks
   and Native Americans as oncology nurses than oncologists, compared to
   Asians (p < 0.01 and < 0.001, respectively). Similarly, they are also
   significantly more likely to predict females than males as oncology
   nurses (p < 0.001). Chat GPT's real-world oncologist recommendations
   overrepresent Asians by almost double and underrepresent Blacks by
   double and Hispanics by seven times. Chatbots also generate different
   job descriptions based on demographics, including cultural competency
   and advocacy and excluding treatment administration for underrepresented
   backgrounds. AI-generated cancer cases are not fully representative of
   real-world demographic distributions and encode stereotypes on substance
   abuse, such as Hispanics having a greater proportion of smokers than
   Whites by about 20% in Chat GPT breast cancer cases. Conclusion: To our
   knowledge, this is the first study of its kind to investigate racial and
   gender biases of such a diverse set of AI chatbots, and that too, within
   oncology. The methodology presented in this study provides a framework
   for targeted bias evaluation of LLMs in various fields across medicine.
ZB 0
Z8 0
ZA 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2024-09-29
UT WOS:001318056600011
PM 39416584
ER

PT J
AU Garcia-Barragan, Alvaro
   Sakor, Ahmad
   Vidal, Maria-Esther
   Menasalvas, Ernestina
   Gonzalez, Juan Cristobal Sanchez
   Provencio, Mariano
   Robles, Victor
TI NSSC: a neuro-symbolic AI system for enhancing accuracy of named entity
   recognition and linking from oncologic clinical notes
SO MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING
AR s11517-024-03227-4
DI 10.1007/s11517-024-03227-4
EA NOV 2024
DT Article; Early Access
PY 2024
AB Accurate recognition and linking of oncologic entities in clinical notes
   is essential for extracting insights across cancer research, patient
   care, clinical decision-making, and treatment optimization. We present
   the Neuro-Symbolic System for Cancer (NSSC), a hybrid AI framework that
   integrates neurosymbolic methods with named entity recognition (NER) and
   entity linking (EL) to transform unstructured clinical notes into
   structured terms using medical vocabularies, with the Unified Medical
   Language System (UMLS) as a case study. NSSC was evaluated on a dataset
   of clinical notes from breast cancer patients, demonstrating significant
   improvements in the accuracy of both entity recognition and linking
   compared to state-of-the-art models. Specifically, NSSC achieved a 33%
   improvement over BioFalcon and a 58% improvement over scispaCy. By
   combining large language models (LLMs) with symbolic reasoning, NSSC
   improves the recognition and interoperability of oncologic entities,
   enabling seamless integration with existing biomedical knowledge. This
   approach marks a significant advancement in extracting meaningful
   information from clinical narratives, offering promising applications in
   cancer research and personalized patient care.
ZA 0
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
Z9 1
DA 2024-11-07
UT WOS:001345890000001
PM 39485651
ER

PT J
AU John, Annette
   Alhajj, Reda
   Rokne, Jon
TI A systematic review of AI as a digital twin for prostate cancer care
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 268
AR 108804
DI 10.1016/j.cmpb.2025.108804
EA MAY 2025
DT Review
PD AUG 2025
PY 2025
AB Artificial Intelligence (AI) and Digital Twin (DT) technologies are
   rapidly transforming healthcare, offering the potential for
   personalized, accurate, and efficient medical care. This systematic
   review focuses on the intersection of AI-based digital twins and their
   applications in prostate cancer pathology. A digital twin, when applied
   to healthcare, creates a dynamic, data-driven virtual model that
   simulates a patient's biological systems in real-time. By incorporating
   AI techniques such as Machine Learning (ML) and Deep Learning (DL),
   these systems enhance predictive accuracy, enable early diagnosis, and
   facilitate individualized treatment strategies for prostate cancer. This
   review systematically examines recent advances (2020-2025) in AI-driven
   digital twins for prostate cancer, highlighting key methodologies,
   algorithms, and data integration strategies. The literature analysis
   also reveals substantial progress in image processing, predictive
   modeling, and clinical decision support systems, which are the basic
   tools used when implementing digital twins for prostate cancer care. Our
   survey also critically evaluates the strengths and limitations of
   current approaches, identifying gaps such as the need for real-time data
   integration, improved explainability in AI models, and more robust
   clinical validation. It concludes with a discussion of future research
   directions, emphasizing the importance of integrating multi-modal data
   with Large Language Models (LLMs) and Vision-Language Models (VLMs),
   scalability, and ethical considerations in advancing AI-driven digital
   twins for prostate cancer diagnosis and treatment. This paper provides a
   comprehensive resource for researchers and clinicians, offering insights
   into how AI-based digital twins can enhance precision medicine and
   improve patient outcomes in prostate cancer care.
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
DA 2025-05-23
UT WOS:001490802200002
PM 40347618
ER

PT J
AU Li, Ya
   Zheng, Xuecong
   Li, Jiaping
   Dai, Qingyun
   Wang, Chang-Dong
   Chen, Min
TI LKAN: LLM-Based Knowledge-Aware Attention Network for Clinical Staging
   of Liver Cancer
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
VL 29
IS 4
BP 3007
EP 3020
DI 10.1109/JBHI.2024.3478809
DT Article
PD APR 2025
PY 2025
AB Clinical staging of liver cancer (CSoLC), an important indicator for
   evaluating primary liver cancer (PLC), is key in the diagnosis,
   treatment, and rehabilitation of liver cancer. In China, the current
   CSoLC adopts the China liver cancer (CNLC) staging, which is usually
   evaluated by clinicians based on radiology reports. Therefore, inferring
   clinical information from unstructured radiology reports can provide
   auxiliary decision support for clinicians. The key to solving the
   challenging task is to guide the model to pay attention to the
   staging-related words or sentences, and the following issues may occur:
   1) Imbalanced categories: Early- and mid-stage liver cancer symptoms are
   subtle, resulting in more data in the end-stage. 2) Domain sensitivity
   of liver cancer data: The liver cancer dataset contains substantial
   domain knowledge, leading to out-of-vocabulary issues and reduced
   classification accuracy. 3) Free-text and lengthy report: Radiology
   reports sparsely describe various lesions using domain-specific terms,
   making it hard to mine staging-related information. To address these,
   this article proposes a large language model (LLM)-based Knowledge-aware
   Attention Network (LKAN) for CSoLC. First, for maintaining semantic
   consistency, LLM and a rule-based algorithm are integrated to generate
   more diverse and reasonable data. Second, an unlabeled radiology corpus
   is pre-trained to introduce domain knowledge for subsequent
   representation learning. Third, attention is improved by incorporating
   both global and local features to guide the model's focus on
   staging-relevant information. Compared with the baseline models, LKAN
   has achieved the best results with 90.3% Accuracy, 90.0% Macro_F1 score,
   and 90.0% Macro_Recall.
ZR 0
ZS 0
Z8 0
ZA 0
ZB 0
TC 1
Z9 1
DA 2025-04-19
UT WOS:001459663700029
PM 39392729
ER

PT C
AU Kim, Kyungwon
   Lee, Yongmoon
   Park, Doohyun
   Eo, Taejoon
   Youn, Daemyung
   Lee, Hyesang
   Hwang, Dosik
BE Feragen, A
   Giannarou, S
   Glocker, B
   Lekadir, K
   Schnabel, JA
   Linguraru, MG
   Dou, Q
TI LLM-Guided Multi-modal Multiple Instance Learning for 5-Year Overall
   Survival Prediction of Lung Cancer
SO MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI
   2024, PT III
SE Lecture Notes in Computer Science
VL 15003
BP 239
EP 249
DI 10.1007/978-3-031-72384-1_23
DT Proceedings Paper
PD 2024
PY 2024
AB Accurately predicting the 5-year prognosis of lung cancer patients is
   crucial for guiding treatment planning and providing optimal patient
   care. Traditional methods relying on CT image-based cancer stage
   assessment and morphological analysis of cancer cells in pathology
   images have encountered challenges in terms of reliability and accuracy
   due to the complexity and diversity of information within these images.
   Recent rapid advancements in deep learning have shown promising
   performance in prognosis prediction, however utilizing CT and pathology
   images independently is limited by their differing imaging
   characteristics and the unique prognostic information. To effectively
   address these challenges, this study proposes a novel framework that
   integrates prognostic capabilities of both CT and pathology images with
   clinical information, employing a multi-modal integration approach via
   multiple instance learning, leveraging large language models (LLMs) to
   analyze clinical notes and align them with image modalities. The
   proposed approach was rigorously validated using external datasets from
   different hospitals, demonstrating superior performance over models
   reliant on vision or clinical data alone. This highlights the
   adaptability and strength of LLMs in managing complex multi-modal
   medical datasets for lung cancer prognosis, marking a significant
   advance towards more accurate and comprehensive patient care strategies.
   The code is publicly available on
   https://github.com/KyleKWKim/LLM-guided-Multimodal-MIL.
CT 27th International Conference on Medical Image Computing and Computer
   Assisted Intervention (MICCAI)
CY OCT 06-10, 2024
CL Palmeraie Conf Ctr, Marrakesh, MOROCCO
HO Palmeraie Conf Ctr
SP GH Labs; Childrens Natl Hosp; Pierre Fabre; Comp Assisted Med Intervent
   Labex; Multidisciplinary Inst Artificial Intelligence Grenoble Alpes;
   Western Univ, Frugal Biomed Innovat Program; Int Soc Radiol; Medtronic;
   Pasqual Maragall Fdn; Delft Imaging; Univ Barcelona, Artificial
   Intelligence Med Lab; Cadi Ayyad Univ; Natl Ctr Sci & Tech Res
ZR 0
Z8 0
ZB 0
ZS 0
TC 1
ZA 0
Z9 1
DA 2024-11-28
UT WOS:001342227700023
ER

PT J
AU Hooshangnejad, Hamed
   Huang, Gaofeng
   Kelly, Katelyn
   Feng, Xue
   Luo, Yi
   Zhang, Rui
   Xu, Ziyue
   Chen, Quan
   Ding, Kai
TI EXACT-Net: Framework for EHR-Guided Lung Tumor Auto-Segmentation for
   Non-Small Cell Lung Cancer Radiotherapy
SO CANCERS
VL 16
IS 23
AR 4097
DI 10.3390/cancers16234097
DT Article
PD DEC 2024
PY 2024
AB Background/Objectives: Lung cancer is a devastating disease with the
   highest mortality rate among cancer types. Over 60% of non-small cell
   lung cancer (NSCLC) patients, accounting for 87% of lung cancer
   diagnoses, require radiation therapy. Rapid treatment initiation
   significantly increases the patient's survival rate and reduces the
   mortality rate. Accurate tumor segmentation is a critical step in
   diagnosing and treating NSCLC. Manual segmentation is time- and
   labor-consuming and causes delays in treatment initiation. Although many
   lung nodule detection methods, including deep learning-based models,
   have been proposed. Most of these methods still have a long-standing
   problem of high false positives (FPs). Methods: Here, we developed an
   electronic health record (EHR)-guided lung tumor auto-segmentation
   called EXACT-Net (EHR-enhanced eXACtitude in Tumor segmentation), where
   the extracted information from EHRs using a pre-trained large language
   model (LLM) was used to remove the FPs and keep the TP nodules only.
   Results: The auto-segmentation model was trained on NSCLC patients'
   computed tomography (CT), and the pre-trained LLM was used with the
   zero-shot learning approach. Our approach resulted in a 250% boost in
   successful nodule detection using the data from ten NSCLC patients
   treated in our institution. Conclusions: We demonstrated that combining
   vision-language information in EXACT-Net multi-modal AI framework
   greatly enhances the performance of vision only models, paving the road
   to multimodal AI framework for medical image processing.
ZS 0
ZA 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2024-12-19
UT WOS:001376131100001
PM 39682283
ER

PT J
AU Bhayana, Rajesh
   Alwahbi, Omar
   Ladak, Aly Muhammad
   Deng, Yangqing
   Dias, Adriano Basso
   Elbanna, Khaled
   Gomez, Jorge Abreu
   Jajodia, Ankush
   Jhaveri, Kartik
   Johnson, Sarah
   Kajal, Dilkash
   Wang, David
   Soong, Christine
   Kielar, Ania
   Krishna, Satheesh
TI Leveraging Large Language Models to Generate Clinical Histories for
   Oncologic Imaging Requisitions
SO RADIOLOGY
VL 314
IS 2
AR e242134
DI 10.1148/radiol.242134
DT Article
PD FEB 2025
PY 2025
AB Background: Clinical information improves imaging interpretation, but
   physician-provided histories on requisitions for oncologic imaging often
   lack key details. Purpose: To evaluate large language models (LLMs) for
   automatically generating clinical histories for oncologic imaging
   requisitions from clinical notes and compare them with original
   requisition histories. Materials and Methods: In total, 207 patients
   with CT performed at a cancer center from January to November 2023 and
   with an electronic health record clinical note coinciding with ordering
   date were randomly selected. A multidisciplinary team informed selection
   of 10 parameters important for oncologic imaging history, including
   primary oncologic diagnosis, treatment history, and acute symptoms.
   Clinical notes were independently reviewed to establish the reference
   standard regarding presence of each parameter. After prompt engineering
   with seven patients, GPT-4 (version 0613; OpenAI) was prompted on April
   9, 2024, to automatically generate structured clinical histories for the
   200 remaining patients. Using the reference standard, LLM extraction
   performance was calculated (recall, precision, F1 score). LLM-generated
   and original requisition histories were compared for completeness
   (proportion including each parameter), and 10 radiologists performed
   pairwise comparison for quality, preference, and subjective likelihood
   of harm. Results: For the 200 LLM-generated histories, GPT-4 performed
   well, extracting oncologic parameters from clinical notes (F1 = 0.983).
   Compared with original requisition histories, LLM-generated histories
   more frequently included parameters critical for radiologist
   interpretation, including primary oncologic diagnosis (99.5% vs 89% [199
   and 178 of 200 histories, respectively]; P < .001), acute or worsening
   symptoms (15% vs 4% [29 and seven of 200]; P < .001), and relevant
   surgery (61% vs 12% [122 and 23 of 200]; P < .001). Radiologists
   preferred LLM-generated histories for imaging interpretation (89% vs 5%,
   7% equal; P < .001), indicating they would enable more complete
   interpretation (86% vs 0%, 15% equal; P < .001) and have a lower
   likelihood of harm (3% vs 55%, 42% neither; P < .001). Conclusion: An
   LLM enabled accurate automated clinical histories for oncologic imaging
   from clinical notes. Compared with original requisition histories,
   LLM-generated histories were more complete and were preferred by
   radiologists for imaging interpretation and perceived safety.
ZA 0
Z8 0
ZR 0
ZB 0
ZS 0
TC 1
Z9 1
DA 2025-03-08
UT WOS:001434851700023
PM 39903072
ER

PT J
AU Griewing, Sebastian
   Lechner, Fabian
   Gremke, Niklas
   Lukac, Stefan
   Janni, Wolfgang
   Wallwiener, Markus
   Wagner, Uwe
   Hirsch, Martin
   Kuhn, Sebastian
TI Proof-of-concept study of a small language model chatbot for breast
   cancer decision support - a transparent, source-controlled, explainable
   and data-secure approach
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 10
AR 451
DI 10.1007/s00432-024-05964-3
DT Article
PD OCT 9 2024
PY 2024
AB Purpose Large language models (LLM) show potential for decision support
   in breast cancer care. Their use in clinical care is currently
   prohibited by lack of control over sources used for decision-making,
   explainability of the decision-making process and health data security
   issues. Recent development of Small Language Models (SLM) is discussed
   to address these challenges. This preclinical proof-of-concept study
   tailors an open-source SLM to the German breast cancer guideline
   (BC-SLM) to evaluate initial clinical accuracy and technical
   functionality in a preclinical simulation. Methods A multidisciplinary
   tumor board (MTB) is used as the gold-standard to assess the initial
   clinical accuracy in terms of concordance of the BC-SLM with MTB and
   comparing it to two publicly available LLM, ChatGPT3.5 and 4. The study
   includes 20 fictional patient profiles and recommendations for 5
   treatment modalities, resulting in 100 binary treatment recommendations
   (recommended or not recommended). Statistical evaluation includes
   concordance with MTB in % including Cohen's Kappa statistic (kappa).
   Technical functionality is assessed qualitatively in terms of local
   hosting, adherence to the guideline and information retrieval. Results
   The overall concordance amounts to 86% for BC-SLM (kappa = 0.721, p <
   0.001), 90% for ChatGPT4 (kappa = 0.820, p < 0.001) and 83% for
   ChatGPT3.5 (kappa = 0.661, p < 0.001). Specific concordance for each
   treatment modality ranges from 65 to 100% for BC-SLM, 85-100% for
   ChatGPT4, and 55-95% for ChatGPT3.5. The BC-SLM is locally functional,
   adheres to the standards of the German breast cancer guideline and
   provides referenced sections for its decision-making. Conclusion The
   tailored BC-SLM shows initial clinical accuracy and technical
   functionality, with concordance to the MTB that is comparable to
   publicly-available LLMs like ChatGPT4 and 3.5. This serves as a
   proof-of-concept for adapting a SLM to an oncological disease and its
   guideline to address prevailing issues with LLM by ensuring decision
   transparency, explainability, source control, and data security, which
   represents a necessary step towards clinical validation and safe use of
   language models in clinical oncology.
ZR 0
ZA 0
Z8 0
TC 1
ZB 1
ZS 0
Z9 1
DA 2024-10-24
UT WOS:001335902900001
PM 39382778
ER

PT J
AU Rinderknecht, Emily
   von Winning, Dominik
   Kravchuk, Anton
   Schaefer, Christof
   Schnabel, Marco J.
   Siepmann, Stephan
   Mayr, Roman
   Grassinger, Jochen
   Gossler, Christopher
   Pohl, Fabian
   Siska, Peter J.
   Zeman, Florian
   Breyer, Johannes
   Schmelzer, Anna
   Gilfrich, Christian
   Brookman-May, Sabine D.
   Burger, Maximilian
   Haas, Maximilian
   May, Matthias
TI Modification and Validation of the System Causability Scale Using
   AI-Based Therapeutic Recommendations for Urological Cancer Patients: A
   Basis for the Development of a Prospective Comparative Study
SO CURRENT ONCOLOGY
VL 31
IS 11
BP 7061
EP 7073
DI 10.3390/curroncol31110520
DT Article
PD NOV 2024
PY 2024
AB The integration of artificial intelligence, particularly Large Language
   Models (LLMs), has the potential to significantly enhance therapeutic
   decision-making in clinical oncology. Initial studies across various
   disciplines have demonstrated that LLM-based treatment recommendations
   can rival those of multidisciplinary tumor boards (MTBs); however, such
   data are currently lacking for urological cancers. This preparatory
   study establishes a robust methodological foundation for the forthcoming
   CONCORDIA trial, including the validation of the System Causability
   Scale (SCS) and its modified version (mSCS), as well as the selection of
   LLMs for urological cancer treatment recommendations based on
   recommendations from ChatGPT-4 and an MTB for 40 urological cancer
   scenarios. Both scales demonstrated strong validity, reliability (all
   aggregated Cohen's K > 0.74), and internal consistency (all Cronbach's
   Alpha > 0.9), with the mSCS showing superior reliability, internal
   consistency, and clinical applicability (p < 0.01). Two Delphi processes
   were used to define the LLMs to be tested in the CONCORDIA study
   (ChatGPT-4 and Claude 3.5 Sonnet) and to establish the acceptable
   non-inferiority margin for LLM recommendations compared to MTB
   recommendations. The forthcoming ethics-approved and registered
   CONCORDIA non-inferiority trial will require 110 urological cancer
   scenarios, with an mSCS difference threshold of 0.15, a Bonferroni
   corrected alpha of 0.025, and a beta of 0.1. Blinded mSCS assessments of
   MTB recommendations will then be compared to those of the LLMs. In
   summary, this work establishes the necessary prerequisites prior to
   initiating the CONCORDIA study and validates a modified score with high
   applicability and reliability for this and future trials.
ZS 0
ZR 0
TC 1
ZB 0
Z8 0
ZA 0
Z9 1
DA 2024-12-03
UT WOS:001364848300001
PM 39590151
ER

PT J
AU Huang, Hanyao
   Zheng, Ou
   Wang, Dongdong
   Yin, Jiayi
   Wang, Zijin
   Ding, Shengxuan
   Yin, Heng
   Xu, Chuan
   Yang, Renjie
   Zheng, Qian
   Shi, Bing
TI ChatGPT for shaping the future of dentistry: the potential of
   multi-modal large language model
SO INTERNATIONAL JOURNAL OF ORAL SCIENCE
VL 15
IS 1
AR 29
DI 10.1038/s41368-023-00239-y
DT Review
PD JUL 28 2023
PY 2023
AB The ChatGPT, a lite and conversational variant of Generative Pretrained
   Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large
   Language Models (LLMs) with billions of parameters. LLMs have stirred up
   much interest among researchers and practitioners in their impressive
   skills in natural language processing tasks, which profoundly impact
   various fields. This paper mainly discusses the future applications of
   LLMs in dentistry. We introduce two primary LLM deployment methods in
   dentistry, including automated dental diagnosis and cross-modal dental
   diagnosis, and examine their potential applications. Especially,
   equipped with a cross-modal encoder, a single LLM can manage
   multi-source data and conduct advanced natural language reasoning to
   perform complex clinical operations. We also present cases to
   demonstrate the potential of a fully automatic Multi-Modal LLM AI system
   for dentistry clinical application. While LLMs offer significant
   potential benefits, the challenges, such as data privacy, data quality,
   and model bias, need further study. Overall, LLMs have the potential to
   revolutionize dental diagnosis and treatment, which indicates a
   promising avenue for clinical application and research in dentistry.
ZR 0
ZA 0
TC 112
ZS 0
ZB 10
Z8 4
Z9 115
DA 2023-08-15
UT WOS:001039606900001
PM 37507396
ER

PT J
AU Nabieva, Naiba
   Brucker, Sara Y.
   Gmeiner, Benjamin
TI ChatGPT's Agreement with the Recommendations from the 18th St. Gallen
   International Consensus Conference on the Treatment of Early Breast
   Cancer
SO CANCERS
VL 16
IS 24
AR 4163
DI 10.3390/cancers16244163
DT Article
PD DEC 2024
PY 2024
AB Introduction: Organizations like the European Society for Medical
   Oncology and the St. Gallen Oncology Conference panel regularly review
   the latest research data to align on common recommendations for the
   treatment of breast cancer patients. In the era of artificial
   intelligence (AI), the question arises whether AI can enhance scientific
   debates by providing potential recommendations for expert discussions.
   Methods: We focused on the St. Gallen International Breast Cancer
   Conference (SGBCC) in 2023, where 71 experts from 27 countries answered
   127 questions across 17 topics related to early breast cancer. OpenAI's
   ChatGPT version 4.0 was employed to respond to the same set of
   questions. We simulated response variability and mitigated potential
   memory effects using several question-rounds in new chat sessions.
   Results: ChatGPT answered 71 questions (55.91%) in accordance with the
   most common answer voted by the SGBCC panel and showed a moderate
   overall agreement. In these cases, AI voted with an average reliability
   of 98.31%, compared to the panel's average majority of 65.39% for the
   most common answer. A very high agreement could be observed in questions
   on "Genetics", "Pathology", "Oligometastatic disease", "Ductal carcinoma
   in situ" and "Well-being for breast cancer survivors". A very low
   agreement was seen in the topics "BRCA associated", "Adjuvant endocrine
   therapy", "HER2 positive", "Local/regional recurrence" and
   "Bone-modifying therapy". Conclusions: Our study demonstrates that
   ChatGPT shows potential in the development of breast cancer treatment
   recommendations, particularly in areas where high agreement with expert
   panel responses was observed. However, significant improvements are
   necessary before AI can be considered a reliable tool to support human
   expertise.
ZS 0
Z8 0
ZR 0
ZB 1
ZA 0
TC 2
Z9 2
DA 2024-12-31
UT WOS:001383770000001
PM 39766061
ER

PT J
AU Luo, Man
   Trivedi, Shubham
   Kurian, Allison W.
   Ward, Kevin
   Keegan, Theresa H. M.
   Rubin, Daniel
   Banerjee, Imon
TI Automated Extraction of Patient-Centered Outcomes After Breast Cancer
   Treatment: An Open-Source Large Language Model-Based Toolkit
SO JCO CLINICAL CANCER INFORMATICS
VL 8
AR e2300258
DI 10.1200/CCI.23.00258
DT Article
PD AUG 2024
PY 2024
AB PURPOSEPatient-centered outcomes (PCOs) are pivotal in cancer treatment,
   as they directly reflect patients' quality of life. Although multiple
   studies suggest that factors affecting breast cancer-related morbidity
   and survival are influenced by treatment side effects and adherence to
   long-term treatment, such data are generally only available on a smaller
   scale or from a single center. The primary challenge with collecting
   these data is that the outcomes are captured as free text in clinical
   narratives written by clinicians.MATERIALS AND METHODSGiven the
   complexity of PCO documentation in these narratives, computerized
   methods are necessary to unlock the wealth of information buried in
   unstructured text notes that often document PCOs. Inspired by the
   success of large language models (LLMs), we examined the adaptability of
   three LLMs, GPT-2, BioGPT, and PMC-LLaMA, on PCO tasks across three
   institutions, Mayo Clinic, Emory University Hospital, and Stanford
   University. We developed an open-source framework for fine-tuning LLM
   that can directly extract the five different categories of PCO from the
   clinic notes.RESULTSWe found that these LLMs without fine-tuning
   (zero-shot) struggle with challenging PCO extraction tasks, displaying
   almost random performance, even with some task-specific examples
   (few-shot learning). The performance of our fine-tuned, task-specific
   models is notably superior compared with their non-fine-tuned LLM
   models. Moreover, the fine-tuned GPT-2 model has demonstrated a
   significantly better performance than the other two larger
   LLMs.CONCLUSIONOur discovery indicates that although LLMs serve as
   effective general-purpose models for tasks across various domains, they
   require fine-tuning when applied to the clinician domain. Our proposed
   approach has the potential to lead more efficient, adaptable models for
   PCO information extraction, reducing reliance on extensive computational
   resources while still delivering superior performance for specific
   tasks.
TC 1
ZS 0
ZB 0
Z8 0
ZR 0
ZA 0
Z9 1
DA 2024-11-23
UT WOS:001299613900001
PM 39167746
ER

PT J
AU Li, Zhong-Liang
   Hu, Bao-Shan
   Liu, Yong-Kang
   Zheng, You-Bing
   He, Xu
   Li, Yong
   Lu, Li-Gong
TI Transhepatic arterial chemoembolizations with lobaplatin-eluting
   microspheres for the treatment of unresectable hepatocellular carcinoma
SO INTERNATIONAL JOURNAL OF CLINICAL AND EXPERIMENTAL MEDICINE
VL 11
IS 2
BP 1192
EP 1199
DT Article
PD 2018
PY 2018
AB Objective: To assess the clinical safety and efficacy of Transhepatic
   Arterial Chemoembolizations (TACE) with lobaplatin-eluting microspheres
   in treating unresectable hepatocellular carcinoma (HCC). Materials and
   Methods: A total of 70 patients with unresectable hepatocellular
   carcinoma and preserved liver function, who were treated with TACE using
   lobaplatin-eluting microspheres (Group-LEM, as experimental group) or
   using lobaplatin-lipiodol mixtures (Group-LLM, as control group), were
   evaluated retrospectively. Tumor response was determined with follow-up
   computed tomography after each chemoembolized procedure according to
   modified Response Evaluation Criteria in Solid Tumors (mRECIST). The
   side effects and complications were evaluated by the National Cancer
   Institute Common Terminology Criteria for Adverse Events (CTCAE) v4.0.
   Results: A database of 70 patients with advanced HCC admitted to
   Guangdong General Hospital between January 2016 and October 2016 was
   evaluated retrospectively. Four weeks after TACE procedure, radiological
   evaluation of tumour response was available in all patients, According
   to mRECIST, disease control rate (DCR) and objective response rate (ORR)
   differed significantly between Group-LEM and Group-LLM (60.00% vs
   31.43%, and 22.86% vs 2.86%). The most common adverse event was
   postembolization syndrome (PES), with 18 in Group-LEM and 24 in
   Group-LLM respectively. Liver dysfunction and thrombocytopenia also had
   significant difference through comparative analysis between Group-LEM
   and Group-LLM (8 vs 16, and 1 vs 8). There were neither periprocedural
   deaths nor adverse events (AEs) of grade 5 documented in all patients.
   Conclusion: TACE with lobaplatin-eluting microspheres is a safe and
   feasible treatment without major adverse events in treating unresectable
   hepatocellular carcinoma. However, the long-term effects of this
   treatment need further observation.
ZA 0
ZR 0
ZS 0
TC 0
ZB 0
Z8 0
Z9 0
DA 2018-04-02
UT WOS:000427417600101
ER

PT C
AU Bandara, Eranga
   Foytik, Peter
   Shetty, Sachin
   Mukkamala, Ravi
   Rahman, Abdul
   Liang, Xueping
   Keon, Ng Wee
   De Zoysa, Kasun
GP IEEE
TI WedaGPT - Generative-AI (with Custom-Trained Meta's Llama2 LLM),
   Blockchain, Self Sovereign Identity, NFT and Model Card Enabled
   Indigenous Medicine Platform
SO 2024 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, ISCC 2024
SE IEEE Symposium on Computers and Communications ISCC
DI 10.1109/ISCC61673.2024.10733674
DT Proceedings Paper
PD 2024
PY 2024
AB Traditional and indigenous medicine, deeply rooted in ancient traditions
   and wisdom, plays a crucial role in global healthcare and cultural
   identity. These practices provide treatments for illnesses such as
   cancer and bone injuries, which often lack effective remedies in Western
   medicine. However, these valuable systems face challenges like potential
   knowledge loss, undervaluation of practitioners' expertise, and the risk
   of fraud due to the absence of credential verification mechanisms. In
   this research, we introduce "WedaGPT," a Generative AI-enabled platform
   that utilizes a custom-trained Meta's Llama2 Large Language Model (LLM),
   Blockchain, self-sovereign identity (SSI), Non-Fungible Tokens (NFTs),
   and model cards to share traditional medical knowledge and address these
   issues. WedaGPT creates a collaborative ecosystem connecting doctors,
   medicine providers, therapists, patients, and technology experts, all
   committed to preserving and advancing traditional healing practices.
   This platform enables secure and transparent contributions from all
   stakeholders to patient well-being. Ancient medical recipe books are
   translated into English and digitized into PDF formats to enrich the
   platform's knowledge base. These texts are used to fine-tune the Llama2
   LLM, which has been quantized and optimized with Qlora for performance
   on consumer-grade hardware. Through a chat-based interface in the
   SSI-enabled mobile wallet, users can interact with the LLM and access
   detailed information on treatments, recipes, prescriptions, and healing
   methods. Additionally, users can consult remotely with doctors who
   prescribe treatments through this wallet. A key feature of WedaGPT is
   transforming ancient medicinal recipes into NFT tokens for sale on NFT
   marketplaces, giving traditional knowledge digital authenticity and
   economic value. Revenue from these sales is distributed among platform
   contributors, promoting equitable ownership and recognition. Medical
   recipe data, including treatment histories and physician details, are
   encapsulated in Model Cards and securely stored on the blockchain. This
   system offers mechanisms to verify doctors and treatments in a
   privacy-preserving way, potentially reducing fraud and medication
   errors.
CT 29th IEEE Symposium on Computers and Communications (IEEE ISCC)
CY JUN 26-29, 2024
CL Paris, FRANCE
SP IEEE
Z8 0
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-01-03
UT WOS:001363176200111
ER

PT J
AU Li, Bo
   Cheng, Aoming
   Liu, Huan
   Wang, Hao
   Wang, Chong
   Xu, Qiaoshi
   Han, Zhengxue
   Feng, Zhien
TI The modified vermilion border-marionette line approach: A management for
   buccal cancer with wider indications and higher satisfaction
SO ORAL DISEASES
VL 29
IS 7
BP 2650
EP 2657
DI 10.1111/odi.14340
EA SEP 2022
DT Article
PD OCT 2023
PY 2023
AB Objective The purpose of this study is to explore the effects of
   modified vermilion border-marionette line (MVBML) approach on
   postoperative facial scar, nerves injury, and prognosis of patients with
   buccal squamous cell carcinoma (BSCC). Patients and Methods This is a
   single-center, prospective cohort study that enrolled 80 patients with
   BSCC from June 2015 to December 2020. According to the different
   surgical approaches, the patients were divided into two groups: the
   lower lip median (LLM) approach group and the MVBML approach group.
   Results The results showed that the appearance (p = 0.003), scar
   consciousness (p < 0.001) and satisfaction with appearance (p = 0.001)
   of patients in the MVBML group were significantly better than those in
   the LLM group, and the difference was more obvious in elderly group.
   Statistical analysis of postoperative nerves injury showed that the
   MVBML group had a lower risk of facial and mental nerves injury than the
   LLM group, and there was a significant statistical difference in mental
   nerve injury between the two groups (p < 0.001). Through Kaplan-Meier
   survival analysis, we found no significant difference in
   disease-specific survival (p = 0.47) or disease-free survival (p = 0.70)
   between the LLM approach group and the MVBML approach group. Conclusions
   The MVBML surgical approach is worthy of advancement for the surgical
   treatment of BSCC.
Z8 0
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z9 3
DA 2022-09-20
UT WOS:000852977200001
PM 35925052
ER

PT J
AU Scherbakov, Dmitry
   Heider, Paul M.
   Wehbe, Ramsey
   Alekseyenko, Alexander V.
   Lenert, Leslie A.
   Obeid, Jihad S.
TI Using large language models for extracting stressful life events to
   assess their impact on preventive colon cancer screening adherence
SO BMC PUBLIC HEALTH
VL 25
IS 1
AR 12
DI 10.1186/s12889-024-21123-2
DT Article
PD JAN 2 2025
PY 2025
AB BackgroundIncrease in early onset colorectal cancer makes adherence to
   screening a significant public health concern, with various social
   determinants playing a crucial role in its incidence, diagnosis,
   treatment, and outcomes. Stressful life events, such as divorce,
   marriage, or sudden loss of job, have a unique position among the social
   determinants of health.MethodsWe applied a large language model (LLM) to
   social history sections of clinical notes in the health records database
   of the Medical University of South Carolina to extract recent stressful
   life events and assess their impact on colorectal cancer screening
   adherence. We used pattern-matching regular expressions to detect a
   possible signal in social histories and ran LLM four times on each
   social history to achieve self-consistency and then used logistic
   regression to estimate the impact of life events on the probability of
   having a code in health records related to colorectal cancer
   screening.ResultsThe LLM detected 380 patients with one or more
   stressful life events and 5,344 patients with no life events. The events
   with the most negative impact on screening were arrest or incarceration
   (OR 0.26 95% CI 0.06-0.77), becoming homeless (OR 0.18 95% CI
   0.01-0.92), separation from spouse or partner (OR 0.32 95% CI
   0.05-1.18), getting married or starting to live with a partner (OR 0.60
   95% CI 0.19-1.53). Death of somebody close to the patient (excluding
   their spouse) increased the chance of screening (OR 1.21 95% CI
   0.71-2.05). Many of the observed effects did not reach statistical
   significance.ConclusionOur findings suggest that stressful life events
   might have a counterintuitive impact on screening, with some events,
   such as bereavement, were associated with increased screening. Future
   work should be focused on validating the research findings using data
   from other health institutions. In addition, expanding the list of
   stressful life events by including a validated scale of stressful life
   events for patients from historically marginalized groups is warranted.
Z8 0
ZB 0
ZS 0
TC 2
ZA 0
ZR 0
Z9 2
DA 2025-01-11
UT WOS:001389970300003
PM 39748338
ER

PT C
AU Panagoulias, Dimitrios P.
   Palamidas, Filippos A.
   Virvou, Maria
   Tsihrintzis, George A.
GP IEEE
TI Evaluation of ChatGPT-supported diagnosis, staging and treatment
   planning for the case of lung cancer
SO 2023 20TH ACS/IEEE INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS, AICCSA
SE International Conference on Computer Systems and Applications
DI 10.1109/AICCSA59173.2023.10479348
DT Proceedings Paper
PD 2023
PY 2023
AB In this paper, we evaluate the validity, accuracy, usefulness, and
   specificity of medical diagnoses related to lung cancer and its staging
   provided by ChatGPT based on symptoms described by humans. The
   evaluation is grounded on three main pillars: the validity and accuracy
   of answers in relation to context and associated references. The
   specificity and usefulness of the information for both doctors and
   patients. The economic value added to the healthcare system, determined
   by several weighted factors derived from the provided answers. The
   system's responses are expected to return proposed diagnoses and
   diagnostic steps, ranked by probability and importance. A specialist
   conducts the review process.
CT 20th ACS/IEEE International Conference on Computer Systems and
   Applications (AICCSA)
CY DEC 04-07, 2023
CL Giza, EGYPT
SP IEEE; ACS
ZB 0
ZS 0
ZR 0
TC 1
ZA 0
Z8 0
Z9 1
DA 2024-07-06
UT WOS:001222477900114
ER

PT J
AU Sezgin, Emre
   Jackson, Daniel I.
   Kocaballi, A. Baki
   Bibart, Mindy
   Zupanec, Sue
   Landier, Wendy
   Audino, Anthony
   Ranalli, Mark
   Skeens, Micah
TI Can Large Language Models Aid Caregivers of Pediatric Cancer Patients in
   Information Seeking? A Cross-Sectional Investigation
SO CANCER MEDICINE
VL 14
IS 1
AR e70554
DI 10.1002/cam4.70554
DT Article
PD JAN 2025
PY 2025
AB PurposeCaregivers in pediatric oncology need accurate and understandable
   information about their child's condition, treatment, and side effects.
   This study assesses the performance of publicly accessible large
   language model (LLM)-supported tools in providing valuable and reliable
   information to caregivers of children with cancer. MethodsIn this
   cross-sectional study, we evaluated the performance of the four
   LLM-supported tools-ChatGPT (GPT-4), Google Bard (Gemini Pro), Microsoft
   Bing Chat, and Google SGE-against a set of frequently asked questions
   (FAQs) derived from the Children's Oncology Group Family Handbook and
   expert input (In total, 26 FAQs and 104 generated responses). Five
   pediatric oncology experts assessed the generated LLM responses using
   measures including accuracy, clarity, inclusivity, completeness,
   clinical utility, and overall rating. Additionally, the content quality
   was evaluated including readability, AI disclosure, source credibility,
   resource matching, and content originality. We used descriptive analysis
   and statistical tests including Shapiro-Wilk, Levene's, Kruskal-Wallis
   H-tests, and Dunn's post hoc tests for pairwise comparisons.
   ResultsChatGPT shows high overall performance when evaluated by the
   experts. Bard also performed well, especially in accuracy and clarity of
   the responses, whereas Bing Chat and Google SGE had lower overall
   scores. Regarding the disclosure of responses being generated by AI, it
   was observed less frequently in ChatGPT responses, which may have
   affected the clarity of responses, whereas Bard maintained a balance
   between AI disclosure and response clarity. Google SGE generated the
   most readable responses whereas ChatGPT answered with the most
   complexity. LLM tools varied significantly (p < 0.001) across all expert
   evaluations except inclusivity. Through our thematic analysis of expert
   free-text comments, emotional tone and empathy emerged as a unique theme
   with mixed feedback on expectations from AI to be empathetic.
   ConclusionLLM-supported tools can enhance caregivers' knowledge of
   pediatric oncology. Each model has unique strengths and areas for
   improvement, indicating the need for careful selection based on specific
   clinical contexts. Further research is required to explore their
   application in other medical specialties and patient demographics,
   assessing broader applicability and long-term impacts.
ZA 0
TC 2
Z8 0
ZS 0
ZB 1
ZR 0
Z9 2
DA 2025-01-13
UT WOS:001391811100001
PM 39776222
ER

PT J
AU Skoulakis, Charalambos E.
   Stavroulaki, Pelagia
   Moschotzopoulos, Panagiotis
   Paxinos, Mihalis
   Fericean, Angela
   Valagiannis, Dimitris E.
TI Laryngeal leiomyosarcoma: a case report and review of the literature
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 263
IS 10
BP 929
EP 934
DI 10.1007/s00405-006-0092-0
DT Article
PD OCT 2006
PY 2006
AB Laryngeal leiomyosarcoma (LLM) is a rare malignancy originating from the
   smooth muscles of blood vessels or from aberrant undifferentiated
   mesenchymal tissue. Histological diagnosis may be particularly difficult
   and correct diagnosis is based on immunohistochemical investigations and
   electron microscopy. A case report of a LLM in a 74-year-old man is
   presented. Direct laryngoscopy revealed a large glottic lesion causing
   airway compromise and an emergency tracheotomy was performed. Subsequent
   total laryngectomy confirmed the diagnosis of leiomyosarcoma. Lung
   metastases developed 8 months following treatment, despite the absence
   of local or regional recurrence, and the patient died 3 months later. A
   review of the English and French literature revealed 30 previous cases
   of LLM. Clinical presentation, histological diagnosis, and management of
   this rare malignancy are analyzed aiming to improve our knowledge
   regarding the best treatment modality.
Z8 0
TC 17
ZR 0
ZS 0
ZB 4
ZA 0
Z9 17
DA 2006-10-01
UT WOS:000240396200009
PM 16804717
ER

PT J
AU Chen, Chien-Hsin
   Hsieh, Mao-Chih
   Lao, Wilson T.
   Lin, En-Kwang
   Lu, Yen-Jung
   Wu, Szu-Yuan
TI Multidisciplinary team intervention associated with improved survival
   for patients with colorectal adenocarcinoma with liver or lung
   metastasis
SO AMERICAN JOURNAL OF CANCER RESEARCH
VL 8
IS 9
BP 1887
EP +
DT Article
PD 2018
PY 2018
AB Background and Objectives: To investigate whether multidisciplinary team
   (MDT) intervention is associated with improved survival for patients
   with colorectal adenocarcinoma with liver or lung metastasis (CRA-LLM).
   Methods: We enrolled 161 consecutive patients with histologically
   confirmed CRA-LLM at Taipei Medical UniversityWan Fang Hospital between
   January 2007 and December 2017. In total, 75 patients with CRA-LLM
   received MDT intervention, and 86 patients did not receive MDT
   intervention. To evaluate prognostic factors for overall death, we
   performed univariate and multivariate Cox regression analyses of the
   overall death rate in all patients. Overall survival rates were
   calculated using the Kaplan-Meier method, and Kaplan-Meier survival
   curves were compared using the log-rank test (P < .001). Results: A
   multivariate Cox regression analysis of the overall death rate in
   patients with CRA-LLM showed that age <= 65 years, systemic
   chemotherapy, curative-intent treatments, and MDT intervention are
   strong prognostic factors. The adjusted hazard ratio of death risk for
   age <= 65 years, systemic chemotherapy, curative-intent treatments, and
   MDT intervention were 0.60 (95% confidence interval [CI], 0.40-0.92; P
   =.019), 0.19 (95% CI, 0.12-0.32; P = .001), 0.25 (95% CI, 0.13-0.50; P =
   .001), and 0.40 (95% CI, 0.25-0.65; P =.001), respectively. The 3-year
   overall survival rates in patients with CRA-LLM receiving MDT
   intervention and not receiving MDT intervention were 48.75% and 24.21%,
   respectively. Conclusion: MDT intervention is associated with improved
   survival for patients with CRA-LLM.
ZR 0
ZB 6
TC 20
Z8 4
ZA 0
ZS 0
Z9 23
DA 2018-10-15
UT WOS:000445929700020
PM 30323980
ER

PT C
AU Gagan, N.
   Sanand, Sasidharan
GP IEEE
TI ENHANCING ONCOLOGY CARE WITH FEDERATED LEARNING AND FOUNDATION MODELS
SO 2024 ITU KALEIDOSCOPE: INNOVATION AND DIGITAL TRANSFORMATION FOR A
   SUSTAINABLE WORLD, ITU K 2024
BP 151
EP 157
DT Proceedings Paper
PD 2024
PY 2024
AB Millions of people worldwide are battling cancer, and personalised care
   plans are essential for effective diagnosis, treatment, and monitoring
   of this disease. Recently, Large Language Models (LLMs) have proven
   valuable in cancer treatment, for instance, extracting key information
   from Electronic Medical Records (EMRs). This study presents a
   transformer encoder based LLM, that is domain adapted for Oncology, and
   outperforms generic models in recognising critical oncology related
   elements from clinical text. We observe that the development of such
   domain specific LLMs demands a huge amount of data and computational
   resources, which is a deterrent to the sustainability development goal
   of equitable health. To address this problem, we propose a federated
   learning approach for model development that will eliminate data sharing
   and centralised computational resource costs. Our evaluations show that
   the federated approach outperforms the generic base model, highlighting
   the advantages of collaborative learning in capturing domain specific
   knowledge and enhancing performance in oncology related NLP tasks. Our
   work is in line with the United Nations Sustainable Development Goals
   (SDGs) which are aimed at promoting equitable health and narrowing down
   the differences in access to advanced cancer treatment.
CT 15th ITU Kaleidoscope Conference : Innovation and Digital Transformation
   for a Sustainable World
CY OCT 21-23, 2024
CL New Delhi, INDIA
SP Istanbul Teknik Universitesi
TC 0
ZB 0
Z8 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2025-04-02
UT WOS:001426781800022
ER

PT J
AU Sun, Di
   Hadjiiski, Lubomir
   Gormley, John
   Chan, Heang-Ping
   Caoili, Elaine
   Cohan, Richard
   Alva, Ajjai
   Bruno, Grace
   Mihalcea, Rada
   Zhou, Chuan
   Gulani, Vikas
TI Outcome Prediction Using Multi-Modal Information: Integrating Large
   Language Model-Extracted Clinical Information and Image Analysis
SO CANCERS
VL 16
IS 13
AR 2402
DI 10.3390/cancers16132402
DT Article
PD JUL 2024
PY 2024
AB Simple Summary: Predicting the survival of bladder cancer patients
   following cystectomy can offer valuable information for treatment
   planning, decision-making, patient counseling, and resource allocation.
   Our aim was to develop large language model (LLM)-aided multi-modal
   predictive models, based on clinical information and CT images. These
   models achieved performances comparable to those of multi-modal
   predictive models that rely on manually extracted clinical information.
   This study demonstrates the potential of employing LLMs to process
   medical data, and of integrating LLM-processed data into modeling for
   prognosis.
   Survival prediction post-cystectomy is essential for the follow-up care
   of bladder cancer patients. This study aimed to evaluate artificial
   intelligence (AI)-large language models (LLMs) for extracting clinical
   information and improving image analysis, with an initial application
   involving predicting five-year survival rates of patients after radical
   cystectomy for bladder cancer. Data were retrospectively collected from
   medical records and CT urograms (CTUs) of bladder cancer patients
   between 2001 and 2020. Of 781 patients, 163 underwent chemotherapy, had
   pre- and post-chemotherapy CTUs, underwent radical cystectomy, and had
   an available post-surgery five-year survival follow-up. Five AI-LLMs
   (Dolly-v2, Vicuna-13b, Llama-2.0-13b, GPT-3.5, and GPT-4.0) were used to
   extract clinical descriptors from each patient's medical records. As a
   reference standard, clinical descriptors were also extracted manually.
   Radiomics and deep learning descriptors were extracted from CTU images.
   The developed multi-modal predictive model, CRD, was based on the
   clinical (C), radiomics (R), and deep learning (D) descriptors. The LLM
   retrieval accuracy was assessed. The performances of the survival
   predictive models were evaluated using AUC and Kaplan-Meier analysis.
   For the 163 patients (mean age 64 +/- 9 years; M:F 131:32), the LLMs
   achieved extraction accuracies of 74%similar to 87% (Dolly), 76%similar
   to 83% (Vicuna), 82%similar to 93% (Llama), 85%similar to 91% (GPT-3.5),
   and 94%similar to 97% (GPT-4.0). For a test dataset of 64 patients, the
   CRD model achieved AUCs of 0.89 +/- 0.04 (manually extracted
   information), 0.87 +/- 0.05 (Dolly), 0.83 +/- 0.06 similar to 0.84 +/-
   0.05 (Vicuna), 0.81 +/- 0.06 similar to 0.86 +/- 0.05 (Llama), 0.85 +/-
   0.05 similar to 0.88 +/- 0.05 (GPT-3.5), and 0.87 +/- 0.05 similar to
   0.88 +/- 0.05 (GPT-4.0). This study demonstrates the use of LLM
   model-extracted clinical information, in conjunction with imaging
   analysis, to improve the prediction of clinical outcomes, with bladder
   cancer as an initial example.
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
TC 4
Z9 4
DA 2024-07-24
UT WOS:001270395100001
PM 39001463
ER

PT J
AU Tripathi, Aaksh
   Waqas, Asim
   Venkatesan, Kavya
   Ullah, Ehsan
   Khan, Asma
   Khalil, Farah
   Chen, Wei-Shen
   Ozturk, Zarifa Gahramanli
   Saeed-Vafa, Daryoush
   Bui, Marilyn M
   Schabath, Matthew B
   Rasool, Ghulam
TI Employing Consensus-Based Reasoning with Locally Deployed LLMs for
   Enabling Structured Data Extraction from Surgical Pathology Reports.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2025.04.22.25326217
DT Journal Article; Preprint
PD 2025 Apr 29
PY 2025
AB Surgical pathology reports contain essential diagnostic information, in
   free-text form, required for cancer staging, treatment planning, and
   cancer registry documentation. However, their unstructured nature and
   variability across tumor types and institutions pose challenges for
   automated data extraction. We present a consensus-driven,
   reasoning-based framework that uses multiple locally deployed large
   language models (LLMs) to extract six key diagnostic variables: site,
   laterality, histology, stage, grade, and behavior. Each LLM produces
   structured outputs with accompanying justifications, which are evaluated
   for accuracy and coherence by a separate reasoning model. Final
   consensus values are determined through aggregation, and expert
   validation is conducted by board-certified or equivalent pathologists.
   The framework was applied to over 4,000 pathology reports from The
   Cancer Genome Atlas (TCGA) and Moffitt Cancer Center. Expert review
   confirmed high agreement in the TCGA dataset for behavior (100.0%),
   histology (98.5%), site (95.2%), and grade (95.6%), with lower
   performance for stage (87.6%) and laterality (84.8%). In the pathology
   reports from Moffitt (brain, breast, and lung), accuracy remained high
   across variables, with histology (95.6%), behavior (98.3%), and stage
   (92.4%), achieving strong agreement. However, certain challenges
   emerged, such as inconsistent mention of sentinel lymph node details or
   anatomical ambiguity in biopsy site interpretations. Statistical
   analyses revealed significant main effects of model type, variable, and
   organ system, as well as model * variable * organ interactions,
   emphasizing the role of clinical context in model performance. These
   results highlight the importance of stratified, multi-organ evaluation
   frameworks in LLM benchmarking for clinical applications. Textual
   justifications enhanced interpretability and enabled human reviewers to
   audit model outputs. Overall, this consensus-based approach demonstrates
   that locally deployed LLMs can provide a transparent, accurate, and
   auditable solution for integrating AI-driven data extraction into
   real-world pathology workflows, including cancer registry abstraction
   and synoptic reporting.
ZA 0
ZB 0
ZS 0
TC 0
Z8 0
ZR 0
Z9 0
DA 2025-05-12
UT MEDLINE:40343037
PM 40343037
ER

PT J
AU Oh, Yujin
   Park, Sangjoon
   Byun, Hwa Kyung
   Cho, Yeona
   Lee, Ik Jae
   Kim, Jin Sung
   Ye, Jong Chul
TI LLM-driven multimodal target volume contouring in radiation oncology
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 9186
DI 10.1038/s41467-024-53387-y
DT Article
PD OCT 24 2024
PY 2024
AB Target volume contouring for radiation therapy is considered
   significantly more challenging than the normal organ segmentation tasks
   as it necessitates the utilization of both image and text-based clinical
   information. Inspired by the recent advancement of large language models
   (LLMs) that can facilitate the integration of the textural information
   and images, here we present an LLM-driven multimodal artificial
   intelligence (AI), namely LLMSeg, that utilizes the clinical information
   and is applicable to the challenging task of 3-dimensional context-aware
   target volume delineation for radiation oncology. We validate our
   proposed LLMSeg within the context of breast cancer radiotherapy using
   external validation and data-insufficient environments, which attributes
   highly conducive to real-world applications. We demonstrate that the
   proposed multimodal LLMSeg exhibits markedly improved performance
   compared to conventional unimodal AI models, particularly exhibiting
   robust generalization performance and data-efficiency.
   The integration of multimodal knowledge would be essential for radiation
   oncologist to determine the therapeutic treatment. Here, inspired by the
   large language models facilitating the integration of textural
   information and images, this group reports a 3D multimodal clinical
   target volume delineation model combining image and text-based clinical
   information for decision-making in radiation oncology.
TC 9
ZS 0
Z8 2
ZB 3
ZR 0
ZA 0
Z9 10
DA 2024-11-07
UT WOS:001342098500028
PM 39448587
ER

PT J
AU Chen, Ziyi
   Zhang, Mengyuan
   Ahmed, Mustafa Mohammed
   Guo, Yi
   George, Thomas J
   Bian, Jiang
   Wu, Yonghui
TI Narrative Feature or Structured Feature? A Study of Large Language
   Models to Identify Cancer Patients at Risk of Heart Failure.
SO AMIA ... Annual Symposium proceedings. AMIA Symposium
VL 2024
BP 242
EP 251
DT Journal Article
PD 2024
PY 2024
AB Cancer treatments are known to introduce cardiotoxicity, negatively
   impacting outcomes and survivorship. Identifying cancer patients at risk
   of heart failure (HF) is critical to improving cancer treatment outcomes
   and safety. This study examined machine learning (ML) models to identify
   cancer patients at risk of HF using electronic health records (EHRs),
   including traditional ML, Time-Aware long short-term memory (T-LSTM),
   and large language models (LLMs) using novel narrative features derived
   from the structured medical codes. We identified a cancer cohort of
   12,806 patients from the University of Florida Health, diagnosed with
   lung, breast, and colorectal cancers, among which 1,602 individuals
   developed HF after cancer. The LLM, GatorTron-3.9B, achieved the best F1
   scores, outperforming the traditional support vector machines by 39%,
   the T-LSTM deep learning model by 7%, and a widely used transformer
   model, BERT, by 5.6%. The analysis shows that the proposed narrative
   features remarkably increased feature density and improved performance.
ZS 0
ZB 0
ZR 0
ZA 0
Z8 0
TC 0
Z9 0
DA 2025-05-28
UT MEDLINE:40417538
PM 40417538
ER

PT J
AU Hou, Yihao
   Bert, Christoph
   Gomaa, Ahmed
   Lahmer, Godehard
   Hoefler, Daniel
   Weissmann, Thomas
   Voigt, Raphaela
   Schubert, Philipp
   Schmitter, Charlotte
   Depardon, Alina
   Semrau, Sabine
   Maier, Andreas
   Fietkau, Rainer
   Huang, Yixing
   Putz, Florian
TI Fine-tuning a local LLaMA-3 large language model for automated
   privacy-preserving physician letter generation in radiation oncology
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
VL 7
AR 1493716
DI 10.3389/frai.2024.1493716
DT Article
PD JAN 14 2025
PY 2025
AB Introduction Generating physician letters is a time-consuming task in
   daily clinical practice.Methods This study investigates local
   fine-tuning of large language models (LLMs), specifically LLaMA models,
   for physician letter generation in a privacy-preserving manner within
   the field of radiation oncology.Results Our findings demonstrate that
   base LLaMA models, without fine-tuning, are inadequate for effectively
   generating physician letters. The QLoRA algorithm provides an efficient
   method for local intra-institutional fine-tuning of LLMs with limited
   computational resources (i.e., a single 48 GB GPU workstation within the
   hospital). The fine-tuned LLM successfully learns radiation
   oncology-specific information and generates physician letters in an
   institution-specific style. ROUGE scores of the generated summary
   reports highlight the superiority of the 8B LLaMA-3 model over the 13B
   LLaMA-2 model. Further multidimensional physician evaluations of 10
   cases reveal that, although the fine-tuned LLaMA-3 model has limited
   capacity to generate content beyond the provided input data, it
   successfully generates salutations, diagnoses and treatment histories,
   recommendations for further treatment, and planned schedules. Overall,
   clinical benefit was rated highly by the clinical experts (average score
   of 3.4 on a 4-point scale).Discussion With careful physician review and
   correction, automated LLM-based physician letter generation has
   significant practical value.
Z8 0
ZR 0
TC 0
ZB 0
ZA 0
ZS 0
Z9 0
DA 2025-02-01
UT WOS:001406781800001
PM 39877751
ER

PT J
AU Fushimi, Atsushi
   Terada, Mitsuo
   Tahara, Rie
   Nakazawa, Yuko
   Iwase, Madoka
   Shibayama, Tomoko
   Kotti, Samy
   Yamashita, Nami
   Iesato, Asumi
TI Assessing the quality of Japanese online breast cancer treatment
   information using large language models: a comparison of ChatGPT,
   Claude, and expert evaluations
SO BREAST CANCER
DI 10.1007/s12282-025-01719-1
EA MAY 2025
DT Article; Early Access
PY 2025
AB BackgroundThe internet is a primary source of health information for
   breast cancer patients, but online content quality varies widely. This
   study aimed to evaluate the capability of large language models (LLMs),
   including ChatGPT and Claude, to assess the quality of online Japanese
   breast cancer treatment information by calculating and comparing their
   DISCERN scores with those of expert raters.MethodsWe analyzed 60
   Japanese web pages on breast cancer treatments (surgery, chemotherapy,
   immunotherapy) using the DISCERN instrument. Each page was evaluated by
   the LLMs ChatGPT and Claude, along with two expert raters. We assessed
   LLMs evaluation consistency, correlations between LLMs and expert
   assessments, and relationships between DISCERN scores, Google search
   rankings, and content length.ResultsEvaluations by LLMs showed high
   consistency and moderate to strong correlations with expert assessments
   (ChatGPT vs Expert: r = 0.65; Claude vs Expert: r = 0.68). LLMs assigned
   slightly higher scores than expert raters. Chemotherapy pages received
   the highest quality scores, followed by surgery and immunotherapy. We
   found a weak negative correlation between Google search ranking and
   DISCERN scores, and a moderate positive correlation (r = 0.45) between
   content length and quality ratings.ConclusionsThis study demonstrates
   the potential of LLM-assisted evaluation in assessing online health
   information quality, while highlighting the importance of human
   expertise. LLMs could efficiently process large volumes of health
   information but should complement human insight for comprehensive
   assessments. These findings have implications for improving the
   accessibility and reliability of breast cancer treatment information.
Z8 0
ZA 0
ZB 0
TC 0
ZS 0
ZR 0
Z9 0
DA 2025-05-29
UT WOS:001492115500001
PM 40399592
ER

PT J
AU Benson, Ryzen
   Elia, Marianna
   Hyams, Benjamin
   Chang, Ji Hyun
   Hong, Julian C
TI A Narrative Review on the Application of Large Language Models to
   Support Cancer Care and Research.
SO Yearbook of medical informatics
VL 33
IS 1
BP 90
EP 98
DI 10.1055/s-0044-1800726
DT Journal Article; Review
PD 2024-Aug
PY 2024
AB OBJECTIVES: The emergence of large language models has resulted in a
   significant shift in informatics research and carries promise in
   clinical cancer care. Here we provide a narrative review of the recent
   use of large language models (LLMs) to support cancer care, prevention,
   and research.
   METHODS: We performed a search of the Scopus database for studies on the
   application of bidirectional encoder representations from transformers
   (BERT) and generative-pretrained transformer (GPT) LLMs in cancer care
   published between the start of 2021 and the end of 2023. We present
   salient and impactful papers related to each of these themes.
   RESULTS: Studies identified focused on aspects of clinical decision
   support (CDS), cancer education, and support for research activities.
   The use of LLMs for CDS primarily focused on aspects of treatment and
   screening planning, treatment response, and the management of adverse
   events. Studies using LLMs for cancer education typically focused on
   question-answering, assessing cancer myths and misconceptions, and text
   summarization and simplification. Finally, studies using LLMs to support
   research activities focused on scientific writing and idea generation,
   cohort identification and extraction, clinical data processing, and
   NLP-centric tasks.
   CONCLUSIONS: The application of LLMs in cancer care has shown promise
   across a variety of diverse use cases. Future research should utilize
   quantitative metrics, qualitative insights, and user insights in the
   development and evaluation of LLM-based cancer care tools. The
   development of open-source LLMs for use in cancer care research and
   activities should also be a priority.
ZS 0
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
Z9 0
DA 2025-04-11
UT MEDLINE:40199294
PM 40199294
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT B
AU Parent, Nicolas
Z2  
TI Mécanismes d'activation de la voie lysosomale durant l'apoptose
   chimio-induite
DT Dissertation/Thesis
PD Jan 01 2009
PY 2009
Z8 0
ZS 0
TC 0
ZR 0
ZA 0
ZB 0
Z9 0
UT PQDT:55744756
ER

PT J
AU Haider, Syed Ali
   Pressman, Sophia M.
   Borna, Sahar
   Gomez-Cabello, Cesar A.
   Sehgal, Ajai
   Leibovich, Bradley C.
   Forte, Antonio Jorge
TI Evaluating Large Language Model (LLM) Performance on Established Breast
   Classification Systems
SO DIAGNOSTICS
VL 14
IS 14
AR 1491
DI 10.3390/diagnostics14141491
DT Article
PD JUL 2024
PY 2024
AB Medical researchers are increasingly utilizing advanced LLMs like
   ChatGPT-4 and Gemini to enhance diagnostic processes in the medical
   field. This research focuses on their ability to comprehend and apply
   complex medical classification systems for breast conditions, which can
   significantly aid plastic surgeons in making informed decisions for
   diagnosis and treatment, ultimately leading to improved patient
   outcomes. Fifty clinical scenarios were created to evaluate the
   classification accuracy of each LLM across five established
   breast-related classification systems. Scores from 0 to 2 were assigned
   to LLM responses to denote incorrect, partially correct, or completely
   correct classifications. Descriptive statistics were employed to compare
   the performances of ChatGPT-4 and Gemini. Gemini exhibited superior
   overall performance, achieving 98% accuracy compared to ChatGPT-4's 71%.
   While both models performed well in the Baker classification for
   capsular contracture and UTSW classification for gynecomastia, Gemini
   consistently outperformed ChatGPT-4 in other systems, such as the
   Fischer Grade Classification for gender-affirming mastectomy, Kajava
   Classification for ectopic breast tissue, and Regnault Classification
   for breast ptosis. With further development, integrating LLMs into
   plastic surgery practice will likely enhance diagnostic support and
   decision making.
ZA 0
TC 11
ZS 0
Z8 0
ZB 2
ZR 0
Z9 11
DA 2024-08-02
UT WOS:001276540600001
PM 39061628
ER

PT J
AU Desolneux, Gregoire
   Maziere, Camille
   Vara, Jeremy
   Brouste, Veronique
   Fonck, Marianne
   Bechade, Dominique
   Becouarn, Yves
   Evrard, Serge
TI Cytoreductive Surgery of Colorectal Peritoneal Metastases: Outcomes
   after Complete Cytoreductive Surgery and Systemic Chemotherapy Only
SO PLOS ONE
VL 10
IS 3
AR e0122816
DI 10.1371/journal.pone.0122816
DT Article
PD MAR 31 2015
PY 2015
AB Background
   Cytoreductive peritoneal surgery (CRS) associated with hyperthermic
   peritoneal chemotherapy (HIPEC) has long been considered the standard
   treatment for colorectal peritoneal metastases (CPM). However, although
   efficacy of surgery has been demonstrated, evidence supporting HIPEC's
   role is less certain.
   Method
   Overall survival (OS), progression-free survival (PFS) and morbidity
   were analysed retrospectively for fifty consecutively included patients
   treated for colorectal CPM with complete CRS and systemic chemotherapy
   only.
   Results
   Median peritoneal cancer index (PCI) was 8 (range 1-24). 23 patients had
   liver or lung metastases (LLM). 22 patients had synchronous CPM. 27
   complications occurred (12 Grade 1/2, 14 Grade 3, 1 Grade 4a, 0 Grade
   5). Median follow-up was 62.5 months (95 % CI 45.481.3), median survival
   32.4 months (21.5-41.7). Three-and 5-year OS were 45.5% (0.31-0.59) and
   29.64% (0.17-0.44) respectively. Presence of LLMs associated with
   peritoneal carcinomatosis was significantly associated with poorer
   prognosis, with survival at 5 years of 13.95% (95 % CI 2.9-33.6) vs.
   43.87% (22.2-63.7) when no metastases were present (P=0.018). Median PFS
   was 9.5 months (95 % CI 6.2-11.1).
   Conclusion
   With an equivalent PCI range and despite one of the highest rates of LLM
   in the literature, our survival data of CRS + systemic chemotherapy only
   compare well with results reported after additional HIPEC. Tolerance was
   better with acceptable morbidity without any mortality. Extra-hepatic
   metastasis (LLM) is a strong factor of poor prognosis. Awaiting the
   results of the randomized PRODIGE trial, these results indicate that CRS
   + systemic chemotherapy only is a robust hypothesis to treat colorectal
   CPM.
ZR 0
ZA 0
ZB 5
Z8 1
ZS 0
TC 42
Z9 43
DA 2015-03-31
UT WOS:000352084800094
PM 25825874
ER

PT J
AU Zhu, L.
   Anand, A.
   Gevorkyan, G.
   Mcgee, L. A.
   Rwigema, J. C.
   Rong, Y.
   Patel, S. H.
TI Testing and Validation of a Custom Trained Large Language Model for HN
   Patients with Guardrails
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 118
IS 5
MA 182
BP E52
EP E53
DT Meeting Abstract
PD APR 1 2024
PY 2024
CT Multidisciplinary Head and Neck Cancers Symposium
CY FEB 29-MAR 02, 2024
CL Phoenix, AZ
TC 1
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
Z9 1
DA 2024-10-18
UT WOS:001300212900102
ER

PT J
AU Abdel-Rehim, Abbi
   Zenil, Hector
   Orhobor, Oghenejokpeme
   Fisher, Marie
   Collins, Ross J.
   Bourne, Elizabeth
   Fearnley, Gareth W.
   Tate, Emma
   Smith, Holly X.
   Soldatova, Larisa N.
   King, Ross
TI Scientific hypothesis generation by large language models: laboratory
   validation in breast cancer treatment
SO JOURNAL OF THE ROYAL SOCIETY INTERFACE
VL 22
IS 227
AR 20240674
DI 10.1098/rsif.2024.0674
DT Article
PD JUN 4 2025
PY 2025
AB Large language models (LLMs) have transformed artificial intelligence
   (AI) and achieved breakthrough performance on a wide range of tasks. In
   science, the most interesting application of LLMs is for hypothesis
   formation. A feature of LLMs, which results from their probabilistic
   structure, is that the output text is not necessarily a valid inference
   from the training text. These are termed 'hallucinations', and are
   harmful in many applications. In science, some hallucinations may be
   useful: novel hypotheses whose validity may be tested by laboratory
   experiments. Here, we experimentally test the application of LLMs as a
   source of scientific hypotheses using the domain of breast cancer
   treatment. We applied the LLM GPT4 to hypothesize novel synergistic
   pairs of US Food and Drug Administration (FDA)-approved non-cancer drugs
   that target the MCF7 breast cancer cell line relative to the
   non-tumorigenic breast cell line MCF10A. In the first round of
   laboratory experiments, GPT4 succeeded in discovering three drug
   combinations (out of 12 tested) with synergy scores above the positive
   controls. GPT4 then generated new combinations based on its initial
   results, this generated three more combinations with positive synergy
   scores (out of four tested). We conclude that LLMs are a valuable source
   of scientific hypotheses.
ZA 0
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
Z9 0
DA 2025-06-08
UT WOS:001501540900001
PM 40462712
ER

PT J
AU Ra, Sinyoung
   Kim, Jonghun
   Na, Inye
   Ko, Eun Sook
   Park, Hyunjin
TI Enhancing radiomics features via a large language model for classifying
   benign and malignant breast tumors in mammography
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 265
AR 108765
DI 10.1016/j.cmpb.2025.108765
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Background and Objectives: Radiomics is widely used to assist in
   clinical decision-making, disease diagnosis, and treatment planning for
   various target organs, including the breast. Recent advances in large
   language models (LLMs) have helped enhance radiomics analysis. Materials
   and Methods: Herein, we sought to improve radiomics analysis by
   incorporating LLM-learned clinical knowledge, to classify benign and
   malignant tumors in breast mammography. We extracted radiomics features
   from the mammograms based on the region of interest and retained the
   features related to the target task. Using prompt engineering, we
   devised an input sequence that reflected the selected features and the
   target task. The input sequence was fed to the chosen LLM (LLaMA
   variant), which was fine-tuned using low-rank adaptation to enhance
   radiomics features. This was then evaluated on two mammogram datasets
   (VinDr-Mammo and INbreast) against conventional baselines. Results: The
   enhanced radiomics-based method performed better than baselines using
   conventional radiomics features tested on two mammogram datasets,
   achieving accuracies of 0.671 for the VinDr-Mammo dataset and 0.839 for
   the INbreast dataset. Conventional radiomics models require retraining
   from scratch for an unseen dataset using a new set of features. In
   contrast, the model developed in this study effectively reused the
   common features between the training and unseen datasets by explicitly
   linking feature names with feature values, leading to extensible
   learning across datasets. Our method performed better than the baseline
   method in this retraining setting using an unseen dataset. Conclusions:
   Our method, one of the first to incorporate LLM into radiomics, has the
   potential to improve radiomics analysis.
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
ZB 0
Z9 0
DA 2025-04-21
UT WOS:001466026900001
PM 40203779
ER

PT J
AU Omar, Mahmud
   Soffer, Shelly
   Agbareia, Reem
   Bragazzi, Nicola Luigi
   Glicksberg, Benjamin S
   Hurd, Yasmin L
   Apakama, Donald U
   Charney, Alexander W
   Reich, David L
   Nadkarni, Girish N
   Klang, Eyal
TI LLM-Guided Pain Management: Examining Socio-Demographic Gaps in Cancer
   vs non-Cancer cases.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2025.03.04.25323396
DT Journal Article; Preprint
PD 2025 Mar 05
PY 2025
AB Large language models (LLMs) offer potential benefits in clinical care.
   However, concerns remain regarding socio-demographic biases embedded in
   their outputs. Opioid prescribing is one domain in which these biases
   can have serious implications, especially given the ongoing opioid
   epidemic and the need to balance effective pain management with
   addiction risk. We tested ten LLMs-both open-access and closed-source-on
   1,000 acute-pain vignettes. Half of the vignettes were labeled as
   non-cancer and half as cancer. Each vignette was presented in 34
   socio-demographic variations, including a control group without
   demographic identifiers. We analyzed the models' recommendations on
   opioids, anxiety treatment, perceived psychological stress, risk scores,
   and monitoring recommendations. Overall, yielding 3.4 million
   model-generated responses. Using logistic and linear mixed-effects
   models, we measured how these outputs varied by demographic group and
   whether a cancer diagnosis intensified or reduced observed disparities.
   Across both cancer and non-cancer cases, historically marginalized
   groups-especially cases labeled as individuals who are unhoused, Black,
   or identify as LGBTQIA+-often received more or stronger opioid
   recommendations, sometimes exceeding 90% in cancer settings, despite
   being labeled as high risk by the same models. Meanwhile, low-income or
   unemployed groups were assigned elevated risk scores yet fewer opioid
   recommendations, hinting at inconsistent rationales. Disparities in
   anxiety treatment and perceived psychological stress similarly clustered
   within marginalized populations, even when clinical details were
   identical. These patterns diverged from standard guidelines and point to
   model-driven bias rather than acceptable clinical variation. Our
   findings underscore the need for rigorous bias evaluation and the
   integration of guideline-based checks in LLMs to ensure equitable and
   evidence-based pain care.
Z8 0
ZA 0
ZB 0
ZS 0
TC 0
ZR 0
Z9 0
DA 2025-03-21
UT MEDLINE:40093243
PM 40093243
ER

PT J
AU Wei, Shuoyang
   Hu, Ankang
   Liang, Yongguang
   Yang, Jingru
   Yu, Lang
   Li, Wenbo
   Yang, Bo
   Qiu, Jie
TI Feasibility study of automatic radiotherapy treatment planning for
   cervical cancer using a large language model
SO RADIATION ONCOLOGY
VL 20
IS 1
AR 77
DI 10.1186/s13014-025-02660-5
DT Article
PD MAY 15 2025
PY 2025
AB BackgroundRadiotherapy treatment planning traditionally involves complex
   and time-consuming processes, often relying on trial-and-error methods.
   The emergence of artificial intelligence, particularly Large Language
   Models (LLMs), surpassing human capabilities and existing algorithms in
   various domains, presents an opportunity to automate and enhance this
   optimization process.PurposeThis study seeks to evaluate the capacity of
   LLMs to generate radiotherapy treatment plans comparable to those
   crafted by human medical physicists, focusing on target volume
   conformity and organs-at-risk (OARs) dose sparing. The goal is to
   automate the optimization process of radiotherapy treatment plans
   through the utilization of LLMs.MethodsMultiple LLMs were employed to
   adjust optimization parameters for radiotherapy treatment plans, using a
   dataset comprising 35 cervical cancer patients treated with volumetric
   modulated arc therapy (VMAT). Customized prompts were applied to 5
   patients to tailor the LLMs, which were subsequently tested on 30
   patients. Evaluation metrics included target volume conformity, dose
   homogeneity, monitor units (MU) value, and OARs dose sparing, comparing
   plans generated by various LLMs to manual plans.ResultsWith the
   exception of Gemini-1.5-flash, which faced challenges due to
   hallucinations, Qwen-2.5-max and Llama-3.2 produced acceptable VMAT
   plans in 16.3 +/- 5.0 and 9.8 +/- 2.1 min, respectively, outperforming
   an experienced human physicist's time cost of about 20 min. The average
   conformity index (CI) for Qwen-2.5-max plans, Llama-3.2 plans, and
   manual plans on the test set were 0.929 +/- 0.007, 0.928 +/- 0.007, and
   0.926 +/- 0.007, respectively. The average homogeneity index (HI) was
   0.058 +/- 0.006, 0.059 +/- 0.005, and 0.065 +/- 0.006, respectively.
   While there was a significant difference in target volume conformity
   between LLM plans and manual plans, OARs dose sparing showed no
   significant variations. In lateral comparisons among different LLMs, no
   statistically significant differences were observed in the PTV dose,
   OARs dose sparing, and target volume conformity between Qwen-2.5-max and
   Llama-3.2 plans.ConclusionsThrough an assessment of LLM-generated plans
   and clinical plans in terms of target volume conformity and OARs dose
   sparing, this study provides preliminary evidence supporting the
   viability of LLMs for optimizing radiotherapy treatment plans. The
   implementation of LLMs demonstrates the potential for enhancing clinical
   workflows and reducing the workload associated with treatment planning.
ZA 0
ZR 0
ZS 0
ZB 0
Z8 0
TC 0
Z9 0
DA 2025-05-21
UT WOS:001489386700002
PM 40375332
ER

PT J
AU Piras, Antonio
   Morelli, Ilaria
   Colciago, Riccardo Ray
   Boldrini, Luca
   D'Aviero, Andrea
   De Felice, Francesca
   Grassi, Roberta
   Iorio, Giuseppe Carlo
   Longo, Silvia
   Mastroleo, Federico
   Desideri, Isacco
   Salvestrini, Viola
TI The continuous improvement of digital assistance in the radiation
   oncologist's work: from web-based nomograms to the adoption of
   large-language models (LLMs). A systematic review by the young group of
   the Italian association of radiotherapy and clinical oncology (AIRO)
SO RADIOLOGIA MEDICA
VL 129
IS 11
BP 1720
EP 1735
DI 10.1007/s11547-024-01891-y
EA OCT 2024
DT Review
PD NOV 2024
PY 2024
AB PurposeRecently, the availability of online medical resources for
   radiation oncologists and trainees has significantly expanded, alongside
   the development of numerous artificial intelligence (AI)-based tools.
   This review evaluates the impact of web-based clinical decision-making
   tools in the clinical practice of radiation oncology.Material and
   methodsWe searched databases, including PubMed, EMBASE, and Scopus,
   using keywords related to web-based clinical decision-making tools and
   radiation oncology, adhering to PRISMA guidelines.ResultsOut of 2161
   identified manuscripts, 70 were ultimately included in our study. These
   papers all supported the evidence that web-based tools can be
   transversally integrated into multiple radiation oncology fields, with
   online applications available for dose and clinical calculations,
   staging and other multipurpose intents. Specifically, the possible
   benefit of web-based nomograms for educational purposes was investigated
   in 35 of the evaluated manuscripts. As regards to the applications of
   digital and AI-based tools to treatment planning, diagnosis, treatment
   strategy selection and follow-up adoption, a total of 35 articles were
   selected. More specifically, 19 articles investigated the role of these
   tools in heterogeneous cancer types, while nine and seven articles were
   related to breast and head & neck cancers, respectively.ConclusionsOur
   analysis suggests that employing web-based and AI tools offers promising
   potential to enhance the personalization of cancer treatment.
TC 1
ZB 0
ZS 0
ZA 0
ZR 0
Z8 0
Z9 1
DA 2024-10-18
UT WOS:001330390000001
PM 39397129
ER

PT J
AU Schaefer, Moritz
   Reichl, Stephan
   Ter Horst, Rob
   Nicolas, Adele M
   Krausgruber, Thomas
   Piras, Francesco
   Stepper, Peter
   Bock, Christoph
   Samwald, Matthias
TI GPT-4 as a biomedical simulator.
SO Computers in biology and medicine
VL 178
BP 108796
EP 108796
DI 10.1016/j.compbiomed.2024.108796
DT Journal Article
PD 2024-Aug
PY 2024
AB BACKGROUND: Computational simulation of biological processes can be a
   valuable tool for accelerating biomedical research, but usually requires
   extensive domain knowledge and manual adaptation. Large language models
   (LLMs) such as GPT-4 have proven surprisingly successful for a wide
   range of tasks. This study provides proof-of-concept for the use of
   GPT-4 as a versatile simulator of biological systems.
   METHODS: We introduce SimulateGPT, a proof-of-concept for
   knowledge-driven simulation across levels of biological organization
   through structured prompting of GPT-4. We benchmarked our approach
   against direct GPT-4 inference in blinded qualitative evaluations by
   domain experts in four scenarios and in two quantitative scenarios with
   experimental ground truth. The qualitative scenarios included mouse
   experiments with known outcomes and treatment decision support in
   sepsis. The quantitative scenarios included prediction of gene
   essentiality in cancer cells and progression-free survival in cancer
   patients.
   RESULTS: In qualitative experiments, biomedical scientists rated
   SimulateGPT's predictions favorably over direct GPT-4 inference. In
   quantitative experiments, SimulateGPT substantially improved
   classification accuracy for predicting the essentiality of individual
   genes and increased correlation coefficients and precision in the
   regression task of predicting progression-free survival.
   CONCLUSION: This proof-of-concept study suggests that LLMs may enable a
   new class of biomedical simulators. Such text-based simulations appear
   well suited for modeling and understanding complex living systems that
   are difficult to describe with physics-based first-principles
   simulations, but for which extensive knowledge is available as written
   text. Finally, we propose several directions for further development of
   LLM-based biomedical simulators, including augmentation through web
   search retrieval, integrated mathematical modeling, and fine-tuning on
   experimental data.
ZR 0
TC 5
ZS 0
Z8 0
ZB 1
ZA 0
Z9 5
DA 2024-06-25
UT MEDLINE:38909448
PM 38909448
ER

PT J
AU Liu, Hui
   Peng, Jialun
   Li, Lu
   Deng, Ao
   Huang, XiangXin
   Yin, Guobing
   Luo, Haojun
TI Large Language Models as a Consulting Hotline for Patients With Breast
   Cancer and Specialists in China: Cross-Sectional Questionnaire Study
SO JMIR MEDICAL INFORMATICS
VL 13
AR e66429
DI 10.2196/66429
DT Article
PD 2025
PY 2025
AB Background: The disease burden of breast cancer is increasing in China.
   Guiding people to obtain accurate information on breast cancer and
   improving the public's health literacy are crucial for the early
   detection and timely treatment of breast cancer. Large language model
   (LLM) is a currently popular source of health information. However, the
   accuracy and practicality of the breast cancer-related information
   provided by LLMs have not yet been evaluated. Objective: This study aims
   to evaluate and compare the accuracy, practicality, and
   generalization-specificity of responses to breast cancer-related
   questions from two LLMs, ChatGPT and ERNIE Bot (EB). Methods: The
   questions asked to the LLMs consisted of a patient questionnaire and an
   expert questionnaire, each containing 15 questions. ChatGPT was queried
   in both Chinese and English, recorded as ChatGPT-Chinese (ChatGPT-C) and
   ChatGPT-English (ChatGPT-E) respectively, while EB was queried in
   Chinese. The accuracy, practicality, and generalization-specificity of
   each inquiry's responses were rated by a breast cancer multidisciplinary
   treatment team using Likert scales. Results: Overall, for both the
   patient and expert questionnaire, the accuracy and practicality of
   responses from ChatGPT-E were significantly higher than those from
   ChatGPT-C and EB (all Ps<.001). However, the responses from all LLMs are
   relatively generalized, leading to lower accuracy and practicality for
   the expert questionnaire compared to the patient questionnaire.
   Additionally, there were issues such as the lack of supporting evidence
   and potential ethical risks in the responses of LLMs. Conclusions:
   Currently, compared to other LLMs, ChatGPT-E has demonstrated greater
   potential for application in educating Chinese patients with breast
   cancer, and may serve as an effective tool for them to obtain health
   information. However, for breast cancer specialists, these LLMs are not
   yet suitable for assisting in clinical diagnosis or treatment
   activities. Additionally, data security, ethical, and legal risks
   associated with using LLMs in clinical practice cannot be ignored. In
   the future, further research is needed to determine the true efficacy of
   LLMs in clinical scenarios related to breast cancer in China.
TC 0
Z8 0
ZB 0
ZA 0
ZR 0
ZS 0
Z9 0
DA 2025-06-14
UT WOS:001506204800004
PM 40424585
ER

PT J
AU Delourme, Solene
   Redjdal, Akram
   Bouaud, Jacques
   Seroussi, Brigitte
TI Leveraging Guideline-Based Clinical Decision Support Systems with Large
   Language Models: A Case Study with Breast Cancer
SO METHODS OF INFORMATION IN MEDICINE
VL 63
IS 03/04
BP 85
EP 96
DI 10.1055/a-2528-4299
EA APR 2025
DT Article
PD SEP 2024
PY 2024
AB Background Multidisciplinary tumor boards (MTBs) have been established
   in most countries to allow experts collaboratively determine the best
   treatment decisions for cancer patients. However, MTBs often face
   challenges such as case overload, which can compromise MTB decision
   quality. Clinical decision support systems (CDSSs) have been introduced
   to assist clinicians in this process. Despite their potential, CDSSs are
   still underutilized in routine practice. The emergence of large language
   models (LLMs), such as ChatGPT, offers new opportunities to improve the
   efficiency and usability of traditional CDSSs. Objectives OncoDoc2 is a
   guideline-based CDSS developed using a documentary approach and applied
   to breast cancer management. This study aims to evaluate the potential
   of LLMs, used as question-answering (QA) systems, to improve the
   usability of OncoDoc2 across different prompt engineering techniques
   (PETs). Methods Data extracted from breast cancer patient summaries
   (BCPSs), together with questions formulated by OncoDoc2, were used to
   create prompts for various LLMs, and several PETs were designed and
   tested. Using a sample of 200 randomized BCPSs, LLMs and PETs were
   initially compared with regard to their responses to OncoDoc2 questions
   using classic metrics (accuracy, precision, recall, and F1 score). Best
   performing LLMs and PETs were further assessed by comparing the
   therapeutic recommendations generated by OncoDoc2, based on LLM inputs,
   to those provided by MTB clinicians using OncoDoc2. Finally, the best
   performing method was validated using a new sample of 30 randomized
   BCPSs. Results The combination of Mistral and OpenChat models under the
   enhanced Zero-Shot PET showed the best performance as a
   question-answering system. This approach gets a precision of 60.16%, a
   recall of 54.18%, an F1 score of 56.59%, and an accuracy of 75.57% on
   the validation set of 30 BCPSs. However, this approach yielded poor
   results as a CDSS, with only 16.67% of the recommendations generated by
   OncoDoc2 based on LLM inputs matching the gold standard. Conclusion All
   the criteria in the OncoDoc2 decision tree are crucial for capturing the
   uniqueness of each patient. Any deviation from a criterion alters the
   recommendations generated. Despite achieving a good accuracy rate of
   75.57%, LLMs still face challenges in reliably understanding complex
   medical contexts and be effective as CDSSs.
ZS 0
ZR 0
ZB 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2025-04-26
UT WOS:001468790500001
PM 39880005
ER

PT J
AU Buhr, Christoph Raphael
   Ernst, Benjamin Philipp
   Blaikie, Andrew
   Smith, Harry
   Kelsey, Tom
   Matthias, Christoph
   Fleischmann, Maximilian
   Jungmann, Florian
   Alt, Juergen
   Brandts, Christian
   Kaemmerer, Peer W.
   Foersch, Sebastian
   Kuhn, Sebastian
   Eckrich, Jonas
TI Assessment of decision-making with locally run and web-based large
   language models versus human board recommendations in
   otorhinolaryngology, head and neck surgery
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1593
EP 1607
DI 10.1007/s00405-024-09153-3
EA JAN 2025
DT Article
PD MAR 2025
PY 2025
AB IntroductionTumor boards are a cornerstone of modern cancer treatment.
   Given their advanced capabilities, the role of Large Language Models
   (LLMs) in generating tumor board decisions for otorhinolaryngology (ORL)
   head and neck surgery is gaining increasing attention. However, concerns
   over data protection and the use of confidential patient information in
   web-based LLMs have restricted their widespread adoption and hindered
   the exploration of their full potential. In this first study of its kind
   we compared standard human multidisciplinary tumor board recommendations
   (MDT) against a web-based LLM (ChatGPT-4o) and a locally run LLM (Llama
   3) addressing data protection concerns.Material and methodsTwenty-five
   simulated tumor board cases were presented to an MDT composed of
   specialists from otorhinolaryngology, craniomaxillofacial surgery,
   medical oncology, radiology, radiation oncology, and pathology. This
   multidisciplinary team provided a comprehensive analysis of the cases.
   The same cases were input into ChatGPT-4o and Llama 3 using structured
   prompts, and the concordance between the LLMs' and MDT's recommendations
   was assessed. Four MDT members evaluated the LLMs' recommendations in
   terms of medical adequacy (using a six-point Likert scale) and whether
   the information provided could have influenced the MDT's original
   recommendations.ResultsChatGPT-4o showed 84% concordance (21 out of 25
   cases) and Llama 3 demonstrated 92% concordance (23 out of 25 cases)
   with the MDT in distinguishing between curative and palliative treatment
   strategies. In 64% of cases (16/25) ChatGPT-4o and in 60% of cases
   (15/25) Llama, identified all first-line therapy options considered by
   the MDT, though with varying priority. ChatGPT-4o presented all the
   MDT's first-line therapies in 52% of cases (13/25), while Llama 3
   offered a homologous treatment strategy in 48% of cases (12/25).
   Additionally, both models proposed at least one of the MDT's first-line
   therapies as their top recommendation in 28% of cases (7/25). The
   ratings for medical adequacy yielded a mean score of 4.7 (IQR: 4-6) for
   ChatGPT-4o and 4.3 (IQR: 3-5) for Llama 3. In 17% of the assessments
   (33/200), MDT members indicated that the LLM recommendations could
   potentially enhance the MDT's decisions.DiscussionThis study
   demonstrates the capability of both LLMs to provide viable therapeutic
   recommendations in ORL head and neck surgery. Llama 3, operating
   locally, bypasses many data protection issues and shows promise as a
   clinical tool to support MDT decisions. However at present, LLMs should
   augment rather than replace human decision-making.
TC 0
ZA 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
DA 2025-01-19
UT WOS:001394124400001
PM 39792200
ER

PT J
AU Omar, Mahmud
   Nassar, Salih
   Sharif, Kassem
   Glicksberg, Benjamin S.
   Nadkarni, Girish N.
   Klang, Eyal
TI Emerging applications of NLP and large language models in
   gastroenterology and hepatology: a systematic review
SO FRONTIERS IN MEDICINE
VL 11
AR 1512824
DI 10.3389/fmed.2024.1512824
DT Article
PD JAN 22 2025
PY 2025
AB Background and aim In the last years, natural language processing (NLP)
   has transformed significantly with the introduction of large language
   models (LLM). This review updates on NLP and LLM applications and
   challenges in gastroenterology and hepatology. Methods Registered with
   PROSPERO (CRD42024542275) and adhering to PRISMA guidelines, we searched
   six databases for relevant studies published from 2003 to 2024,
   ultimately including 57 studies. Results Our review of 57 studies notes
   an increase in relevant publications in 2023-2024 compared to previous
   years, reflecting growing interest in newer models such as GPT-3 and
   GPT-4. The results demonstrate that NLP models have enhanced data
   extraction from electronic health records and other unstructured medical
   data sources. Key findings include high precision in identifying disease
   characteristics from unstructured reports and ongoing improvement in
   clinical decision-making. Risk of bias assessments using ROBINS-I,
   QUADAS-2, and PROBAST tools confirmed the methodological robustness of
   the included studies. Conclusion NLP and LLMs can enhance diagnosis and
   treatment in gastroenterology and hepatology. They enable extraction of
   data from unstructured medical records, such as endoscopy reports and
   patient notes, and for enhancing clinical decision-making. Despite these
   advancements, integrating these tools into routine practice is still
   challenging. Future work should prospectively demonstrate real-world
   value.
Z8 0
ZA 0
ZS 0
ZB 0
TC 1
ZR 0
Z9 1
DA 2025-02-13
UT WOS:001415374900001
PM 39917263
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Assessing the role of advanced artificial intelligence as a tool in
   multidisciplinary tumor board decision-making for recurrent/metastatic
   head and neck cancer cases - the first study on ChatGPT 4o and a
   comparison to ChatGPT 4.0
SO FRONTIERS IN ONCOLOGY
VL 14
AR 1455413
DI 10.3389/fonc.2024.1455413
DT Article
PD SEP 5 2024
PY 2024
AB Background Recurrent and metastatic head and neck squamous cell
   carcinoma (HNSCC) is characterized by a complex therapeutic management
   that needs to be discussed in multidisciplinary tumor boards (MDT).
   While artificial intelligence (AI) improved significantly to assist
   healthcare professionals in making informed treatment decisions for
   primary cases, an application in the even more complex
   recurrent/metastatic setting has not been evaluated yet. This study also
   represents the first evaluation of the recently published LLM ChatGPT
   4o, compared to ChatGPT 4.0 for providing therapy
   recommendations.Methods The therapy recommendations for 100 HNSCC cases
   generated by each LLM, 50 cases of recurrence and 50 cases of distant
   metastasis were evaluated by two independent reviewers. The primary
   outcome measured was the quality of the therapy recommendations measured
   by the following parameters: clinical recommendation, explanation, and
   summarization.Results In this study, ChatGPT 4o and 4.0 provided mostly
   general answers for surgery, palliative care, or systemic therapy.
   ChatGPT 4o proved to be 48.5% faster than ChatGPT 4.0. For clinical
   recommendation, explanation, and summarization both LLMs obtained high
   scores in terms of performance of therapy recommendations, with no
   significant differences between both LLMs, but demonstrated to be mostly
   an assisting tool, requiring validation by an experienced clinician due
   to a lack of transparency and sometimes recommending treatment
   modalities that are not part of the current treatment
   guidelines.Conclusion This research demonstrates that ChatGPT 4o and 4.0
   share a similar performance, while ChatGPT 4o is significantly faster.
   Since the current versions cannot tailor therapy recommendations, and
   sometimes recommend incorrect treatment options and lack information on
   the source material, advanced AI models at the moment can merely assist
   in the MDT setting for recurrent/metastatic HNSCC.
ZS 0
Z8 0
ZB 2
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-09-23
UT WOS:001315310200001
PM 39301542
ER

PT C
AU Marques, Adriell Gomes
   Candido de Figueiredo, Marcus Vinicius
   Da Costa Nascimento, Jose Jerovane
   de Souza, Cidcley Teixeira
   Jaborandy de Mattos Dourado, Carlos Mauricio, Jr.
   de Albuquerque, Victor Hugo C.
   de Freitas Souza, Luis Fabricio
BE Emmendorfer, LR
   Kieling, A
TI New approach Generative AI Melanoma Data Fusion for classification in
   dermoscopic images with Large Language Model
SO 2024 37TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES, SIBGRAPI
   2024
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
BP 157
EP 162
DI 10.1109/SIBGRAPI62404.2024.10716298
DT Proceedings Paper
PD 2024
PY 2024
AB Skin cancer is a disease that causes thousands of deaths each year.
   Early diagnosis and monitoring the progression of the disease are
   crucial factors for the treatment and health indicators of a society.
   This study presents an innovative approach for the detection,
   segmentation, and classification of melanomas in dermoscopic images
   using advanced Computer Vision and Artificial Intelligence (AI) methods.
   Specifically, it applies Large Language Model (LLM) solutions for
   pre-diagnosis results through generative AI. This work explores
   combinations of methods for melanoma detection and segmentation based on
   the YOLO and SAM architectures, achieving 99% accuracy, surpassing
   various studies in the literature. The classification phase is based on
   a pipeline integrating feature extraction and selecting the best
   combination for melanoma region classification, achieving an accuracy of
   86.0%, also outperforming different studies in the literature.
CT 37th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)
CY SEP 30-OCT 03, 2024
CL Manaus, BRAZIL
SP SIBGRAPI; Univ Estado Amazonas, Escola Super Tecnologia; Coordinat
   Improvement Higher Educ Personnel; SiDi Tecnologia lnformacao Servicos
   lnterdependencia; Inst Pesquisas Eldorado; Sidia; Tutiplast Ind &
   Comercio Ltda; LUDUS Lab Tecnologia, lnovavao & Economia Criativa;
   ThinkTED Lab Pesquisa, Desenvolvimento & lnovacao Tecnologias
   Emergentes; Brazilian Comp Soc; IEEE Brazil NE; Governo Estado Amazonas
ZB 0
ZR 0
ZS 0
Z8 0
ZA 0
TC 0
Z9 0
DA 2025-01-25
UT WOS:001345126400027
ER

PT J
AU Fan, K
   Li, GQ
   Yang, SH
   An, X
   Ma, GY
   Roufogalis, BD
   Joshua, DE
   Sze, D
TI Dual roles of T/NK immunomodulatory and anti-tumor properties for
   selected herbal medicines in multiple myeloma therapy.
SO BLOOD
VL 106
IS 11
MA 5097
BP 356B
EP 356B
PN 2
DT Meeting Abstract
PD NOV 16 2005
PY 2005
CT 47th Annual Meeting of the American-Society-of-Hematology
CY DEC 10-13, 2005
CL Atlanta, GA
SP Amer Soc Hematol
ZA 0
ZB 0
Z8 0
ZS 0
TC 0
ZR 0
Z9 0
DA 2005-11-16
UT WOS:000233426102199
ER

PT J
AU Chao, Pei-Ju
   Chang, Chu-Ho
   Wu, Jyun-Jie
   Liu, Yen-Hsien
   Shiau, Junping
   Shih, Hsin-Hung
   Lin, Guang-Zhi
   Lee, Shen-Hao
   Lee, Tsair-Fwu
TI Improving Prediction of Complications Post-Proton Therapy in Lung Cancer
   Using Large Language Models and Meta-Analysis
SO CANCER CONTROL
VL 31
AR 10732748241286749
DI 10.1177/10732748241286749
DT Article
PD SEP 2024
PY 2024
AB Purpose: This study enhances the efficiency of predicting complications
   in lung cancer patients receiving proton therapy by utilizing large
   language models (LLMs) and meta-analytical techniques for literature
   quality assessment. Materials and Methods: We integrated systematic
   reviews with LLM evaluations, sourcing studies from Web of Science,
   PubMed, and Scopus, managed via EndNote X20. Inclusion and exclusion
   criteria ensured literature relevance. Techniques included
   meta-analysis, heterogeneity assessment using Cochran's Q test and I2
   statistics, and subgroup analyses for different complications. Quality
   and bias risk were assessed using the PROBAST tool and further analyzed
   with models such as ChatGPT-4, Llama2-13b, and Llama3-8b. Evaluation
   metrics included AUC, accuracy, precision, recall, F1 score, and time
   efficiency (WPM). Results: The meta-analysis revealed an overall effect
   size of 0.78 for model predictions, with high heterogeneity observed (I2
   = 72.88%, P < 0.001). Subgroup analysis for radiation-induced
   esophagitis and pneumonitis revealed predictive effect sizes of 0.79 and
   0.77, respectively, with a heterogeneity index (I2) of 0%, indicating
   that there were no significant differences among the models in
   predicting these specific complications. A literature assessment using
   LLMs demonstrated that ChatGPT-4 achieved the highest accuracy at 90%,
   significantly outperforming the Llama3 and Llama2 models, which had
   accuracies ranging from 44% to 62%. Additionally, LLM evaluations were
   conducted 3229 times faster than manual assessments were, markedly
   enhancing both efficiency and accuracy. The risk assessment results
   identified nine studies as high risk, three as low risk, and one as
   unknown, confirming the robustness of the ChatGPT-4 across various
   evaluation metrics. Conclusion: This study demonstrated that the
   integration of large language models with meta-analysis techniques can
   significantly increase the efficiency of literature evaluations and
   reduce the time required for assessments, confirming that there are no
   significant differences among models in predicting post proton therapy
   complications in lung cancer patients.
ZB 0
ZA 0
TC 1
ZR 0
ZS 0
Z8 0
Z9 1
DA 2024-09-29
UT WOS:001318729400001
PM 39307562
ER

PT J
AU Bellamkonda, Nikhil
   Farlow, Janice L.
   Haring, Catherine T.
   Sim, Michael W.
   Seim, Nolan B.
   Cannon, Richard B.
   Monroe, Marcus M.
   Agrawal, Amit
   Rocco, James W.
   McCrary, Hilary C.
TI Evaluating the Accuracy of ChatGPT in Common Patient Questions Regarding
   HPV plus Oropharyngeal Carcinoma
SO ANNALS OF OTOLOGY RHINOLOGY AND LARYNGOLOGY
VL 133
IS 9
BP 814
EP 819
DI 10.1177/00034894241259137
EA JUL 2024
DT Article
PD SEP 2024
PY 2024
AB Objectives: Large language model (LLM)-based chatbots such as ChatGPT
   have been publicly available and increasingly utilized by the general
   public since late 2022. This study sought to investigate ChatGPT
   responses to common patient questions regarding Human Papilloma Virus
   (HPV) positive oropharyngeal cancer (OPC). Methods: This was a
   prospective, multi-institutional study, with data collected from high
   volume institutions that perform >50 transoral robotic surgery cases per
   year. The 100 most recent discussion threads including the term "HPV" on
   the American Cancer Society's Cancer Survivors Network's Head and Neck
   Cancer public discussion board were reviewed. The 11 most common
   questions were serially queried to ChatGPT 3.5; answers were recorded. A
   survey was distributed to fellowship trained head and neck oncologic
   surgeons at 3 institutions to evaluate the responses. Results: A total
   of 8 surgeons participated in the study. For questions regarding HPV
   contraction and transmission, ChatGPT answers were scored as clinically
   accurate and aligned with consensus in the head and neck surgical
   oncology community 84.4% and 90.6% of the time, respectively. For
   questions involving treatment of HPV+ OPC, ChatGPT was clinically
   accurate and aligned with consensus 87.5% and 91.7% of the time,
   respectively. For questions regarding the HPV vaccine, ChatGPT was
   clinically accurate and aligned with consensus 62.5% and 75% of the
   time, respectively. When asked about circulating tumor DNA testing, only
   12.5% of surgeons thought responses were accurate or consistent with
   consensus. Conclusion: ChatGPT 3.5 performed poorly with questions
   involving evolving therapies and diagnostics-thus, caution should be
   used when using a platform like ChatGPT 3.5 to assess use of advanced
   technology. Patients should be counseled on the importance of consulting
   their surgeons to receive accurate and up to date recommendations, and
   use LLM's to augment their understanding of these important
   health-related topics.
ZB 0
Z8 0
ZR 0
ZA 0
TC 1
ZS 0
Z9 1
DA 2024-08-06
UT WOS:001280661600001
PM 39075853
ER

PT J
AU Gumilar, Khanisyah Erza
   Indraprasta, Birama R.
   Faridzi, Ach Salman
   Wibowo, Bagus M.
   Herlambang, Aditya
   Rahestyningtyas, Eccita
   Irawan, Budi
   Tambunan, Zulkarnain
   Bustomi, Ahmad Fadhli
   Brahmantara, Bagus Ngurah
   Yu, Zih-Ying
   Hsu, Yu-Cheng
   Pramuditya, Herlangga
   Putra, Very Great E.
   Nugroho, Hari
   Mulawardhana, Pungky
   Tjokroprawiro, Brahmana A.
   Hedianto, Tri
   Ibrahim, Ibrahim H.
   Huang, Jingshan
   Lij, Dongqi
   Lu, Chien-Hsing
   Yang, Jer-Yen
   Liao, Li-Na
   Tan, Ming
TI Assessment of Large Language Models (LLMs) in decision-making support
   for gynecologic oncology
SO COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL
VL 23
BP 4019
EP 4026
DI 10.1016/j.csbj.2024.10.050
EA NOV 2024
DT Article
PD DEC 2024
PY 2024
AB Objective: This study investigated the ability of Large Language Models
   (LLMs) to provide accurate and consistent answers by focusing on their
   performance in complex gynecologic cancer cases. Background: LLMs are
   advancing rapidly and require a thorough evaluation to ensure that they
   can be safely and effectively used in clinical decision-making. Such
   evaluations are essential for confirming LLM reliability and accuracy in
   supporting medical professionals in casework. Study design: We assessed
   three prominent LLMs-ChatGPT-4 (CG-4), Gemini Advanced (GemAdv), and
   Copilot-evaluating their accuracy, consistency, and overall performance.
   Fifteen clinical vignettes of varying difficulty and five open-ended
   questions based on real patient cases were used. The responses were
   coded, randomized, and evaluated blindly by six expert gynecologic
   oncologists using a 5-point Likert scale for relevance, clarity, depth,
   focus, and coherence. Results: GemAdv demonstrated superior accuracy
   (81.87 %) compared to both CG-4 (61.60 %) and Copilot (70.67 %) across
   all difficulty levels. GemAdv consistently provided correct answers more
   frequently (>60 % every day during the testing period). Although CG-4
   showed a slight advantage in adhering to the National Comprehensive
   Cancer Network (NCCN) treatment guidelines, GemAdv excelled in the depth
   and focus of the answers provided, which are crucial aspects of clinical
   decision-making. Conclusion: LLMs, especially GemAdv, show potential in
   supporting clinical practice by providing accurate, consistent, and
   relevant information for gynecologic cancer. However, further refinement
   is needed for more complex scenarios. This study highlights the promise
   of LLMs in gynecologic oncology, emphasizing the need for ongoing
   development and rigorous evaluation to maximize their clinical utility
   and reliability.
ZA 0
ZR 0
ZB 0
TC 4
ZS 0
Z8 0
Z9 4
DA 2024-11-30
UT WOS:001362231200001
PM 39610903
ER

PT J
AU Alkhnbashi, Omer S.
   Mohammad, Rasheed
   Hammoudeh, Mohammad
TI Aspect-Based Sentiment Analysis of Patient Feedback Using Large Language
   Models
SO BIG DATA AND COGNITIVE COMPUTING
VL 8
IS 12
AR 167
DI 10.3390/bdcc8120167
DT Article
PD DEC 2024
PY 2024
AB Online medical forums have emerged as vital platforms for patients to
   share their experiences and seek advice, providing a valuable,
   cost-effective source of feedback for medical service management. This
   feedback not only measures patient satisfaction and improves health
   service quality but also offers crucial insights into the effectiveness
   of medical treatments, pain management strategies, and alternative
   therapies. This study systematically identifies and categorizes key
   aspects of patient experiences, emphasizing both positive and negative
   sentiments expressed in their narratives. We collected a dataset of
   approximately 15,000 entries from various sections of the widely used
   medical forum, patient.info. Our innovative approach integrates content
   analysis with aspect-based sentiment analysis, deep learning techniques,
   and a large language model (LLM) to analyze these data. Our methodology
   is designed to uncover a wide range of aspect types reflected in patient
   feedback. The analysis revealed seven distinct aspect types prevalent in
   the feedback, demonstrating that deep learning models can effectively
   predict these aspect types and their corresponding sentiment values.
   Notably, the LLM with few-shot learning outperformed other models. Our
   findings enhance the understanding of patient experiences in online
   forums and underscore the utility of advanced analytical techniques in
   extracting meaningful insights from unstructured patient feedback,
   offering valuable implications for healthcare providers and medical
   service management.
ZR 0
ZB 0
TC 1
ZA 0
Z8 0
ZS 0
Z9 1
DA 2025-01-09
UT WOS:001389594900001
ER

PT J
AU Wu Daocheng
   Wan Mingxi
TI Preparation of the core-shell structure adriamycin lipiodol
   microemulsions and their synergistic anti-tumor effects with
   diethyldithiocarbamate in vivo
SO BIOMEDICINE & PHARMACOTHERAPY
VL 64
IS 9
BP 615
EP 623
DI 10.1016/j.biopha.2010.03.001
DT Article
PD NOV 2010
PY 2010
AB We prepared the core-shell structure adriamycin lipiodol microemulsions
   (ADM-CSLMs) and evaluated their in vivo antitumor effects in combination
   with Diethyldithiocarbamate (DDC). Two types of ADM-CSLMs, adriamycin
   liposome-lipiodol inicroemulsion(ADM-LLM) and adriamycin microsphere
   lipiodol microemulsion (ADM-MLM), were prepared through the
   emulsification method. The drug loading and encapsulation efficiency of
   ADM-CSLMs were measured by the high-performance liquid chromatograph
   (HPLC). The size and shape of the ADM-CSLMs were determined by an atom
   force microscopy (AFM), a transmission electron microscopy (TEM), and a
   particle size analyzer, respectively. The synergistic effects of DDC and
   ADM-CSLMs for cancer treatment of carcinoma drug-resistance cell was
   evaluated by the MTI' method, the activation of superoxide dismutase
   (SOD) was detected by chemiluminescence, and the ADM accumulation in
   cells was measured by flow cytometry. Walker-256 carcinoma was
   transplanted to the livers of the male SD rats, ADM-CSLMs were
   administrated to the livers of the rats by intervention hepatic artery
   embolization through microsurgery. The tumor growth and animal survival
   were evaluated. The results show that the average diameter of ADM-LLM
   and ADM-MLM were 4.23 +/- 1.2 mu m and 4.67 +/- 1.4 mu m, respectively,
   and their ADM encapsulation efficiency were 83.7% and 87.2% with respect
   to loading efficiency of 82 mu g/ml and 91 mu g/ml. The tumor growth and
   animal survival in two of the ADM-CSLMs combined with DDC groups were
   significantly higher than that of ADM only treatment, ADM liposome
   combined with DDC (P < 0.01), as well as the ADM microsphere combined
   with DDC (P < 0.01). Therefore, ADM-CSLMs are useful carriers for the
   treatment of carcinoma and their antitumor effect can be enhanced by DDC
   in a suitable concentration. (C) 2010 Elsevier Masson SAS. All rights
   reserved.
Z8 0
ZS 0
ZR 0
ZB 1
ZA 0
TC 6
Z9 6
DA 2010-11-01
UT WOS:000284862000007
PM 20888179
ER

PT J
AU Chen, Zikang
   Wang, Qinchuan
   Sun, Yaoqian
   Cai, Hailing
   Lu, Xudong
TI Chat-ePRO: Development and pilot study of an electronic patient-reported
   outcomes system based on ChatGPT
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 154
AR 104651
DI 10.1016/j.jbi.2024.104651
EA MAY 2024
DT Article
PD JUN 2024
PY 2024
AB Objective: Chatbots have the potential to improve user compliance in
   electronic Patient-Reported Outcome (ePRO) system. Compared to
   rule-based chatbots, Large Language Model (LLM) offers advantages such
   as simplifying the development process and increasing conversational
   flexibility. However, there is currently a lack of practical
   applications of LLMs in ePRO systems. Therefore, this study utilized
   ChatGPT to develop the ChatePRO system and designed a pilot study to
   explore the feasibility of building an ePRO system based on LLM.
   Materials and Methods: This study employed prompt engineering and
   offline knowledge distillation to design a dialogue algorithm and built
   the Chat-ePRO system on the WeChat Mini Program platform. In order to
   compare Chat-ePRO with the form-based ePRO and rule-based chatbot ePRO
   used in previous studies, we conducted a pilot study applying the three
   ePRO systems sequentially at the Sir Run Run Shaw Hospital to collect
   patients' PRO data. Result: Chat-ePRO is capable of correctly generating
   conversation based on PRO forms (success rate: 95.7 %) and accurately
   extracting the PRO data instantaneously from conversation (Macro-F1:
   0.95). The majority of subjective evaluations from doctors (>70 %)
   suggest that Chat-ePRO is able to comprehend questions and consistently
   generate responses. Pilot study shows that Chat-ePRO demonstrates higher
   response rate (9/10, 90 %) and longer interaction time (10.86 s/turn)
   compared to the other two methods. Conclusion: Our study demonstrated
   the feasibility of utilizing algorithms such as prompt engineering to
   drive LLM in completing ePRO data collection tasks, and validated that
   the Chat-ePRO system can effectively enhance patient compliance.
Z8 0
ZA 0
ZR 0
ZS 0
TC 1
ZB 0
Z9 1
DA 2024-06-17
UT WOS:001243033900001
PM 38703936
ER

PT J
AU Feng, Jia-Li
   Qin, Xiwen
TI Lipid-lowering medication use and cancer-specific survival among
   endometrial or lung cancer patients: an Australian nationwide cohort
   study
SO EUROPEAN JOURNAL OF CLINICAL PHARMACOLOGY
VL 77
IS 3
BP 399
EP 407
DI 10.1007/s00228-020-03009-5
EA OCT 2020
DT Article
PD MAR 2021
PY 2021
AB Purpose Inconsistent results of lipid-lowering medications (LLMs) on
   improved cancer survival need more investigations. We tested the
   hypothesis that adherence to the drug would be associated with a lower
   cancer-specific mortality in a homogeneous population who has ever used
   the drug. Methods Utilising data from the Australian Cancer database,
   linked to the Pharmaceutical Benefits Scheme data and the National Death
   Index, we identified two separate cohorts of 4519 and 3083 women
   patients with newly diagnosed endometrial and lung cancer respectively
   between 2003 and 2013. Adherence to this drug was calculated by
   proportion of days covered. Cox regression models with time-varying
   covariates were used to estimate the multivariable-adjusted
   cause-specific hazard ratios (HRs) and 95% confidence intervals (CIs)
   for the association of adherence to LLMs, statins, lipophilic and
   hydrophilic statins, and cancer-specific mortality. Results Each 10%
   increase in 1-year adherence to LLMs reduced cancer-specific mortality
   among women with endometrial cancer (adjusted HR=0.93, 95% CI 0.90-0.96)
   or lung cancer (adjusted HR=0.95, 95% CI 0.93-0.97). The inverse
   associations remained unchanged in different subgroup analyses. The
   reductions in lung cancer mortality were not apparent for women who
   adhered to lipophilic statins albeit better endometrial cancer survival
   appeared in the lipophilic statin group and borderline statistical
   improvement in the hydrophilic statin group. Conclusions Among LLM
   users, adherence to this drug is inversely associated with reduced
   cancer-specific mortality. Together with previous evidence, randomised
   controlled trials are called for to confirm whether LLMs could be
   considered as an adjuvant treatment to improve prognosis.
TC 2
ZR 0
Z8 1
ZA 0
ZS 0
ZB 0
Z9 3
DA 2020-10-27
UT WOS:000577981300001
PM 33030570
ER

PT J
AU Luo, Peng-Wei
   Liu, Ji-Wen
   Xie, Xi
   Jiang, Jia-Wei
   Huo, Xin-Yu
   Chen, Zhen-Lin
   Huang, Zhang-Cheng
   Jiang, Shao-Qin
   Li, Meng-Qiang
TI DeepSeek vs ChatGPT: a comparison study of their performance in
   answering prostate cancer radiotherapy questions in multiple languages
SO AMERICAN JOURNAL OF CLINICAL AND EXPERIMENTAL UROLOGY
VL 13
IS 2
BP 176
EP 185
DI 10.62347/UIAP7979
DT Article
PD 2025
PY 2025
AB Introduction: The medical information generated by large language models
   (LLM) is crucial for improving patient education and clinical
   decision-making. This study aims to evaluate the performance of two LLMs
   (DeepSeek and ChatGPT) in answering questions related to prostate cancer
   radiotherapy in both Chinese and English environments. Through a
   comparative analysis, we aim to determine which model can provide
   higher-quality answers in different language environments. Methods: A
   structured evaluation framework was developed using a set of clinically
   relevant questions covering three key domains: foundational knowledge,
   patient education, and treatment and follow-up care. Responses from
   DeepSeek and ChatGPT were generated in both English and Chinese and
   independently assessed by a panel of five oncology specialists using a
   five-point Likert scale. Statistical analyses, including the Wilcoxon
   signed-rank test, were performed to compare the models' performance
   across different linguistic contexts. Results: This study ultimately
   included 33 questions for scoring. In Chinese, DeepSeek outperformed
   ChatGPT, achieving top ratings (score = 5) in 75.76% vs. 36.36% of
   responses (P < 0.001), excelling in foundational knowledge (76.92% vs.
   38.46%, P = 0.047) and treatment/follow-up (81.82% vs. 36.36%, P =
   0.031). In English, ChatGPT showed comparable performance (66.7% vs.
   54.55% top-rated responses, P = 0.236), with marginal advantages in
   treatment/follow-up (63.64% vs. 54.55%, P = 0.563). DeepSeek maintained
   strengths in English foundational knowledge (69.23% vs. 30.77%, P =
   0.047) and patient education (88.89% vs. 55.56%, P = 0.125). These
   findings underscore DeepSeek's superior Chinese proficiency and
   language-specific optimization impacts. Conclusions: This study shows
   that DeepSeek performs excellently in providing Chinese medical
   information, while the two models perform similarly in an English
   environment. These findings underscore the importance of selecting
   language-specific artificial intelligence (AI) models to enhance the
   accuracy and reliability of medical AI applications. While both models
   show promise in supporting patient education and clinical
   decision-making, human expert review remains necessary to ensure
   response accuracy and minimize potential misinformation.
TC 0
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
Z9 0
DA 2025-05-23
UT WOS:001490798400001
PM 40400997
ER

PT J
AU Rubinstein, Samuel
   Mohsin, Aleenah
   Banerjee, Rahul
   Ma, Will
   Mishra, Sanjay
   Kwok, Mary
   Yang, Peter
   Warner, Jeremy L.
   Cowan, Andrew J.
TI Summarizing clinical evidence utilizing large language models for cancer
   treatments: a blinded comparative analysis
SO FRONTIERS IN DIGITAL HEALTH
VL 7
AR 1569554
DI 10.3389/fdgth.2025.1569554
DT Article
PD APR 29 2025
PY 2025
AB Background Concise synopses of clinical evidence support treatment
   decision-making but are time-consuming to curate. Large language models
   (LLMs) offer potential but they may provide inaccurate information. We
   objectively assessed the abilities of four commercially available LLMs
   to generate synopses for six treatment regimens in multiple myeloma and
   amyloid light chain (AL) amyloidosis.Methods We compared the performance
   of four LLMs: Claude 3.5, ChatGPT 4.0; Gemini 1.0 and Llama-3.1. Each
   LLM was prompted to write synopses for six regimens. Two hematologists
   independently assessed accuracy, completeness, relevance, clarity,
   coherence, and hallucinations using Likert scales. Mean scores with 95%
   confidence intervals (CI) were calculated across all domains and
   inter-rater reliability was evaluated using Cohen's quadratic weighted
   kappa.Results Claude demonstrated the highest performance in all
   domains, outperforming the other LLMs in accuracy: mean Likert score
   3.92 (95% CI 3.54-4.29); ChatGPT 3.25 (2.76-3.74); Gemini 3.17
   (2.54-3.80); Llama 1.92 (1.41-2.43);completeness: mean Likert score 4.00
   (3.66-4.34); GPT 2.58 (2.02-3.15); Gemini 2.58 (2.02-3.15); Llama 1.67
   (1.39-1.95); and extentofhallucinations: mean Likert score 4.00
   (4.00-4.00); ChatGPT 2.75 (2.06-3.44); Gemini 3.25 (2.65-3.85); Llama
   1.92 (1.26-2.57). Llama performed considerably poorer across all the
   studied domains. ChatGPT and Gemini had intermediate performance.
   Notably, none of the LLMs registered perfect accuracy, completeness, or
   relevance.Conclusion Claude performed at a consistently higher level
   than other LLMs, all tested LLMs required careful editing from a domain
   expert to become usable. More time will be needed to determine the
   suitability of LLMsto independently generate clinical synopses.
TC 0
Z8 0
ZS 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2025-05-24
UT WOS:001485758800001
PM 40364850
ER

PT J
AU Fu, Sidney W.
   Tang, Cong
   Tan, Xiaohui
   Srivastava, Sudhir
TI Liquid biopsy for early cancer detection: technological revolutions and
   clinical dilemma
SO EXPERT REVIEW OF MOLECULAR DIAGNOSTICS
VL 24
IS 10
BP 937
EP 955
DI 10.1080/14737159.2024.2408744
EA OCT 2024
DT Review
PD OCT 2 2024
PY 2024
AB IntroductionLiquid biopsy is an innovative advancement in oncology,
   offering a noninvasive method for early cancer detection and monitoring
   by analyzing circulating tumor cells, DNA, RNA, and other biomarkers in
   bodily fluids. This technique has the potential to revolutionize
   precision oncology by providing real-time analysis of tumor dynamics,
   enabling early detection, monitoring treatment responses, and tailoring
   personalized therapies based on the molecular profiles of individual
   patients.Areas coveredIn this review, the authors discuss current
   methodologies, technological challenges, and clinical applications of
   liquid biopsy. This includes advancements in detecting minimal residual
   disease, tracking tumor evolution, and combining liquid biopsy with
   other diagnostic modalities for precision oncology. Key areas explored
   are the sensitivity, specificity, and integration of multi-omics, AI,
   ML, and LLM technologies.Expert opinionLiquid biopsy holds great
   potential to revolutionize cancer care through early detection and
   personalized treatment strategies. However, its success depends on
   overcoming technological and clinical hurdles, such as ensuring high
   sensitivity and specificity, interpreting results amidst tumor
   heterogeneity, and making tests accessible and affordable. Continued
   innovation and collaboration are crucial to fully realize the potential
   of liquid biopsy in improving early cancer detection, treatment, and
   monitoring.
ZR 0
ZA 0
Z8 0
ZB 2
TC 6
ZS 0
Z9 6
DA 2024-10-09
UT WOS:001325602700001
PM 39360748
ER

PT J
AU Chen, Li-Ching
   Zack, Travis
   Demirci, Arda
   Sushil, Madhumita
   Miao, Brenda
   Kasap, Corynn
   Butte, Atul
   Collisson, Eric A.
   Hong, Julian C.
TI Assessing Large Language Models for Oncology Data Inference From
   Radiology Reports
SO JCO CLINICAL CANCER INFORMATICS
VL 8
AR e2400126
DI 10.1200/CCI.24.00126
DT Article
PD DEC 2024
PY 2024
AB PURPOSEWe examined the effectiveness of proprietary and open large
   language models (LLMs) in detecting disease presence, location, and
   treatment response in pancreatic cancer from radiology reports.METHODSWe
   analyzed 203 deidentified radiology reports, manually annotated for
   disease status, location, and indeterminate nodules needing follow-up.
   Using generative pre-trained transformer (GPT)-4, GPT-3.5-turbo, and
   open models such as Gemma-7B and Llama3-8B, we employed strategies such
   as ablation and prompt engineering to boost accuracy. Discrepancies
   between human and model interpretations were reviewed by a secondary
   oncologist.RESULTSAmong 164 patients with pancreatic tumor, GPT-4 showed
   the highest accuracy in inferring disease status, achieving a 75.5%
   correctness (F1-micro). Open models Mistral-7B and Llama3-8B performed
   comparably, with accuracies of 68.6% and 61.4%, respectively. Mistral-7B
   excelled in deriving correct inferences from objective findings
   directly. Most tested models demonstrated proficiency in identifying
   disease containing anatomic locations from a list of choices, with GPT-4
   and Llama3-8B showing near-parity in precision and recall for disease
   site identification. However, open models struggled with differentiating
   benign from malignant postsurgical changes, affecting their precision in
   identifying findings indeterminate for cancer. A secondary review
   occasionally favored GPT-3.5's interpretations, indicating the
   variability in human judgment.CONCLUSIONLLMs, especially GPT-4, are
   proficient in deriving oncologic insights from radiology reports. Their
   performance is enhanced by effective summarization strategies,
   demonstrating their potential in clinical support and health care
   analytics. This study also underscores the possibility of zero-shot open
   model utility in environments where proprietary models are restricted.
   Finally, by providing a set of annotated radiology reports, this paper
   presents a valuable data set for further LLM research in oncology.
ZB 0
TC 2
Z8 0
ZS 0
ZA 0
ZR 0
Z9 2
DA 2024-12-22
UT WOS:001379072100001
PM 39661914
ER

PT J
AU Wenz, Frederik
   Ebener, Stefan
TI Artificial intelligence applications in oncology: opportunities,
   feasibility, and regulatory challenges
SO ONKOLOGIE
VL 30
IS 5
SI SI
BP 339
EP 346
DI 10.1007/s00761-023-01428-4
EA NOV 2023
DT Review
PD MAY 2024
PY 2024
AB The integration of artificial intelligence (AI) into oncology promises a
   revolution in diagnosis, treatment, and research. Various applications
   are considered, with a focus on stress and burnout experienced by
   oncologists. The potentials are comprehensively discussed, starting from
   prevention through wearables and AI-assisted analysis of health data to
   personalized treatment planning and accelerated drug development. One
   area of focus is AlphaFold, an AI application for protein folding. The
   management of patient data and the creation of medical reports are
   optimized by AI, with search engines and large language models (LLM)
   playing a prominent role. The increasing specialization of LLMs,
   particularly in medical text generation, underscores their growing
   importance. The feasibility of AI applications is emphasized, addressing
   the need for resources and training for medical personnel. Commercial
   organizations, such as DeepMind, play a crucial role in implementing AI
   in clinical practice. Regulatory challenges are discussed, including
   data privacy, quality control, liability, and ethical aspects. The
   European Health Data Space (EHDS) is a promising initiative for
   promoting secure data exchange within the European Union. Overall, AI
   can facilitate significant advancements in oncology. However, regulatory
   challenges require careful attention to ensure an ethically responsible
   and safe implementation. AI applications have the potential to improve
   cancer care, revolutionize patient management, and reduce the workload
   for medical personnel.
TC 0
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
Z9 0
DA 2024-04-02
UT WOS:001193607500001
ER

PT J
AU Busch, Felix
   Hoffmann, Lena
   Rueger, Christopher
   van Dijk, Elon H. C.
   Kader, Rawen
   Ortiz-Prado, Esteban
   Makowski, Marcus R.
   Saba, Luca
   Hadamitzky, Martin
   Kather, Jakob Nikolas
   Truhn, Daniel
   Cuocolo, Renato
   Adams, Lisa C.
   Bressem, Keno K.
TI Current applications and challenges in large language models for patient
   care: a systematic review
SO COMMUNICATIONS MEDICINE
VL 5
IS 1
AR 26
DI 10.1038/s43856-024-00717-2
DT Article
PD JAN 21 2025
PY 2025
AB BackgroundThe introduction of large language models (LLMs) into clinical
   practice promises to improve patient education and empowerment, thereby
   personalizing medical care and broadening access to medical knowledge.
   Despite the popularity of LLMs, there is a significant gap in
   systematized information on their use in patient care. Therefore, this
   systematic review aims to synthesize current applications and
   limitations of LLMs in patient care.MethodsWe systematically searched 5
   databases for qualitative, quantitative, and mixed methods articles on
   LLMs in patient care published between 2022 and 2023. From 4349 initial
   records, 89 studies across 29 medical specialties were included. Quality
   assessment was performed using the Mixed Methods Appraisal Tool 2018. A
   data-driven convergent synthesis approach was applied for thematic
   syntheses of LLM applications and limitations using free line-by-line
   coding in Dedoose.ResultsWe show that most studies investigate
   Generative Pre-trained Transformers (GPT)-3.5 (53.2%, n = 66 of 124
   different LLMs examined) and GPT-4 (26.6%, n = 33/124) in answering
   medical questions, followed by patient information generation, including
   medical text summarization or translation, and clinical documentation.
   Our analysis delineates two primary domains of LLM limitations: design
   and output. Design limitations include 6 second-order and 12 third-order
   codes, such as lack of medical domain optimization, data transparency,
   and accessibility issues, while output limitations include 9
   second-order and 32 third-order codes, for example, non-reproducibility,
   non-comprehensiveness, incorrectness, unsafety, and bias.ConclusionsThis
   review systematically maps LLM applications and limitations in patient
   care, providing a foundational framework and taxonomy for their
   implementation and evaluation in healthcare settings.
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 8
Z9 8
DA 2025-01-29
UT WOS:001402540700001
PM 39838160
ER

PT C
AU Chang, Chia-Hsuan
   Lucas, Mary M.
   Lu-Yao, Grace
   Yang, Christopher C.
GP IEEE COMPUTER SOC
TI Classifying Cancer Stage with Open-Source Clinical Large Language Models
SO 2024 IEEE 12TH INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS, ICHI
   2024
SE IEEE International Conference on Healthcare Informatics
BP 76
EP 82
DI 10.1109/ICHI61247.2024.00018
DT Proceedings Paper
PD 2024
PY 2024
AB Cancer stage classification is important for making treatment and care
   management plans for oncology patients. Information on staging is often
   included in unstructured form in clinical, pathology, radiology and
   other free-text reports in the electronic health record system,
   requiring extensive work to parse and obtain. To facilitate the
   extraction of this information, previous NLP approaches rely on labeled
   training datasets, which are labor-intensive to prepare. In this study,
   we demonstrate that without any labeled training data, open-source
   clinical large language models (LLMs) can extract pathologic
   tumor-node-metastasis (pTNM) staging information from real-world
   pathology reports. Our experiments compare LLMs and a BERT-based model
   fine-tuned using the labeled data. Our findings suggest that while LLMs
   still exhibit subpar performance in Tumor (T) classification, with the
   appropriate adoption of prompting strategies, they can achieve
   comparable performance on Metastasis (M) classification and improved
   performance on Node (N) classification.
CT 12th IEEE International Conference on Healthcare Informatics (IEEE-ICHI)
CY JUN 03-06, 2024
CL Orlando, FL
SP IEEE; IEEE Comp Soc Tech Community Intelligent Informat; Univ Minnesota,
   Div Computat Hlth Sci; Weill Cornell Med Inst Artificial Intelligence &
   Digital Hlth; Univ Florida Hlth; Yale Univ, Sch Med; Springer; Florida
   State Univ, Coll Commun & Informat
ZR 0
TC 1
ZS 0
ZB 1
ZA 0
Z8 0
Z9 1
DA 2024-11-05
UT WOS:001304501700010
ER

PT J
AU Zhou, Juexiao
   He, Xiaonan
   Sun, Liyuan
   Xu, Jiannan
   Chen, Xiuying
   Chu, Yuetan
   Zhou, Longxi
   Liao, Xingyu
   Zhang, Bin
   Afvari, Shawn
   Gao, Xin
TI Pre-trained multimodal large language model enhances dermatological
   diagnosis using SkinGPT-4
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 5649
DI 10.1038/s41467-024-50043-3
DT Article
PD JUL 5 2024
PY 2024
AB Large language models (LLMs) are seen to have tremendous potential in
   advancing medical diagnosis recently, particularly in dermatological
   diagnosis, which is a very important task as skin and subcutaneous
   diseases rank high among the leading contributors to the global burden
   of nonfatal diseases. Here we present SkinGPT-4, which is an interactive
   dermatology diagnostic system based on multimodal large language models.
   We have aligned a pre-trained vision transformer with an LLM named
   Llama-2-13b-chat by collecting an extensive collection of skin disease
   images (comprising 52,929 publicly available and proprietary images)
   along with clinical concepts and doctors' notes, and designing a
   two-step training strategy. We have quantitatively evaluated SkinGPT-4
   on 150 real-life cases with board-certified dermatologists. With
   SkinGPT-4, users could upload their own skin photos for diagnosis, and
   the system could autonomously evaluate the images, identify the
   characteristics and categories of the skin conditions, perform in-depth
   analysis, and provide interactive treatment recommendations.
   Here, authors develop SkinGPT-4, an interactive dermatology diagnostic
   system that uses multimodal large language models and aligns a vision
   transformer with Llama-2-13b-chat. Evaluated by dermatologists, it
   offers autonomous diagnosis and treatment recommendations.
ZA 0
Z8 0
ZB 2
ZR 0
ZS 0
TC 21
Z9 21
DA 2024-07-18
UT WOS:001263353700018
PM 38969632
ER

PT J
AU Cai, Huizhu
   Zhuge, Lingdun
   Huang, Zehao
   Wang, Shixu
   Shi, Ping
   Yan, Dangui
   Wei, Minghui
   Niu, Lijuan
   Li, Zhengjiang
TI Predictive Value of Jugulo-omohyoid Lymph Nodes in Lateral Lymph Node
   Metastasis of Papillary Thyroid Cancer
SO BMC ENDOCRINE DISORDERS
VL 24
IS 1
AR 74
DI 10.1186/s12902-024-01576-7
DT Article
PD MAY 21 2024
PY 2024
AB Background Jugulo-omohyoid lymph nodes (JOHLN) metastasis has proven to
   be associated with lateral lymph node metastasis (LLNM). This study
   aimed to reveal the clinical features and evaluate the predictive value
   of JOHLN in PTC to guide the extent of surgery.Methods A total of 550
   patients pathologically diagnosed with PTC between October 2015 and
   January 2020, all of whom underwent thyroidectomy and lateral lymph node
   dissection, were included in this study.Results Thyroiditis, tumor
   location, tumor size, extra-thyroidal extension, extra-nodal extension,
   central lymph node metastasis (CLNM), and LLMM were associated with
   JOHLN. Male, upper lobe tumor, multifocality, extra-nodal extension,
   CLNM, and JOHLN metastasis were independent risk factors from LLNM. A
   nomogram based on predictors performed well. Nerve invasion contributed
   the most to the prediction model, followed by JOHLN metastasis. The area
   under the curve (AUC) was 0.855, and the p-value of the Hosmer-Lemeshow
   goodness of fit test was 0.18. Decision curve analysis showed that the
   nomogram was clinically helpful.Conclusion JOLHN metastasis could be a
   clinically sensitive predictor of further LLM. A high-performance
   nomogram was established, which can provide an individual risk
   assessment of LNM and guide treatment decisions for patients.
TC 0
ZS 0
Z8 0
ZR 0
ZA 0
ZB 0
Z9 0
DA 2024-05-27
UT WOS:001228647500001
PM 38773428
ER

PT J
AU Hao, Yuexing
   Holmes, Jason
   Hobson, Jared
   Bennett, Alexandra
   McKone, Elizabeth L
   Ebner, Daniel K
   Routman, David M
   Shiraishi, Satomi
   Patel, Samir H
   Yu, Nathan Y
   Hallemeier, Chris L
   Ball, Brooke E
   Waddle, Mark
   Liu, Wei
TI Retrospective Comparative Analysis of Prostate Cancer In-Basket
   Messages: Responses From Closed-Domain Large Language Models Versus
   Clinical Teams.
SO Mayo Clinic proceedings. Digital health
VL 3
IS 1
DI 10.1016/j.mcpdig.2025.100198
DT Journal Article
PD 2025-Mar
PY 2025
AB Objective: To evaluate the effectiveness of RadOnc-generative pretrained
   transformer (GPT), a GPT-4 based large language model, in assisting with
   in-basket message response generation for prostate cancer treatment,
   with the goal of reducing the workload and time on clinical care teams
   while maintaining response quality.
   Patients and Methods: RadOnc-GPT was integrated with electronic health
   records from both Mayo Clinic-wide databases and a
   radiation-oncology-specific database. The model was evaluated on 158
   previously recorded in-basket message interactions, selected from 90
   patients with nonmetastatic prostate cancer from the Mayo Clinic
   Department of Radiation Oncology in-basket message database in the
   calendar years 2022-2024. Quantitative natural language processing
   analysis and 2 grading studies, conducted by 5 clinicians and 4 nurses,
   were used to assess RadOnc-GPT's responses. Three primary clinicians
   independently graded all messages, whereas a fourth senior clinician
   reviewed 41 responses with relevant discrepancies, and a fifth senior
   clinician evaluated 2 additional responses. The grading focused on 5 key
   areas: completeness, correctness, clarity, empathy, and editing time.
   The grading study was performed from July 20, 2024 to December 15, 2024.
   Results: The RadOnc-GPT slightly outperformed the clinical care team in
   empathy, whereas achieving comparable scores with the clinical care team
   in completeness, correctness, and clarity. Five clinician graders
   identified key limitations in RadOnc-GPT's responses, such as lack of
   context, insufficient domain-specific knowledge, inability to perform
   essential meta-tasks, and hallucination. It was estimated that
   RadOnc-GPT could save an average of 5.2 minutes per message for nurses
   and 2.4 minutes for clinicians, from reading the inquiry to sending the
   response.
   Conclusion: RadOnc-GPT has the potential to considerably reduce the
   workload of clinical care teams by generating high-quality, timely
   responses for in-basket message interactions. This could lead to
   improved efficiency in health care workflows and reduced costs while
   maintaining or enhancing the quality of communication between patients
   and health care providers.Abbreviations and AcronymsAI; artificial
   intelligence; LLM; large language model; NLP; natural language
   processing; RadOnc-GPT; radiation oncology generative pretrained
   transformer.
ZA 0
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
Z9 0
DA 2025-03-28
UT MEDLINE:40130001
PM 40130001
ER

PT J
AU Cangelosi, Davide
   Blengio, Fabiola
   Versteeg, Rogier
   Eggert, Angelika
   Garaventa, Alberto
   Gambini, Claudio
   Conte, Massimo
   Eva, Alessandra
   Muselli, Marco
   Varesio, Luigi
TI Logic Learning Machine creates explicit and stable rules stratifying
   neuroblastoma patients
SO BMC BIOINFORMATICS
VL 14
AR S12
DI 10.1186/1471-2105-14-S7-S12
SU 7
DT Article
PD APR 22 2013
PY 2013
AB Background: Neuroblastoma is the most common pediatric solid tumor.
   About fifty percent of high risk patients die despite treatment making
   the exploration of new and more effective strategies for improving
   stratification mandatory. Hypoxia is a condition of low oxygen tension
   occurring in poorly vascularized areas of the tumor associated with poor
   prognosis. We had previously defined a robust gene expression signature
   measuring the hypoxic component of neuroblastoma tumors (NB-hypo) which
   is a molecular risk factor. We wanted to develop a prognostic classifier
   of neuroblastoma patients' outcome blending existing knowledge on
   clinical and molecular risk factors with the prognostic NB-hypo
   signature. Furthermore, we were interested in classifiers outputting
   explicit rules that could be easily translated into the clinical
   setting.
   Results: Shadow Clustering (SC) technique, which leads to final models
   called Logic Learning Machine (LLM), exhibits a good accuracy and
   promises to fulfill the aims of the work. We utilized this algorithm to
   classify NB-patients on the bases of the following risk factors: Age at
   diagnosis, INSS stage, MYCN amplification and NB-hypo. The algorithm
   generated explicit classification rules in good agreement with existing
   clinical knowledge. Through an iterative procedure we identified and
   removed from the dataset those examples which caused instability in the
   rules. This workflow generated a stable classifier very accurate in
   predicting good and poor outcome patients. The good performance of the
   classifier was validated in an independent dataset. NB-hypo was an
   important component of the rules with a strength similar to that of
   tumor staging.
   Conclusions: The novelty of our work is to identify stability, explicit
   rules and blending of molecular and clinical risk factors as the key
   features to generate classification rules for NB patients to be conveyed
   to the clinic and to be used to design new therapies. We derived,
   through LLM, a set of four stable rules identifying a new class of poor
   outcome patients that could benefit from new therapies potentially
   targeting tumor hypoxia or its consequences.
ZR 0
ZB 8
TC 24
ZS 0
ZA 0
Z8 1
Z9 25
DA 2013-04-22
UT WOS:000318869400012
PM 23815266
ER

PT J
AU Li, Yiming
   Zhao, Jeff
   Li, Manqi
   Dang, Yifang
   Yu, Evan
   Li, Jianfu
   Sun, Zenan
   Hussein, Usama
   Wen, Jianguo
   Abdelhameed, Ahmed M.
   Mai, Junhua
   Li, Shenduo
   Yu, Yue
   Hu, Xinyue
   Yang, Daowei
   Feng, Jingna
   Li, Zehan
   He, Jianping
   Tao, Wei
   Duan, Tiehang
   Lou, Yanyan
   Li, Fang
   Tao, Cui
TI RefAI: a GPT-powered retrieval-augmented generative tool for biomedical
   literature recommendation and summarization
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 9
BP 2030
EP 2039
DI 10.1093/jamia/ocae129
EA JUN 2024
DT Article
PD JUN 10 2024
PY 2024
AB Objectives: Precise literature recommendation and summarization are
   crucial for biomedical professionals. While the latest iteration of
   generative pretrained transformer (GPT) incorporates 2 distinct
   modes-real-time search and pretrained model utilization-it encounters
   challenges in dealing with these tasks. Specifically, the real-time
   search can pinpoint some relevant articles but occasionally provides
   fabricated papers, whereas the pretrained model excels in generating
   well-structured summaries but struggles to cite specific sources. In
   response, this study introduces RefAI, an innovative retrieval-augmented
   generative tool designed to synergize the strengths of large language
   models (LLMs) while overcoming their limitations. Materials and Methods:
   RefAI utilized PubMed for systematic literature retrieval, employed a
   novel multivariable algorithm for article recommendation, and leveraged
   GPT-4 turbo for summarization. Ten queries under 2 prevalent topics
   ("cancer immunotherapy and target therapy" and "LLMs in medicine") were
   chosen as use cases and 3 established counterparts (ChatGPT-4,
   ScholarAI, and Gemini) as our baselines. The evaluation was conducted by
   10 domain experts through standard statistical analyses for performance
   comparison. Results: The overall performance of RefAI surpassed that of
   the baselines across 5 evaluated dimensions-relevance and quality for
   literature recommendation, accuracy, comprehensiveness, and reference
   integration for summarization, with the majority exhibiting
   statistically significant improvements (P-values <.05). Discussion:
   RefAI demonstrated substantial improvements in literature recommendation
   and summarization over existing tools, addressing issues like fabricated
   papers, metadata inaccuracies, restricted recommendations, and poor
   reference integration. Conclusion: By augmenting LLM with external
   resources and a novel ranking algorithm, RefAI is uniquely capable of
   recommending high-quality literature and generating well-structured
   summaries, holding the potential to meet the critical needs of
   biomedical professionals in navigating and synthesizing vast amounts of
   scientific literature.
Z8 1
ZA 0
ZS 0
ZR 0
ZB 3
TC 13
Z9 14
DA 2024-06-17
UT WOS:001243328800001
PM 38857454
ER

PT J
AU Han, B.
   Chen, Y.
   Buyyounouski, M. K.
   Gensheimer, M. F.
   Xing, L.
TI RadAlonc: Enhancing Decision-Making in Radiation Oncology with a
   GPT-4-Based Prompt-Driven Large Language Model
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 2297
BP E134
EP E134
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892300029
ER

PT J
AU Yang, Z.
   Kazemimoghadam, M.
   Wang, L.
   Szalkowski, G. A.
   Chuang, C. F.
   Liu, L.
   Soltys, S. G.
   Pollom, E.
   Rahimy, E.
   Jiang, H.
   Park, D.
   Persad, A.
   Hori, Y.
   Fu, J.
   Romero, I. O.
   Zalavari, L.
   Chen, M.
   Lu, W.
   Gu, X.
TI A Deep Learning-Driven Framework for Large Language Model -Assisted
   Automatic Target Volume Localization and Delineation for Enhancing
   Spinal Metastases Stereotactic Body Radiotherapy Workflow
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 195
BP S61
EP S62
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302564
ER

PT J
AU Giannuzzi, Federico
   Carla, Matteo Mario
   Hu, Lorenzo
   Cestrone, Valentina
   Caputo, Carmela Grazia
   Sammarco, Maria Grazia
   Savino, Gustavo
   Rizzo, Stanislao
   Blasi, Maria Antonietta
   Pagliara, Monica Maria
TI Artificial intelligence with ChatGPT 4: a large language model in
   support of ocular oncology cases
SO INTERNATIONAL OPHTHALMOLOGY
VL 45
IS 1
AR 59
DI 10.1007/s10792-024-03399-w
DT Article
PD FEB 7 2025
PY 2025
AB PurposeTo evaluate ChatGPT's ability to analyze comprehensive case
   descriptions of patients with uveal melanoma and provide recommendations
   for the most appropriate management.DesignRetrospective analysis of
   ocular oncology patients' medical records.Subjects.Forty patients
   treated for uveal melanoma between May 2019 and October
   2023.DesignRetrospective analysis of ocular oncology patients' medical
   records.Subjects.Forty patients treated for uveal melanoma between May
   2019 and October 2023.DesignRetrospective analysis of ocular oncology
   patients' medical records.Subjects.Forty patients treated for uveal
   melanoma between May 2019 and October 2023.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.MethodsWe uploaded each case description into the ChatGPT
   interface (version 4.0) and asked the model to provide realistic
   treatment options by asking the question, "What type of treatment do you
   recommend?" The accuracy of decisions produced by ChatGPT was compared
   to those recorded in patients' files and the treatment recommendations
   provided by three ocular oncologists, each with more than 10 years of
   experience.Main outcome measures.The primary objective of this research
   was to assess the accuracy of ChatGPT replies in ocular oncology cases,
   analyzing its competence in both straightforward and intricate
   situations. Our secondary purpose was to assess the concordance between
   the responses of ChatGPT and those of ocular oncology specialists when
   faced with analogous clinical scenarios.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.ResultsChatGPT's surgical choices matched those in patients'
   files in 55% of cases (22 out of 40). ChatGPT options were agreed upon
   by 50%, 55%, and 57% of the three ocular oncology specialists. The
   investigation revealed significant differences between ChatGPT's
   responses and those of the three cancer specialists when compared to
   patients' files (p = 0.003, p = 0.001, and p = 0.001). ChatGPT's
   surgical responses matched with patient data in 18 out of 24 cases
   (75%), excluding enucleation cases.
   The decisions matched with the three ocular oncology specialists in
   17/24, 18/24, and 18/24 cases, reflecting agreements of 70%, 75%, and
   75%, respectively. The decisions made by ChatGPT were not significantly
   different from those of the three professionals in this cohort (p =
   0.50, p = 0.36, and p = 0.36 for ChatGPT compared to specialists 1, 2,
   and 3).ConclusionChatGPT exhibited a level of proficiency that was
   comparable to that of trained ocular oncology specialists. However, it
   exhibited its limitations when evaluating more complex scenarios, such
   as extrascleral extension or infiltration of the optic nerve, when a
   comprehensive evaluation of the patient is therefore necessary.
ZS 0
Z8 0
ZB 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-04-25
UT WOS:001468330700001
PM 39918656
ER

PT J
AU Bentzen, S. M.
TI Artificial Intelligence in Health Care: A Rallying Cry for Critical
   Clinical Research and Ethical Thinking
SO CLINICAL ONCOLOGY
VL 41
AR 103798
DI 10.1016/j.clon.2025.103798
EA APR 2025
DT Article
PD MAY 2025
PY 2025
AB Artificial intelligence (AI) will impact a large proportion of jobs in
   the short to medium term, especially in the developed countries. The
   consequences will be felt across many sectors including health care, a
   critical sector for implementation of AI tools because glitches in
   algorithms or biases in training datasets may lead to suboptimal
   treatment that may negatively affect the health of an individual. The
   stakes are obviously higher in case of potentially life-threatening
   diseases such as cancer and therapies with a potential for causing
   severe or even fatal adverse events. Over the last two decades, much of
   the research on AI in health care has focussed on diagnostic radiology
   and digital pathology, but a solid body of research is emerging on AI
   tools in the radiation oncology workflow. Many of these applications are
   relatively uncontroversial, although there is still a lack of evidence
   regarding effectiveness rather than efficiency, and-the ultimate
   bar-evidence of clinical utility. Proponents of AI will argue that these
   algorithms should be implemented with robust human supervision. One
   challenge here is the deskilling effect associated with new
   technologies. We will become increasingly dependent on the AI tools over
   time, and we will become less capable of assessing the quality of the AI
   output. Much of this research appears almost old-fashioned in view of
   the rapid advances in Generative artificial intelligence (GenAI). GenAI
   can draw from multiple types of data and produce output that is
   personalised and appears relevant in the given context. Especially the
   rapid progress in large language models (LLMs) has opened a wide field
   of potential applications that were out of bounds just a few years ago.
   One LLM, Generative Pre-trained Transformer 4 (GPT-4), has been made
   widely accessible to end-users as ChatGPT-4, which passed a rigorous
   Turing test in a recent study. In this viewpoint, I argue for the
   necessity of independent academic research to establish evidence-based
   applications of AI in medicine. Algorithmic medicine is an intervention
   similar to a new drug or a new medical device. We should be especially
   concerned about under-represented minorities and rare/atypical clinical
   cases that may drown in the petabyte-sized training sets. A huge
   educational push is needed to ensure that the end-users of AI in health
   care understand the strengths and weaknesses of algorithmic medicine.
   Finally, we need to address the ethical boundaries for where and when
   GenAI can replace humans in the relation between patients and healthcare
   providers. (c) 2025 The Royal College of Radiologists. Published by
   Elsevier Ltd. All rights are reserved, including those for text and data
   mining, AI training, and similar technologies.
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2025-04-17
UT WOS:001463027500001
PM 40184826
ER

PT J
AU Jang, B. S.
   Alcorn, S. R.
   McNutt, T. R.
   Ehsan, U.
TI Hype or Reality: Utility of Large Language Models in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3382
BP E629
EP E630
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
Z8 0
ZR 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302063
ER

PT J
AU Jinia, A. J.
   Chapman, K. L.
   Liu, S.
   Della Biancia, C.
   Li, A.
   Moran, J. M.
TI Challenges in Developing an Al -Based Analysis System for Incident
   Learning
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3198
BP E542
EP E542
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
ZS 0
Z8 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2024-12-16
UT WOS:001325892301523
ER

PT B
AU Asly, Amneh
Z2  
TI Developing Objective Chronic Pain Assessment Based on Linguistic
   Characteristics of Patients' Narratives
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
TC 0
ZA 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
UT PQDT:119375393
ER

PT C
AU Sharma, Manish
   Farough, Samira
   Burkett, Andre
   Prasanth, Jerome
   El-Shafeey, Nabil
   Zygadlo, Dominic
   Dunn, Chera
   Korn, Ron
BE Yoshida, H
   Wu, S
TI Leveraging LLMs like ChatGPT for robust quality checks and medical text
   agreement rationale enhancing adjudication quality and alignment in BICR
   for oncology clinical trials
SO IMAGING INFORMATICS FOR HEALTHCARE, RESEARCH, AND APPLICATIONS, MEDICAL
   IMAGING 2024
SE Proceedings of SPIE
VL 12931
AR 1293103
DI 10.1117/12.3009153
DT Proceedings Paper
PD 2024
PY 2024
AB Purpose: Blinded independent central review (BICR) is recommended by the
   US FDA for registration of oncology trials as image assessment bias is
   avoided and no chance of unblinding of patient data. Double read with
   adjudication is the method used to reduce endpoint assessment
   variability. In cases of disagreement between the readers, a third
   reader called an adjudicator, reviews the assessment by the two
   radiologists and decides which assessment is most accurate. Adjudication
   rate (AR) and adjudicator agreement rate (AAR) are the two indicators
   used to evaluate reviewer performance and overall trial variability and
   quality. Sentiment analysis (SA) is based on natural language processing
   and can tag the data as 'positive', 'negative' or 'neutral' although
   current technologies can provide a more complex analysis of emotions in
   the written text. Medical SA can analyze patients' and doctors'
   opinions, sentiments, attitudes, and emotions in the clinical
   background. Python, the most frequently used programming language for
   deep learning worldwide and ChatGPT, an AI-based chatbot can be used for
   assessing adjudicator comment quality based on sentiment analysis. If
   successful, this analysis can open another novel implementation for
   Large Language Models (LLMs) or ChatGPT in clinical research and medical
   imaging.
   Methods: This prospective study involved the review of cases for 100
   subjects by board-certified radiologists using the Response Evaluation
   Criteria in Solid Tumors (RECIST) 1.1 criteria. The study employed a
   double read with adjudication paradigm in a central imaging review
   setup. The agreement of adjudication was assessed and compared with the
   overall response, agreed reader, and medical text. The medical text
   entered by the adjudicator is usually a free text field that typically
   lacks standardization and control over its content, which may affect its
   correlation with reviewer selection for agreement. Although uncommon,
   errors by the adjudicator can occur due to ambiguous text, mis-clicks,
   or application delay errors. To analyze the adjudicator's comments,
   sentiment analysis was conducted using a Python plug-in with ChatGPT as
   a large language model. Based on this analysis, the subjects were
   categorized as either having "Potential Error" or "No Error".
   Results: The algorithm supported by ChatGPT was evaluated against a Gold
   Standard, determined by a board-certified radiologist with over 20 years
   of experience in the BICR process. A comparison was made to assess
   accuracy and reproducibility, revealing that only 4 out of 100 subjects
   had different outcomes. The sensitivity was calculated as 0.857,
   specificity as 1.0, and accuracy as 0.96.
   Conclusions: The remarkable Natural Language Processing (NLP)
   capabilities of ChatGPT are evident in its ability to classify the
   sentiment as positive, negative, or neutral based on the free-text
   adjudicator comments provided during the review process. This
   classification enables a comparison with the actual assessment,
   adjudicator agreement, and overall patient outcome, highlighting the
   impressive performance of ChatGPT in this regard.
CT Conference on Medical Imaging - Imaging Informatics for Healthcare,
   Research, and Applications
CY FEB 19-21, 2024
CL San Diego, CA
SP SPIE; Amer Assoc Physicists Med; Radiol Soc N Amer; World Mol Imaging
   Soc; Soc Imaging Informat Med; Int Fdn Comp Assisted Radiol & Surg; Med
   Image Percept Soc
ZA 0
ZS 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
DA 2024-05-31
UT WOS:001219280700002
ER

EF