FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Gallifant, Jack
   Afshar, Majid
   Ameen, Saleem
   Aphinyanaphongs, Yindalon
   Chen, Shan
   Cacciamani, Giovanni
   Demner-Fushman, Dina
   Dligach, Dmitriy
   Daneshjou, Roxana
   Fernandes, Chrystinne
   Hansen, Lasse Hyldig
   Landman, Adam
   Lehmann, Lisa
   Mccoy, Liam G.
   Miller, Timothy
   Moreno, Amy
   Munch, Nikolaj
   Restrepo, David
   Savova, Guergana
   Umeton, Renato
   Gichoya, Judy Wawira
   Collins, Gary S.
   Moons, Karel G. M.
   Celi, Leo A.
   Bitterman, Danielle S.
TI The TRIPOD-LLM reporting guideline for studies using large language
   models
SO NATURE MEDICINE
VL 31
IS 1
DI 10.1038/s41591-024-03425-5
EA JAN 2025
DT Review
PD JAN 2025
PY 2025
AB Large language models (LLMs) are rapidly being adopted in healthcare,
   necessitating standardized reporting guidelines. We present transparent
   reporting of a multivariable model for individual prognosis or diagnosis
   (TRIPOD)-LLM, an extension of the TRIPOD + artificial intelligence
   statement, addressing the unique challenges of LLMs in biomedical
   applications. TRIPOD-LLM provides a comprehensive checklist of 19 main
   items and 50 subitems, covering key aspects from title to discussion.
   The guidelines introduce a modular format accommodating various LLM
   research designs and tasks, with 14 main items and 32 subitems
   applicable across all categories. Developed through an expedited Delphi
   process and expert consensus, TRIPOD-LLM emphasizes transparency, human
   oversight and task-specific performance reporting. We also introduce an
   interactive website (https://tripod-llm.vercel.app/) facilitating easy
   guideline completion and PDF generation for submission. As a living
   document, TRIPOD-LLM will evolve with the field, aiming to enhance the
   quality, reproducibility and clinical applicability of LLM research in
   healthcare through comprehensive reporting.
TC 15
ZR 0
Z8 0
ZB 1
ZA 0
ZS 0
Z9 15
DA 2025-01-13
UT WOS:001391790800001
PM 39779929
ER

PT J
AU Wu, Dongyuan
   Nie, Liming
   Mumtaz, Rao Asad
   Agarwal, Kadambri
TI A LLM-Based Hybrid-Transformer Diagnosis System in Healthcare.
SO IEEE journal of biomedical and health informatics
VL PP
DI 10.1109/JBHI.2024.3481412
DT Journal Article
PD 2024-Oct-16
PY 2024
AB The application of computer vision-powered large language models (LLMs)
   for medical image diagnosis has significantly advanced healthcare
   systems. Recent progress in developing symmetrical architectures has
   greatly impacted various medical imaging tasks. While CNNs or RNNs have
   demonstrated excellent performance, these architectures often face
   notable limitations of substantial losses in detailed information, such
   as requiring to capture global semantic information effectively and
   relying heavily on deep encoders and aggressive downsampling. This paper
   introduces a novel LLM-based Hybrid-Transformer Network (HybridTransNet)
   designed to encode tokenized Big Data patches with the transformer
   mechanism, which elegantly embeds multimodal data of varying sizes as
   token sequence inputs of LLMS. Subsequently, the network performs both
   inter-scale and intra-scale self-attention, processing data features
   through a transformer-based symmetric architecture with a refining
   module, which facilitates accurately recovering both local and global
   context information. Additionally, the output is refined using a novel
   fuzzy selector. Compared to other existing methods on two distinct
   datasets, the experimental findings and formal assessment demonstrate
   that our LLM-based HybridTransNet provides superior performance for
   brain tumor diagnosis in healthcare informatics.
ZA 0
ZS 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
DA 2024-10-18
UT MEDLINE:39412973
PM 39412973
ER

PT J
AU Qiu, Jianing
   Lam, Kyle
   Li, Guohao
   Acharya, Amish
   Wong, Tien Yin
   Darzi, Ara
   Yuan, Wu
   Topol, Eric J.
TI LLM-based agentic systems in medicine and healthcare
SO NATURE MACHINE INTELLIGENCE
VL 6
IS 12
BP 1418
EP 1420
DI 10.1038/s42256-024-00944-1
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB Large language model-based agentic systems can process input
   information, plan and decide, recall and reflect, interact and
   collaborate, leverage various tools and act. This opens up a wealth of
   opportunities within medicine and healthcare, ranging from clinical
   workflow automation to multi-agent-aided diagnosis.
ZS 0
Z8 0
TC 6
ZR 0
ZA 0
ZB 1
Z9 6
DA 2024-12-11
UT WOS:001370695300001
ER

PT J
AU Kang, Yan
   Yang, Mingjian
   Peng, Yue
   Cai, Jingwen
   Zhao, Lei
   Gao, Zhan
   Li, Ningshu
   Pu, Bin
TI LLM-DG: Leveraging large language model for enhanced disease prediction
   via inter-patient and intra-patient modeling
SO INFORMATION FUSION
VL 121
AR 103145
DI 10.1016/j.inffus.2025.103145
EA APR 2025
DT Article
PD SEP 2025
PY 2025
AB Existing methods play a crucial role in clinical decision support by
   enabling disease prediction and personalizing healthcare based on
   swiftly accumulated electronic Health Records (EHRs). However, these
   methods often overlook multi-source data integration by relying solely
   on specific domain knowledge and fail to model intricate relationships
   among patients as focusing on inter or intra-patient relationships,
   respectively. To address these limitations, we propose LLM-DG, a
   multi-level health event prediction framework enhanced by large language
   models (LLMs). Specifically, LLM performs semantic enhancement for
   patient and discharge summary representations and injects domain
   knowledge into disease modeling, improving prediction accuracy and
   robustness. Moreover, LLM-DG synchronously models inter-patient and
   intra-patient relationships by capturing high-order patient correlations
   and fusing dynamic and static patient features. At the inter-patient
   level, LLM-DG clusters patients based on LLM-enhanced features,
   identifying similar health trajectories. At the intra-patient level, it
   models disease evolution characteristics through a dynamic graph and
   extracts textual information from LLM-enhanced discharge summaries using
   a text encoder. Experiments on MIMIC-III and MIMIC-IV datasets
   demonstrate that LLM-DG significantly outperforms state-of-the-art
   models, achieving a 12.39% improvement in w-F1 on the diagnosis
   prediction task of the MIMIC-IV dataset. Overall, LLM-DG demonstrates
   strong potential in complex healthcare environments by integrating
   patient histories and cross-patient health patterns, highlighting its
   applicability in clinical decision support and personalized treatment
   planning.
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001464997000001
ER

PT J
AU Shah, Krish
   Xu, Andrew Y.
   Sharma, Yatharth
   Daher, Mohammed
   Mcdonald, Christopher
   Diebo, Bassel G.
   Daniels, Alan H.
TI Large Language Model Prompting Techniques for Advancement in Clinical
   Medicine
SO JOURNAL OF CLINICAL MEDICINE
VL 13
IS 17
AR 5101
DI 10.3390/jcm13175101
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs have the potential to revolutionize clinical
   medicine by enhancing healthcare access, diagnosis, surgical planning,
   and education. However, their utilization requires careful, prompt
   engineering to mitigate challenges like hallucinations and biases.
   Proper utilization of LLMs involves understanding foundational concepts
   such as tokenization, embeddings, and attention mechanisms, alongside
   strategic prompting techniques to ensure accurate outputs. For
   innovative healthcare solutions, it is essential to maintain ongoing
   collaboration between AI technology and medical professionals. Ethical
   considerations, including data security and bias mitigation, are
   critical to their application. By leveraging LLMs as supplementary
   resources in research and education, we can enhance learning and support
   knowledge-based inquiries, ultimately advancing the quality and
   accessibility of medical care. Continued research and development are
   necessary to fully realize the potential of LLMs in transforming
   healthcare.
ZB 1
ZS 0
Z8 0
TC 9
ZA 0
ZR 0
Z9 9
DA 2024-09-21
UT WOS:001311343800001
PM 39274316
ER

PT J
AU Gaber, Farieda
   Shaik, Maqsood
   Allega, Fabio
   Bilecz, Agnes Julia
   Busch, Felix
   Goon, Kelsey
   Franke, Vedran
   Akalin, Altuna
TI Evaluating large language model workflows in clinical decision support
   for triage and referral and diagnosis
SO NPJ DIGITAL MEDICINE
VL 8
IS 1
AR 263
DI 10.1038/s41746-025-01684-1
DT Article
PD MAY 9 2025
PY 2025
AB Accurate medical decision-making is critical for both patients and
   clinicians. Patients often struggle to interpret their symptoms,
   determine their severity, and select the right specialist.
   Simultaneously, clinicians face challenges in integrating complex
   patient data to make timely, accurate diagnoses. Recent advances in
   large language models (LLMs) offer the potential to bridge this gap by
   supporting decision-making for both patients and healthcare providers.
   In this study, we benchmark multiple LLM versions and an LLM-based
   workflow incorporating retrieval-augmented generation (RAG) on a curated
   dataset of 2000 medical cases derived from the Medical Information Mart
   for Intensive Care database. Our findings show that these LLMs are
   capable of providing personalized insights into likely diagnoses,
   suggesting appropriate specialists, and assessing urgent care needs.
   These models may also support clinicians in refining diagnoses and
   decision-making, offering a promising approach to improving patient
   outcomes and streamlining healthcare delivery.
Z8 0
ZR 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
DA 2025-05-16
UT WOS:001485848400003
PM 40346344
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Yang, Bufang
   Jiang, Siyang
   Xu, Lilin
   Liu, Kaiwei
   Li, Hai
   Xing, Guoliang
   Chen, Hongkai
   Jiang, Xiaofan
   Yan, Zhenyu
TI DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing
   Outcomes from Sensor Data and Expert Knowledge
SO PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS
   TECHNOLOGIES-IMWUT
VL 8
IS 4
AR 153
DI 10.1145/3699765
DT Article
PD DEC 2024
PY 2024
AB Large language models (LLMs) have the potential to transform digital
   healthcare, as evidenced by recent advances in LLMbased virtual doctors.
   However, current approaches rely on patient's subjective descriptions of
   symptoms, causing increased misdiagnosis. Recognizing the value of daily
   data from smart devices, we introduce a novel LLM-based multi-turn
   consultation virtual doctor system, DrHouse, which incorporates three
   significant contributions: 1) It utilizes sensor data from smart devices
   in the diagnosis process, enhancing accuracy and reliability. 2) DrHouse
   leverages continuously updating medical knowledge bases to ensure its
   model remains at diagnostic standard's forefront. 3) DrHouse introduces
   a novel diagnostic algorithm that concurrently evaluates potential
   diseases and their likelihood, facilitating more nuanced and informed
   medical assessments. Through multi-turn interactions, DrHouse determines
   the next steps, such as accessing daily data from smart devices or
   requesting in-lab tests, and progressively refines its diagnoses.
   Evaluations on three public datasets and our self-collected datasets
   show that DrHouse can achieve up to an 31.5% increase in diagnosis
   accuracy over the state-of-the-art baselines. The results of a
   32-participant user study show that 75% medical experts and 91.7% test
   subjects are willing to use DrHouse.
ZB 0
ZS 0
ZA 0
TC 5
ZR 0
Z8 0
Z9 5
DA 2025-01-05
UT WOS:001387195100002
ER

PT J
AU Burgisser, Nils
   Chalot, Etienne
   Mehouachi, Samia
   Buclin, Clement P.
   Lauper, Kim
   Courvoisier, Delphine S.
   Mongin, Denis
TI Large language models for accurate disease detection in electronic
   health records: the examples of crystal arthropathies
SO RMD OPEN
VL 10
IS 4
AR e005003
DI 10.1136/rmdopen-2024-005003
DT Article
PD DEC 19 2024
PY 2024
AB Objectives We propose and test a framework to detect disease diagnosis
   using a recent large language model (LLM), Meta's Llama-3-8B, on
   French-language electronic health record (EHR) documents. Specifically,
   it focuses on detecting gout ('goutte' in French), a ubiquitous French
   term that has multiple meanings beyond the disease. The study compares
   the performance of the LLM-based framework with traditional natural
   language processing techniques and tests its dependence on the parameter
   used.Methods The framework was developed using a training and testing
   set of 700 paragraphs assessing 'gout' from a random selection of EHR
   documents from a tertiary university hospital in Geneva, Switzerland.
   All paragraphs were manually reviewed and classified by two healthcare
   professionals into disease (true gout) and non-disease (gold standard).
   The LLM's accuracy was tested using few-shot and chain-of-thought
   prompting and compared with a regular expression (regex)-based method,
   focusing on the effects of model parameters and prompt structure. The
   framework was further validated on 600 paragraphs assessing 'Calcium
   Pyrophosphate Deposition Disease (CPPD)'.Results The LLM-based algorithm
   outperformed the regex method, achieving a 92.7% (88.7%-95.4%) positive
   predictive value, a 96.6% (94.6%-97.8%) negative predictive value and an
   accuracy of 95.4% (93.6%-96.7%) for gout. In the validation set on CPPD,
   accuracy was 94.1% (90.2%-97.6%). The LLM framework performed well over
   a wide range of parameter values.Conclusion LLMs accurately detected
   disease diagnoses from EHRs, even in non-English languages. They could
   facilitate creating large disease registers in any language, improving
   disease care assessment and patient recruitment for clinical trials.
ZS 0
ZA 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
DA 2024-12-27
UT WOS:001381748400001
PM 39794274
ER

PT J
AU Rosskopf, Steffen
   Meder, Benjamin
TI Healthcare 4.0-Medizin im Wandel
SO HERZ
VL 49
IS 5
BP 350
EP 354
DI 10.1007/s00059-024-05267-w
EA AUG 2024
DT Review
PD OCT 2024
PY 2024
AB Healthcare 4.0 describes the future transformation of the healthcare
   sector driven by the combination of digital technologies, such as
   artificial intelligence (AI), big data and the Internet of Medical
   Things, enabling the advancement of precision medicine. This overview
   article addresses various areas such as large language models (LLM),
   diagnostics and robotics, shedding light on the positive aspects of
   Healthcare 4.0 and showcasing exciting methods and application examples
   in cardiology. It delves into the broad knowledge base and enormous
   potential of LLMs, highlighting their immediate benefits as digital
   assistants or for administrative tasks. In diagnostics, the increasing
   usefulness of wearables is emphasized and an AI for predicting heart
   filling pressures based on cardiac magnetic resonance imaging (MRI) is
   introduced. Additionally, it discusses the revolutionary methodology of
   a digital simulation of the physical heart (digital twin). Finally, it
   addresses both regulatory frameworks and a brief vision of data-driven
   healthcare delivery, explaining the need for investments in technical
   personnel and infrastructure to achieve a more effective medicine.
Z8 0
ZB 0
ZS 0
ZA 0
TC 0
ZR 0
Z9 0
DA 2024-08-14
UT WOS:001287384100001
PM 39115627
ER

PT J
AU Tozzi, Alberto Eugenio
TI [An LLM for a friend.]
FT Un LLM per amico.
SO Recenti progressi in medicina
VL 115
IS 7
BP 321
EP 322
DI 10.1701/4314.42983
DT English Abstract; Journal Article
PD 2024 Jul-Aug
PY 2024
AB The large language models (LLMs) represent a technology that has not yet
   seen widespread use. In addition to the automatic transcription of
   doctor-patient conversations, these tools will be able to support
   doctors in diagnosis and improve communication between doctors and
   patients. Their large-scale adoption is still limited due to concerns
   about sharing sensitive data, a lack of digital literacy, and the need
   to build new processes in clinical routines. To fully realize their
   potential, it is essential to train healthcare personnel on the
   functionalities of LLMs and to promote interdisciplinarity and
   scientific research, transforming artificial intelligence into augmented
   intelligence.
ZS 0
Z8 0
TC 0
ZR 0
ZB 0
ZA 0
Z9 0
DA 2024-07-18
UT MEDLINE:39011911
PM 39011911
ER

PT J
AU John, Annette
   Alhajj, Reda
   Rokne, Jon
TI A systematic review of AI as a digital twin for prostate cancer care
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 268
AR 108804
DI 10.1016/j.cmpb.2025.108804
EA MAY 2025
DT Review
PD AUG 2025
PY 2025
AB Artificial Intelligence (AI) and Digital Twin (DT) technologies are
   rapidly transforming healthcare, offering the potential for
   personalized, accurate, and efficient medical care. This systematic
   review focuses on the intersection of AI-based digital twins and their
   applications in prostate cancer pathology. A digital twin, when applied
   to healthcare, creates a dynamic, data-driven virtual model that
   simulates a patient's biological systems in real-time. By incorporating
   AI techniques such as Machine Learning (ML) and Deep Learning (DL),
   these systems enhance predictive accuracy, enable early diagnosis, and
   facilitate individualized treatment strategies for prostate cancer. This
   review systematically examines recent advances (2020-2025) in AI-driven
   digital twins for prostate cancer, highlighting key methodologies,
   algorithms, and data integration strategies. The literature analysis
   also reveals substantial progress in image processing, predictive
   modeling, and clinical decision support systems, which are the basic
   tools used when implementing digital twins for prostate cancer care. Our
   survey also critically evaluates the strengths and limitations of
   current approaches, identifying gaps such as the need for real-time data
   integration, improved explainability in AI models, and more robust
   clinical validation. It concludes with a discussion of future research
   directions, emphasizing the importance of integrating multi-modal data
   with Large Language Models (LLMs) and Vision-Language Models (VLMs),
   scalability, and ethical considerations in advancing AI-driven digital
   twins for prostate cancer diagnosis and treatment. This paper provides a
   comprehensive resource for researchers and clinicians, offering insights
   into how AI-based digital twins can enhance precision medicine and
   improve patient outcomes in prostate cancer care.
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
DA 2025-05-23
UT WOS:001490802200002
PM 40347618
ER

PT J
AU Nia, Masoumeh Farhadi
   Ahmadi, Mohsen
   Irankhah, Elyas
TI Transforming dental diagnostics with artificial intelligence: advanced
   integration of ChatGPT and large language models for patient care
SO FRONTIERS IN DENTAL MEDICINE
VL 5
AR 1456208
DI 10.3389/fdmed.2024.1456208
DT Review
PD JAN 6 2025
PY 2025
AB Artificial intelligence has dramatically reshaped our interaction with
   digital technologies, ushering in an era where advancements in AI
   algorithms and Large Language Models (LLMs) have natural language
   processing (NLP) systems like ChatGPT. This study delves into the impact
   of cutting-edge LLMs, notably OpenAI's ChatGPT, on medical diagnostics,
   with a keen focus on the dental sector. Leveraging publicly accessible
   datasets, these models augment the diagnostic capabilities of medical
   professionals, streamline communication between patients and healthcare
   providers, and enhance the efficiency of clinical procedures. The advent
   of ChatGPT-4 is poised to make substantial inroads into dental
   practices, especially in the realm of oral surgery. This paper sheds
   light on the current landscape and explores potential future research
   directions in the burgeoning field of LLMs, offering valuable insights
   for both practitioners and developers. Furthermore, it critically
   assesses the broad implications and challenges within various sectors,
   including academia and healthcare, thus mapping out an overview of AI's
   role in transforming dental diagnostics for enhanced patient care.
Z8 0
ZS 0
TC 3
ZR 0
ZB 0
ZA 0
Z9 3
DA 2025-01-24
UT WOS:001399392200001
PM 39917691
ER

PT J
AU Meng, Xiangbin
   Yan, Xiangyu
   Zhang, Kuo
   Liu, Da
   Cui, Xiaojuan
   Yang, Yaodong
   Zhang, Muhan
   Cao, Chunxia
   Wang, Jingjia
   Wang, Xuliang
   Gao, Jun
   Wang, Yuan-Geng-Shuo
   Ji, Jia-ming
   Qiu, Zifeng
   Li, Muzi
   Qian, Cheng
   Guo, Tianze
   Ma, Shuangquan
   Wang, Zeying
   Guo, Zexuan
   Lei, Youlan
   Shao, Chunli
   Wang, Wenyao
   Fan, Haojun
   Tang, Yi-Da
TI The application of large language models in medicine: A scoping review
SO ISCIENCE
VL 27
IS 5
AR 109713
DI 10.1016/j.isci.2024.109713
EA MAY 2024
DT Review
PD MAY 17 2024
PY 2024
AB This study systematically reviewed the application of large language
   models (LLMs) in medicine, analyzing 550 selected studies from a vast
   literature search. LLMs like ChatGPT transformed healthcare by enhancing
   diagnostics, medical writing, education, and project management. They
   assisted in drafting medical documents, creating training simulations,
   and streamlining research processes. Despite their growing utility in
   assisted diagnosis and improving doctor -patient communication,
   challenges persisted, including limitations in contextual understanding
   and the risk of over -reliance. The surge in LLM-related research
   indicated a focus on medical writing, diagnostics, and patient
   communication, but highlighted the need for careful integration,
   considering validation, ethical concerns, and the balance with
   traditional medical practice. Future research directions suggested a
   focus on multimodal LLMs, deeper algorithmic understanding, and ensuring
   responsible, effective use in healthcare.
ZR 0
Z8 0
ZS 0
ZB 7
ZA 0
TC 57
Z9 57
DA 2024-06-12
UT WOS:001240677700001
PM 38746668
ER

PT J
AU Arnold, Philipp
   Henkel, Maurice
   Bamberg, Fabian
   Kotter, Elmar
TI Integration of large language models into the clinic. Revolution in
   analysing and processing patient data to increase efficiency and quality
   in radiology
SO RADIOLOGIE
DI 10.1007/s00117-025-01431-3
EA MAR 2025
DT Review; Early Access
PY 2025
AB BackgroundLarge Language Models (LLMs) like ChatGPT, Llama and Claude
   are transforming healthcare by interpreting complex text, extracting
   information, and providing guideline-based support. Radiology, with its
   high patient volume and digital workflows, is a ideal field for LLM
   integration. ObjectiveAssessment of the potential of LLMs to enhance
   efficiency, standardization, and decision support in radiology, while
   addressing ethical and regulatory challenges. Material and methodsPilot
   studies at Freiburg and Basel university hospitals evaluated local LLM
   systems for tasks like prior report summarization and guideline-driven
   reporting. Integration with Picture Archiving and Communication System
   (PACS) and Electronic Health Record (EHR) systems was achieved via
   Digital Imaging and Communications in Medicine (DICOM) and Fast
   Healthcare Interoperability Resources (FHIR) standards. Metrics included
   time savings, compliance with the European Union (EU) Artificial
   Intelligence (AI) Act, and user acceptance. ResultsLLMs demonstrate
   significant potential as a support tool for radiologists in clinical
   practice by reducing reporting times, automating routine tasks, and
   ensuring consistent, high-quality results. They also support
   interdisciplinary workflows (e.g., tumor boards) and meet data
   protection requirements when locally implemented. DiscussionLocal LLM
   systems are feasible and beneficial in radiology, enhancing efficiency
   and diagnostic quality. Future work should refine transparency, expand
   applications, and ensure LLMs complement medical expertise while
   adhering to ethical and legal standards.
ZS 0
ZA 0
Z8 0
ZR 0
TC 0
ZB 0
Z9 0
DA 2025-03-26
UT WOS:001442977100001
PM 40072530
ER

PT C
AU Liu, Zhengliang
   Zhong, Aoxiao
   Li, Yiwei
   Yang, Longtao
   Ju, Chao
   Wu, Zihao
   Ma, Chong
   Shu, Peng
   Chen, Cheng
   Kim, Sekeun
   Dai, Haixing
   Zhao, Lin
   Zhu, Dajiang
   Liu, Jun
   Liu, Wei
   Shen, Dinggang
   Li, Quanzheng
   Liu, Tianming
   Li, Xiang
BE Cao, X
   Xu, X
   Rekik, I
   Cui, Z
   Ouyang, X
TI Tailoring Large Language Models to Radiology: A Preliminary Approach to
   LLM Adaptation for a Highly Specialized Domain
SO MACHINE LEARNING IN MEDICAL IMAGING, MLMI 2023, PT I
SE Lecture Notes in Computer Science
VL 14348
BP 464
EP 473
DI 10.1007/978-3-031-45673-2_46
DT Proceedings Paper
PD 2024
PY 2024
AB In this preliminary work, we present a domain fine-tuned LLM model for
   radiology, an experimental large language model adapted for radiology.
   This model, created through an exploratory application of instruction
   tuning on a comprehensive dataset of radiological information,
   demonstrates promising performance when compared with broader language
   models such as StableLM, Dolly, and LLaMA. This model exhibits initial
   versatility in applications related to radiological diagnosis, research,
   and communication. Our work contributes an early but encouraging step
   towards the evolution of clinical NLP by implementing a large language
   model that is local and domain-specific, conforming to stringent privacy
   norms like HIPAA. The hypothesis of creating customized, large-scale
   language models catering to distinct requirements of various medical
   specialties, presents a thought-provoking direction. The blending of
   conversational prowess and specific domain knowledge in these models
   kindles hope for future enhancements in healthcare AI. While it is still
   in its early stages, the potential of generative large language models
   is intriguing and worthy of further exploration. The demonstration code
   of our domain fine-tuned LLM model for radiology can be accessed at
   https://anonymous.4open.science/r/radiology-llm-demo-C3E2/.
CT 14th International Workshop on Machine Learning in Medical Imaging
   (MLMI)
CY OCT 08, 2023
CL Vancouver, CANADA
Z8 0
ZA 0
ZR 0
ZB 0
TC 10
ZS 0
Z9 10
DA 2024-01-04
UT WOS:001109643200046
ER

PT J
AU Liu, Xiaoguang
   Liu, Peize
   Yang, Bo
   Chen, Yizhan
TI One multi-receiver certificateless searchable public key encryption
   scheme for IoMT assisted by LLM
SO JOURNAL OF INFORMATION SECURITY AND APPLICATIONS
VL 90
AR 104011
DI 10.1016/j.jisa.2025.104011
EA MAR 2025
DT Article
PD MAY 2025
PY 2025
AB The Internet of Medical Things (IoMT) has become widely adopted across
   the healthcare sector, offering transformative benefits. By utilizing a
   range of wearable medical devices and cloud servers, IoMT enables the
   rapid transmission of data over networks, which supports timely health
   monitoring and data-driven decision- making. In recent years, some
   applications have used the Large Language Model (LLM) to assist in
   diagnosis, significantly improving diagnostic efficiency in IoMT.
   However, secure transmission of sensitive medical information remains a
   key concern. To address this, we propose a multi-receiver
   certificateless searchable public key encryption (mCLSPE) scheme that
   leverages proxy re-encryption. This scheme not only addresses the
   inherent issues in searchable public key encryption (SPE) but also
   allows for more flexible addition of receivers and enhances data-sharing
   flexibility. The proposed scheme is proven secure in the random oracle
   model. The performance analysis shows that it has ideal comprehensive
   performance. The growth rate of communication overhead with the increase
   in users is significantly lower compared to other mCLSPE schemes.
   Finally, we design a specific IoMT assisted by LLM application scenario
   based on this scheme.
ZS 0
Z8 0
ZR 0
ZB 0
TC 2
ZA 0
Z9 2
DA 2025-03-21
UT WOS:001443103200001
ER

PT J
AU Gencer, Gulcan
   Gencer, Kerem
TI Large Language Models in Healthcare: A Bibliometric Analysis and
   Examination of Research Trends
SO JOURNAL OF MULTIDISCIPLINARY HEALTHCARE
VL 18
BP 223
EP 238
DI 10.2147/JMDH.S502351
DT Article
PD 2025
PY 2025
AB Background: The integration of large language models (LLMs) in
   healthcare has generated significant interest due to their potential to
   improve diagnostic accuracy, personalization of treatment, and patient
   care efficiency. Objective: This study aims to conduct a comprehensive
   bibliometric analysis to identify current research trends, main themes
   and future directions regarding applications in the healthcare sector.
   Methods: A systematic scan of publications until 08.05.2024 was carried
   out from an important database such as Web of Science.Using bibliometric
   tools such as VOSviewer and CiteSpace, we analyzed data covering
   publication counts, citation analysis, co-authorship, co- occurrence of
   keywords and thematic development to map the intellectual landscape and
   collaborative networks in this field. Results: The analysis included
   more than 500 articles published between 2021 and 2024. The United
   States, Germany and the United Kingdom were the top contributors to this
   field. The study highlights that neural network applications in
   diagnostic imaging, natural language processing for clinical
   documentation, and patient data in the field of general internal
   medicine, radiology, medical informatics, health care services, surgery,
   oncology, ophthalmology, neurology, orthopedics and psychiatry have seen
   significant growth in publications over the past two years. Keyword
   trend analysis revealed emerging sub-themes such as clinical research,
   artificial intelligence, ChatGPT, education, natural language
   processing, clinical management, virtual reality, chatbot, indicating a
   shift towards addressing the broader implications of LLM application in
   healthcare. Conclusion: The use of LLM in healthcare is an expanding
   field with significant academic and clinical interest. This bibliometric
   analysis not only maps the current state of the research, but also
   identifies important areas that require further research and
   development. Continued advances in this field are expected to
   significantly impact future healthcare applications, with a focus on
   increasing the accuracy and personalization of patient care through
   advanced data analytics.
ZR 0
Z8 0
ZS 0
ZA 0
TC 3
ZB 0
Z9 3
DA 2025-01-25
UT WOS:001400829200001
PM 39844924
ER

PT J
AU Kashyap, Aditya M.
   Rao, Delip
   Boland, Mary Regina
   Shen, Li
   Callison-Burch, Chris
TI Predicting explainable dementia types with LLM-aided feature engineering
SO BIOINFORMATICS
VL 41
IS 4
AR btaf156
DI 10.1093/bioinformatics/btaf156
DT Article
PD APR 2025
PY 2025
AB Motivation The integration of Machine Learning and Artificial
   Intelligence (AI) into healthcare has immense potential due to the
   rapidly growing volume of clinical data. However, existing AI models,
   particularly Large Language Models (LLMs) like GPT-4, face significant
   challenges in terms of explainability and reliability, particularly in
   high-stakes domains like healthcare.Results This paper proposes a novel
   LLM-aided feature engineering approach that enhances interpretability by
   extracting clinically relevant features from the Oxford Textbook of
   Medicine. By converting clinical notes into concept vector
   representations and employing a linear classifier, our method achieved
   an accuracy of 0.72, outperforming a traditional n-gram Logistic
   Regression baseline (0.64) and the GPT-4 baseline (0.48), while focusing
   on high-level clinical features. We also explore using Text Embeddings
   to reduce the overall time and cost of our approach by 97%.Availability
   and implementation All code relevant to this paper is available at:
   https://github.com/AdityaKashyap423/Dementia_LLM_Feature_Engineering/tre
   e/main.
TC 0
ZR 0
ZS 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-02
UT WOS:001473768800001
PM 40199828
ER

PT C
AU Makram, Manal
   Mohammed, Ammar
BE AbdelRaouf, A
   Shorim, N
   Hatem, S
   Kandil, Y
   Bahaa-Eldin, A
TI AI Applications in Medical Reporting and Diagnosis
SO 2024 INTERNATIONAL MOBILE, INTELLIGENT, AND UBIQUITOUS COMPUTING
   CONFERENCE, MIUCC 2024
BP 185
EP 192
DI 10.1109/MIUCC62295.2024.10783552
DT Proceedings Paper
PD 2024
PY 2024
AB The integration of artificial intelligence (AI) in healthcare is
   revolutionizing diagnosis and patient care by improving clinical
   documentation and the management of electronic health records that
   depend on medical image interpretation, increasing accuracy, and
   reducing time. Egypt ranks first in liver disease and second in liver
   cancer mortality worldwide in 2020. Large language models, a subset of
   AI techniques, can assist in disease diagnosis. LLM models with
   multimodal capabilities can classify and describe patient scan images
   and extract information from clinical notes. These models can extract
   vital diagnoses with the support of prompt engineering, as one of these
   models can answer questions, summarize information, and translate
   complex medical terminology into plain language, enabling patients to
   understand their medical reports and diagnoses. There are two primary
   approaches to achieving this. First, fine-tuning can adapt the model to
   medical data, which can be resource-intensive. The second approach,
   pre-trained LLM models can be utilized to leverage pre-trained models to
   perform the necessary tasks, focusing on effectively using prompts to
   guide the model for precise and relevant outputs. This study highlights
   the role of generative AI models by focusing on prompt engineering, and
   how carefully crafting prompts can enhance the effectiveness of LLM
   models in medical applications with high accuracy. It demonstrates this
   through experiments using pre-trained models based on semantic
   similarity with GPT-4o and BioGPT. Implementing a zero-shot model for
   liver tumor classification is one of the prompt engineering techniques.
   The performance metrics achieved were impressive, accuracy, precision,
   recall, and F1-scores are 88, 81, 88, and 83 percent, respectively.
CT 4th International Mobile, Intelligent, and Ubiquitous Computing
   Conference
CY NOV 13-14, 2024
CL Cairo, EGYPT
SP Misr International University
ZS 0
Z8 0
ZB 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-03-07
UT WOS:001416363600027
ER

PT J
AU Gilbert, M.
   Crutchfield, A.
   Luo, B.
   Thind, K.
   Ghanem, A. I.
   Siddiqui, F.
TI Using a Large Language Model (LLM) for Automated Extraction of Discrete
   Elements from Clinical Notes for Creation of Cancer Databases
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3371
BP E625
EP E625
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
ZA 0
ZS 0
ZB 0
ZR 0
TC 1
Z9 1
DA 2024-12-16
UT WOS:001325892302054
ER

PT J
AU Dahiya, Dushyant Singh
   Ali, Hassam
   Moond, Vishali
   Shah, M. Danial Ali
   Santana, Christina
   Ali, Noor
   Sheikh, Abu Baker
   Nadeem, Muhammad Ahmad
   Munir, Aqsa
   Quazi, Mohammed A.
   Bharadwaj, Hareesha Rishab
   Sohail, Amir Humza
TI Large Language Models in Gastroenterology and Gastrointestinal Surgery:
   A New Frontier in Patient Communication and Education
SO GASTROENTEROLOGY RESEARCH
VL 18
IS 2
BP 39
EP 48
DI 10.14740/gr2011
DT Review
PD APR 2025
PY 2025
AB When integrated into healthcare, large language models (LLMs) have
   transformative and revolutionary effects, including significant
   potential for improving patient care and streamlining clinical
   processes. However, one specialty that particularly requires data on LLM
   use is gastroenterology and gastrointestinal surgery, a gap we sought to
   address in our research. Advanced artificial intelligence (AI) systems
   like LLMs have demonstrated the ability to mimic human communication,
   assist in diagnosis, provide patient education, and support medical
   research simultaneously. Despite these advantages, challenges such as
   biases, data privacy concerns, and lack of transparency in
   decision-making remain critical. The role of regulations in mitigating
   these risks is widely debated, with proponents advocating for structured
   oversight to enhance trust and patient safety, while others caution
   against potential barriers to innovation. Rather than replacing human
   expertise, AI should be integrated thoughtfully to complement clinical
   decision-making. Ensuring a balanced approach requires col-laboration
   between medical professionals, AI developers, and poli-cymakers to
   optimize its responsible implementation in healthcare.
ZB 0
Z8 0
TC 0
ZA 0
ZR 0
ZS 0
Z9 0
DA 2025-05-24
UT WOS:001491973300001
PM 40322195
ER

PT J
AU Gabriel, Rodney A.
   Litake, Onkar
   Simpson, Sierra
   Burton, Brittany N.
   Waterman, Ruth S.
   Macias, Alvaro A.
TI On the development and validation of large language model- based
   classifiers for identifying social determinants of health
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
VL 121
IS 39
AR e2320716121
DI 10.1073/pnas.2320716121
DT Article
PD SEP 24 2024
PY 2024
AB The assessment of social determinants of health (SDoH) within healthcare
   systems is crucial for comprehensive patient care and addressing health
   disparities. Current challenges arise from the limited inclusion of
   structured SDoH information within electronic health record (EHR)
   systems, often due to the lack of standardized diagnosis codes. This
   study delves into the transformative potential of large language models
   (LLM) to overcome these challenges. LLM-based classifiers-using
   Bidirectional Encoder Representations from Transformers (BERT) and A
   Robustly Optimized BERT Pretraining Approach (RoBERTa)-were developed
   for SDoH concepts, including homelessness, food insecurity, and domestic
   violence, using synthetic training datasets generated by generative pre-
   trained transformers combined with authentic clinical notes. Models were
   then validated on separate datasets: Medical Information Mart for
   Intensive Care- III and our institutional EHR data. When training the
   model with a combination of synthetic and authentic notes, validation on
   our institutional dataset yielded an area under the receiver operating
   characteristics curve of 0.78 for detecting homelessness, 0.72 for
   detecting food insecurity, and 0.83 for detecting domestic violence.
   This study underscores the potential of LLMs in extracting SDoH
   information from clinical text. Automated detection of SDoH may be
   instrumental for healthcare providers in identifying at- risk patients,
   guiding targeted interventions, and contributing to population health
   initiatives aimed at mitigating disparities.
TC 5
ZA 0
ZS 0
ZR 0
ZB 2
Z8 0
Z9 5
DA 2024-12-11
UT WOS:001369554000005
PM 39284061
ER

PT C
AU Chang, Jocelyn J.
   Chang, Edward Y.
GP IEEE COMPUTER SOC
TI SocraHealth: hnhancing Medical Diagnosis and Correcting Historical
   Records
SO 2023 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL
   INTELLIGENCE, CSCI 2023
SE International Conference on Computational Science and Computational
   Intelligence
BP 1400
EP 1405
DI 10.1109/CSCI62032.2023.00229
DT Proceedings Paper
PD 2023
PY 2023
AB This study introduces SocraHealth, an innovative method using Large
   Language Models (LLMs) for medical diagnostics. By engaging LLM-based
   agents in structured debates, Socrallealth not only refines diagnoses
   but also corrects historical record inaccuracies, utilizing patient data
   effectively. The case study, featuring GPT-4 and Bard across two
   experiments, showcases this approach's success in producing logical,
   hallucination free debates. Demonstrating a significant advancement over
   traditional diagnostic techniques, Socrallealth highlights the
   transformative power of LLMs in healthcare, especially in enhancing
   diagnostic accuracy and rectifying past diagnostic errors.
CT International Conference on Computational Science and Computational
   Intelligence (CSCI)
CY DEC 13-15, 2023
CL Las Vegas, NV
SP IEEE
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
ZA 0
Z9 0
DA 2024-09-07
UT WOS:001283930300235
ER

PT B
AU Gu, Zhanzhong
Z2  
TI Automatic Quantitative Stroke Severity Assessment from Chinese
   Electronic Health Records Based on Advanced Large Language Models
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
UT PQDT:121107541
ER

PT J
AU Pan, Jie
   Lee, Seungwon
   Cheligeer, Cheligeer
   Martin, Elliot A
   Riazi, Kiarash
   Quan, Hude
   Li, Na
TI Integrating large language models with human expertise for disease
   detection in electronic health records.
SO Computers in biology and medicine
VL 191
BP 110161
EP 110161
DI 10.1016/j.compbiomed.2025.110161
DT Journal Article
PD 2025-Jun
PY 2025
AB OBJECTIVE: Electronic health records (EHR) are widely available to
   complement administrative data-based disease surveillance and healthcare
   performance evaluation. Defining conditions from EHR is labour-intensive
   and requires extensive manual labelling of disease outcomes. This study
   developed an efficient strategy based on advanced large language models
   to identify multiple conditions from EHR clinical notes.
   METHODS: We linked a cardiac registry cohort in 2015 with an EHR system
   in Alberta, Canada. We developed a pipeline that leveraged a generative
   large language model (LLM) to analyze, understand, and interpret EHR
   notes by prompts based on specific diagnosis, treatment management, and
   clinical guidelines. The pipeline was applied to detect acute myocardial
   infarction (AMI), diabetes, and hypertension. The performance was
   compared against clinician-validated diagnoses as the reference standard
   and widely adopted International Classification of Diseases (ICD)
   codes-based methods.
   RESULTS: The study cohort accounted for 3088 patients and 551,095
   clinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI,
   diabetes, and hypertension, respectively. The performance of the
   LLM-based pipeline for detecting conditions varied: AMI had 88%
   sensitivity, 63% specificity, and 77% positive predictive value (PPV);
   diabetes had 91% sensitivity, 86% specificity, and 71% PPV; and
   hypertension had 94% sensitivity, 32% specificity, and 72% PPV. Compared
   with ICD codes, the LLM-based method demonstrated improved sensitivity
   and negative predictive value across all conditions. The monthly
   percentage trends from the detected cases by LLM and reference standard
   showed consistent patterns.
   CONCLUSION: The proposed LLM-based pipeline demonstrated reasonable
   accuracy and high efficiency in disease detection for multiple
   conditions. Human expert knowledge can be integrated into the pipeline
   to guide EHR note analysis without manually curated labels. The method
   could enable comprehensive real-time disease surveillance using EHRs.
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-04-11
UT MEDLINE:40198990
PM 40198990
ER

PT J
AU Lee, Jung-Hyun
   Choi, Eunhee
   Angulo, Sergio L.
   Mcdougal, Robert A.
   Lytton, William W.
TI Neurological history both twinned and queried by generative artificial
   intelligence
SO FRONTIERS IN MEDICINE
VL 11
AR 1496866
DI 10.3389/fmed.2024.1496866
DT Article
PD JAN 17 2025
PY 2025
AB Background and objectives We propose the use of GPT-4 to facilitate
   initial history-taking in neurology and other medical specialties. A
   large language model (LLM) could be utilized as a digital twin which
   could enhance queryable electronic medical record (EMR) systems and
   provide healthcare conversational agents (HCAs) to replace waiting-room
   questionnaires.Methods In this observational pilot study, we presented
   verbatim history of present illness (HPI) narratives from published case
   reports of headache, stroke, and neurodegenerative diseases. Three
   standard GPT-4 models were designated Models P: patient digital twin; N:
   neurologist to query Model P; and S: supervisor to synthesize the N-P
   dialogue into a derived HPI and formulate the differential diagnosis.
   Given the random variability of GPT-4 output, each case was presented
   five separate times to check consistency and reliability.Results The
   study achieved an overall HPI content retrieval accuracy of 81%, with
   accuracies of 84% for headache, 82% for stroke, and 77% for
   neurodegenerative diseases. Retrieval accuracies for individual HPI
   components were as follows: 93% for chief complaints, 47% for associated
   symptoms and review of systems, 76% for relevant symptom details, and
   94% for histories of past medical, surgical, allergies, social, and
   family factors. The ranking of case diagnoses in the differential
   diagnosis list averaged in the 89th percentile.Discussion Our tripartite
   LLM model demonstrated accuracy in extracting essential information from
   published case reports. Further validation with EMR HPIs, and then with
   direct patient care will be needed to move toward adaptation of enhanced
   diagnostic digital twins that incorporate real-time data from
   health-monitoring devices and self-monitoring assessments.
ZS 0
ZB 0
ZR 0
Z8 0
TC 0
ZA 0
Z9 0
DA 2025-02-05
UT WOS:001409771700001
PM 39895821
ER

PT J
AU Alsaif, Khalid
   Albeshri, Aiiad
   Khemakhem, Maher
   Eassa, Fathy
TI Healthcare 4.0: A Large Language Model-Based Blockchain Framework for
   Medical Device Fault Detection and Diagnostics
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
VL 16
IS 4
BP 980
EP 992
DT Article
PD 2025
PY 2025
AB This paper introduces a novel framework integrating Large Language
   Models (LLMs) with blockchain technology for medical device fault
   detection and diagnostics in Healthcare 4.0 environments. The proposed
   framework addresses key challenges, including real-time fault detection,
   data security, and automated diagnostics through a multi-layered
   architecture incorporating Internet of Things (IoT) integration,
   blockchain-based security, and LLM-driven diagnostics. Experimental
   evaluations demonstrate substantial improvements in diagnostic accuracy
   and response time while maintaining stringent security standards and
   regulatory compliance. The system provides enhanced fault detection with
   real-time monitoring capabilities and secure maintenance record
   management for smart healthcare. Comparative analysis of different LLMs
   and traditional Machine Learning (ML) methods shows that Deepseek-R1:7b
   achieved 97.6% classification accuracy, while O3-mini reached 90.4% and
   91.2% in diagnosis accuracy and problem identification, respectively.
   Claude demonstrated the highest technical accuracy (98.4%), while
   Traditional ML excelled in processing time (11.7) and processing rate
   (10.68). Deepseek-R1:7b's offline capabilities ensure stringent
   security, privacy, and confidentiality with restricted connectivity,
   making it particularly suitable for sensitive healthcare applications
   where data protection is paramount.
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-06-14
UT WOS:001503392900001
ER

PT J
AU Xu, Xiaowei
   Jiang, Ruixuan
   Zheng, Si
   Wang, Min
   Ju, Yi
   Li, Jiao
TI Classification of Chronic Dizziness Using Large Language Models
SO JOURNAL OF HEALTHCARE INFORMATICS RESEARCH
VL 9
IS 1
BP 88
EP 102
DI 10.1007/s41666-024-00178-1
EA NOV 2024
DT Article
PD MAR 2025
PY 2025
AB Efficiently classifying chronic dizziness disorders, including
   persistent postural-perceptual dizziness (PPPD), anxiety, and depressive
   disorders, is crucial, particularly in primary healthcare settings. This
   study introduces DizzyInsight, an innovative etiological classification
   model, designed to enhance the accuracy and reliability of large
   language model (LLM) and machine learning approaches for etiological
   classification of chronic dizziness. Eight physicians specializing in
   chronic dizziness diagnosis, affiliated with the Clinical Center for
   Vertigo and Balance Disturbance at Beijing Tiantan Hospital, Capital
   Medical University, furnished comprehensive definitions and evaluations
   of chronic dizziness characteristics. The study included 260 patients,
   consisting of 105 males and 155 females, with a mean age of 59.52 +/- 13
   years. These patients were recruited from the same center between July
   2021 and October 2023. For comparative analysis, we utilized the general
   models bidirectional encoder representations from transformers (BERT)
   and LLM to assess different outcomes. Seven major categories and 33
   subcategory evidence have been defined for etiological classification of
   chronic dizziness. With DizzyInsight, we constructed the feature dataset
   regarding chronic dizziness. The DizzyInsight based on the identified
   evidence of LLM method yielded a positive predictive value of 0.69, a
   sensitivity of 0.86 for persistent postural-perceptual dizziness (PPPD),
   a positive predictive value of 0.81, and a sensitivity of 0.66 for
   anxiety and depressive disorders. These findings highlight the potential
   of DizzyInsight leveraging LLM to improve the efficacy and
   interpretability of machine learning models in etiological
   classification of chronic dizziness disorders. Further research and
   model development are necessary to improve the accuracy of evidence
   identification and assess the applicability of DizzyInsight in primary
   care settings, as well as to evaluate its external validity.
TC 0
ZS 0
Z8 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2024-11-30
UT WOS:001361419000001
PM 39897102
ER

PT J
AU Abbasian, Mahyar
   Khatibi, Elahe
   Azimi, Iman
   Oniani, David
   Abad, Zahra Shakeri Hossein
   Thieme, Alexander
   Sriram, Ram
   Yang, Zhongqi
   Wang, Yanshan
   Lin, Bryant
   Gevaert, Olivier
   Li, Li-Jia
   Jain, Ramesh
   Rahmani, Amir M.
TI Foundation metrics for evaluating effectiveness of healthcare
   conversations powered by generative AI
SO NPJ DIGITAL MEDICINE
VL 7
IS 1
AR 82
DI 10.1038/s41746-024-01074-z
DT Review
PD MAR 29 2024
PY 2024
AB Generative Artificial Intelligence is set to revolutionize healthcare
   delivery by transforming traditional patient care into a more
   personalized, efficient, and proactive process. Chatbots, serving as
   interactive conversational models, will probably drive this
   patient-centered transformation in healthcare. Through the provision of
   various services, including diagnosis, personalized lifestyle
   recommendations, dynamic scheduling of follow-ups, and mental health
   support, the objective is to substantially augment patient health
   outcomes, all the while mitigating the workload burden on healthcare
   providers. The life-critical nature of healthcare applications
   necessitates establishing a unified and comprehensive set of evaluation
   metrics for conversational models. Existing evaluation metrics proposed
   for various generic large language models (LLMs) demonstrate a lack of
   comprehension regarding medical and health concepts and their
   significance in promoting patients' well-being. Moreover, these metrics
   neglect pivotal user-centered aspects, including trust-building, ethics,
   personalization, empathy, user comprehension, and emotional support. The
   purpose of this paper is to explore state-of-the-art LLM-based
   evaluation metrics that are specifically applicable to the assessment of
   interactive conversational models in healthcare. Subsequently, we
   present a comprehensive set of evaluation metrics designed to thoroughly
   assess the performance of healthcare chatbots from an end-user
   perspective. These metrics encompass an evaluation of language
   processing abilities, impact on real-world clinical tasks, and
   effectiveness in user-interactive conversations. Finally, we engage in a
   discussion concerning the challenges associated with defining and
   implementing these metrics, with particular emphasis on confounding
   factors such as the target audience, evaluation methods, and prompt
   techniques involved in the evaluation process.
ZB 8
Z8 0
ZA 0
ZS 0
TC 38
ZR 0
Z9 38
DA 2024-04-12
UT WOS:001195095800001
PM 38553625
ER

PT J
AU Cusido, Jordi
   Sole-Vilaro, Lluc
   Marti-Puig, Pere
   Sole-Casals, Jordi
TI Assessing the Capability of Advanced AI Models in Cardiovascular Symptom
   Recognition: A Comparative Study
SO APPLIED SCIENCES-BASEL
VL 14
IS 18
AR 8440
DI 10.3390/app14188440
DT Article
PD SEP 2024
PY 2024
AB The field of medical informatics has been significantly transformed in
   recent years with the emergence of Natural Language Understanding (NLU)
   and Large Language Models (LLM), providing new opportunities for
   innovative patient care solutions. This study aims to evaluate the
   effectiveness of publicly available LLMs as symptom checkers for
   cardiological diseases by comparing their diagnostic capabilities in
   real disease cases. We employed a set of 9 models, including ChatGPT-4,
   OpenSource models, Google PaLM 2, and Meta's LLaMA, to assess their
   diagnostic accuracy, reliability, and safety across various clinical
   scenarios. Our methodology involved presenting these LLMs with symptom
   descriptions and test results in Spanish, requiring them to provide
   specialist diagnoses and recommendations in English. This approach
   allowed us to compare the performance of each model, highlighting their
   respective strengths and limitations in a healthcare context. The
   results revealed varying levels of accuracy, precision, and sensitivity
   among the models, demonstrating the potential of LLMs to enhance medical
   education and patient care. By analysing the capabilities of each model,
   our study contributes to a deeper understanding of artificial
   intelligence's role in medical diagnosis. We argue for the strategic
   implementation of LLMs in healthcare, emphasizing the importance of
   balancing sensitivity and realism to optimize patient outcomes.
ZB 0
TC 2
ZR 0
ZS 0
ZA 0
Z8 0
Z9 2
DA 2024-10-07
UT WOS:001323933700001
ER

PT J
AU Gu, Zhanzhong
   Jia, Wenjing
   Piccardi, Massimo
   Yu, Ping
TI Empowering large language models for automated clinical assessment with
   generation-augmented retrieval and hierarchical chain-of-thought
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
VL 162
AR 103078
DI 10.1016/j.artmed.2025.103078
EA FEB 2025
DT Article
PD APR 2025
PY 2025
AB Background: Understanding and extracting valuable information from
   electronic health records (EHRs) is important for improving healthcare
   delivery and health outcomes. Large language models (LLMs) have
   demonstrated significant proficiency in natural language understanding
   and processing, offering promises for automating the typically
   labor-intensive and time-consuming analytical tasks with EHRs. Despite
   the active application of LLMs in the healthcare setting, many
   foundation models lack real-world healthcare relevance. Applying LLMs to
   EHRs is still in its early stage. To advance this field, in this study,
   we pioneer a generation- augmented prompting paradigm "GAPrompt"to
   empower generic LLMs for automated clinical assessment, in particular,
   quantitative stroke severity assessment, using data extracted from EHRs.
   Methods: The GAPrompt paradigm comprises five components: (i)
   prompt-driven selection of LLMs, (ii) generation-augmented construction
   of a knowledge base, (iii) summary-based generation-augmented retrieval
   (SGAR); (iv) inferencing with a hierarchical chain-of-thought (HCoT),
   and (v) ensembling of multiple generations. Results: GAPrompt addresses
   the limitations of generic LLMs in clinical applications in a
   progressive manner. It efficiently evaluates the applicability of LLMs
   in specific tasks through LLM selection prompting, enhances their
   understanding of task-specific knowledge from the constructed knowledge
   base, improves the accuracy of knowledge and demonstration retrieval via
   SGAR, elevates LLM inference precision through HCoT, enhances generation
   robustness, and reduces hallucinations of LLM via ensembling. Experiment
   results demonstrate the capability of our method to empower LLMs to
   automatically assess EHRs and generate quantitative clinical assessment
   results. Conclusion: Our study highlights the applicability of enhancing
   the capabilities of foundation LLMs in medical domain-specific tasks,
   i.e., automated quantitative analysis of EHRs, addressing the challenges
   of labor-intensive and often manually conducted quantitative assessment
   of stroke in clinical practice and research. This approach offers a
   practical and accessible GAPrompt paradigm for researchers and industry
   practitioners seeking to leverage the power of LLMs in domain-specific
   applications. Its utility extends beyond the medical domain, applicable
   to a wide range of fields.
ZA 0
Z8 0
TC 2
ZB 0
ZR 0
ZS 0
Z9 2
DA 2025-03-01
UT WOS:001429469000001
PM 39978047
ER

PT J
AU Ardila, Carlos M.
   Gonzalez-Arroyave, Daniel
   Ramirez-Arbelaez, Jaime
TI Advancing large language models as patient education tools for
   inflammatory bowel disease
SO WORLD JOURNAL OF GASTROENTEROLOGY
VL 31
IS 20
AR 105285
DI 10.3748/wjg.v31.i20.105285
DT Letter
PD MAY 28 2025
PY 2025
AB This article evaluates the transformative potential of large language
   models (LLMs) as patient education tools for managing inflammatory bowel
   disease. The discussion highlights their ability to deliver nuanced and
   personalized information, addressing limitations in traditional
   educational materials. Key considerations include the necessity for
   domain-specific fine-tuning to enhance accuracy, the adoption of robust
   evaluation metrics beyond readability, and the integration of LLMs with
   clinical decision support systems to improve real-time patient
   education. Ethical and accessibility challenges, such as algorithmic
   bias, data privacy, and digital literacy, are also examined.
   Recommendations emphasize the importance of interdisciplinary
   collaboration to optimize LLM integration, ensuring equitable access and
   improved patient outcomes. By advancing LLM technology, healthcare can
   empower patients with accurate and personalized information, enhancing
   engagement and disease management.
Z8 0
ZS 0
TC 0
ZR 0
ZA 0
ZB 0
Z9 0
DA 2025-06-08
UT WOS:001501422800007
PM 40495941
ER

PT J
AU Liu, Xiaohong
   Liu, Hao
   Yang, Guoxing
   Jiang, Zeyu
   Cui, Shuguang
   Zhang, Zhaoze
   Wang, Huan
   Tao, Liyuan
   Sun, Yongchang
   Song, Zhu
   Hong, Tianpei
   Yang, Jin
   Gao, Tianrun
   Zhang, Jiangjiang
   Li, Xiaohu
   Zhang, Jing
   Sang, Ye
   Yang, Zhao
   Xue, Kanmin
   Wu, Song
   Zhang, Ping
   Yang, Jian
   Song, Chunli
   Wang, Guangyu
TI A generalist medical language model for disease diagnosis assistance
SO NATURE MEDICINE
VL 31
IS 3
DI 10.1038/s41591-024-03416-6
EA JAN 2025
DT Article
PD MAR 2025
PY 2025
AB The delivery of accurate diagnoses is crucial in healthcare and
   represents the gateway to appropriate and timely treatment. Although
   recent large language models (LLMs) have demonstrated impressive
   capabilities in few-shot or zero-shot learning, their effectiveness in
   clinical diagnosis remains unproven. Here we present MedFound, a
   generalist medical language model with 176 billion parameters,
   pre-trained on a large-scale corpus derived from diverse medical text
   and real-world clinical records. We further fine-tuned MedFound to learn
   physicians' inferential diagnosis with a self-bootstrapping
   strategy-based chain-of-thought approach and introduced a unified
   preference alignment framework to align it with standard clinical
   practice. Extensive experiments demonstrate that our medical LLM
   outperforms other baseline LLMs and specialized models in
   in-distribution (common diseases), out-of-distribution (external
   validation) and long-tailed distribution (rare diseases) scenarios
   across eight specialties. Further ablation studies indicate the
   effectiveness of key components in our medical LLM training approach. We
   conducted a comprehensive evaluation of the clinical applicability of
   LLMs for diagnosis involving artificial intelligence (AI) versus
   physician comparison, AI-assistance study and human evaluation
   framework. Our proposed framework incorporates eight clinical evaluation
   metrics, covering capabilities such as medical record summarization,
   diagnostic reasoning and risk management. Our findings demonstrate the
   model's feasibility in assisting physicians with disease diagnosis as
   part of the clinical workflow.
Z8 0
ZB 0
ZA 0
ZS 0
TC 3
ZR 0
Z9 3
DA 2025-01-13
UT WOS:001391696700001
PM 39779927
ER

PT J
AU Bannett, Yair
   Gunturkun, Fatma
   Pillai, Malvika
   Herrmann, Jessica E
   Luo, Ingrid
   Huffman, Lynne C
   Feldman, Heidi M
TI Leveraging a Large Language Model to Assess Quality-of-Care: Monitoring
   ADHD Medication Side Effects.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2024.04.23.24306225
DT Preprint
PD 2024 Apr 24
PY 2024
AB Objective: To assess the accuracy of a large language model (LLM) in
   measuring clinician adherence to practice guidelines for monitoring side
   effects after prescribing medications for children with
   attention-deficit/hyperactivity disorder (ADHD).
   Methods: Retrospective population-based cohort study of electronic
   health records. Cohort included children aged 6-11 years with ADHD
   diagnosis and ≥2 ADHD medication encounters (stimulants or
   non-stimulants prescribed) between 2015-2022 in a community-based
   primary healthcare network (n=1247). To identify documentation of side
   effects inquiry, we trained, tested, and deployed an open-source LLM
   (LLaMA) on all clinical notes from ADHD-related encounters (ADHD
   diagnosis or ADHD medication prescription), including
   in-clinic/telehealth and telephone encounters (n=15,593 notes). Model
   performance was assessed using holdout and deployment test sets,
   compared to manual chart review.
   Results: The LLaMA model achieved excellent performance in classifying
   notes that contain side effects inquiry (sensitivity= 87.2%,
   specificity=86.3/90.3%, area under curve (AUC)=0.93/0.92 on
   holdout/deployment test sets). Analyses revealed no model bias in
   relation to patient age, sex, or insurance. Mean age (SD) at first
   prescription was 8.8 (1.6) years; patient characteristics were similar
   across patients with and without documented side effects inquiry. Rates
   of documented side effects inquiry were lower in telephone encounters
   than in-clinic/telehealth encounters (51.9% vs. 73.0%, p<0.01). Side
   effects inquiry was documented in 61% of encounters following stimulant
   prescriptions and 48% of encounters following non-stimulant
   prescriptions (p<0.01).
   Conclusions: Deploying an LLM on a variable set of clinical notes,
   including telephone notes, offered scalable measurement of
   quality-of-care and uncovered opportunities to improve
   psychopharmacological medication management in primary care.
ZS 0
TC 0
ZR 0
ZB 0
Z8 0
ZA 0
Z9 0
DA 2024-05-09
UT MEDLINE:38712037
PM 38712037
ER

PT C
AU Kumi, Sandra
   Ray, Madhurima
   Walia, Sanskriti
   Lomotey, Richard K.
   Deters, Ralph
BE Paul, R
   Kundu, A
   Bhattacharyya, R
TI Digital Twins for Stress Management Utilizing Synthetic Data
SO 2024 IEEE 5TH ANNUAL WORLD AI IOT CONGRESS, AIIOT 2024
BP 0329
EP 0335
DI 10.1109/AIIoT61789.2024.10579038
DT Proceedings Paper
PD 2024
PY 2024
AB In the era of Medical 4.0, technologies such as big data, wearables, and
   Machine Learning (ML) are being deployed for predictive healthcare
   delivery. In this regard, digital twins have been adopted in healthcare
   to enhance diagnosis and personalized treatment. Health Digital Twins
   (HDTs) are virtual representations of patients' data, mirroring the
   health state of patients to provide insights. Despite its promise, the
   existing works on HDTs relied on large historical data to train ML
   models. These historical data may be difficult to obtain due to privacy
   concerns of data fiduciaries and subjects. In this paper, we propose a
   Digital Twin for Stress Management (DTSM) that employs generative models
   to learn the distribution of patients' data retrieved from a wearable
   device for stress management score prediction. To obtain a virtual
   replica of a patient's data, we used synthetic data generative models
   such as Conditional Tabular Generative Adversarial Network (CTGAN),
   Tabular Variational Autoencoder (TVAE), Gaussian Copula, and Large
   Language Models (LLM) (REaLTabFormer and GReaT). The best result came
   from REaLTabFormer which accurately learns the distributions of the real
   data with a data quality score of approximately 93%. Furthermore, four
   wellknown ML models trained on the synthetic data obtained a mean
   absolute error (MAE) of less than 5% in the prediction of stress score.
   Our experimental results show that the proposed DTSM can be used for the
   prediction of stress management scores.
CT IEEE 5th Annual World AI IoT Congress (AIIoT)
CY MAY 29-31, 2024
CL WA
SP IEEE; SMART; IEEE USA; Inst Engn & Management; Univ Engn & Management
ZR 0
ZA 0
Z8 0
ZB 0
TC 1
ZS 0
Z9 1
DA 2024-10-10
UT WOS:001289206000048
ER

PT J
AU Sai, Siva
   Gaur, Aanchal
   Sai, Revant
   Chamola, Vinay
   Guizani, Mohsen
   Rodrigues, Joel J. P. C.
TI Generative AI for Transformative Healthcare: A Comprehensive Study of
   Emerging Models, Applications, Case Studies, and Limitations
SO IEEE ACCESS
VL 12
BP 31078
EP 31106
DI 10.1109/ACCESS.2024.3367715
DT Article
PD 2024
PY 2024
AB Generative artificial intelligence (GAI) can be broadly described as an
   artificial intelligence system capable of generating images, text, and
   other media types with human prompts. GAI models like ChatGPT, DALL-E,
   and Bard have recently caught the attention of industry and academia
   equally. GAI applications span various industries like art, gaming,
   fashion, and healthcare. In healthcare, GAI shows promise in medical
   research, diagnosis, treatment, and patient care and is already making
   strides in real-world deployments. There has yet to be any detailed
   study concerning the applications and scope of GAI in healthcare.
   Addressing this research gap, we explore several applications,
   real-world scenarios, and limitations of GAI in healthcare. We examine
   how GAI models like ChatGPT and DALL-E can be leveraged to aid in the
   applications of medical imaging, drug discovery, personalized patient
   treatment, medical simulation and training, clinical trial optimization,
   mental health support, healthcare operations and research, medical
   chatbots, human movement simulation, and a few more applications. Along
   with applications, we cover four real-world healthcare scenarios that
   employ GAI: visual snow syndrome diagnosis, molecular drug optimization,
   medical education, and dentistry. We also provide an elaborate
   discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT,
   DeepHealth, etc.,Since GAI is still evolving, it poses challenges like
   the lack of professional expertise in decision making, risk of patient
   data privacy, issues in integrating with existing healthcare systems,
   and the problem of data bias which are elaborated on in this work along
   with several other challenges. We also put forward multiple directions
   for future research in GAI for healthcare.
ZS 0
ZA 0
Z8 0
ZR 0
ZB 5
TC 39
Z9 40
DA 2024-03-21
UT WOS:001176001000001
ER

PT J
AU Beheshti, Mohammad
   Toubal, Imad Eddine
   Alaboud, Khuder
   Almalaysha, Mohammed
   Ogundele, Olabode B.
   Turabieh, Hamza
   Abdalnabi, Nader
   Boren, Suzanne A.
   Scott, Grant J.
   Dahu, Butros M.
TI Evaluating the Reliability of ChatGPT for Health-Related Questions: A
   Systematic Review
SO INFORMATICS-BASEL
VL 12
IS 1
AR 9
DI 10.3390/informatics12010009
DT Review
PD JAN 17 2025
PY 2025
AB The rapid advancement of large language models like ChatGPT has
   significantly impacted natural language processing, expanding its
   applications across various fields, including healthcare. However, there
   remains a significant gap in understanding the consistency and
   reliability of ChatGPT's performance across different medical domains.
   We conducted this systematic review according to an LLM-assisted PRISMA
   setup. The high-recall search term "ChatGPT" yielded 1101 articles from
   2023 onwards. Through a dual-phase screening process, initially
   automated via ChatGPT and subsequently manually by human reviewers, 128
   studies were included. The studies covered a range of medical
   specialties, focusing on diagnosis, disease management, and patient
   education. The assessment metrics varied, but most studies compared
   ChatGPT's accuracy against evaluations by clinicians or reliable
   references. In several areas, ChatGPT demonstrated high accuracy,
   underscoring its effectiveness. However, performance varied, and some
   contexts revealed lower accuracy. The mixed outcomes across different
   medical domains emphasize the challenges and opportunities of
   integrating AI like ChatGPT into healthcare. The high accuracy in
   certain areas suggests that ChatGPT has substantial utility, yet the
   inconsistent performance across all applications indicates a need for
   ongoing evaluation and refinement. This review highlights ChatGPT's
   potential to improve healthcare delivery alongside the necessity for
   continued research to ensure its reliability.
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
TC 0
Z9 0
DA 2025-03-31
UT WOS:001452439400001
ER

PT J
AU Schmidl, Benedikt
   Huetten, Tobias
   Pigorsch, Steffi
   Stoegbauer, Fabian
   Hoch, Cosima C.
   Hussain, Timon
   Wollenberg, Barbara
   Wirth, Markus
TI Assessing the use of the novel tool Claude 3 in comparison to ChatGPT
   4.0 as an artificial intelligence tool in the diagnosis and therapy of
   primary head and neck cancer cases
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6099
EP 6109
DI 10.1007/s00405-024-08828-1
EA AUG 2024
DT Article
PD NOV 2024
PY 2024
AB ObjectivesHead and neck squamous cell carcinoma (HNSCC) is a complex
   malignancy that requires a multidisciplinary tumor board approach for
   individual treatment planning. In recent years, artificial intelligence
   tools have emerged to assist healthcare professionals in making informed
   treatment decisions. This study investigates the application of the
   newly published LLM Claude 3 Opus compared to the currently most
   advanced LLM ChatGPT 4.0 for the diagnosis and therapy planning of
   primary HNSCC. The results were compared to that of a conventional
   multidisciplinary tumor board; (2) Materials and Methods: We conducted a
   study in March 2024 on 50 consecutive primary head and neck cancer
   cases. The diagnostics and MDT recommendations were compared to the
   Claude 3 Opus and ChatGPT 4.0 recommendations for each patient and rated
   by two independent reviewers for the following parameters: clinical
   recommendation, explanation, and summarization in addition to the
   Artificial Intelligence Performance Instrument (AIPI); (3) Results: In
   this study, Claude 3 achieved better scores for the diagnostic workup of
   patients than ChatGPT 4.0 and provided treatment recommendations
   involving surgery, chemotherapy, and radiation therapy. In terms of
   clinical recommendations, explanation and summarization Claude 3 scored
   similar to ChatGPT 4.0, listing treatment recommendations which were
   congruent with the MDT, but failed to cite the source of the
   information; (4) Conclusion: This study is the first analysis of Claude
   3 for primary head and neck cancer cases and demonstrates a superior
   performance in the diagnosis of HNSCC than ChatGPT 4.0 and similar
   results for therapy recommendations. This marks the advent of a newly
   launched advanced AI model that may be superior to ChatGPT 4.0 for the
   assessment of primary head and neck cancer cases and may assist in the
   clinical diagnostic and MDT setting.
   Claude 3 OpusHNSCCMultidisciplinary TumorboardArtificial IntelligenceLLM
ZA 0
ZS 0
ZB 4
TC 17
Z8 0
ZR 0
Z9 17
DA 2024-08-13
UT WOS:001285919100001
PM 39112556
ER

PT J
AU Kozaily, Elie
   Geagea, Mabelissa
   Akdogan, Ecem R.
   Atkins, Jessica
   Elshazly, Mohamed B.
   Guglin, Maya
   Tedford, Ryan J.
   Wehbe, Ramsey M.
TI Accuracy and consistency of online large language model-based artificial
   intelligence chat platforms in answering patients' questions about heart
   failure
SO INTERNATIONAL JOURNAL OF CARDIOLOGY
VL 408
AR 132115
DI 10.1016/j.ijcard.2024.132115
EA MAY 2024
DT Article
PD AUG 1 2024
PY 2024
AB Background: Heart failure (HF) is a prevalent condition associated with
   significant morbidity. Patients may have questions that they feel
   embarrassed to ask or will face delays awaiting responses from their
   healthcare providers which may impact their health behavior. We aimed to
   investigate the potential of large language model (LLM) based artificial
   intelligence (AI) chat platforms in complementing the delivery of
   patient -centered care. Methods: Using online patient forums and
   physician experience, we created 30 questions related to diagnosis,
   management and prognosis of HF. The questions were posed to two
   LLM-based AI chat platforms (OpenAI's ChatGPT-3.5 and Google's Bard).
   Each set of answers was evaluated by two HF experts, independently and
   blinded to each other, for accuracy (adequacy of content) and
   consistency of content. Results: ChatGPT provided mostly appropriate
   answers (27/30, 90%) and showed a high degree of consistency (93%). Bard
   provided a similar content in its answers and thus was evaluated only
   for adequacy (23/30, 77%). The two HF experts' grades were concordant in
   83% and 67% of the questions for ChatGPT and Bard, respectively.
   Conclusion: LLM-based AI chat platforms demonstrate potential in
   improving HF education and empowering patients, however, these platforms
   currently suffer from issues related to factual errors and difficulty
   with more contemporary recommendations. This inaccurate information may
   pose serious and life -threatening implications for patients that should
   be considered and addressed in future research.
TC 13
ZB 0
ZS 0
ZR 0
ZA 0
Z8 0
Z9 13
DA 2024-06-15
UT WOS:001240180400001
PM 38697402
ER

PT J
AU McInerney, Samuel
   Nash, Tamsin
   Lee, Rebecca
   Falis, Matus
   Gruber, Franz
   Casey, Arlene
TI AI Chatbot for Cancer Patient Support: Development and Evaluation Using
   Llama 3.1, Mistral 7B, and PHI 3B.
SO Studies in health technology and informatics
VL 327
BP 890
EP 891
DI 10.3233/SHTI250494
DT Journal Article
PD 2025-May-15
PY 2025
AB This study develops and evaluates a question-answering (Q&A) system for
   breast cancer patients using generative AI technologies. We compared the
   performance of three language models-Llama 3.1, Mistral 7B and Phi 3.5.
   The goal is to integrate this system into a patient-facing application,
   providing personalised, interactive support based on reliable sources
   such as Cancer Research UK. However, findings indicate that
   misinformation remains a significant concern. Medical chatbots utilising
   retrieval augmented generation (RAG) providing clinical information
   require significant refinement before being suitable for clinical use.
ZB 0
TC 0
ZR 0
Z8 0
ZS 0
ZA 0
Z9 0
DA 2025-05-20
UT MEDLINE:40380602
PM 40380602
ER

PT J
AU Zheng, Ce
   Ye, Hongfei
   Guo, Jinming
   Yang, Junrui
   Fei, Ping
   Yuan, Yuanzhi
   Huang, Danqing
   Huang, Yuqiang
   Peng, Jie
   Xie, Xiaoling
   Xie, Meng
   Zhao, Peiquan
   Chen, Li
   Zhang, Mingzhi
TI Development and evaluation of a large language model of ophthalmology in
   Chinese
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1390
EP 1397
DI 10.1136/bjo-2023-324526
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background Large language models (LLMs), such as ChatGPT, have
   considerable implications for various medical applications. However,
   ChatGPT's training primarily draws from English-centric internet data
   and is not tailored explicitly to the medical domain. Thus, an
   ophthalmic LLM in Chinese is clinically essential for both healthcare
   providers and patients in mainland China.
   Methods We developed an LLM of ophthalmology (MOPH) using Chinese
   corpora and evaluated its performance in three clinical scenarios:
   ophthalmic board exams in Chinese, answering evidence-based
   medicine-oriented ophthalmic questions and diagnostic accuracy for
   clinical vignettes. Additionally, we compared MOPH's performance to that
   of human doctors.
   Results In the ophthalmic exam, MOPH's average score closely aligned
   with the mean score of trainees (64.7 (range 62-68) vs 66.2 (range
   50-92), p=0.817), but achieving a score above 60 in all seven mock
   exams. In answering ophthalmic questions, MOPH demonstrated an adherence
   of 83.3% (25/30) of responses following Chinese guidelines (Likert scale
   4-5). Only 6.7% (2/30, Likert scale 1-2) and 10% (3/30, Likert scale 3)
   of responses were rated as 'poor or very poor' or 'potentially
   misinterpretable inaccuracies' by reviewers. In diagnostic accuracy,
   although the rate of correct diagnosis by ophthalmologists was superior
   to that by MOPH (96.1% vs 81.1%, p>0.05), the difference was not
   statistically significant.
   Conclusion This study demonstrated the promising performance of MOPH, a
   Chinese-specific ophthalmic LLM, in diverse clinical scenarios. MOPH has
   potential real-world applications in Chinese-language ophthalmology
   settings.
ZS 0
ZA 0
TC 4
ZR 0
Z8 0
ZB 0
Z9 4
DA 2024-07-29
UT WOS:001274616900001
PM 39019566
ER

PT C
AU Panagoulias, Dimitrios P.
   Palamidas, Filippos A.
   Virvou, Maria
   Tsihrintzis, George A.
GP IEEE
TI Evaluation of ChatGPT-supported diagnosis, staging and treatment
   planning for the case of lung cancer
SO 2023 20TH ACS/IEEE INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS, AICCSA
SE International Conference on Computer Systems and Applications
DI 10.1109/AICCSA59173.2023.10479348
DT Proceedings Paper
PD 2023
PY 2023
AB In this paper, we evaluate the validity, accuracy, usefulness, and
   specificity of medical diagnoses related to lung cancer and its staging
   provided by ChatGPT based on symptoms described by humans. The
   evaluation is grounded on three main pillars: the validity and accuracy
   of answers in relation to context and associated references. The
   specificity and usefulness of the information for both doctors and
   patients. The economic value added to the healthcare system, determined
   by several weighted factors derived from the provided answers. The
   system's responses are expected to return proposed diagnoses and
   diagnostic steps, ranked by probability and importance. A specialist
   conducts the review process.
CT 20th ACS/IEEE International Conference on Computer Systems and
   Applications (AICCSA)
CY DEC 04-07, 2023
CL Giza, EGYPT
SP IEEE; ACS
ZB 0
ZS 0
ZR 0
TC 1
ZA 0
Z8 0
Z9 1
DA 2024-07-06
UT WOS:001222477900114
ER

PT J
AU Park, SaYoon
   Chang-EopKim
TI Enhancing Korean Medicine Education with Large Language Models: Focusing
   on the Development of Educational Artificial Intelligence
Z1 거대언어모델을 활용한 한의학 교육 강화: 교육용 인공지능 개발을 중심으로
SO Journal of Physiology & Pathology in Korean Medicine
S1 동의생리병리학회지
VL 37
IS 5
BP 134
EP 138
DT research-article
PD 2023
PY 2023
AB Large language models (LLMs) have introduced groundbreaking innovations
   in various fields, including healthcare, where they augment medical
   diagnosis, decision-making, and facilitate patient-doctor communication
   through their exceptional contextual understanding and inferential
   abilities. In the realm of Korean medicine (KM), the utilization of LLMs
   is highly anticipated. However, it demands additional training with
   domain-specific KM data for seamless integration of KM knowledge. There
   are two predominant strategies for training domain-specific LLMs in the
   KM domain. The first approach entails direct manipulation of the LLM's
   internals by either pretraining a base model on an extensive corpus of
   KM data or fine-tuning a pretrained model's parameters using KM-related
   question-answering datasets. The second approach avoids internal model
   manipulation and leverages techniques like prompt engineering, retrieval
   augmented generation, and cognitive augmentation. Domain-specific LLMs
   specialized for KM hold the potential for diverse applications, ranging
   from personalized medical education plans and content generation to
   knowledge integration, curriculum development, automated student
   assessment, virtual patient simulations, and advanced research and
   scholarly activities. These advancements are poised to significantly
   impact the field of KM and medical education at large.
ZB 0
Z8 0
TC 0
ZA 0
ZS 0
ZR 0
Z9 0
DA 2023-01-01
UT KJD:ART003011785
ER

PT J
AU Abi-Rafeh, Jad
   Mroueh, Vanessa J.
   Bassiri-Tehrani, Brian
   Marks, Jacob
   Kazan, Roy
   Nahai, Foad
TI Complications Following Body Contouring: Performance Validation of Bard,
   a Novel AI Large Language Model, in Triaging and Managing Postoperative
   Patient Concerns
SO AESTHETIC PLASTIC SURGERY
VL 48
IS 5
BP 953
EP 976
DI 10.1007/s00266-023-03819-9
EA JAN 2024
DT Article
PD MAR 2024
PY 2024
AB Introduction Large language models (LLM) have revolutionized the way
   humans interact with artificial intelligence (AI) technology, with
   marked potential for applications in esthetic surgery. The present study
   evaluates the performance of Bard, a novel LLM, in identifying and
   managing postoperative patient concerns for complications following body
   contouring surgery.Methods The American Society of Plastic Surgeons'
   website was queried to identify and simulate all potential postoperative
   complications following body contouring across different acuities and
   severity. Bard's accuracy was assessed in providing a differential
   diagnosis, soliciting a history, suggesting a most-likely diagnosis,
   appropriate disposition, treatments/interventions to begin from home,
   and red-flag signs/symptoms indicating deterioration, or requiring
   urgent emergency department (ED) presentation.Results Twenty-two
   simulated body contouring complications were examined. Overall, Bard
   demonstrated a 59% accuracy in listing relevant diagnoses on its
   differentials, with a 52% incidence of incorrect or misleading
   diagnoses. Following history-taking, Bard demonstrated an overall
   accuracy of 44% in identifying the most-likely diagnosis, and a 55%
   accuracy in suggesting the indicated medical dispositions. Helpful
   treatments/interventions to begin from home were suggested with a 40%
   accuracy, whereas red-flag signs/symptoms, indicating deterioration,
   were shared with a 48% accuracy. A detailed analysis of performance,
   stratified according to latency of postoperative presentation (<48hours,
   48hours-1month, or >1month postoperatively), and according to acuity and
   indicated medical disposition, is presented herein.Conclusions Despite
   promising potential of LLMs and AI in healthcare-related applications,
   Bard's performance in the present study significantly falls short of
   accepted clinical standards, thus indicating a need for further research
   and development prior to adoption.Level of Evidence IV This journal
   requires that authors assign a level of evidence to each article. For a
   full description of these Evidence-Based Medicine ratings, please refer
   to the Table of Contents or the online Instructions to Authors
   www.springer.com/00266.
ZS 0
ZB 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-02-03
UT WOS:001150315000001
PM 38273152
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT C
AU Panagoulias, Dimitrios P.
   Palamidas, Filippos A.
   Virvou, Maria
   Tsihrintzis, George A.
GP IEEE
TI Rule-Augmented Artificial Intelligence-empowered Systems for Medical
   Diagnosis using Large Language Models
SO 2023 IEEE 35TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE, ICTAI
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
BP 70
EP 77
DI 10.1109/ICTAI59109.2023.00018
DT Proceedings Paper
PD 2023
PY 2023
AB In this paper, we investigate the enhancement of Artificial Intelligence
   (AI) technologies in healthcare and the better understanding of medical
   literature with the use of Large Language Models (LLMs) and Natural
   Language Processing (NLP). Specifically, we introduce a rule-augmented
   AI-empowered system which incorporates a rule-based decision system, the
   ChatGPT application programming interface (API), and other external
   machine learning and analytical APIs to offer diagnostic suggestions to
   patients. The complexities of patient healthcare experiences, including
   doctor-patient interactions, understanding levels, treatment procedures,
   and preventive care, are considered. We illustrate how a diagnostic
   process typically integrates various strategies depending on various
   factors. To digitize the greatest portion of the process, we propose and
   illustrate the use of LLMs for humanizing the communication process and
   investigating ways to reduce burdens and costs in primary healthcare. We
   also outline a theoretical decision model for evaluating the use of
   technological components from external sources versus building them from
   scratch. The paper is structured into sections detailing background
   theories and context, our proposed and implemented rule-augmented
   AI-empowered system, as well as a system test in a corresponding use
   case. Finally, the paper key findings are presented, which contribute
   valuable insights for future work in this field.
CT 35th IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 06-08, 2023
CL Atlanta, GA
SP IEEE; IEEE Comp Soc; Biol & Artificial Intelligence Fdn
Z8 0
ZA 0
TC 5
ZR 0
ZB 0
ZS 0
Z9 5
DA 2024-02-28
UT WOS:001139095400010
ER

PT J
AU Seifen, Christopher
   Bahr-Hamm, Katharina
   Gouveris, Haralampos
   Pordzik, Johannes
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Simulation-Based Evaluation of Large Language Models for Comorbidity
   Detection in Sleep Medicine - a Pilot Study on ChatGPT o1 Preview
SO NATURE AND SCIENCE OF SLEEP
VL 17
BP 677
EP 688
DI 10.2147/NSS.S510254
DT Article
PD 2025
PY 2025
AB Purpose: Timely identification of comorbidities is critical in sleep
   medicine, where large language models (LLMs) like ChatGPT are currently
   emerging as transformative tools. Here, we investigate whether the novel
   LLM ChatGPT o1 preview can identify individual health risks or
   potentially existing comorbidities from the medical data of fictitious
   sleep medicine patients. Methods: We conducted a simulation-based study
   using 30 fictitious patients, designed to represent realistic variations
   in demographic and clinical parameters commonly seen in sleep medicine.
   Each profile included personal data (eg, body mass index, smoking
   status, drinking habits), blood pressure, and routine blood test
   results, along with a predefined sleep medicine diagnosis. Each patient
   profile was evaluated independently by the LLM and a sleep medicine
   specialist (SMS) for identification of potential comorbidities or
   individual health risks. Their recommendations were compared for
   concordance across lifestyle changes and further medical measures.
   Results: The LLM achieved high concordance with the SMS for lifestyle
   modification recommendations, including 100% concordance on smoking
   cessation (kappa = 1; p < 0.001), 97% on alcohol reduction (kappa =
   0.92; p < 0.001) and endocrinological examination (kappa = 0.92; p <
   0.001) or 93% on weight loss (kappa = 0.86; p < 0.001). However, it
   exhibited a tendency to over-recommend further medical measures
   (particularly 57% concordance for cardiological examination (kappa =
   0.08; p = 0.28) and 33% for gastrointestinal examination (kappa = 0.1; p
   = 0.22)) compared to the SMS. Conclusion: Despite the obvious limitation
   of using fictitious data, the findings suggest that LLMs like ChatGPT
   have the potential to complement clinical workflows in sleep medicine by
   identifying individual health risks and comorbidities. As LLMs continue
   to evolve, their integration into healthcare could redefine the approach
   to patient evaluation and risk stratification. Future research should
   contextualize the findings within broader clinical applications ideally
   testing locally run LLMs meeting data protection requirements.
ZA 0
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-05-10
UT WOS:001480706400001
PM 40321662
ER

PT J
AU CHEN, QINGYU 
TI Addressing Factual Inaccuracy and Unfaithful Reasoning of Large Language
   Models in Biomedicine and Healthcare
DT Awarded Grant
PD Aug 29 2024
PY 2024
AB PROJECT SUMMARY/ABSTRACTLarge Language Models (LLMs) represent the
   latest advancement in Natural Language Processing (NLP) andArtificial
   Intelligence (AI), holding tremendous potential to revolutionize
   biomedical and healthcare applications.Extensive research has
   demonstrated the effectiveness of LLMs in a range of biomedical and
   healthapplications, ranging from medical question answering to
   summarizing systematic reviews and AI-assisteddisease diagnosis.
   However, the major barriers to applying LLMs in biomedical and health
   applications arefactual incorrectness – where LLM-generated responses
   are inaccurate or incomplete – and unfaithfulreasoning – where
   LLM-generated responses lack supporting evidence, contradict existing
   evidence, or evenrely on hallucinated evidence. Such issues further pose
   the risk of propagating misinformation, potentiallyleading to
   misdiagnosis or incorrect treatment recommendations. Addressing these
   issues has beenchallenging, primarily due to three fundamental
   obstacles: (1) from the data perspective, LLMs may capturemisinformation
   from lower-quality or unauthorized sources in the general domain data
   during pretraining, lackaccess to accurate and up-to-date biomedical
   knowledge, and consequently generate inaccurate, outdated, orunfaithful
   results; (2) from the methods perspective, there is a lack of mechanisms
   for fact-checking andevidence attribution throughout the lifecycle of
   LLMs when applied to biomedical and health studies, spanningfrom
   training/fine-tuning to inference and post-hoc analysis; (3) from the
   accountability perspective, fewapproaches have evaluated their
   effectiveness in biomedical and health downstream applications. Our
   overallobjective in this proposal is to systematically address the issue
   of factuality and unfaithful reasoning of LLMs inbiomedicine and
   healthcare. The specific aims include (1) from the data perspective,
   establishing a self-augmentation framework to teach LLMs to
   automatically select and use relevant biomedical digital resources
   toaugment their responses; (2) from the methods perspective, developing
   an LLM curator by stimulating fact-checking and evidence attribution
   performed in biocuration via a multi-stage, multi-task instruction
   tuningpipeline; (3) from the methods perspective, introducing a
   step-level automated feedback-guided paradigm forLLMs to reflect and
   improve from its intermediate responses via fact-checking and evidence
   attribution; and (4)from the accountability perspective, evaluating the
   methods in downstream use cases. The proposed work isexpected to address
   factual incorrectness and unfaithful reasoning of LLMs – the key barrier
   to their use inbiomedical and health domains – and make LLMs generate
   accurate and trustworthy responses to advancebiomedical discovery and
   healthcare. It is also expected to refine the current development and
   evaluationpipelines of LLMs in biomedical and health domains by making
   fact-checking and evidence attribution essentialcomponents and providing
   related benchmarks, methods, and tools to facilitate the implementation.
ZA 0
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
Z9 0
G1 10946218; 1R01LM014604-01; R01LM014604
DA 2024-09-29
UT GRANTS:17811425
ER

PT J
AU Jeyaraman, Madhan
   Balaji, Sangeetha
   Jeyaraman, Naveen
   Yadav, Sankalp
TI Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 15
IS 8
AR e43262
DI 10.7759/cureus.43262
DT Article
PD AUG 10 2023
PY 2023
AB The integration of artificial intelligence (AI) into healthcare promises
   groundbreaking advancements in patient care, revolutionizing clinical
   diagnosis, predictive medicine, and decision-making. This transformative
   technology uses machine learning, natural language processing, and large
   language models (LLMs) to process and reason like human intelligence.
   OpenAI's ChatGPT, a sophisticated LLM, holds immense potential in
   medical practice, research, and education. However, as AI in healthcare
   gains momentum, it brings forth profound ethical challenges that demand
   careful consideration. This comprehensive review explores key ethical
   concerns in the domain, including privacy, transparency, trust,
   responsibility, bias, and data quality. Protecting patient privacy in
   data-driven healthcare is crucial, with potential implications for
   psychological well-being and data sharing. Strategies like homomorphic
   encryption (HE) and secure multiparty computation (SMPC) are vital to
   preserving confidentiality. Transparency and trustworthiness of AI
   systems are essential, particularly in high-risk decision-making
   scenarios. Explainable AI (XAI) emerges as a critical aspect, ensuring a
   clear understanding of AI-generated predictions. Cybersecurity becomes a
   pressing concern as AI's complexity creates vulnerabilities for
   potential breaches. Determining responsibility in AI-driven outcomes
   raises important questions, with debates on AI's moral agency and human
   accountability. Shifting from data ownership to data stewardship enables
   responsible data management in compliance with regulations. Addressing
   bias in healthcare data is crucial to avoid AI-driven inequities. Biases
   present in data collection and algorithm development can perpetuate
   healthcare disparities. A public-health approach is advocated to address
   inequalities and promote diversity in AI research and the workforce.
   Maintaining data quality is imperative in AI applications, with
   convolutional neural networks showing promise in multi-input/mixed data
   models, offering a comprehensive patient perspective. In this
   ever-evolving landscape, it is imperative to adopt a multidimensional
   approach involving policymakers, developers, healthcare practitioners,
   and patients to mitigate ethical concerns. By understanding and
   addressing these challenges, we can harness the full potential of AI in
   healthcare while ensuring ethical and equitable outcomes.
ZR 0
Z8 2
TC 82
ZB 13
ZA 0
ZS 0
Z9 83
DA 2024-03-17
UT WOS:001168567200012
PM 37692617
ER

PT J
AU Shaikh, Tawseef Ayoub
   Rasool, Tabasum
   Mir, Waseem Ahmad
TI Fields of the future: Digital transformation in smart agriculture with
   large language models and generative AI
SO COMPUTER STANDARDS & INTERFACES
VL 94
AR 104005
DI 10.1016/j.csi.2025.104005
EA APR 2025
DT Article
PD AUG 2025
PY 2025
AB Language models (LLMs) have shown to be very useful in many fields like
   healthcare and finance, as natural language comprehension and generation
   have advanced. The capacity of LLM to participate in textual discussion
   has been the subject of much research, and the findings have proved
   encouraging across several domains. The inability of conventional image
   classification networks to comprehend the causes of crop diseases and
   etiology further impedes precise diagnosis. Agricultural diagnostic
   models on a grand scale will be based on generative pre-trained
   transformers (GPT) assisted with agrarian settings. By examining the
   efficacy of text corpora linked to agriculture for pretraining
   transformer-based language (TBL) models, this research delves into
   agricultural natural language processing (ANLP). To make the most of it,
   we looked at several important aspects, including prompt building,
   response parsing, and several ChatGPT versions. Despite the proven
   effectiveness and huge potential, there has been little exploration of
   LLM and Generative AI to agriculture artificial intelligence (AI).
   Therefore, this study aims to explore the possibility of LLM and
   Generative AI in smart agriculture. In particular, we present conceptual
   tools and technical background to facilitate understanding the problem
   space and uncover new research directions in this field. The paper
   presents an overview of the evolution of generative adversarial network
   (GAN) architectures followed by a first systematic review of various
   applications in smart agriculture and precision farming systems,
   involving a diversity of visual recognition tasks for smart farming and
   livestock, precision agriculture, agricultural language processing
   (ALP), agricultural robots (AR), plant phenotyping (PP), and postharvest
   quality assessment. We outline the possibilities, difficulties,
   constraints, and shortcomings. The study lays forth a road map of
   accessible areas in agriculture where LLM integration is likely to
   happen shortly. The research suggests exciting directions for further
   study in this area, which could lead to better agricultural NLP
   applications.
ZB 0
ZS 0
ZR 0
Z8 0
ZA 0
TC 0
Z9 0
DA 2025-04-19
UT WOS:001465662400001
ER

PT J
AU Zhang, Peng
   Shi, Jiayu
   Boulos, Maged N. Kamel
TI Generative AI in Medicine and Healthcare: Moving Beyond the 'Peak of
   Inflated Expectations'
SO FUTURE INTERNET
VL 16
IS 12
AR 462
DI 10.3390/fi16120462
DT Review
PD DEC 2024
PY 2024
AB The rapid development of specific-purpose Large Language Models (LLMs),
   such as Med-PaLM, MEDITRON-70B, and Med-Gemini, has significantly
   impacted healthcare, offering unprecedented capabilities in clinical
   decision support, diagnostics, and personalized health monitoring. This
   paper reviews the advancements in medicine-specific LLMs, the
   integration of Retrieval-Augmented Generation (RAG) and prompt
   engineering, and their applications in improving diagnostic accuracy and
   educational utility. Despite the potential, these technologies present
   challenges, including bias, hallucinations, and the need for robust
   safety protocols. The paper also discusses the regulatory and ethical
   considerations necessary for integrating these models into mainstream
   healthcare. By examining current studies and developments, this paper
   aims to provide a comprehensive overview of the state of LLMs in
   medicine and highlight the future directions for research and
   application. The study concludes that while LLMs hold immense potential,
   their safe and effective integration into clinical practice requires
   rigorous testing, ongoing evaluation, and continuous collaboration among
   stakeholders.
ZR 0
TC 4
ZB 0
ZA 0
ZS 0
Z8 0
Z9 4
DA 2025-01-01
UT WOS:001384353900001
ER

PT J
AU Stanley, Jack
   Rabot, Emmett
   Reddy, Siva
   Belilovsky, Eugene
   Mottron, Laurent
   Bzdok, Danilo
TI Large language models deconstruct the clinical intuition behind
   diagnosing autism
SO CELL
VL 188
IS 8
DI 10.1016/j.cell.2025.02.025
EA APR 2025
DT Article
PD APR 17 2025
PY 2025
AB Efforts to use genome-wide assays or brain scans to diagnose autism have
   seen diminishing returns. Yet the clinical intuition of healthcare
   professionals, based on longstanding first-hand experience, remains the
   gold standard for diagnosis of autism. We leveraged deep learning to
   deconstruct and interrogate the logic of expert clinician intuition from
   clinical reports to inform our understanding of autism. After
   pre-training on hundreds of millions of general sentences, we finessed
   large language models (LLMs) on >4,000 free-form health records from
   healthcare professionals to distinguish confirmed versus suspected
   autism cases. By introducing an explainability strategy, our extended
   language model architecture could pin down the most salient single
   sentences in what drives clinical thinking toward correct diagnoses. Our
   framework flagged the most autism-critical DSM-5 criteria to be
   stereotyped repetitive behaviors, special interests, and
   perception-based behaviors, which challenges today's focus on deficits
   in social interplay, suggesting necessary revision of long-trusted
   diagnostic criteria in gold-standard instruments.
ZS 0
ZB 0
ZA 0
ZR 0
Z8 0
TC 0
Z9 0
DA 2025-05-06
UT WOS:001476532200001
PM 40147442
ER

PT J
AU Xie, Kevin
   Ojemann, William K. S.
   Gallagher, Ryan S.
   Shinohara, Russell T.
   Lucas, Alfredo
   Hill, Chloe E.
   Hamilton, Roy H.
   Johnson, Kevin B.
   Roth, Dan
   Litt, Brian
   Ellis, Colin A.
TI Disparities in seizure outcomes revealed by large language models
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 6
BP 1348
EP 1355
DI 10.1093/jamia/ocae047
EA MAR 2024
DT Article
PD MAY 20 2024
PY 2024
AB Objective Large-language models (LLMs) can potentially revolutionize
   health care delivery and research, but risk propagating existing biases
   or introducing new ones. In epilepsy, social determinants of health are
   associated with disparities in care access, but their impact on seizure
   outcomes among those with access remains unclear. Here we (1) evaluated
   our validated, epilepsy-specific LLM for intrinsic bias, and (2) used
   LLM-extracted seizure outcomes to determine if different demographic
   groups have different seizure outcomes.Materials and Methods We tested
   our LLM for differences and equivalences in prediction accuracy and
   confidence across demographic groups defined by race, ethnicity, sex,
   income, and health insurance, using manually annotated notes. Next, we
   used LLM-classified seizure freedom at each office visit to test for
   demographic outcome disparities, using univariable and multivariable
   analyses.Results We analyzed 84 675 clinic visits from 25 612 unique
   patients seen at our epilepsy center. We found little evidence of bias
   in the prediction accuracy or confidence of outcome classifications
   across demographic groups. Multivariable analysis indicated worse
   seizure outcomes for female patients (OR 1.33, P <= .001), those with
   public insurance (OR 1.53, P <= .001), and those from lower-income zip
   codes (OR >= 1.22, P <= .007). Black patients had worse outcomes than
   White patients in univariable but not multivariable analysis (OR 1.03, P
   = .66).Conclusion We found little evidence that our LLM was
   intrinsically biased against any demographic group. Seizure freedom
   extracted by LLM revealed disparities in seizure outcomes across several
   demographic groups. These findings quantify the critical need to reduce
   disparities in the care of people with epilepsy.
ZB 1
Z8 0
ZA 0
ZS 0
TC 5
ZR 0
Z9 5
DA 2024-03-29
UT WOS:001184502000001
PM 38481027
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Iqbal, Usman
   Tanweer, Afifa
   Rahmanti, Annisa Ristya
   Greenfield, David
   Lee, Leon Tsung-Ju
   Li, Yu-Chuan Jack
TI Impact of large language model (ChatGPT) in healthcare: an umbrella
   review and evidence synthesis
SO JOURNAL OF BIOMEDICAL SCIENCE
VL 32
IS 1
AR 45
DI 10.1186/s12929-025-01131-z
DT Article
PD MAY 7 2025
PY 2025
AB Background The emergence of Artificial Intelligence (AI), particularly
   Chat Generative Pre-Trained Transformer (ChatGPT), a Large Language
   Model (LLM), in healthcare promises to reshape patient care, clinical
   decision-making, and medical education. This review aims to synthesise
   research findings to consolidate the implications of ChatGPT integration
   in healthcare and identify research gaps. Main body The umbrella review
   was conducted following Preferred Reporting Items for Systematic Reviews
   and Meta-Analyses (PRISMA) guidelines. The Cochrane Library, PubMed,
   Scopus, Web of Science, and Google Scholar were searched from inception
   until February 2024. Due to the heterogeneity of the included studies,
   no quantitative analysis was performed. Instead, information was
   extracted, summarised, synthesised, and presented in a narrative form.
   Two reviewers undertook title, abstract, and full text screening
   independently. The methodological quality and overall rating of the
   included reviews were assessed using the A Measurement Tool to Assess
   systematic Reviews (AMSTAR-2) checklist. The review examined 17 studies,
   comprising 15 systematic reviews and 2 meta-analyses, on ChatGPT in
   healthcare, revealing diverse focuses. The AMSTAR-2 assessment
   identified 5 moderate and 12 low-quality reviews, with deficiencies like
   study design justification and funding source reporting. The most
   reported theme that emerged was ChatGPT's use in disease diagnosis or
   clinical decision-making. While 82.4% of studies focused on its general
   usage, 17.6% explored unique topics like its role in medical
   examinations and conducting systematic reviews. Among these, 52.9%
   targeted general healthcare, with 41.2% focusing on specific domains
   like radiology, neurosurgery, gastroenterology, public health dentistry,
   and ophthalmology. ChatGPT's use for manuscript review or writing was
   mentioned in 17.6% of reviews. Promising applications include enhancing
   patient care and clinical decision-making, though ethical, legal, and
   accuracy concerns require cautious integration. Conclusion We summarise
   the identified areas in reviews regarding ChatGPT's transformative
   impact in healthcare, highlighting patient care, decision-making, and
   medical education. Emphasising the importance of ethical regulations and
   the involvement of policymakers, we urge further investigation to ensure
   the reliability of ChatGPT and to promote trust in healthcare and
   research.
ZR 0
TC 0
ZA 0
ZS 0
ZB 0
Z8 0
Z9 0
DA 2025-05-16
UT WOS:001485796900001
PM 40335969
ER

PT J
AU Mira, Felipe Ahumada
   Favier, Valentin
   Nunes, Heloisa dos Santos Sobreira
   de Castro, Joana Vaz
   Carsuzaa, Florent
   Meccariello, Giuseppe
   Vicini, Claudio
   De Vito, Andrea
   Lechien, Jerome R.
   Estomba, Carlos Chiesa
   Maniaci, Antonino
   Iannella, Giannicola
   Rojas, Eduardo Pena
   Cornejo, Jenifer Barros
   Cammaroto, Giovanni
TI Chat GPT for the management of obstructive sleep apnea: do we have a
   polar star?
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 2087
EP 2093
DI 10.1007/s00405-023-08270-9
EA NOV 2023
DT Article
PD APR 2024
PY 2024
AB PurposeThis study explores the potential of the Chat-Generative
   Pre-Trained Transformer (Chat-GPT), a Large Language Model (LLM), in
   assisting healthcare professionals in the diagnosis of obstructive sleep
   apnea (OSA). It aims to assess the agreement between Chat-GPT's
   responses and those of expert otolaryngologists, shedding light on the
   role of AI-generated content in medical decision-making.MethodsA
   prospective, cross-sectional study was conducted, involving 350
   otolaryngologists from 25 countries who responded to a specialized OSA
   survey. Chat-GPT was tasked with providing answers to the same survey
   questions. Responses were assessed by both super-experts and
   statistically analyzed for agreement.ResultsThe study revealed that
   Chat-GPT and expert responses shared a common answer in over 75% of
   cases for individual questions. However, the overall consensus was
   achieved in only four questions. Super-expert assessments showed a
   moderate agreement level, with Chat-GPT scoring slightly lower than
   experts. Statistically, Chat-GPT's responses differed significantly from
   experts' opinions (p = 0.0009). Sub-analysis revealed areas of
   improvement for Chat-GPT, particularly in questions where super-experts
   rated its responses lower than expert consensus.ConclusionsChat-GPT
   demonstrates potential as a valuable resource for OSA diagnosis,
   especially where access to specialists is limited. The study emphasizes
   the importance of AI-human collaboration, with Chat-GPT serving as a
   complementary tool rather than a replacement for medical professionals.
   This research contributes to the discourse in otolaryngology and
   encourages further exploration of AI-driven healthcare applications.
   While Chat-GPT exhibits a commendable level of consensus with expert
   responses, ongoing refinements in AI-based healthcare tools hold
   significant promise for the future of medicine, addressing the
   underdiagnosis and undertreatment of OSA and improving patient outcomes.
ZS 0
ZB 5
Z8 0
TC 23
ZR 0
ZA 0
Z9 23
DA 2023-12-07
UT WOS:001103635400001
PM 37980605
ER

PT J
AU Pugliese, Giorgia
   Maccari, Alberto
   Felisati, Elena
   Felisati, Giovanni
   Giudici, Leonardo
   Rapolla, Chiara
   Pisani, Antonia
   Saibene, Alberto Maria
TI Are artificial intelligence large language models a reliable tool for
   difficult differential diagnosis? An a posteriori analysis of a peculiar
   case of necrotizing otitis externa
SO CLINICAL CASE REPORTS
VL 11
IS 9
AR e7933
DI 10.1002/ccr3.7933
DT Article
PD SEP 2023
PY 2023
AB Key Clinical MessageLarge language models have made artificial
   intelligence readily available to the general public and potentially
   have a role in healthcare; however, their use in difficult differential
   diagnosis is still limited, as demonstrated by a case of necrotizing
   otitis externa.AbstractThis case report presents a peculiar case of
   necrotizing otitis externa (NOE) with skull base involvement which
   proved diagnostically challenging. The initial patient presentation and
   the imaging performed on the 78-year-old patient suggested a neoplastic
   rhinopharyngeal lesion and only after several unsuccessful biopsies the
   patient was transferred to our unit. Upon re-evaluation of the clinical
   picture, a clinical hypothesis of NOE with skull base erosion was made
   and confirmed by identifying Pseudomonas aeruginosa in biopsy specimens
   of skull base bone and external auditory canal skin. Upon diagnosis
   confirmation, the patient was treated with culture-oriented long-term
   antibiotics with complete resolution of the disease. Given the complex
   clinical presentation, we chose to submit a posteriori this NOE case to
   two large language models (LLM) to test their ability to handle
   difficult differential diagnoses. LLMs are easily approachable
   artificial intelligence tools that enable human-like interaction with
   the user relying upon large information databases for analyzing queries.
   The LLMs of choice were ChatGPT-3 and ChatGPT-4 and they were requested
   to analyze the case being provided with only objective clinical and
   imaging data.
   This computed tomography scan shows bilateral partial erosion of the
   bony boundaries of the middle skull base (simple arrows) with moderate
   soft tissue contrast enhancement (double arrows) in a case of
   necrotizing otitis externa case.image
Z8 0
ZS 0
TC 3
ZB 0
ZR 0
ZA 0
Z9 3
DA 2023-09-27
UT WOS:001067165300001
PM 37736475
ER

PT J
AU Fisch, Urs
   Kliem, Paulina
   Grzonka, Pascale
   Sutter, Raoul
TI Performance of large language models on advocating the management of
   meningitis: a comparative qualitative stud
SO BMJ HEALTH & CARE INFORMATICS
VL 31
IS 1
AR e100978
DI 10.1136/bmjhci-2023-100978
DT Article
PD FEB 2024
PY 2024
AB Objectives We aimed to examine the adherence of large language models
   (LLMs) to bacterial meningitis guidelines using a hypothetical medical
   case, highlighting their utility and limitations in healthcare.Methods A
   simulated clinical scenario of a patient with bacterial meningitis
   secondary to mastoiditis was presented in three independent sessions to
   seven publicly accessible LLMs (Bard, Bing, Claude-2, GTP-3.5, GTP-4,
   Llama, PaLM). Responses were evaluated for adherence to good clinical
   practice and two international meningitis guidelines.Results A central
   nervous system infection was identified in 90% of LLM sessions. All
   recommended imaging, while 81% suggested lumbar puncture. Blood cultures
   and specific mastoiditis work-up were proposed in only 62% and 38%
   sessions, respectively. Only 38% of sessions provided the correct
   empirical antibiotic treatment, while antiviral treatment and
   dexamethasone were advised in 33% and 24%, respectively. Misleading
   statements were generated in 52%. No significant correlation was found
   between LLMs' text length and performance (r=0.29, p=0.20). Among all
   LLMs, GTP-4 demonstrated the best performance.Discussion Latest LLMs
   provide valuable advice on differential diagnosis and diagnostic
   procedures but significantly vary in treatment-specific information for
   bacterial meningitis when introduced to a realistic clinical scenario.
   Misleading statements were common, with performance differences
   attributed to each LLM's unique algorithm rather than output
   length.Conclusions Users must be aware of such limitations and
   performance variability when considering LLMs as a support tool for
   medical decision-making. Further research is needed to refine these
   models' comprehension of complex medical scenarios and their ability to
   provide reliable information.
TC 7
Z8 0
ZS 0
ZR 0
ZB 1
ZA 0
Z9 7
DA 2024-02-12
UT WOS:001156524500002
PM 38307617
ER

PT J
AU Argymbay, Mariyam
   Khan, Shams
   Ahmad, Noman
   Salih, Mira
   Mamatjan, Yasin
TI A Smart Recommender System for Stroke Risk Assessment with an Integrated
   Strokebot
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
VL 44
IS 6
BP 799
EP 808
DI 10.1007/s40846-024-00922-3
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB PurposeWe present a machine learning-based online recommendation system
   for stroke risk assessments. With this tool, users will be able to take
   proactive steps in managing their health by predicting stroke risk based
   on diverse data input, providing transparent and reliable risk factor
   interpretations, and helping healthcare professionals make informed
   clinical decisions.MethodsThis study uses the publicly available Stroke
   Analysis dataset. To predict stroke risk, the CatBoost classifier is
   employed, while the XAI component incorporates SHAP explainer to provide
   insights into its reasoning. A Django-based web application allows users
   to upload risk factor data and receive personalized stroke risk
   predictions. Smartwatch integration allows continuous monitoring of
   dynamic risk factors. BioMistral 7B Large Language Models (LLM) is
   employed to create an intuitive AI medical assistant.ResultsThe
   developed automated online recommender system is highly accurate and
   robust for stroke risk assessment. The CatBoost classifier shows an
   average AUC of 0.98. In addition to the SHAP explainer, the recommender
   system also integrates Google Maps, Alert System, and Q/A chatbot based
   on LLMs.ConclusionAccording to the study, AI-driven systems can assist
   in stroke risk assessment and preventive care strategies. Developing a
   user-friendly online recommender system provides proof of principle for
   an efficient and user-friendly health management tool using machine
   learning, explainable AI, and LLM.
ZR 0
ZB 0
Z8 0
ZS 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001372713100001
ER

PT J
AU Shashikumar, Supreeth P
   Nemati, Shamim
TI A Prospective Comparison of Large Language Models for Early Prediction
   of Sepsis.
SO Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
VL 30
BP 109
EP 120
DI 10.1142/9789819807024_0009
DT Journal Article; Comparative Study
PD 2025
PY 2025
AB We present a comparative study on the performance of two popular
   open-source large language models for early prediction of sepsis:
   Llama-3 8B and Mixtral 8x7B. The primary goal was to determine whether a
   smaller model could achieve comparable predictive accuracy to a
   significantly larger model in the context of sepsis prediction using
   clinical data.Our proposed LLM-based sepsis prediction system,
   COMPOSER-LLM, enhances the previously published COMPOSER model, which
   utilizes structured EHR data to generate hourly sepsis risk scores. The
   new system incorporates an LLM-based approach to extract sepsis-related
   clinical signs and symptoms from unstructured clinical notes. For scores
   falling within high-uncertainty prediction regions, particularly those
   near the decision threshold, the system uses the LLM to draw additional
   clinical context from patient notes; thereby enhancing the model's
   predictive accuracy in challenging diagnostic scenarios.A total of 2,074
   patient encounters admitted to the Emergency Department at two hospitals
   within the University of California San Diego Health system were used
   for model evaluation in this study. Our findings reveal that the Llama-3
   8B model based system (COMPOSER-LLMLlama) achieved a sensitivity of
   70.3%, positive predictive value (PPV) of 32.5%, F-1 score of 44.4% and
   false alarms per patient hour (FAPH) of 0.0194, closely matching the
   performance of the larger Mixtral 8x7B model based system
   (COMPOSER-LLMmixtral) which achieved a sensitivity of 72.1%, PPV of
   31.9%, F-1 score of 44.2% and FAPH of 0.020. When prospectively
   evaluated, COMPOSER-LLMLlama demonstrated similar performance to the
   COMPOSER-LLMmixtral pipeline, with a sensitivity of 68.7%, PPV of 36.6%,
   F-1 score of 47.7% and FAPH of 0.019 vs. sensitivity of 70.5%, PPV of
   36.3%, F-1 score of 47.9% and FAPH of 0.020. This result indicates that,
   for extraction of clinical signs and symptoms from unstructured clinical
   notes to enable early prediction of sepsis, the Llama-3 generation of
   smaller language models can perform as effectively and more efficiently
   than larger models. This finding has significant implications for
   healthcare settings with limited resources.
ZS 0
ZB 0
Z8 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-05-17
UT MEDLINE:39670365
PM 39670365
ER

PT C
AU Almeida, Ruben
   Sousa, Hugo
   Cunha, Luis F.
   Guimaraes, Nuno
   Campos, Ricardo
   Jorge, Alipio
BE Goharian, N
   Tonellotto, N
   He, Y
   Lipani, A
   McDonald, G
   Macdonald, C
   Ounis, I
TI Physio: An LLM-Based Physiotherapy Advisor
SO ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT V
SE Lecture Notes in Computer Science
VL 14612
BP 189
EP 193
DI 10.1007/978-3-031-56069-9_16
DT Proceedings Paper
PD 2024
PY 2024
AB The capabilities of the most recent language models have increased the
   interest in integrating them into real-world applications. However, the
   fact that these models generate plausible, yet incorrect text poses a
   constraint when considering their use in several domains. Healthcare is
   a prime example of a domain where text-generative trustworthiness is a
   hard requirement to safeguard patient well-being. In this paper, we
   present Physio, a chat-based application for physical rehabilitation.
   Physio is capable of making an initial diagnosis while citing reliable
   health sources to support the information provided. Furthermore, drawing
   upon external knowledge databases, Physio can recommend rehabilitation
   exercises and over-the-counter medication for symptom relief. By
   combining these features, Physio can leverage the power of generative
   models for language processing while also conditioning its response on
   dependable and verifiable sources. A live demo of Physio is available at
   https://physio.inesctec.pt.
CT 46th European Conference on Information Retrieval (ECIR)
CY MAR 24-28, 2024
CL Glasgow, SCOTLAND
SP Univ Glasgow; British Comp Soc, Informat Retrieval Specialist Grp
ZB 0
ZR 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-05-31
UT WOS:001211835200016
ER

PT J
AU Gu, Zhanzhong
   He, Xiangjian
   Yu, Ping
   Jia, Wenjing
   Yang, Xiguang
   Peng, Gang
   Hu, Penghui
   Chen, Shiyan
   Chen, Hongjie
   Lin, Yiguang
TI Automatic quantitative stroke severity assessment based on Chinese
   clinical named entity recognition with domain-adaptive pre-trained large
   language model
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
VL 150
AR 102822
DI 10.1016/j.artmed.2024.102822
EA FEB 2024
DT Article
PD APR 2024
PY 2024
AB Background: Stroke is a prevalent disease with a significant global
   impact. Effective assessment of stroke severity is vital for an accurate
   diagnosis, appropriate treatment, and optimal clinical outcomes. The
   National Institutes of Health Stroke Scale (NIHSS) is a widely used
   scale for quantitatively assessing stroke severity. However, the current
   manual scoring of NIHSS is labor-intensive, time-consuming, and
   sometimes unreliable. Applying artificial intelligence (AI) techniques
   to automate the quantitative assessment of stroke on vast amounts of
   electronic health records (EHRs) has attracted much interest. Objective:
   This study aims to develop an automatic, quantitative stroke severity
   assessment framework through automating the entire NIHSS scoring process
   on Chinese clinical EHRs. Methods: Our approach consists of two major
   parts: Chinese clinical named entity recognition (CNER) with a domain
   -adaptive pre -trained large language model (LLM) and automated NIHSS
   scoring. To build a highperforming CNER model, we first construct a
   stroke -specific, densely annotated dataset "Chinese Stroke Clinical
   Records"(CSCR) from EHRs provided by our partner hospital, based on a
   stroke ontology that defines semantically related entities for stroke
   assessment. We then pre -train a Chinese clinical LLM coined
   "CliRoberta"through domain -adaptive transfer learning and construct a
   deep learning -based CNER model that can accurately extract entities
   directly from Chinese EHRs. Finally, an automated, end -to -end NIHSS
   scoring pipeline is proposed by mapping the extracted entities to
   relevant NIHSS items and values, to quantitatively assess the stroke
   severity. Results: Results obtained on a benchmark dataset CCKS2019 and
   our newly created CSCR dataset demonstrate the superior performance of
   our domain -adaptive pre -trained LLM and the CNER model, compared with
   the existing benchmark LLMs and CNER models. The high F1 score of 0.990
   ensures the reliability of our model in accurately extracting the
   entities for the subsequent automatic NIHSS scoring. Subsequently, our
   automated, end -to -end NIHSS scoring approach achieved excellent inter
   -rater agreement (0.823) and intraclass consistency (0.986) with the
   ground truth and significantly reduced the processing time from minutes
   to a few seconds. Conclusion: Our proposed automatic and quantitative
   framework for assessing stroke severity demonstrates exceptional
   performance and reliability through directly scoring the NIHSS from
   diagnostic notes in Chinese clinical EHRs. Moreover, this study also
   contributes a new clinical dataset, a pre -trained clinical LLM, and an
   effective deep learning -based CNER model. The deployment of these
   advanced algorithms can improve the accuracy and efficiency of clinical
   assessment, and help improve the quality, affordability and productivity
   of healthcare services.
ZS 0
TC 7
ZA 0
Z8 0
ZR 0
ZB 1
Z9 7
DA 2024-04-13
UT WOS:001197568100001
PM 38553162
ER

PT J
AU Javid, Mohamed
   Reddiboina, Madhu
   Bhandari, Mahendra
TI Emergence of artificial generative intelligence and its potential impact
   on urology
SO CANADIAN JOURNAL OF UROLOGY
VL 30
IS 4
BP 11588
EP 11598
DT Review
PD AUG 2023
PY 2023
AB Introduction: Artificial generative intelligence (AGI) and large
   language models (LLMs) have gained significant attention in healthcare
   and hold enormous promise for transforming every aspect of our life and
   urology is no exception.
   Materials and methods: We conducted a comprehensive literature search of
   electronic databases and included articles discussing AGI and LLMs in
   healthcare. Additionally, we have incorporated our experiences
   interacting with the ChatGPT and GPT-4 in different situations with real
   case reports and case constructs.
   Results: Our review highlights the potential applications and likely
   impact of these technologies in urology, for differential diagnosis,
   prioritizing treatment options, and facilitating research, surgeon, and
   patient education. At their current developmental stage, we have
   recognized the need for concurrent validation and continuous human
   interaction necessary to induce inverse reinforced learning with human
   feedback to mature them to authenticity. We need to consciously adjust
   to the hallucinations and guard patients' confidentiality before their
   extensive implementations in clinical practice. We propose possible
   remedies for these shortcomings and emphasize the critical role of human
   interaction in their evolution.
   Conclusion: The integration of these tools has the potential to
   revolutionize urology, but it also presents several challenges needing
   attention. To harness the full potential of these models, urologists
   must consistently engage in training these tools with their clinical
   sense and experience. We urge the urology community to actively
   participate in AGI and LLM development to address potential challenges.
   These models could help us in unleashing our full potential and help us
   achieve a better work-life balance.
Z8 0
ZS 0
ZA 0
ZR 0
TC 14
ZB 4
Z9 14
DA 2023-11-10
UT WOS:001087939300004
PM 37633285
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT J
AU Laios, Alexandros
   Theophilou, Georgios
   De Jong, Diederick
   Kalampokis, Evangelos
TI The Future of AI in Ovarian Cancer Research: The Large Language Models
   Perspective
SO CANCER CONTROL
VL 30
AR 10732748231197915
DI 10.1177/10732748231197915
DT Editorial Material
PD AUG 2023
PY 2023
AB Conversational large language model (LLM)-based chatbots utilize neural
   networks to process natural language. By generating highly sophisticated
   outputs from contextual input text, they revolutionize the access to
   further learning, leading to the development of new skills and
   personalized interactions. Although they are not developed to provide
   healthcare, their potential to address biomedical issues is rather
   unexplored. Healthcare digitalization and documentation of electronic
   health records is now developing into a standard practice. Developing
   tools to facilitate clinical review of unstructured data such as LLMs
   can derive clinical meaningful insights for ovarian cancer, a
   heterogeneous but devastating disease. Compared to standard approaches,
   they can host capacity to condense results and optimize analysis time.
   To help accelerate research in biomedical language processing and
   improve the validity of scientific writing, task-specific and
   domain-specific language models may be required. In turn, we propose a
   bespoke, proprietary ovarian cancer-specific natural language using
   solely in-domain text, whereas transfer learning drifts away from the
   pretrained language models to fine-tune task-specific models for all
   possible downstream applications. This venture will be fueled by the
   abundance of unstructured text information in the electronic health
   records resulting in ovarian cancer research ultimately reaching its
   linguistic home.
Z8 0
ZB 0
ZR 0
TC 5
ZS 0
ZA 0
Z9 5
DA 2023-09-25
UT WOS:001064803500001
PM 37624621
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT J
AU Wang, Yue
   Yang, Shuo
   Zeng, Chengcheng
   Xie, Yingwei
   Shen, Ya
   Li, Jian
   Huang, Xiao
   Wei, Ruili
   Chen, Yuqing
TI Evaluating the performance of ChatGPT in patient consultation and
   image-based preliminary diagnosis in thyroid eye disease
SO FRONTIERS IN MEDICINE
VL 12
AR 1546706
DI 10.3389/fmed.2025.1546706
DT Article
PD FEB 18 2025
PY 2025
AB Background The emergence of Large Language Model (LLM) chatbots, such as
   ChatGPT, has great promise for enhancing healthcare practice. Online
   consultation, accurate pre-diagnosis, and clinical efforts are of
   fundamental importance for the patient-oriented management
   system.Objective This cross-sectional study aims to evaluate the
   performance of ChatGPT in inquiries across ophthalmic domains and to
   focus on Thyroid Eye Disease (TED) consultation and image-based
   preliminary diagnosis in a non-English language.Methods We obtained
   frequently consulted clinical inquiries from a published reference based
   on patient consultation data, titled A Comprehensive Collection of
   Thyroid Eye Disease Knowledge. Additionally, we collected facial and
   Computed Tomography (CT) images from 16 patients with a definitive
   diagnosis of TED. From 18 to 30 May 2024, inquiries about the TED
   consultation and preliminary diagnosis were posed to ChatGPT using a new
   chat for each question. Responses to questions from ChatGPT-4, 4o, and
   an experienced ocular professor were compiled into three questionnaires,
   which were evaluated by patients and ophthalmologists on four
   dimensions: accuracy, comprehensiveness, conciseness, and satisfaction.
   The preliminary diagnosis of TED was deemed accurate, and the
   differences in the accuracy rates were further calculated.Results For
   common TED consultation questions, ChatGPT-4o delivered more accurate
   information with logical consistency, adhering to a structured format of
   disease definition, detailed sections, and summarized conclusions.
   Notably, the answers generated by ChatGPT-4o were rated higher than
   those of ChatGPT-4 and the professor, with accuracy (4.33 [0.69]),
   comprehensiveness (4.17 [0.75]), conciseness (4.12 [0.77]), and
   satisfaction (4.28 [0.70]). The characteristics of the evaluators, the
   response variables, and other quality scores were all correlated with
   overall satisfaction levels. Based on several facial images, ChatGPT-4
   twice failed to make diagnoses because of lacking characteristic
   symptoms or a complete medical history, whereas ChatGPT-4o accurately
   identified the pathologic conditions in 31.25% of cases (95% confidence
   interval, CI: 11.02-58.66%). Furthermore, in combination with CT images,
   ChatGPT-4o performed comparably to the professor in terms of diagnosis
   accuracy (87.5, 95% CI 61.65-98.45%).Conclusion ChatGPT-4o excelled in
   comprehensive and satisfactory patient consultation and imaging
   interpretation, indicating the potential to improve clinical practice
   efficiency. However, limitations in disinformation management and legal
   permissions remain major concerns, which require further investigation
   in clinical practice.
TC 1
ZB 0
ZS 0
ZA 0
Z8 0
ZR 0
Z9 1
DA 2025-03-08
UT WOS:001435934700001
PM 40041459
ER

PT C
AU del Hoyo, Pablo
   Schez-Sobrino, Santiago
   Garcia, Francisco
   Cardoso, Jorge C. S.
   Albusac, Javier
   Vallejo, David
BE Bravo, J
   Nugent, C
   Cleland, I
TI PrimARy: Intelligent System Based on Mixed Reality for Diagnosis and
   Assistance in Primary Care
SO PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING AND
   AMBIENT INTELLIGENCE, UCAMI 2024
SE Lecture Notes in Networks and Systems
VL 1212
BP 45
EP 56
DI 10.1007/978-3-031-77571-0_5
DT Proceedings Paper
PD 2024
PY 2024
AB This research aims to improve the diagnostic and support capabilities of
   healthcare professionals in primary care settings. We present PrimARy, a
   system that enables primary care workers to follow medical protocols in
   a guided manner using Mixed Reality and Artificial Intelligence. These
   protocols, defined using a node-based visual editor, can be
   automatically integrated into the Mixed Reality application, extending
   the system's capabilities to different healthcare scenarios. The
   protocols can be enriched with documents and multimedia, and serve as
   the basis for the virtual assistant built into PrimARy to guide users in
   following a medical protocol. This functionality makes use of a Large
   Language Model deployed on a dedicated server for inference processes.
   As a practical application, the integration of a visual triage process
   to assess overweight and obesity is proposed. The ultimate goal is to
   scale our proposal for use in primary care centers, patients' homes, and
   emergency situations by medical and nursing staff.
CT 16th International Conference on Ubiquitous Computing and Ambient
   Intelligence
CY NOV 27-29, 2024
CL Belfast, IRELAND
ZA 0
TC 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 0
DA 2025-04-05
UT WOS:001443925900005
ER

PT C
AU Bani-Harouni, David
   Navab, Nassir
   Keicher, Matthias
BE Deng, Z
   Shen, Y
   Kim, HJ
   Jeong, WK
   Aviles-Rivero, AI
   He, J
   Zhang, S
TI MAGDA: Multi-agent Guideline-Driven Diagnostic Assistance
SO FOUNDATION MODELS FOR GENERAL MEDICAL AI, MEDAGI 2024
SE Lecture Notes in Computer Science
VL 15184
BP 163
EP 172
DI 10.1007/978-3-031-73471-7_17
DT Proceedings Paper
PD 2025
PY 2025
AB In emergency departments, rural hospitals, or clinics in less developed
   regions, clinicians often lack fast image analysis by trained
   radiologists, which can have a detrimental effect on patients
   healthcare. Large Language Models (LLMs) have the potential to alleviate
   some pressure from these clinicians by providing insights that can help
   them in their decision-making. While these LLMs achieve high test
   results on medical exams showcasing their great theoretical medical
   knowledge, they tend not to follow medical guidelines. In this work, we
   introduce a new approach for zero-shot guideline-driven decision
   support. We model a system of multiple LLM agents augmented with a
   contrastive vision-language model that collaborate to reach a patient
   diagnosis. After providing the agents with simple diagnostic guidelines,
   they will synthesize prompts and screen the image for findings following
   these guidelines. Finally, they provide understandable chain-of-thought
   reasoning for their diagnosis, which is then self-refined to consider
   inter-dependencies between diseases. As our method is zero-shot, it is
   adaptable to settings with rare diseases, where training data is
   limited, but expert-crafted disease descriptions are available. We
   evaluate our method on two chest X-ray datasets, CheXpert and ChestX-ray
   14 Longtail, showcasing performance improvement over existing zero-shot
   methods and generalizability to rare diseases.
CT 2nd International Workshop on Foundation Models for General Medical AI
CY OCT 06, 2024
CL Marrakesh, MOROCCO
ZS 0
TC 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 0
DA 2025-03-21
UT WOS:001426955400017
ER

PT J
AU Frosolini, Andrea
   Catarzi, Lisa
   Benedetti, Simone
   Latini, Linda
   Chisci, Glauco
   Franz, Leonardo
   Gennaro, Paolo
   Gabriele, Guido
TI The Role of Large Language Models (LLMs) in Providing Triage for
   Maxillofacial Trauma Cases: A Preliminary Study
SO DIAGNOSTICS
VL 14
IS 8
AR 839
DI 10.3390/diagnostics14080839
DT Article
PD APR 2024
PY 2024
AB Background: In the evolving field of maxillofacial surgery, integrating
   advanced technologies like Large Language Models (LLMs) into medical
   practices, especially for trauma triage, presents a promising yet
   largely unexplored potential. This study aimed to evaluate the
   feasibility of using LLMs for triaging complex maxillofacial trauma
   cases by comparing their performance against the expertise of a tertiary
   referral center. Methods: Utilizing a comprehensive review of patient
   records in a tertiary referral center over a year-long period,
   standardized prompts detailing patient demographics, injury
   characteristics, and medical histories were created. These prompts were
   used to assess the triage suggestions of ChatGPT 4.0 and Google GEMINI
   against the center's recommendations, supplemented by evaluating the
   AI's performance using the QAMAI and AIPI questionnaires. Results: The
   results in 10 cases of major maxillofacial trauma indicated moderate
   agreement rates between LLM recommendations and the referral center,
   with some variances in the suggestion of appropriate examinations (70%
   ChatGPT and 50% GEMINI) and treatment plans (60% ChatGPT and 45%
   GEMINI). Notably, the study found no statistically significant
   differences in several areas of the questionnaires, except in the
   diagnosis accuracy (GEMINI: 3.30, ChatGPT: 2.30; p = 0.032) and
   relevance of the recommendations (GEMINI: 2.90, ChatGPT: 3.50; p =
   0.021). A Spearman correlation analysis highlighted significant
   correlations within the two questionnaires, specifically between the
   QAMAI total score and AIPI treatment scores (rho = 0.767, p = 0.010).
   Conclusions: This exploratory investigation underscores the potential of
   LLMs in enhancing clinical decision making for maxillofacial trauma
   cases, indicating a need for further research to refine their
   application in healthcare settings.
TC 17
ZB 2
ZS 0
ZR 0
Z8 0
ZA 0
Z9 17
DA 2024-05-05
UT WOS:001210140800001
PM 38667484
ER

PT J
AU Wu, Wanying
   Guo, Yuhu
   Li, Qi
   Jia, Congzhuo
TI Exploring the potential of large language models in identifying
   metabolic dysfunction-associated steatotic liver disease: A comparative
   study of non-invasive tests and artificial intelligence-generated
   responses
SO LIVER INTERNATIONAL
VL 45
IS 4
DI 10.1111/liv.16112
EA NOV 2024
DT Article
PD APR 2025
PY 2025
AB Background and AimsThis study sought to assess the capabilities of large
   language models (LLMs) in identifying clinically significant metabolic
   dysfunction-associated steatotic liver disease (MASLD).MethodsWe
   included individuals from NHANES 2017-2018. The validity and reliability
   of MASLD diagnosis by GPT-3.5 and GPT-4 were quantitatively examined and
   compared with those of the Fatty Liver Index (FLI) and United States FLI
   (USFLI). A receiver operating characteristic curve was conducted to
   assess the accuracy of MASLD diagnosis via different scoring systems.
   Additionally, GPT-4V's potential in clinical diagnosis using ultrasound
   images from MASLD patients was evaluated to provide assessments of LLM
   capabilities in both textual and visual data interpretation.ResultsGPT-4
   demonstrated comparable performance in MASLD diagnosis to FLI and USFLI
   with the AUROC values of .831 (95% CI .796-.867), .817 (95% CI
   .797-.837) and .827 (95% CI .807-.848), respectively. GPT-4 exhibited a
   trend of enhanced accuracy, clinical relevance and efficiency compared
   to GPT-3.5 based on clinician evaluation. Additionally, Pearson's r
   values between GPT-4 and FLI, as well as USFLI, were .718 and .695,
   respectively, indicating robust and moderate correlations. Moreover,
   GPT-4V showed potential in understanding characteristics from hepatic
   ultrasound imaging but exhibited limited interpretive accuracy in
   diagnosing MASLD compared to skilled radiologists.ConclusionsGPT-4
   achieved performance comparable to traditional risk scores in diagnosing
   MASLD and exhibited improved convenience, versatility and the capacity
   to offer user-friendly outputs. The integration of GPT-4V highlights the
   capacities of LLMs in handling both textual and visual medical data,
   reinforcing their expansive utility in healthcare practice.
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
DA 2024-11-23
UT WOS:001354198800001
PM 39526465
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT J
AU Albalawi, Farraj
   Khanagar, Sanjeev B.
   Iyer, Kiran
   Alhazmi, Nora
   Alayyash, Afnan
   Alhazmi, Anwar S.
   Awawdeh, Mohammed
   Singh, Oinam Gokulchandra
TI Evaluating the Performance of Artificial Intelligence-Based Large
   Language Models in Orthodontics-A Systematic Review and Meta-Analysis
SO APPLIED SCIENCES-BASEL
VL 15
IS 2
AR 893
DI 10.3390/app15020893
DT Review
PD JAN 2025
PY 2025
AB Background: In recent years, there has been remarkable growth in
   AI-based applications in healthcare, with a significant breakthrough
   marked by the launch of large language models (LLMs) such as ChatGPT and
   Google Bard. Patients and health professional students commonly utilize
   these models due to their accessibility. The increasing use of LLMs in
   healthcare necessitates an evaluation of their ability to generate
   accurate and reliable responses. Objective: This study assessed the
   performance of LLMs in answering orthodontic-related queries through a
   systematic review and meta-analysis. Methods: A comprehensive search of
   PubMed, Web of Science, Embase, Scopus, and Google Scholar was conducted
   up to 31 October 2024. The quality of the included studies was evaluated
   using the Prediction model Risk of Bias Assessment Tool (PROBAST), and R
   Studio software (Version 4.4.0) was employed for meta-analysis and
   heterogeneity assessment. Results: Out of 278 retrieved articles, 10
   studies were included. The most commonly used LLM was ChatGPT (10/10,
   100% of papers), followed by Google's Bard/Gemini (3/10, 30% of papers),
   and Microsoft's Bing/Copilot AI (2/10, 20% of papers). Accuracy was
   primarily evaluated using Likert scales, while the DISCERN tool was
   frequently applied for reliability assessment. The meta-analysis
   indicated that the LLMs, such as ChatGPT-4 and other models, do not
   significantly differ in generating responses to queries related to the
   specialty of orthodontics. The forest plot revealed a Standard Mean
   Deviation of 0.01 [CI: 0.42-0.44]. No heterogeneity was observed between
   the experimental group (ChatGPT-3.5, Gemini, and Copilot) and the
   control group (ChatGPT-4). However, most studies exhibited a high
   PROBAST risk of bias due to the lack of standardized evaluation tools.
   Conclusions: ChatGPT-4 has been extensively used for a variety of tasks
   and has demonstrated advanced and encouraging outcomes compared to other
   LLMs, and thus can be regarded as a valuable tool for enhancing
   educational and learning experiences. While LLMs can generate
   comprehensive responses, their reliability is compromised by the absence
   of peer-reviewed references, necessitating expert oversight in
   healthcare applications.
TC 0
ZA 0
ZB 0
ZS 0
Z8 0
ZR 0
Z9 0
DA 2025-01-30
UT WOS:001403965800001
ER

PT J
AU Chen, Qian
   Lin, Zihang
   Li, Xudong
   Zheng, Jingyuan
   Zhang, Yan
   Ji, Rongrong
TI Multi-scale and contrastive learning for pediatric chest radiograph
   classification tasks
SO DISPLAYS
VL 87
AR 102951
DI 10.1016/j.displa.2024.102951
EA JAN 2025
DT Article
PD APR 2025
PY 2025
AB Pediatric medical image classification faces enormous challenges due to
   the subtlety of children's physiology, the subtle manifestations of
   pathological changes, and the urgent need for accurate and timely
   diagnosis. This complexity is further exacerbated by the high
   variability in image quality, the small sample sizes of rare diseases,
   and the need for models to generalize well over diverse and often
   limited datasets. Addressing these challenges is imperative to improve
   pediatric healthcare outcomes. To this end, this paper proposes a model
   that combines contrastive learning and multi-scale theory, which
   simulates the behavior of the eye zooming in and out of an image when a
   physician is looking at a medical imaging picture. First, we zoom in and
   out the image and then perform feature extraction and blending by
   feature encoder and scale integration unit for the purpose of learning
   the fine texture and global feature of the lesion. At the same time, we
   write a series of texts for the disease category that needs to be
   diagnosed and get its features through text encoder. Considering the
   further fusion of image features, we also introduce a frozen LLM block
   to do it. Finally, we use text features and image features for
   similarity computation, the crucial step of contrastive learning, and
   obtain the final categories. On four public datasets, our proposed model
   performs excellently and outperforms existing SOTA methods. In addition,
   our model also performs well in generalized proficiency testing,
   particularly in IQA. With this work, we aim to open new avenues for the
   use of contrastive learning and multi-scale theory in pediatric medical
   imaging and to enrich the understanding of its potential in this
   specialized field.
ZR 0
ZB 0
Z8 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-01-22
UT WOS:001397596400001
ER

PT C
AU Bie, Yequan
   Liu, Luyang
   Chen, Zhixuan
   Chen, Hao
BE Linguraru, MG
   Dou, Q
   Feragen, A
   Giannarou, S
   Glocker, B
   Lekadir, K
   Schnabel, JA
TI XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via
   Concept-Guided Context Optimization
SO MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI
   2024, PT XII
SE Lecture Notes in Computer Science
VL 15012
BP 773
EP 783
DI 10.1007/978-3-031-72390-2_72
DT Proceedings Paper
PD 2024
PY 2024
AB Utilizing potent representations of the large vision-language models
   (VLMs) to accomplish various downstream tasks has attracted increasing
   attention. Within this research field, soft prompt learning has become a
   representative approach for efficiently adapting VLMs such as CLIP, to
   tasks like image classification. However, most existing prompt learning
   methods learn text tokens that are unexplainable, which cannot satisfy
   the stringent interpretability requirements of Explainable Artificial
   Intelligence (XAI) in high-stakes scenarios like healthcare. To address
   this issue, we propose a novel explainable prompt learning framework
   that leverages medical knowledge by aligning the semantics of images,
   learnable prompts, and clinical concept-driven prompts at multiple
   granularities. Moreover, our framework addresses the lack of valuable
   concept annotations by eliciting knowledge from large language models
   and offers both visual and textual explanations for the prompts.
   Extensive experiments and explainability analyses conducted on various
   datasets, with and without concept labels, demonstrate that our method
   simultaneously achieves superior diagnostic performance, flexibility,
   and interpretability, shedding light on the effectiveness of foundation
   models in facilitating XAI. The code is available at
   https://github.com/Tommy-Bie/XCoOp.
CT 27th International Conference on Medical Image Computing and Computer
   Assisted Intervention (MICCAI)
CY OCT 06-10, 2024
CL Palmeraie Conf Ctr, Marrakesh, MOROCCO
HO Palmeraie Conf Ctr
SP GH Labs; Childrens Natl Hosp; Pierre Fabre; Comp Assisted Med Intervent
   Labex; Multidisciplinary Inst Artificial Intelligence Grenoble Alpes;
   Western Univ, Frugal Biomed Innovat Program; Int Soc Radiol; Medtronic;
   Pasqual Maragall Fdn; Delft Imaging; Univ Barcelona, Artificial
   Intelligence Med Lab; Cadi Ayyad Univ; Natl Ctr Sci & Tech Res
Z8 0
ZA 0
ZR 0
TC 1
ZS 0
ZB 0
Z9 1
DA 2024-12-03
UT WOS:001344002100072
ER

PT J
AU Kumar, Rohit Prem
   Sivan, Vijay
   Bachir, Hanin
   Sarwar, Syed A.
   Ruzicka, Francis
   O'Malley, Geoffrey R.
   Lobo, Paulo
   Morales, Ilona Cazorla
   Cassimatis, Nicholas D.
   Hundal, Jasdeep S.
   Patel, Nitesh V.
TI Can Artificial Intelligence Mitigate Missed Diagnoses by Generating
   Differential Diagnoses for Neurosurgeons?
SO WORLD NEUROSURGERY
VL 187
BP E1083
EP E1088
DI 10.1016/j.wneu.2024.05.052
EA JUL 2024
DT Article
PD JUL 2024
PY 2024
AB - BACKGROUND/OBJECTIVE: Neurosurgery emphasizes the criticality of
   accurate differential diagnoses, with diagnostic delays posing
   significant health and economic challenges. As large language models
   (LLMs) emerge as transformative tools in healthcare, this study seeks to
   elucidate their role in assisting neurosurgeons with the differential
   diagnosis process, especially during preliminary consultations. -
   METHODS: This study employed 3 chat -based LLMs, ChatGPT (versions 3.5
   and 4.0), Perplexity AI, and Bard AI, to evaluate their diagnostic
   accuracy. Each LLM was prompted using clinical vignettes, and their
   responses were recorded to generate differential diagnoses for 20 common
   and uncommon neurosurgical disorders. Diseasespecific prompts were
   crafted using Dynamed, a clinical reference tool. The accuracy of the
   LLMs was determined based on their ability to identify the target
   disease within their top differential diagnoses correctly. - RESULTS:
   For the initial differential, ChatGPT 3.5 achieved an accuracy of
   52.63%, while ChatGPT 4.0 performed slightly better at 53.68%.
   Perplexity AI and Bard AI demonstrated 40.00% and 29.47% accuracy,
   respectively. As the number of considered differentials increased from 2
   to 5, ChatGPT 3.5 reached its peak accuracy of 77.89% for the top 5
   differentials. Bard AI and Perplexity AI had varied performances, with
   Bard AI improving in the top 5 differentials at 62.11%. On a disease
   -specific note, the LLMs excelled in diagnosing conditions like epilepsy
   and cervical spine stenosis but faced challenges with more complex
   diseases such as Moyamoya disease and amyotrophic lateral sclerosis. -
   CONCLUSIONS: LLMs showcase the potential to enhance diagnostic accuracy
   and decrease the incidence of missed diagnoses in neurosurgery.
ZB 1
ZS 0
ZR 0
TC 6
ZA 0
Z8 0
Z9 6
DA 2024-07-14
UT WOS:001264220600001
PM 38759788
ER

PT J
AU Izhar, Amaan
   Idris, Norisma
   Japar, Nurul
TI Engaging Preference Optimization Alignment in Large Language Model for
   Continual Radiology Report Generation: A Hybrid Approach
SO COGNITIVE COMPUTATION
VL 17
IS 1
AR 53
DI 10.1007/s12559-025-10404-6
DT Letter
PD FEB 2025
PY 2025
AB Large language models (LLMs) remain relatively underutilized in medical
   imaging, particularly in radiology, which is essential for disease
   diagnosis and management. Nonetheless, radiology report generation (RRG)
   is a time-consuming task that can result in delays and inconsistencies.
   To address these challenges, we present a novel hybrid approach that
   integrates multi-modal radiology information and preference optimization
   alignment in LLM for continual RRG. Our method integrates a pre-trained
   small multi-modal model to analyze radiology images and generate an
   initial report, which is subsequently refined and aligned by an LLM
   using odds ratio preference optimization (ORPO) and with historical
   patient data and assessments to mimic radiologist-like responses,
   bypassing reinforcement learning from human feedback-based (RLHF)
   alignment. This two-stage fusion-supervised fine-tuning followed by
   preference optimization-ensures high accuracy while minimizing
   hallucinations and errors. We also propose a data field curation
   strategy extendable to various other RRG modality datasets, focusing on
   selecting relevant responses for preference alignment. We evaluate our
   approach on two public datasets, achieving state-of-the-art performance
   with average Bleu scores of 0.375 and 0.647, Meteor scores of 0.495 and
   0.714, Rouge-L scores of 0.483 and 0.732, and average F1-RadGraph scores
   of 0.488 and 0.487, for chest X-rays and lung CT scan datasets,
   respectively. We further provide in-depth qualitative analyses and
   ablation studies to explain the workings of our model and grasp the
   clinical relevance for RRG. This work presents the first application of
   preference optimization in continual RRG, representing a significant
   advancement in automating clinically reliable report generation. By
   reducing cognitive burdens on radiologists through AI-powered reasoning
   and alignment in LLMs, the proposed model improves decision-making,
   perception, and diagnostic precision, streamlining workflows and
   enhancing patient care. Our code is available at
   https://github.com/AI-14/r2gpoallm.
Z8 0
ZB 0
TC 1
ZS 0
ZR 0
ZA 0
Z9 1
DA 2025-02-01
UT WOS:001407936900001
ER

PT J
AU Wali, Tursun
   Bolatbekov, Almat
   Maimaitijiang, Ehesan
   Salman, Dilbar
   Mamatjan, Yasin
TI A novel recommender framework with chatbot to stratify heart attack
   risk.
SO Discover medicine
VL 1
IS 1
BP 161
EP 161
DI 10.1007/s44337-024-00174-9
DT Journal Article
PD 2024
PY 2024
AB Cardiovascular diseases are a major cause of mortality and morbidity.
   Fast detection of life-threatening emergency events and an earlier start
   of the therapy would save many lives and reduce successive disabilities.
   Understanding the specific risk factors associated with heart attack and
   the degree of association is crucial in the clinical diagnosis.
   Considering the potential benefits of intelligent models in healthcare,
   many researchers have developed a variety of machine learning (ML)-based
   models to identify patients at risk of a heart attack. However, the
   common problem of previous works that used ML concepts was the lack of
   transparency in black-box models, which makes it difficult to understand
   how the model made the prediction. In this study, an automated smart
   recommender system (Explainable Artificial Intelligence) for heart
   attack prediction and risk stratification was developed. For the
   purpose, the CatBoost classifier was applied as the initial step. Then,
   the SHAP (SHapley Additive exPlanation) explainable algorithm was
   employed to determine reasons behind high or low risk classification.
   The recommender system can provide insights into the reasoning behind
   the predictions, including group-based and patient-specific
   explanations. In the final step, we integrated a Large Language Model
   (LLM) called BioMistral for chatting functionally to talk to users based
   on the model output as a digital doctor for consultation. Our smart
   recommender system achieved high accuracy in predicting a patient risk
   level with an average AUC of 0.88 and can explain the results
   transparently. Moreover, a Django-based online application that uses
   patient data to update medical information about an individual's heart
   attack risk was created. The LLM chatbot component would answer user
   questions about heart attacks and serve as a virtual companion on the
   route to heart health, our system also can locate nearby hospitals by
   applying Google Maps API and alert the users. The recommender system
   could improve patient management and lower heart attack risk while
   timely therapy aids in avoiding subsequent disabilities.
ZB 0
ZS 0
ZR 0
TC 0
ZA 0
Z8 0
Z9 0
DA 2025-01-09
UT MEDLINE:39759423
PM 39759423
ER

PT J
AU Delaunay, Julien
   Cusido, Jordi
TI Evaluating the Performance of Large Language Models in Predicting
   Diagnostics for Spanish Clinical Cases in Cardiology
SO APPLIED SCIENCES-BASEL
VL 15
IS 1
AR 61
DI 10.3390/app15010061
DT Article
PD JAN 2025
PY 2025
AB This study explores the potential of large language models (LLMs) in
   predicting medical diagnoses from Spanish-language clinical case
   descriptions, offering an alternative to traditional machine learning
   (ML) and deep learning (DL) techniques. Unlike ML and DL models, which
   typically rely on extensive domain-specific training and complex data
   preprocessing, LLMs can process unstructured text data directly without
   the need for specialized training on medical datasets. This unique
   characteristic of LLMs allows for faster implementation and eliminates
   the risks associated with overfitting, which are common in ML and DL
   models that require tailored training for each new dataset. In this
   research, we investigate the capacities of several state-of-the-art LLMs
   in predicting medical diagnoses based on Spanish textual descriptions of
   clinical cases. We measured the impact of prompt techniques and
   temperatures on the quality of the diagnosis. Our results indicate that
   Gemini Pro and Mixtral 8x22b generally performed well across different
   temperatures and techniques, while Medichat Llama3 showed more
   variability, particularly with the few-shot prompting technique. Low
   temperatures and specific prompt techniques, such as zero-shot and
   Retrieval-Augmented Generation (RAG), tended to yield clearer and more
   accurate diagnoses. This study highlights the potential of LLMs as a
   disruptive alternative to traditional ML and DL approaches, offering a
   more efficient, scalable, and flexible solution for medical diagnostics,
   particularly in the non-English-speaking population.
ZA 0
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
DA 2025-01-15
UT WOS:001393476000001
ER

PT J
AU Tahir, Bilal
   Mehmood, Muhammad Amir
TI TepiSense: A Social Computing-Based Real-Time Epidemic Surveillance
   System Using Artificial Intelligence
SO IEEE ACCESS
VL 13
BP 23816
EP 23832
DI 10.1109/ACCESS.2025.3537168
DT Article
PD 2025
PY 2025
AB Artificial Intelligence (AI) technologies have enabled researchers to
   develop tools to monitor real-world events and user behavior using
   social media platforms. Twitter is particularly useful for gathering
   invaluable information related to diseases and public health to build
   real-time disease surveillance systems. Such systems offer a
   cost-effective and efficient alternative to the passive, expensive, and
   time-consuming process of using data from healthcare organizations and
   hospitals. In this paper, we propose a novel system of TepiSense to
   automatically perform disease surveillance of epidemic-prone diseases.
   Our system classifies tweets related to diseases and further identifies
   'indication' tweets that highlight the presence of patients. Our system
   consists of four distinct modules of pre-processor, feature extractor,
   classifier, and evaluator. TepiSense compares the performance of 3
   feature extraction techniques, 9 machine/deep learning models, and 3
   Large Language Models (LLMs). To test the performance of our system, we
   build a dataset of Twitter Epidemic Surveillance Corpus (TESC)
   containing 23.9K English and 13K labelled Urdu tweets related to six
   diseases: COVID19, hepatitis, malaria, flu, dengue, and HIV/AIDS. Our
   results show that mBERT LLM achieves the highest F-measure values of
   0.96 and 0.83 for topic and indication tweets classification,
   respectively. Furthermore, we compute the correlation of signals
   generated by our system with real-world cases to test the efficacy on
   COVID19 disease. We notice that real-world cases have a correlation of
   0.58-0.63 with the indication category tweets. Finally, we develop an
   interactive and user-friendly dashboard to disseminate the analytics of
   our system. Overall, our system offers a powerful tool for real-time
   disease surveillance using social media with potential implications for
   public health policy and decision-making.
ZS 0
Z8 0
TC 0
ZR 0
ZA 0
ZB 0
Z9 0
DA 2025-03-13
UT WOS:001420679000002
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT C
AU Basi, Abdul
   Hussain, Khizar
   Hanif, Muhammad Abdullah
   Shafique, Muhammad
GP IEEE
TI RoboMed: On-Premise Medical Assistance Leveraging Large Language Models
   in Robotics
SO 2024 18TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, ROBOTICS AND
   VISION, ICARCV
SE International Conference on Control Automation Robotics and Vision
BP 710
EP 717
DI 10.1109/ICARCV63323.2024.10821547
DT Proceedings Paper
PD 2024
PY 2024
AB Large language models (LLMs) are revolutionizing numerous domains with
   their remarkable natural language processing (NLP) capabilities,
   attracting significant interest and widespread adoption. However,
   deploying LLMs in resource-constrained environments, such as edge
   computing and robotics systems without server infrastructure, while also
   aiming to minimize latency, presents significant challenges. Another
   challenge lies in delivering medical assistance to remote areas with
   limited healthcare facilities and infrastructure. To address this, we
   introduce RoboMed, an on-premise healthcare robot that utilizes compact
   versions of large language models (tiny-LLMs) integrated with LangChain
   as its backbone. Moreover, it incorporates automatic speech recognition
   (ASR) models for user interface, enabling efficient, edge-based
   preliminary medical diagnostics and support. RoboMed employs model
   optimizations to achieve minimal memory footprint and reduced latency
   during inference on embedded edge devices. The training process
   optimization involves low-rank adaptation (LoRA), which reduces the
   model's complexity without significantly impacting its performance. For
   fine-tuning, the LLM is trained on a diverse medical dataset compiled
   from online health forums, clinical case studies, and a distilled
   medicine corpus. This fine-tuning process utilizes reinforcement
   learning from human feedback (RLHF) to further enhance its
   domain-specific capabilities. The system is deployed on Nvidia Jetson
   development board and achieves 78% accuracy in medical consultations and
   scores 56 in USMLE benchmark, enabling an resource-efficient healthcare
   assistance robot that alleviates privacy concerns due to edge-based
   deployment, thereby empowering the community.
CT 18th International Conference on Control Automation Robotics and Vision
CY DEC 12-15, 2024
CL U ARAB EMIRATES
ZA 0
ZB 0
ZS 0
Z8 0
TC 0
ZR 0
Z9 0
DA 2025-04-02
UT WOS:001435120000114
ER

PT J
AU Kee, Xiang Lee Jamie
   Sng, Gerald Gui Ren
   Lim, Daniel Yan Zheng
   Tung, Joshua Yi Min
   Abdullah, Hairil Rizal
   Chowdury, Anupama Roy
TI Use of a large language model with instruction-tuning for reliable
   clinical frailty scoring
SO JOURNAL OF THE AMERICAN GERIATRICS SOCIETY
VL 72
IS 12
BP 3849
EP 3854
DI 10.1111/jgs.19114
EA AUG 2024
DT Article
PD DEC 2024
PY 2024
AB BackgroundFrailty is an important predictor of health outcomes,
   characterized by increased vulnerability due to physiological decline.
   The Clinical Frailty Scale (CFS) is commonly used for frailty assessment
   but may be influenced by rater bias. Use of artificial intelligence
   (AI), particularly Large Language Models (LLMs) offers a promising
   method for efficient and reliable frailty scoring.MethodsThe study
   utilized seven standardized patient scenarios to evaluate the
   consistency and reliability of CFS scoring by OpenAI's GPT-3.5-turbo
   model. Two methods were tested: a basic prompt and an instruction-tuned
   prompt incorporating CFS definition, a directive for accurate responses,
   and temperature control. The outputs were compared using the
   Mann-Whitney U test and Fleiss' Kappa for inter-rater reliability. The
   outputs were compared with historic human scores of the same
   scenarios.ResultsThe LLM's median scores were similar to human raters,
   with differences of no more than one point. Significant differences in
   score distributions were observed between the basic and
   instruction-tuned prompts in five out of seven scenarios. The
   instruction-tuned prompt showed high inter-rater reliability (Fleiss'
   Kappa of 0.887) and produced consistent responses in all scenarios.
   Difficulty in scoring was noted in scenarios with less explicit
   information on activities of daily living (ADLs).ConclusionsThis study
   demonstrates the potential of LLMs in consistently scoring clinical
   frailty with high reliability. It demonstrates that prompt engineering
   via instruction-tuning can be a simple but effective approach for
   optimizing LLMs in healthcare applications. The LLM may overestimate
   frailty scores when less information about ADLs is provided, possibly as
   it is less subject to implicit assumptions and extrapolation than
   humans. Future research could explore the integration of LLMs in
   clinical research and frailty-related outcome prediction.
TC 2
ZR 0
ZB 0
ZS 0
ZA 0
Z8 0
Z9 2
DA 2024-08-13
UT WOS:001285634000001
PM 39105505
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU de Arriba-Perez, Francisco
   Garcia-Mendez, Silvia
TI Leveraging large language models through natural language processing to
   provide interpretable machine learning predictions of mental
   deterioration in real time
SO ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING
DI 10.1007/s13369-024-09508-2
EA AUG 2024
DT Article; Early Access
PY 2024
AB Based on official estimates, 50 million people worldwide are affected by
   dementia, and this number increases by 10 million new patients every
   year. Without a cure, clinical prognostication and early intervention
   represent the most effective ways to delay its progression. To this end,
   artificial intelligence and computational linguistics can be exploited
   for natural language analysis, personalized assessment, monitoring, and
   treatment. However, traditional approaches need more semantic knowledge
   management and explicability capabilities. Moreover, using large
   language models (llms) for cognitive decline diagnosis is still scarce,
   even though these models represent the most advanced way for
   clinical-patient communication using intelligent systems. Consequently,
   we leverage an llm using the latest natural language processing (nlp)
   techniques in a chatbot solution to provide interpretable machine
   learning prediction of cognitive decline in real-time.
   Linguistic-conceptual features are exploited for appropriate natural
   language analysis. Through explainability, we aim to fight potential
   biases of the models and improve their potential to help clinical
   workers in their diagnosis decisions. More in detail, the proposed
   pipeline is composed of (i) data extraction employing nlp-based prompt
   engineering; (ii) stream-based data processing including feature
   engineering, analysis, and selection; (iii) real-time classification;
   and (iv) the explainability dashboard to provide visual and natural
   language descriptions of the prediction outcome. Classification results
   exceed 80% in all evaluation metrics, with a recall value for the mental
   deterioration class about 85%. To sum up, we contribute with an
   affordable, flexible, non-invasive, personalized diagnostic system to
   this work.
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
ZR 0
Z9 0
DA 2024-09-01
UT WOS:001298762700003
ER

PT J
AU Li, Ang
   Wang, Yunxin
   Chen, Hongxu
TI AI driven cardiovascular risk prediction using NLP and Large Language
   Models for personalized medicine in athletes
SO SLAS TECHNOLOGY
VL 32
AR 100286
DI 10.1016/j.slast.2025.100286
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB The performance and long-term health of athletes are significantly
   influenced by their cardiovascular resilience and associated risk
   factors. This study explores the innovative applications of Natural
   Language Processing (NLP) and Large Language Models (LLMs) in biomedical
   diagnostics, particularly for AI-driven arrhythmia detection,
   hypertrophic cardiomyopathy (HCM) in athletes, and personalized
   medicine. The complexity of analysing diverse biomedical datasets, such
   as electrocardiograms (ECG), clinical records, genetic screening
   reports, and imaging results, poses challenges in obtaining precise
   early diagnoses. To address these issues, we introduce a hybrid machine
   learning (ML) framework that integrates the Wolf Pack Search Algorithm
   Dynamic Random Forest (WPSA-DRF) with a RoBERTa-based LLM to enhance the
   accuracy of cardiovascular disease predictions. Using advanced NLP
   techniques, including biomedical text mining, entity recognition, and
   feature extraction, the system processes structured and unstructured
   clinical data to detect abnormalities associated with sudden cardiac
   arrest (SCA), arrhythmias, and genetic cardiomyopathies. The proposed
   system achieves a diagnostic accuracy of 92.5 %, precision of 92.7 %,
   recall of 99.23 %, and F1-score of 95.6 %, outperforming traditional
   diagnostic methodologies. Furthermore, the research underscores the role
   of LLMs in personalized medicine, identifying patient-specific risk
   factors and optimizing treatment pathways for cardiac patients. This
   work highlights how NLP-driven AI solutions are transforming biomedical
   research, accelerating early disease detection, and improving clinical
   decision-making for both athletes and the general population.
ZR 0
TC 0
ZA 0
ZS 0
Z8 0
ZB 0
Z9 0
DA 2025-05-08
UT WOS:001478484900001
PM 40216258
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT J
TI Assist GP <> Medwise AI. Improving patient care pathways with LLM
   technology
DT Awarded Grant
PD Apr 30 2024
PY 2024
AB There is an increasing need for healthcare professionals to quickly and
   accurately access information during patient care consultations. Doctors
   and other clinicians typically rely on written guidelines from various
   authorities for decision-making. These guidelines, encompassing
   everything from diagnosis to treatment, present challenges during
   patient care episodes due to their complexity (length, depth or
   presentation). Moreover, discrepancies between these guidelines and
   other online resources, along with local healthcare policies and funding
   protocols, can lead to variations in patient care and outcomes if the
   information - or its whereabouts- is not known to the clinician. 
   Responding to this challenge, Medwise AI is developing a solution to
   assist clinicians in swiftly finding the information they need.
   Utilising advanced technology, the company aims to streamline the
   process of information retrieval, thus enhancing efficiency and the
   consistency of care that this information enables. The solution is
   intended to reduce the time healthcare professionals spend navigating
   extensive guidelines, allowing a greater focus on direct patient care,
   and adherence to best practice.  The project builds upon existing
   technologies already used by GPs in West Yorkshire. It includes the
   development of a tool that provides immediate access to the required
   evidence-based information. This tool is particularly useful for
   navigating lengthy clinical guidelines and ensuring healthcare
   professionals stay abreast of the latest best practices when the
   information is needed.  The next stage of the project involves
   leveraging insights from previous user interactions to develop an
   improved search tool. This tool will provide rapid and precise responses
   to clinical queries, guiding healthcare professionals through various
   patient care options. Advanced technological features are planned to
   enhance the tool's accuracy and response speed, ensuring clinicians have
   timely access to necessary information.  The initiative is focused on
   providing healthcare professionals with accessible, consistent, and
   standardised care information. The goal is to minimise variations in
   treatment approaches and mitigate disparities in patient care. Medwise
   AI is committed to supporting healthcare professionals in delivering
   uniform, high-quality care to all patients. By equipping clinicians with
   more effective tools, the aim is to improve the overall quality of
   patient care and meet the challenges posed by the complex nature of
   current medical guidelines, making these documents more useful and
   usable in the delivery of best practice patient care.
ZR 0
ZS 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
G1 10108507
DA 2024-08-04
UT GRANTS:17771413
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Kawasaki, Ryo
TI How Can Artificial Intelligence Be Implemented Effectively in Diabetic
   Retinopathy Screening in Japan?
SO MEDICINA-LITHUANIA
VL 60
IS 2
AR 243
DI 10.3390/medicina60020243
DT Review
PD FEB 2024
PY 2024
AB Diabetic retinopathy (DR) is a major microvascular complication of
   diabetes, affecting a substantial portion of diabetic patients
   worldwide. Timely intervention is pivotal in mitigating the risk of
   blindness associated with DR, yet early detection remains a challenge
   due to the absence of early symptoms. Screening programs have emerged as
   a strategy to address this burden, and this paper delves into the role
   of artificial intelligence (AI) in advancing DR screening in Japan.
   There are two pathways for DR screening in Japan: a health screening
   pathway and a clinical referral path from physicians to
   ophthalmologists. AI technologies that realize automated image
   classification by applying deep learning are emerging. These
   technologies have exhibited substantial promise, achieving sensitivity
   and specificity levels exceeding 90% in prospective studies. Moreover,
   we introduce the potential of Generative AI and large language models
   (LLMs) to transform healthcare delivery, particularly in patient
   engagement, medical records, and decision support. Considering the use
   of AI in DR screening in Japan, we propose to follow a seven-step
   framework for systematic screening and emphasize the importance of
   integrating AI into a well-designed screening program. Automated scoring
   systems with AI enhance screening quality, but their effectiveness
   depends on their integration into the broader screening ecosystem. LLMs
   emerge as an important tool to fill gaps in the screening process, from
   personalized invitations to reporting results, facilitating a seamless
   and efficient system. However, it is essential to address concerns
   surrounding technical accuracy and governance before full-scale
   integration into the healthcare system. In conclusion, this review
   highlights the challenges in the current screening pathway and the
   potential for AI, particularly LLM, to revolutionize DR screening in
   Japan. The future direction will depend on leadership from
   ophthalmologists and stakeholders to address long-standing challenges in
   DR screening so that all people have access to accessible and effective
   screening.
TC 4
ZR 0
ZA 0
Z8 0
ZS 0
ZB 1
Z9 4
DA 2024-03-16
UT WOS:001172574500001
PM 38399532
ER

PT J
AU Lee, Gabriela Georgina
   Goodman, Deniz
   Chang, Ta Chen
TI Racial and Gender Bias in Artificial Intelligence Generated
   Ophthalmologic Educational Material
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
DA 2024-12-01
UT WOS:001312227701049
ER

PT J
AU Azurmendi, Iker
   Gonzalez, Manuel
   Garcia, Gustavo
   Zulueta, Ekaitz
   Martin, Elena
TI Deep Learning-Based Postural Asymmetry Detection Through Pressure Mat
SO APPLIED SCIENCES-BASEL
VL 14
IS 24
AR 12050
DI 10.3390/app142412050
DT Article
PD DEC 2024
PY 2024
AB Deep learning, a subfield of artificial intelligence that uses neural
   networks with multiple layers, is rapidly changing healthcare. Its
   ability to analyze large datasets and extract relevant information makes
   it a powerful tool for improving diagnosis, treatment, and disease
   management. The integration of DL with pressure mats-which are devices
   that use pressure sensors to continuously and non-invasively monitor the
   interaction between patients and the contact surface-is a promising
   application. These pressure platforms generate data that can be very
   useful for detecting postural anomalies. In this paper we will discuss
   the application of deep learning algorithms in the analysis of pressure
   data for the detection of postural asymmetries in 139 patients aged 3 to
   20 years. We investigated several main tasks: patient classification,
   hemibody segmentation, recognition of specific body parts, and
   generation of automated clinical reports. For this purpose,
   convolutional neural networks in their classification and regression
   modalities, the object detection algorithm YOLOv8, and the open language
   model LLaMa3 were used. Our results demonstrated high accuracy in all
   tasks: classification achieved 100% accuracy; hemibody division obtained
   an MAE of approximately 7; and object detection had an average accuracy
   of 70%. These results demonstrate the potential of this approach for
   monitoring postural and motor disabilities. By enabling personalized
   patient care, our methodology contributes to improved clinical outcomes
   and healthcare delivery. To our best knowledge, this is the first study
   that combines pressure images with multiple deep learning algorithms for
   the detection and assessment of postural disorders and motor
   disabilities in this group of patients.
ZR 0
ZB 0
ZA 0
TC 1
ZS 0
Z8 0
Z9 1
DA 2024-12-31
UT WOS:001384060100001
ER

PT J
AU Huppertz, Marc Sebastian
   Siepmann, Robert
   Topp, David
   Nikoubashman, Omid
   Yueksel, Can
   Kuhl, Christiane Katharina
   Truhn, Daniel
   Nebelung, Sven
TI Revolution or risk?-Assessing the potential and challenges of GPT-4V in
   radiologic image interpretation
SO EUROPEAN RADIOLOGY
VL 35
IS 3
BP 1111
EP 1121
DI 10.1007/s00330-024-11115-6
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB ObjectivesChatGPT-4 Vision (GPT-4V) is a state-of-the-art multimodal
   large language model (LLM) that may be queried using images. We aimed to
   evaluate the tool's diagnostic performance when autonomously assessing
   clinical imaging studies.Materials and methodsA total of 206 imaging
   studies (i.e., radiography (n = 60), CT (n = 60), MRI (n = 60), and
   angiography (n = 26)) with unequivocal findings and established
   reference diagnoses from the radiologic practice of a large university
   hospital were accessed. Readings were performed uncontextualized, with
   only the image provided, and contextualized, with additional clinical
   and demographic information. Responses were assessed along multiple
   diagnostic dimensions and analyzed using appropriate statistical
   tests.ResultsWith its pronounced propensity to favor context over image
   information, the tool's diagnostic accuracy improved from 8.3%
   (uncontextualized) to 29.1% (contextualized, first diagnosis correct)
   and 63.6% (contextualized, correct diagnosis among differential
   diagnoses) (p <= 0.001, Cochran's Q test). Diagnostic accuracy declined
   by up to 30% when 20 images were re-read after 30 and 90 days and seemed
   unrelated to the tool's self-reported confidence (Spearman's rho = 0.117
   (p = 0.776)). While the described imaging findings matched the suggested
   diagnoses in 92.7%, indicating valid diagnostic reasoning, the tool
   fabricated 258 imaging findings in 412 responses and misidentified
   imaging modalities or anatomic regions in 65 images.ConclusionGPT-4V, in
   its current form, cannot reliably interpret radiologic images. Its
   tendency to disregard the image, fabricate findings, and misidentify
   details, especially without clinical context, may misguide healthcare
   providers and put patients at risk.Key PointsQuestionCan Generative
   Pre-trained Transformer 4 Vision (GPT-4V) interpret radiologic
   images-with and without clinical context?FindingsGPT-4V performed
   poorly, demonstrating diagnostic accuracy rates of 8%
   (uncontextualized), 29% (contextualized, most likely diagnosis correct),
   and 64% (contextualized, correct diagnosis among differential
   diagnoses).Clinical relevanceThe utility of commercial multimodal large
   language models, such as GPT-4V, in radiologic practice is limited.
   Without clinical context, diagnostic errors and fabricated findings may
   compromise patient safety and misguide clinical decision-making. These
   models must be further refined to be beneficial.Key PointsQuestionCan
   Generative Pre-trained Transformer 4 Vision (GPT-4V) interpret
   radiologic images-with and without clinical context?FindingsGPT-4V
   performed poorly, demonstrating diagnostic accuracy rates of 8%
   (uncontextualized), 29% (contextualized, most likely diagnosis correct),
   and 64% (contextualized, correct diagnosis among differential
   diagnoses).Clinical relevanceThe utility of commercial multimodal large
   language models, such as GPT-4V, in radiologic practice is limited.
   Without clinical context, diagnostic errors and fabricated findings may
   compromise patient safety and misguide clinical decision-making. These
   models must be further refined to be beneficial.Key PointsQuestionCan
   Generative Pre-trained Transformer 4 Vision (GPT-4V) interpret
   radiologic images-with and without clinical context?FindingsGPT-4V
   performed poorly, demonstrating diagnostic accuracy rates of 8%
   (uncontextualized), 29% (contextualized, most likely diagnosis correct),
   and 64% (contextualized, correct diagnosis among differential
   diagnoses).
   Clinical relevanceThe utility of commercial multimodal large language
   models, such as GPT-4V, in radiologic practice is limited. Without
   clinical context, diagnostic errors and fabricated findings may
   compromise patient safety and misguide clinical decision-making. These
   models must be further refined to be beneficial.
ZA 0
Z8 0
ZR 0
TC 2
ZB 0
ZS 0
Z9 2
DA 2024-10-28
UT WOS:001339015800003
PM 39422726
ER

PT C
AU Wei, Qizhi
   Chen, Xuanyu
   Ni, Yifei
   Cao, Cong
GP ASSOC COMPUTING MACHINERY
TI A Technical Framework for Recognizing and Interpreting Complex Medical
   Records: Based on Multimodal Large Language Model
SO 2024 THE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND TEACHER
   EDUCATION, ICAITE 2024
BP 76
EP 83
DI 10.1145/3702386.3702396
DT Proceedings Paper
PD 2024
PY 2024
AB This paper brings up a technical framework for Interpreting medical
   documentation that integrates multi-modal large language modals, aiming
   to provide patients and doctors with the ability to read nonstandard
   medical documentation in complex environments and to obtain text
   interpretation based on generative AI. The framework proposes a
   three-stage solution, namely Recognition, Formatting, and AI-Processing,
   involving technologies such as OCR, medical multi-modal models, and
   large language models, abbreviated as the RF-AI framework. This paper
   focuses on explaining the potential issues encountered when applying the
   framework and describes the resolution within the framework. In
   addition, this paper conducts experiments on two key stages of the
   framework, recognition and AI-processing, which effectively demonstrate
   the feasibility of the framework. This framework can significantly
   reduce the difficulty for patients in understanding medical records and
   provides necessary resolution for situations where paper records might
   be used. It helps patients better understand their conditions and
   enhances the efficiency of diagnosis and treatment between doctors and
   patients. Benefiting from a large language model, this framework allows
   developers to expand based on actual needs and can be integrated into
   existing electronic healthcare systems to achieve more comprehensive
   functionality.
CT 2024 International Conference on Artificial Intelligence and Teacher
   Education
CY OCT 12-14, 2024
CL Beijing, PEOPLES R CHINA
Z8 0
ZR 0
ZA 0
TC 0
ZS 0
ZB 0
Z9 0
DA 2025-04-04
UT WOS:001443289300012
ER

PT J
AU Huang, Kexin
   Zhang, Serena
   Wang, Hanchen
   Qu, Yuanhao
   Lu, Yingzhou
   Roohani, Yusuf
   Li, Ryan
   Qiu, Lin
   Li, Gavin
   Zhang, Junze
   Yin, Di
   Marwaha, Shruti
   Carter, Jennefer N
   Zhou, Xin
   Wheeler, Matthew
   Bernstein, Jonathan A
   Wang, Mengdi
   He, Peng
   Zhou, Jingtian
   Snyder, Michael
   Cong, Le
   Regev, Aviv
   Leskovec, Jure
TI Biomni: A General-Purpose Biomedical AI Agent.
SO bioRxiv : the preprint server for biology
DI 10.1101/2025.05.30.656746
DT Journal Article; Preprint
PD 2025 Jun 02
PY 2025
AB Biomedical research underpins progress in our understanding of human
   health and disease, drug discovery, and clinical care. However, with the
   growth of complex lab experiments, large datasets, many analytical
   tools, and expansive literature, biomedical research is increasingly
   constrained by repetitive and fragmented workflows that slow discovery
   and limit innovation, underscoring the need for a fundamentally new way
   to scale scientific expertise. Here, we introduce Biomni, a
   general-purpose biomedical AI agent designed to autonomously execute a
   wide spectrum of research tasks across diverse biomedical subfields. To
   systematically map the biomedical action space, Biomni first employs an
   action discovery agent to create the first unified agentic environment -
   mining essential tools, databases, and protocols from tens of thousands
   of publications across 25 biomedical domains. Built on this foundation,
   Biomni features a generalist agentic architecture that integrates large
   language model (LLM) reasoning with retrieval-augmented planning and
   code-based execution, enabling it to dynamically compose and carry out
   complex biomedical workflows - entirely without relying on predefined
   templates or rigid task flows. Systematic benchmarking demonstrates that
   Biomni achieves strong generalization across heterogeneous biomedical
   tasks - including causal gene prioritization, drug repurposing, rare
   disease diagnosis, micro-biome analysis, and molecular cloning - without
   any task-specific prompt tuning. Real-world case studies further
   showcase Biomni's ability to interpret complex, multi-modal biomedical
   datasets and autonomously generate experimentally testable protocols.
   Biomni envisions a future where virtual AI biologists operate alongside
   and augment human scientists to dramatically enhance research
   productivity, clinical insight, and healthcare. Biomni is ready to use
   at https://biomni.stanford.edu , and we invite scientists to explore its
   capabilities, stress-test its limits, and co-create the next era of
   biomedical discoveries.
ZR 0
Z8 0
ZS 0
ZA 0
ZB 0
TC 0
Z9 0
DA 2025-06-14
UT MEDLINE:40501924
PM 40501924
ER

PT J
AU Du, Xinsong
   Novoa-Laurentiev, John
   Plasek, Joseph M.
   Chuang, Ya-Wen
   Wang, Liqin
   Marshall, Gad A.
   Mueller, Stephanie K.
   Chang, Frank
   Datta, Surabhi
   Paek, Hunki
   Lin, Bin
   Wei, Qiang
   Wang, Xiaoyan
   Wang, Jingqi
   Ding, Hao
   Manion, Frank J.
   Du, Jingcheng
   Bates, David W.
   Zhou, Li
TI Enhancing early detection of cognitive decline in the elderly: a
   comparative study utilizing large language models in clinical notes
SO EBIOMEDICINE
VL 109
AR 105401
DI 10.1016/j.ebiom.2024.105401
EA OCT 2024
DT Article
PD NOV 2024
PY 2024
AB Background: Large language models (LLMs) have shown promising
   performance in various healthcare domains, but their effectiveness in
   identifying specific clinical conditions in real medical records is less
   explored. This study evaluates LLMs for detecting signs of cognitive
   decline in real electronic health record (EHR) clinical notes, comparing
   their error profiles with traditional models. The insights gained will
   inform strategies for performance enhancement. Methods: This study,
   conducted at Mass General Brigham in Boston, MA, analyzed clinical notes
   from the four years prior to a 2019 diagnosis of mild cognitive
   impairment in patients aged 50 and older. We used a randomly annotated
   sample of 4,949 note sections, filtered with keywords related to
   cognitive functions, for model development. For testing, a random
   annotated sample of 1,996 note sections without keyword filtering was
   utilized. We developed prompts for two LLMs, Llama 2 and GPT-4, on
   HIPAA-compliant cloud-computing platforms using multiple approaches
   (e.g., both hard and soft prompting and error analysis-based
   instructions) to select the optimal LLM-based method. Baseline models
   included a hierarchical attention-based neural network and XGBoost.
   Subsequently, we constructed an ensemble of the three models using a
   majority vote approach. Results: GPT-4 demonstrated superior accuracy
   and efficiency compared to Llama 2, but did not outperform traditional
   models. The ensemble model outperformed the individual models, achieving
   a precision of 90.3%, a recall of 94.2%, and an F1-score of 92.2%.
   Notably, the ensemble model showed a significant improvement in
   precision, increasing from a range of 70%-79% to above 90%, compared to
   the best-performing single model. Error analysis revealed that 63
   samples were incorrectly predicted by at least one model; however, only
   2 cases (3.2%) were mutual errors across all models, indicating diverse
   error profiles among them. Conclusions: LLMs and
   traditional machine learning models trained using local EHR data
   exhibited diverse error profiles. The ensemble of these models was found
   to be complementary, enhancing diagnostic performance. Future research
   should investigate integrating LLMs with smaller, localized models and
   incorporating medical data and domain knowledge to enhance performance
   on specific tasks.
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 3
Z9 3
DA 2024-10-31
UT WOS:001338984600001
PM 39396423
ER

PT J
AU Postaci, Sevinc Arzu
   Dal, Ali
TI The Ability of Large Language Models to Generate Patient Information
   Materials for Retinopathy of Prematurity: Evaluation of Readability,
   Accuracy, and Comprehensiveness
SO TURK OFTALMOLOJI DERGISI-TURKISH JOURNAL OF OPHTHALMOLOGY
VL 54
IS 6
BP 330
EP 336
DI 10.4274/tjo.galenos.2024.58295
DT Article
PD DEC 2024
PY 2024
AB Objectives: This study compared the readability of patient education
   materials from the Turkish Ophthalmological Association (TOA)
   retinopathy of prematurity (ROP) guidelines with those generated by
   large language models (LLMs). The ability of GPT-4.0, GPT-4o mini, and
   Gemini to produce patient education materials was evaluated in terms of
   accuracy and comprehensiveness. Materials and Methods: Thirty questions
   from the TOA ROP guidelines were posed to GPT-4.0, GPT-4o mini, and
   Gemini. Their responses were then reformulated using the prompts "Can
   you revise this text to be understandable at a 6(th)-grade reading
   level?" (P1 format) and "Can you make this text easier to understand?"
   (P2 format). The readability of the TOA ROP guidelines and the
   LLM-generated responses was analyzed using the Ate & scedil;man and
   Bezirci-Y & imath;lmaz formulas. Additionally, ROP specialists evaluated
   the comprehensiveness and accuracy of the responses. Results: The TOA
   brochure was found to have a reading level above the 6(th)-grade level
   recommended in the literature. Materials generated by GPT-4.0 and Gemini
   had significantly greater readability than the TOA brochure (p<0.05).
   Adjustments made in the P1 and P2 formats improved readability for
   GPT-4.0, while no significant change was observed for GPT-4o mini and
   Gemini. GPT-4.0 had the highest scores for accuracy and
   comprehensiveness, while Gemini had the lowest. Conclusion: GPT-4.0
   appeared to have greater potential for generating more readable,
   accurate, and comprehensive patient education materials. However, when
   integrating LLMs into the healthcare field, regional medical differences
   and the accuracy of the provided information must be carefully assessed.
Z8 0
ZR 0
ZB 0
ZS 0
TC 0
ZA 0
Z9 0
DA 2025-01-11
UT WOS:001390134600004
PM 39743928
ER

PT J
AU Hsieh, Chihcheng
   Moreira, Catarina
   Nobre, Isabel Blanco
   Sousa, Sandra Costa
   Ouyang, Chun
   Brereton, Margot
   Jorge, Joaquim
   Nascimento, Jacinto C
TI DALL-M: Context-aware clinical data augmentation with large language
   models.
SO Computers in biology and medicine
VL 190
BP 110022
EP 110022
DI 10.1016/j.compbiomed.2025.110022
DT Journal Article
PD 2025-May
PY 2025
AB X-ray images are vital in medical diagnostics, but their effectiveness
   is limited without clinical context. Radiologists often find chest
   X-rays insufficient for diagnosing underlying diseases, necessitating
   the integration of structured clinical features with radiology reports.
   To address this, we introduce DALL-M, a novel framework that enhances
   clinical datasets by generating contextual synthetic data. DALL-M
   augments structured patient data, including vital signs (e.g., heart
   rate, oxygen saturation), radiology findings (e.g., lesion presence),
   and demographic factors. It integrates this tabular data with contextual
   knowledge extracted from radiology reports and domain-specific resources
   (e.g., Radiopaedia, Wikipedia), ensuring clinical consistency and
   reliability. DALL-M follows a three-phase process: (i) clinical context
   storage, (ii) expert query generation, and (iii) context-aware feature
   augmentation. Using large language models (LLMs), it generates both
   contextual synthetic values for existing clinical features and entirely
   new, clinically relevant features. Applied to 799 cases from the
   MIMIC-IV dataset, DALL-M expanded the original 9 clinical features to
   91. Empirical validation with machine learning models - including
   Decision Trees, Random Forests, XGBoost, and TabNET - demonstrated a
   16.5% improvement in F1 score and a 25% increase in Precision and
   Recall. DALL-M bridges an important gap in clinical data augmentation by
   preserving data integrity while enhancing predictive modeling in
   healthcare. Our results show that integrating LLM-generated synthetic
   features significantly improves model performance, making DALL-M a
   scalable and practical approach for AI-driven medical diagnostics.
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2025-04-05
UT MEDLINE:40174497
PM 40174497
ER

PT J
AU Zhang, Yufeng
   Kohne, Joseph G.
   Webster, Katherine
   Vartanian, Rebecca
   Wittrup, Emily
   Najarian, Kayvan
TI AXpert: human expert facilitated privacy-preserving large language
   models for abdominal X-ray report labeling
SO JAMIA OPEN
VL 8
IS 1
AR ooaf008
DI 10.1093/jamiaopen/ooaf008
DT Article
PD FEB 10 2025
PY 2025
AB Importance The lack of a publicly accessible abdominal X-ray (AXR)
   dataset has hindered necrotizing enterocolitis (NEC) research. While
   significant strides have been made in applying natural language
   processing (NLP) to radiology reports, most efforts have focused on
   chest radiology. Development of an accurate NLP model to identify
   features of NEC on abdominal radiograph can support efforts to improve
   diagnostic accuracy for this and other rare pediatric
   conditions.Objectives This study aims to develop privacy-preserving
   large language models (LLMs) and their distilled version to efficiently
   annotate pediatric AXR reports.Materials and Methods Utilizing pediatric
   AXR reports collected from C.S. Mott Children's Hospital, we introduced
   AXpert in 2 formats: one based on the instruction-fine-tuned 7-B Gemma
   model, and a distilled version employing a BERT-based model derived from
   the fine-tuned model to improve inference and fine-tuning efficiency.
   AXpert aims to detect NEC presence and classify its
   subtypes-pneumatosis, portal venous gas, and free air.Results Extensive
   testing shows that LLMs, including Axpert, outperforms baseline BERT
   models on all metrics. Specifically, Gemma-7B (F1 score: 0.9 +/- 0.015)
   improves upon BlueBERT by 132% in F1 score for detecting NEC positive
   samples. The distilled BERT model matches the performance of the LLM
   labelers and surpasses expert-trained baseline BERT models.Discussion
   Our findings highlight the potential of using LLMs for clinical NLP
   tasks. With minimal expert knowledge injections, LLMs can achieve
   human-like performance, greatly reducing manual labor. Privacy concerns
   are alleviated as all models are trained and deployed locally.Conclusion
   AXpert demonstrates potential to reduce human labeling efforts while
   maintaining high accuracy in automating NEC diagnosis with AXR, offering
   precise image labeling capabilities.
   In pediatric healthcare, diagnosing conditions like necrotizing
   enterocolitis (NEC), a serious gastrointestinal issue in infants, is
   challenging due to the scarcity of public X-ray data. To address this,
   we introduced AXpert, an innovative tool designed to enhance NEC
   diagnosis by analyzing abdominal X-ray reports from children. AXpert
   utilizes advanced artificial intelligence (AI), specifically tailored
   large language models (LLMs), to interpret medical texts. These models
   were trained using data from C.S. Mott Children's Hospital to identify
   NEC and its critical features, such as pneumatosis, portal venous gas,
   and free air. The study shows that AXpert outperforms previous AI
   models, providing both accurate and efficient diagnostic assessments.
   Importantly, AXpert focuses on privacy, with all data and AI operations
   handled locally to protect patient information. This tool not only
   promises to reduce the workload of medical professionals but also
   improves the accuracy of diagnosing severe conditions in young patients,
   showcasing the potential of AI in enhancing pediatric healthcare.
TC 0
ZR 0
ZB 0
ZS 0
Z8 0
ZA 0
Z9 0
DA 2025-02-15
UT WOS:001416676700001
PM 39931456
ER

PT J
AU Ullah, Ehsan
   Parwani, Anil
   Baig, Mirza Mansoor
   Singh, Rajendra
TI Challenges and barriers of using large language models (LLM) such as
   ChatGPT for diagnostic medicine with a focus on digital pathology - a
   recent scoping review
SO DIAGNOSTIC PATHOLOGY
VL 19
IS 1
AR 43
DI 10.1186/s13000-024-01464-7
DT Review
PD FEB 27 2024
PY 2024
AB BackgroundThe integration of large language models (LLMs) like ChatGPT
   in diagnostic medicine, with a focus on digital pathology, has garnered
   significant attention. However, understanding the challenges and
   barriers associated with the use of LLMs in this context is crucial for
   their successful implementation.MethodsA scoping review was conducted to
   explore the challenges and barriers of using LLMs, in diagnostic
   medicine with a focus on digital pathology. A comprehensive search was
   conducted using electronic databases, including PubMed and Google
   Scholar, for relevant articles published within the past four years. The
   selected articles were critically analyzed to identify and summarize the
   challenges and barriers reported in the literature.ResultsThe scoping
   review identified several challenges and barriers associated with the
   use of LLMs in diagnostic medicine. These included limitations in
   contextual understanding and interpretability, biases in training data,
   ethical considerations, impact on healthcare professionals, and
   regulatory concerns. Contextual understanding and interpretability
   challenges arise due to the lack of true understanding of medical
   concepts and lack of these models being explicitly trained on medical
   records selected by trained professionals, and the black-box nature of
   LLMs. Biases in training data pose a risk of perpetuating disparities
   and inaccuracies in diagnoses. Ethical considerations include patient
   privacy, data security, and responsible AI use. The integration of LLMs
   may impact healthcare professionals' autonomy and decision-making
   abilities. Regulatory concerns surround the need for guidelines and
   frameworks to ensure safe and ethical implementation.ConclusionThe
   scoping review highlights the challenges and barriers of using LLMs in
   diagnostic medicine with a focus on digital pathology. Understanding
   these challenges is essential for addressing the limitations and
   developing strategies to overcome barriers. It is critical for health
   professionals to be involved in the selection of data and fine tuning of
   the models. Further research, validation, and collaboration between AI
   developers, healthcare professionals, and regulatory bodies are
   necessary to ensure the responsible and effective integration of LLMs in
   diagnostic medicine.
TC 73
ZS 0
Z8 0
ZA 0
ZB 11
ZR 0
Z9 73
DA 2024-03-23
UT WOS:001174262700001
PM 38414074
ER

PT J
AU Du, Xinsong
   Novoa-Laurentiev, John
   Plasaek, Joseph M
   Chuang, Ya-Wen
   Wang, Liqin
   Marshall, Gad
   Mueller, Stephanie K
   Chang, Frank
   Datta, Surabhi
   Paek, Hunki
   Lin, Bin
   Wei, Qiang
   Wang, Xiaoyan
   Wang, Jingqi
   Ding, Hao
   Manion, Frank J
   Du, Jingcheng
   Bates, David W
   Zhou, Li
TI Enhancing Early Detection of Cognitive Decline in the Elderly: A
   Comparative Study Utilizing Large Language Models in Clinical Notes.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2024.04.03.24305298
DT Preprint; Journal Article
PD 2024 May 06
PY 2024
AB Background: Large language models (LLMs) have shown promising
   performance in various healthcare domains, but their effectiveness in
   identifying specific clinical conditions in real medical records is less
   explored. This study evaluates LLMs for detecting signs of cognitive
   decline in real electronic health record (EHR) clinical notes, comparing
   their error profiles with traditional models. The insights gained will
   inform strategies for performance enhancement.
   Methods: This study, conducted at Mass General Brigham in Boston, MA,
   analyzed clinical notes from the four years prior to a 2019 diagnosis of
   mild cognitive impairment in patients aged 50 and older. We used a
   randomly annotated sample of 4,949 note sections, filtered with keywords
   related to cognitive functions, for model development. For testing, a
   random annotated sample of 1,996 note sections without keyword filtering
   was utilized. We developed prompts for two LLMs, Llama 2 and GPT-4, on
   HIPAA-compliant cloud-computing platforms using multiple approaches
   (e.g., both hard and soft prompting and error analysis-based
   instructions) to select the optimal LLM-based method. Baseline models
   included a hierarchical attention-based neural network and XGBoost.
   Subsequently, we constructed an ensemble of the three models using a
   majority vote approach.
   Results: GPT-4 demonstrated superior accuracy and efficiency compared to
   Llama 2, but did not outperform traditional models. The ensemble model
   outperformed the individual models, achieving a precision of 90.3%, a
   recall of 94.2%, and an F1-score of 92.2%. Notably, the ensemble model
   showed a significant improvement in precision, increasing from a range
   of 70%-79% to above 90%, compared to the best-performing single model.
   Error analysis revealed that 63 samples were incorrectly predicted by at
   least one model; however, only 2 cases (3.2%) were mutual errors across
   all models, indicating diverse error profiles among them.
   Conclusions: LLMs and traditional machine learning models trained using
   local EHR data exhibited diverse error profiles. The ensemble of these
   models was found to be complementary, enhancing diagnostic performance.
   Future research should investigate integrating LLMs with smaller,
   localized models and incorporating medical data and domain knowledge to
   enhance performance on specific tasks.
TC 1
ZS 0
Z8 0
ZA 0
ZB 0
ZR 0
Z9 1
DA 2024-05-11
UT MEDLINE:38633810
PM 38633810
ER

PT J
AU Yan, Chunyi
   Li, Zexi
   Liang, Yongzhou
   Shao, Shuran
   Ma, Fan
   Zhang, Nanjun
   Li, Bowen
   Wang, Chuan
   Zhou, Kaiyu
TI Assessing large language models as assistive tools in medical
   consultations for Kawasaki disease
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
VL 8
AR 1571503
DI 10.3389/frai.2025.1571503
DT Article
PD MAR 31 2025
PY 2025
AB Background Kawasaki disease (KD) presents complex clinical challenges in
   diagnosis, treatment, and long-term management, requiring a
   comprehensive understanding by both parents and healthcare providers.
   With advancements in artificial intelligence (AI), large language models
   (LLMs) have shown promise in supporting medical practice. This study
   aims to evaluate and compare the appropriateness and comprehensibility
   of different LLMs in answering clinically relevant questions about KD
   and assess the impact of different prompting strategies. Methods
   Twenty-five questions were formulated, incorporating three prompting
   strategies: No prompting (NO), Parent-friendly (PF), and Doctor-level
   (DL). These questions were input into three LLMs: ChatGPT-4o, Claude 3.5
   Sonnet, and Gemini 1.5 Pro. Responses were evaluated based on
   appropriateness, educational quality, comprehensibility, cautionary
   statements, references, and potential misinformation, using Information
   Quality Grade, Global Quality Scale (GQS), Flesch Reading Ease (FRE)
   score, and word count. Results Significant differences were found among
   the LLMs in terms of response educational quality, accuracy, and
   comprehensibility (p < 0.001). Claude 3.5 provided the highest
   proportion of completely correct responses (51.1%) and achieved the
   highest median GQS score (5.0), outperforming GPT-4o (4.0) and Gemini
   1.5 (3.0) significantly. Gemini 1.5 achieved the highest FRE score
   (31.5) and provided highest proportion of responses assessed as
   comprehensible (80.4%). Prompting strategies significantly affected LLM
   responses. Claude 3.5 Sonnet with DL prompting had the highest
   completely correct rate (81.3%), while PF prompting yielded the most
   acceptable responses (97.3%). Gemini 1.5 Pro showed minimal variation
   across prompts but excelled in comprehensibility (98.7% under PF
   prompting). Conclusion This study indicates that LLMs have great
   potential in providing information about KD, but their use requires
   caution due to quality inconsistencies and misinformation risks.
   Significant discrepancies existed across LLMs and prompting strategies.
   Claude 3.5 Sonnet offered the best response quality and accuracy, while
   Gemini 1.5 Pro excelled in comprehensibility. PF prompting with Claude
   3.5 Sonnet is most recommended for parents seeking KD information. As AI
   evolves, expanding research and refining models is crucial to ensure
   reliable, high-quality information.
Z8 0
ZR 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-04-20
UT WOS:001466146900001
PM 40231209
ER

PT J
AU Reicher, Lee
   Lutsker, Guy
   Michaan, Nadav
   Grisaru, Dan
   Laskov, Ido
TI Exploring the role of artificial intelligence, large language models:
   Comparing patient-focused information and clinical decision support
   capabilities to the gynecologic oncology guidelines
SO INTERNATIONAL JOURNAL OF GYNECOLOGY & OBSTETRICS
VL 168
IS 2
BP 419
EP 427
DI 10.1002/ijgo.15869
EA AUG 2024
DT Review
PD FEB 2025
PY 2025
AB Gynecologic cancer requires personalized care to improve outcomes. Large
   language models (LLMs) hold the potential to provide intelligent
   question-answering with reliable information about medical queries in
   clear and plain English, which can be understood by both healthcare
   providers and patients. We aimed to evaluate two freely available LLMs
   (ChatGPT and Google's Bard) in answering questions regarding the
   management of gynecologic cancer. The LLMs' performances were evaluated
   by developing a set questions that addressed common gynecologic
   oncologic findings from a patient's perspective and more complex
   questions to elicit recommendations from a clinician's perspective. Each
   question was presented to the LLM interface, and the responses generated
   by the artificial intelligence (AI) model were recorded. The responses
   were assessed based on the adherence to the National Comprehensive
   Cancer Network and European Society of Gynecological Oncology
   guidelines. This evaluation aimed to determine the accuracy and
   appropriateness of the information provided by LLMs. We showed that the
   models provided largely appropriate responses to questions regarding
   common cervical cancer screening tests and BRCA-related questions. Less
   useful answers were received to complex and controversial gynecologic
   oncology cases, as assessed by reviewing the common guidelines. ChatGPT
   and Bard lacked knowledge of regional guideline variations, However, it
   provided practical and multifaceted advice to patients and caregivers
   regarding the next steps of management and follow up. We conclude that
   LLMs may have a role as an adjunct informational tool to improve
   outcomes.
   ChatGPT and Bard provide appropriate responses to patient's perspective
   gynecologic oncologic questions, but is less useful for complex
   questions compared with the National Comprehensive Cancer
   Network/European Society of Gynecological Oncology guidelines.
TC 5
ZR 0
Z8 0
ZA 0
ZB 0
ZS 0
Z9 5
DA 2024-08-23
UT WOS:001293448800001
PM 39161265
ER

PT J
AU Guillen-Grima, Francisco
   Guillen-Aguinaga, Sara
   Guillen-Aguinaga, Laura
   Alas-Brun, Rosa
   Onambele, Luc
   Ortega, Wilfrido
   Montejo, Rocio
   Aguinaga-Ontoso, Enrique
   Barach, Paul
   Aguinaga-Ontoso, Ines
TI Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical
   Residency Entrance Examination (MIR): Promising Horizons for AI in
   Clinical Medicine
SO CLINICS AND PRACTICE
VL 13
IS 6
BP 1460
EP 1487
DI 10.3390/clinpract13060130
DT Article
PD DEC 2023
PY 2023
AB The rapid progress in artificial intelligence, machine learning, and
   natural language processing has led to increasingly sophisticated large
   language models (LLMs) for use in healthcare. This study assesses the
   performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the
   MIR medical examination for access to medical specialist training in
   Spain. Our objectives included gauging the model's overall performance,
   analyzing discrepancies across different medical specialties, discerning
   between theoretical and practical questions, estimating error
   proportions, and assessing the hypothetical severity of errors committed
   by a physician. Material and methods: We studied the 2022 Spanish MIR
   examination results after excluding those questions requiring image
   evaluations or having acknowledged errors. The remaining 182 questions
   were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English.
   Logistic regression models analyzed the relationships between question
   length, sequence, and performance. We also analyzed the 23 questions
   with images, using GPT-4's new image analysis capability. Results: GPT-4
   outperformed GPT-3.5, scoring 86.81% in Spanish (p < 0.001). English
   translations had a slightly enhanced performance. GPT-4 scored 26.1% of
   the questions with images in English. The results were worse when the
   questions were in Spanish, 13.0%, although the differences were not
   statistically significant (p = 0.250). Among medical specialties, GPT-4
   achieved a 100% correct response rate in several areas, and the
   Pharmacology, Critical Care, and Infectious Diseases specialties showed
   lower performance. The error analysis revealed that while a 13.2% error
   rate existed, the gravest categories, such as "error requiring
   intervention to sustain life" and "error resulting in death", had a 0%
   rate. Conclusions: GPT-4 performs robustly on the Spanish MIR
   examination, with varying capabilities to discriminate knowledge across
   specialties. While the model's high success rate is commendable,
   understanding the error severity is critical, especially when
   considering AI's potential role in real-world medical practice and its
   implications for patient safety.
ZA 0
TC 28
Z8 0
ZS 1
ZB 6
ZR 0
Z9 28
DA 2024-01-17
UT WOS:001132385500001
PM 37987431
ER

PT J
AU Zhang, YuNing
   Dong, Yijie
   Mei, Zihan
   Hou, Yiqing
   Wei, Minyan
   Yeung, Yat Hin
   Xu, Jiale
   Hua, Qing
   Lai, LiMei
   Li, Ning
   Xia, ShuJun
   Zhou, Chun
   Zhou, JianQiao
TI Performance of large language models on benign prostatic hyperplasia
   frequently asked questions
SO PROSTATE
VL 84
IS 9
BP 807
EP 813
DI 10.1002/pros.24699
EA APR 2024
DT Article
PD JUN 2024
PY 2024
AB Background: Benign prostatic hyperplasia (BPH) is a common condition,
   yet it is challenging for the average BPH patient to find credible and
   accurate information about BPH. Our goal is to evaluate and compare the
   accuracy and reproducibility of large language models (LLMs), including
   ChatGPT-3.5, ChatGPT-4, and the New Bing Chat in responding to a BPH
   frequently asked questions (FAQs) questionnaire. Methods: A total of 45
   questions related to BPH were categorized into basic and professional
   knowledge. Three LLM-ChatGPT-3.5, ChatGPT-4, and New Bing Chat-were
   utilized to generate responses to these questions. Responses were graded
   as comprehensive, correct but inadequate, mixed with incorrect/outdated
   data, or completely incorrect. Reproducibility was assessed by
   generating two responses for each question. All responses were reviewed
   and judged by experienced urologists. Results: All three LLMs exhibited
   high accuracy in generating responses to questions, with accuracy rates
   ranging from 86.7% to 100%. However, there was no statistically
   significant difference in response accuracy among the three (p > 0.017
   for all comparisons). Additionally, the accuracy of the LLMs' responses
   to the basic knowledge questions was roughly equivalent to that of the
   specialized knowledge questions, showing a difference of less than 3.5%
   (GPT-3.5: 90% vs. 86.7%; GPT-4: 96.7% vs. 95.6%; New Bing: 96.7% vs.
   93.3%). Furthermore, all three LLMs demonstrated high reproducibility,
   with rates ranging from 93.3% to 97.8%. Conclusions: ChatGPT-3.5,
   ChatGPT-4, and New Bing Chat offer accurate and reproducible responses
   to BPH-related questions, establishing them as valuable resources for
   enhancing health literacy and supporting BPH patients in conjunction
   with healthcare professionals.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 2
TC 8
Z9 8
DA 2024-04-04
UT WOS:001194679200001
PM 38558009
ER

PT J
AU TOKEDE, OLUWABUNMI 
TI FullMouth: Enhancing Dental Clinical Data and Reducing Disparities
   through Innovative ML Approaches.
DT Awarded Grant
PD Sep 01 2024
PY 2024
AB Project Abstract/SummaryThe vast amount of health data created in the
   United States may hold the key to understanding disease,improving
   quality, and lowering healthcare costs. Electronic health records
   (EHRs), digital collections of patienthealthcare events and
   observations, are now ubiquitous in medicine and critical to healthcare
   delivery,operations, and research. EHR data is often classified as
   structured or unstructured. Structured EHR datainclude standardized
   diagnoses, medications, and laboratory values in fixed numerical or
   categorical fields. Forstructured data, challenges such as missing,
   incomplete, and inconsistent data are very prevalent.Unstructured data,
   in contrast, refer to free-form text written by healthcare providers,
   such as clinical notes anddischarge summaries. Dental care providers
   often write detailed findings, diagnoses, treatment plans andprognostic
   factors in free-text format for clinical care purposes. While this
   information is easily accessible duringpatient care, extracting it for
   generating meaningful insights for secondary analysis can be
   challenging. Utilizingthese records requires manual review by domain
   experts, which can be time-consuming and costly, particularlywhen
   dealing with a large number of patient records. Unstructured data
   represents about 60% of total EHR data.Recently, Large Language Models
   (LLMs) and newer deep learning approaches to Natural Language
   Processing(NLP) have made considerable advances, outperforming
   traditional statistical and rule-based systems on avariety of tasks.To
   fully realize the promise of health information technology in dentistry,
   it is important to address datamissingness and disparity in missingness.
   Through a periodontal use-case, this proposal will tackle the
   challengeof missing structured, and ‘technically’ inaccessible,
   unstructured clinical data. Periodontal (advanced gumdisease) problems
   are very pervasive, and unlike caries (whose prevalence has steadily
   declined over the pastfour decades), disease burden and tooth loss
   secondary to periodontal disease remain intractable. In preliminarywork
   at two dental institutions, we observed that most patients seen for a
   comprehensive oral evaluation hadmissing or incomplete documentation
   with respect to clinical periodontal indices/diagnosis, demographic,
   andhealth-related behavior information – all of which are critical in
   diagnosing and treating periodontal disease. Thissignificantly limits
   our ability to learn and improve. Aim 1 will focus on using LLM-based
   NLP approaches for theconversion of unstructured note entries into
   structured and machine-readable information. In Aim 2, we will
   useimputation techniques to fill in missing structured clinical data
   entries. Aim 3 will then evaluate the impact ofreduction in clinical
   data missingness for both clinical and research applications. This work
   builds on our priorwork in developing the BigMouth Dental Data
   Repository (which contains regularly updated structured data on4.6
   million patients). We will be supported by the collective strength of
   the 11 core BigMouth, and other allieddental institutions that currently
   share and/or contribute data to the repository.
TC 0
ZA 0
Z8 0
ZR 0
ZS 0
ZB 0
Z9 0
G1 11137246; 1R56DE034086-01; R56DE034086
DA 2024-09-29
UT GRANTS:17810133
ER

PT B
AU Zheng, Mengxin
Z2  
TI Secure and Private Large Transformers
DT Dissertation/Thesis
PD Jan 01 2023
PY 2023
ZA 0
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
Z9 0
UT PQDT:86769801
ER

PT J
AU Amini, Maziar
   Chang, Patrick
   Nguyen, Denis
   Davis, Rio O.
   Dodge, Jennifer
   Phan, Jennifer
   Buxbaum, James L.
   Sahakian, Ara B.
TI COMPARING CHATGPT3.5 AND BARD IN RECOMMENDING COLONOSCOPY INTERVALS:
   BRIDGING THE GAP IN HEALTHCARE SETTINGS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Tu1991
BP S1482
EP S1482
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2024-10-30
UT WOS:001282837706089
ER

PT B
AU Mirza, Muhammad Shujaat
Z2  
TI Towards Responsible AI: Safeguarding Privacy, Integrity, and Fairness
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
Z8 0
ZB 0
ZR 0
ZS 0
TC 0
ZA 0
Z9 0
UT PQDT:118963611
ER

PT J
AU Olszewski, Robert
   Watros, Klaudia
   Manczak, Malgorzata
   Owoc, Jakub
   Jeziorski, Krzysztof
   Brzezinski, Jakub
TI Assessing the response quality and readability of chatbots in
   cardiovascular health, oncology, and psoriasis: A comparative study
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 190
AR 105562
DI 10.1016/j.ijmedinf.2024.105562
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background: Chatbots using the Large Language Model (LLM) generate human
   responses to questions from all categories. Due to staff shortages in
   healthcare systems, patients waiting for an appointment increasingly use
   chatbots to get information about their condition. Given the number of
   chatbots currently available, assessing the responses they generate is
   essential. Methods: Five chatbots with free access were selected
   (Gemini, Microsoft Copilot, PiAI, ChatGPT, ChatSpot) and blinded using
   letters (A, B, C, D, E). Each chatbot was asked questions about
   cardiology, oncology, and psoriasis. Responses were compared to
   guidelines from the European Society of Cardiology, American Academy of
   Dermatology and American Society of Clinical Oncology. All answers were
   assessed using readability scales (Flesch Reading Scale, Gunning Fog
   Scale Level, Flesch-Kincaid Grade Level and Dale-Chall Score). Using a
   3point Likert scale, two independent medical professionals assessed the
   compliance of the responses with the guidelines. Results: A total of 45
   questions were asked of all chatbots. Chatbot C gave the shortest
   answers, 7.0 (6.0 - 8.0), and Chatbot A the longest 17.5 (13.0 - 24.5).
   The Flesch Reading Ease Scale ranged from 16.3 (12.2 - 21.9) (Chatbot D)
   to 39.8 (29.0 - 50.4) (Chatbot A). Flesch-Kincaid Grade Level ranged
   from 12.5 (10.6 - 14.6) (Chatbot A) to 15.9 (15.1 - 17.1) (Chatbot D).
   Gunning Fog Scale Level ranged from 15.77 (Chatbot A) to 19.73 (Chatbot
   D). Dale-Chall Score ranged from 10.3 (9.3 - 11.3) (Chatbot A) to 11.9
   (11.5 - 12.4) (Chatbot D). Conclusion: This study indicates that
   chatbots vary in length, quality, and readability. They answer each
   question in their own way, based on the data they have pulled from the
   web. Reliability of the responses generated by chatbots is high. This
   suggests that people who want information from a chatbot need to be
   careful and verify the answers they receive, particularly when they ask
   about medical and health aspects.
ZS 0
ZR 0
TC 3
Z8 1
ZB 0
ZA 0
Z9 4
DA 2024-08-07
UT WOS:001281403200001
PM 39059084
ER

PT J
AU Zhao, Fang-Fang
   He, Han-Jie
   Liang, Jia-Jian
   Cen, Jingyun
   Wang, Yun
   Lin, Hongjie
   Chen, Feifei
   Li, Tai-Ping
   Yang, Jian-Feng
   Chen, Lan
   Cen, Ling-Ping
TI Benchmarking the performance of large language models in uveitis: a
   comparative analysis of ChatGPT-3.5, ChatGPT-4.0, Google Gemini, and
   Anthropic Claude3
SO EYE
VL 39
IS 6
BP 1132
EP 1137
DI 10.1038/s41433-024-03545-9
EA DEC 2024
DT Article
PD APR 2025
PY 2025
AB Background/Objective This study aimed to evaluate the accuracy,
   comprehensiveness, and readability of responses generated by various
   Large Language Models (LLMs) (ChatGPT-3.5, Gemini, Claude 3, and
   GPT-4.0) in the clinical context of uveitis, utilizing a meticulous
   grading methodology. Methods Twenty-seven clinical uveitis questions
   were presented individually to four Large Language Models (LLMs):
   ChatGPT (versions GPT-3.5 and GPT-4.0), Google Gemini, and Claude. Three
   experienced uveitis specialists independently assessed the responses for
   accuracy using a three-point scale across three rounds with a 48-hour
   wash-out interval. The final accuracy rating for each LLM response
   ('Excellent', 'Marginal', or 'Deficient') was determined through a
   majority consensus approach. Comprehensiveness was evaluated using a
   three-point scale for responses rated 'Excellent' in the final accuracy
   assessment. Readability was determined using the Flesch-Kincaid Grade
   Level formula. Statistical analyses were conducted to discern
   significant differences among LLMs, employing a significance threshold
   of p < 0.05. Results Claude 3 and ChatGPT 4 demonstrated significantly
   higher accuracy compared to Gemini (p < 0.001). Claude 3 also showed the
   highest proportion of 'Excellent' ratings (96.3%), followed by ChatGPT 4
   (88.9%). ChatGPT 3.5, Claude 3, and ChatGPT 4 had no responses rated as
   'Deficient', unlike Gemini (14.8%) (p = 0.014). ChatGPT 4 exhibited
   greater comprehensiveness compared to Gemini (p = 0.008), and Claude 3
   showed higher comprehensiveness compared to Gemini (p = 0.042). Gemini
   showed significantly better readability compared to ChatGPT 3.5, Claude
   3, and ChatGPT 4 (p < 0.001). Gemini also had fewer words, letter
   characters, and sentences compared to ChatGPT 3.5 and Claude 3.
   Conclusions Our study highlights the outstanding performance of Claude 3
   and ChatGPT 4 in providing precise and thorough information regarding
   uveitis, surpassing Gemini. ChatGPT 4 and Claude 3 emerge as pivotal
   tools in improving patient understanding and involvement in their
   uveitis healthcare journey.
ZB 0
ZS 0
TC 6
ZR 0
ZA 0
Z8 0
Z9 6
DA 2024-12-25
UT WOS:001380600200001
PM 39690303
ER

PT J
AU Lang, Siegmund
   Vitale, Jacopo
   Galbusera, Fabio
   Fekete, Tamas
   Boissiere, Louis
   Charles, Yann Philippe
   Yucekul, Altug
   Yilgor, Caglar
   Nunez-Pereira, Susana
   Haddad, Sleiman
   Gomez-Rice, Alejandro
   Mehta, Jwalant
   Pizones, Javier
   Pellise, Ferran
   Obeid, Ibrahim
   Alanay, Ahmet
   Kleinstuck, Frank
   Loibl, Markus
CA ESSG European Spine Study Grp
TI Is the information provided by large language models valid in educating
   patients about adolescent idiopathic scoliosis? An evaluation of
   content, clarity, and empathy: The perspective of the European Spine
   Study Group
SO SPINE DEFORMITY
VL 13
IS 2
BP 361
EP 372
DI 10.1007/s43390-024-00955-3
EA NOV 2024
DT Article
PD MAR 2025
PY 2025
AB Purpose Large language models (LLM) have the potential to bridge
   knowledge gaps in patient education and enrich patient-surgeon
   interactions. This study evaluated three chatbots for delivering
   empathetic and precise adolescent idiopathic scoliosis (AIS) related
   information and management advice. Specifically, we assessed the
   accuracy, clarity, and relevance of the information provided, aiming to
   determine the effectiveness of LLMs in addressing common patient queries
   and enhancing their understanding of AIS. Methods We sourced 20 webpages
   for the top frequently asked questions (FAQs) about AIS and formulated
   10 critical questions based on them. Three advanced LLMs-ChatGPT 3.5,
   ChatGPT 4.0, and Google Bard-were selected to answer these questions,
   with responses limited to 200 words. The LLMs' responses were evaluated
   by a blinded group of experienced deformity surgeons (members of the
   European Spine Study Group) from seven European spine centers. A
   pre-established 4-level rating system from excellent to unsatisfactory
   was used with a further rating for clarity, comprehensiveness, and
   empathy on the 5-point Likert scale. If not rated 'excellent', the
   raters were asked to report the reasons for their decision for each
   question. Lastly, raters were asked for their opinion towards AI in
   healthcare in general in six questions. Results The responses among all
   LLMs were 'excellent' in 26% of responses, with ChatGPT-4.0 leading
   (39%), followed by Bard (17%). ChatGPT-4.0 was rated superior to Bard
   and ChatGPT 3.5 (p = 0.003). Discrepancies among raters were significant
   (p < 0.0001), questioning inter-rater reliability. No substantial
   differences were noted in answer distribution by question (p = 0.43).
   The answers on diagnosis (Q2) and causes (Q4) of AIS were top-rated. The
   most dissatisfaction was seen in the answers regarding definitions (Q1)
   and long-term results (Q7). Exhaustiveness, clarity, empathy, and length
   of the answers were positively rated (> 3.0 on 5.0) and did not
   demonstrate any differences among LLMs. However, GPT-3.5 struggled with
   language suitability and empathy, while Bard's responses were overly
   detailed and less empathetic. Overall, raters found that 9% of answers
   were off-topic and 22% contained clear mistakes. Conclusion Our study
   offers crucial insights into the strengths and weaknesses of current
   LLMs in AIS patient and parent education, highlighting the promise of
   advancements like ChatGPT-4.o and Gemini alongside the need for
   continuous improvement in empathy, contextual understanding, and
   language appropriateness.
Z8 0
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z9 2
DA 2024-11-11
UT WOS:001347897500002
PM 39495402
ER

PT J
AU Shi, Michael
   Hanna, Jovana
   Clavell, Christine
   Eid, Kevin
   Eid, Alen
   Ghorayeb, Ghassan
   John Nguyen
TI Assessing Readability of Patient Education Materials: A Comparative
   Study of ASRS Resources and AI-Generated Content by Popular Large
   Language Models (ChatGPT 4.0 and Google Bard)
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 5646
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZS 0
ZR 0
ZB 0
Z8 0
TC 3
ZA 0
Z9 3
DA 2024-11-30
UT WOS:001313316206217
ER

PT J
AU Rauniyar, Ashish
   Hagos, Desta Haileselassie
   Jha, Debesh
   Hakegard, Jan Erik
   Bagci, Ulas
   Rawat, Danda B.
   Vlassov, Vladimir
TI Federated Learning for Medical Applications: A Taxonomy, Current Trends,
   Challenges, and Future Research Directions
SO IEEE INTERNET OF THINGS JOURNAL
VL 11
IS 5
BP 7374
EP 7398
DI 10.1109/JIOT.2023.3329061
DT Article
PD MAR 1 2024
PY 2024
AB With the advent of the Internet of Things (IoT), artificial intelligence
   (AI), machine learning (ML), and deep learning (DL) algorithms, the
   landscape of data-driven medical applications has emerged as a promising
   avenue for designing robust and scalable diagnostic and prognostic
   models from medical data. This has gained a lot of attention from both
   academia and industry, leading to significant improvements in healthcare
   quality. However, the adoption of AI-driven medical applications still
   faces tough challenges, including meeting security, privacy, and
   Quality-of-Service (QoS) standards. Recent developments in federated
   learning (FL) have made it possible to train complex machine-learned
   models in a distributed manner and have become an active research
   domain, particularly processing the medical data at the edge of the
   network in a decentralized way to preserve privacy and address security
   concerns. To this end, in this article, we explore the present and
   future of FL technology in medical applications where data sharing is a
   significant challenge. We delve into the current research trends and
   their outcomes, unraveling the complexities of designing reliable and
   scalable FL models. This article outlines the fundamental statistical
   issues in FL, tackles device-related problems, addresses security
   challenges, and navigates the complexity of privacy concerns, all while
   highlighting its transformative potential in the medical field. Our
   study primarily focuses on medical applications of FL, particularly in
   the context of global cancer diagnosis. We highlight the potential of FL
   to enable computer-aided diagnosis tools that address this challenge
   with greater effectiveness than traditional data-driven methods. Recent
   literature has shown that FL models are robust and generalize well to
   new data, which is essential for medical applications. We hope that this
   comprehensive review will serve as a checkpoint for the field,
   summarizing the current state of the art and identifying open problems
   and future research directions.
ZR 0
ZA 0
ZB 1
Z8 1
TC 51
ZS 0
Z9 52
DA 2024-06-25
UT WOS:001203463700006
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

PT J
AU Guo, Edward
   Gupta, Mehul
   Sinha, Sarthak
   Roessler, Karl
   Tatagiba, Marcos
   Akagami, Ryojo
   Al-Mefty, Ossama
   Sugiyama, Taku
   Stieg, Philip E.
   Pickett, Gwynedd E.
   de Lotbiniere-Bassett, Madeleine
   Singh, Rahul
   Lama, Sanju
   Sutherland, Garnette R.
TI neuroGPT-X: toward a clinic-ready large language model
SO JOURNAL OF NEUROSURGERY
VL 140
IS 4
BP 1041
EP 1053
DT Article
PD APR 2024
PY 2024
AB OBJECTIVE The objective was to assess the performance of a
   context-enriched large language model (LLM) compared with international
   neurosurgical experts on questions related to the management of
   vestibular schwannoma. Furthermore, another objective was to develop a
   chat-based platform incorporating in-text citations, references, and
   memory to enable accurate, relevant, and reliable information in real
   time. METHODS The analysis involved 1) creating a data set through web
   scraping, 2) developing a chat-based platform called neuroGPT-X, 3)
   enlisting 8 expert neurosurgeons across international centers to
   independently create questions (n = 1) and to answer (n = 4) and
   evaluate responses (n = 3) while blinded, and 4) analyzing the
   evaluation results on the management of vestibular schwannoma. In the
   blinded phase, all answers were assessed for accuracy, coherence,
   relevance, thoroughness, speed, and overall rating. All experts were
   unblinded and provided their thoughts on the utility and limitations of
   the tool. In the unblinded phase, all neurosurgeons provided answers to
   a Likert scale survey and longanswer questions regarding the clinical
   utility, likelihood of use, and limitations of the tool. The tool was
   then evaluated on the basis of a set of 103 consensus statements on
   vestibular schwannoma care from the 8th Quadrennial International
   Conference on Vestibular Schwannoma. RESULTS Responses from the naive
   and context-enriched Generative Pretrained Transformer (GPT) models were
   consistently rated not significantly different in terms of accuracy,
   coherence, relevance, thoroughness, and overall performance, and they
   were often rated significantly higher than expert responses. Both the
   naive and content-enriched GPT models provided faster responses to the
   standardized question set than expert neurosurgeon respondents (p <
   0.01). The context-enriched GPT model agreed with 98 of the 103 (95%)
   consensus statements. Of interest, all expert surgeons expressed
   concerns about the reliability of GPT in accurately addressing the
   nuances and controversies surrounding the management of vestibular
   schwannoma. Furthermore, the authors developed neuroGPT-X, a chat-based
   platform designed to provide point-of-care clinical support and mitigate
   the limitations of human memory. neuroGPT-X incorporates features such
   as in-text citations and references to enable accurate, relevant, and
   reliable information in real time. CONCLUSIONS The present study, with
   its subspecialist-level performance in generating written responses to
   complex neurosurgical problems for which evidence-based consensus for
   management is lacking, suggests that context-enriched LLMs show promise
   as a point-of-care medical resource. The authors anticipate that this
   work will be a springboard for expansion into more medical specialties,
   incorporating evidence-based clinical information and developing
   expert-level dialogue surrounding LLMs in healthcare.
ZB 2
ZS 0
Z8 1
ZR 0
TC 10
ZA 0
Z9 11
DA 2024-06-30
UT WOS:001251735100004
PM 38564804
ER

EF