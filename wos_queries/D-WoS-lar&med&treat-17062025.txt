FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Kim, Dong Wook
   Park, Cheol-Young
   Shin, Jeong-Hun
   Lee, Hyunjoo Jenny
TI The Role of Artificial Intelligence in Obesity Medicine
SO ENDOCRINOLOGY AND METABOLISM CLINICS OF NORTH AMERICA
VL 54
IS 1
BP 207
EP 215
DI 10.1016/j.ecl.2024.10.008
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
ZR 0
ZA 0
Z8 0
TC 2
ZB 1
ZS 0
Z9 2
DA 2025-02-23
UT WOS:001424049000001
PM 39919876
ER

PT J
AU Guo, Yan
   Wang, Heyuan
   Ren, Xue
   Wang, Tengjiao
   Chen, Wei
   Xu, Ziming
   Ge, Hui
TI Can GPTs Accelerate the Development of Intelligent Diagnosis and
   Treatment in Traditional Chinese Medicine? A Survey and Empirical
   Analysis
SO JOURNAL OF EVIDENCE BASED MEDICINE
VL 18
IS 1
AR e70004
DI 10.1111/jebm.70004
DT Article
PD MAR 2025
PY 2025
AB Intelligent traditional Chinese medicine (TCM) is a key pathway toward
   the modernization and globalization of TCM in the era of artificial
   intelligence. Due to its unique terminology and diagnostic framework,
   TCM's intelligentization process has long faced a range of challenges,
   from the digitization and formalization of knowledge bases to the
   differentiation of syndromes and personalized treatment. Recently, the
   advent of large language models (LLMs) like GPTs has marked a
   transformative milestone in semantic understanding tasks, attracting
   widespread attention from the medical, academic, and industrial
   communities. Nonetheless, LLMs often suffer from accuracy and logical
   reasoning limitations within specific fields and may manifest
   hallucinations in the generative outputs. Through a comprehensive review
   of existing literature and empirical analyses, this study delves into
   the potential and challenges of adapting LLMs to TCM. Promising
   perspectives on future developments at this innovative intersection are
   discussed.
TC 1
Z8 0
ZA 0
ZS 0
ZR 0
ZB 0
Z9 1
DA 2025-03-01
UT WOS:001428957800001
PM 39989008
ER

PT J
AU Ihara, Keiko
   Dumkrieger, Gina
   Zhang, Pengfei
   Takizawa, Tsubasa
   Schwedt, Todd J.
   Chiang, Chia-Chun
TI Application of Artificial Intelligence in the Headache Field
SO CURRENT PAIN AND HEADACHE REPORTS
VL 28
IS 10
BP 1049
EP 1057
DI 10.1007/s11916-024-01297-5
EA JUL 2024
DT Review
PD OCT 2024
PY 2024
AB Purpose of ReviewHeadache disorders are highly prevalent worldwide.
   Rapidly advancing capabilities in artificial intelligence (AI) have
   expanded headache-related research with the potential to solve unmet
   needs in the headache field. We provide an overview of AI in headache
   research in this article.Recent FindingsWe briefly introduce machine
   learning models and commonly used evaluation metrics. We then review
   studies that have utilized AI in the field to advance diagnostic
   accuracy and classification, predict treatment responses, gather
   insights from various data sources, and forecast migraine attacks.
   Furthermore, given the emergence of ChatGPT, a type of large language
   model (LLM), and the popularity it has gained, we also discuss how LLMs
   could be used to advance the field. Finally, we discuss the potential
   pitfalls, bias, and future directions of employing AI in headache
   medicine.SummaryMany recent studies on headache medicine incorporated
   machine learning, generative AI and LLMs. A comprehensive understanding
   of potential pitfalls and biases is crucial to using these novel
   techniques with minimum harm. When used appropriately, AI has the
   potential to revolutionize headache medicine.
ZA 0
ZR 0
TC 2
ZB 0
Z8 0
ZS 0
Z9 2
DA 2024-07-18
UT WOS:001264634300002
PM 38976174
ER

PT J
AU Chen, Runsheng
TI [Prospects for the Application of Healthcare Big Data Combined With
   Large Language Models].
SO Sichuan da xue xue bao. Yi xue ban = Journal of Sichuan University.
   Medical science edition
VL 54
IS 5
BP 855
EP 856
DI 10.12182/20230960301
DT English Abstract; Journal Article; Review
PD 2023-Sep
PY 2023
AB The application of big data technology combined with large language
   models is expected to make an enormous impact in the field of medicine.
   Herein, the prospects for the application of healthcare big data
   combined with large language models were discussed in several aspects,
   including first in assisting doctors in making diagnosis and
   differential diagnosis and, then, in the field of evidence-based
   medicine. In addition, healthcare big data combined with large language
   models could also be applied in assisting doctors to conduct clinical
   and medical research. Through combining healthcare big data with large
   language models, medical diagnosis and treatment with improved
   precision, efficiency, and intelligence will be realized and greater
   contributions will be made to the field of human health.
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 1
Z9 1
DA 2023-10-26
UT MEDLINE:37866938
PM 37866938
ER

PT J
AU Kang, Bongsu
   LeeSangYeon
   Chang-EopKim
AU 배효진
TI Current Status and Direction of Generative Large Language Model
   Applications in Medicine - Focusing on East Asian Medicine -
Z1 생성형 거대언어모델의 의학 적용 현황과 방향 - 동아시아 의학을 중심으로 -
SO Journal of Physiology & Pathology in Korean Medicine
S1 동의생리병리학회지
VL 38
IS 2
BP 49
EP 58
DT research-article
PD 2024
PY 2024
AB The rapid advancement of generative large language models has
   revolutionized various real-life domains, emphasizing the importance of
   exploring their applications in healthcare. This study aims to examine
   how generative large language models are implemented in the medical
   domain, with the specific objective of searching for the possibility and
   potential of integration between generative large language models and
   East Asian medicine. Through a comprehensive current state analysis, we
   identified limitations in the deployment of generative large language
   models within East Asian medicine and proposed directions for future
   research. Our findings highlight the essential need for accumulating and
   generating structured data to improve the capabilities of generative
   large language models in East Asian medicine. Additionally, we tackle
   the issue of hallucination and the necessity for a robust model
   evaluation framework. Despite these challenges, the application of
   generative large language models in East Asian medicine has demonstrated
   promising results. Techniques such as model augmentation, multimodal
   structures, and knowledge distillation have the potential to
   significantly enhance accuracy, efficiency, and accessibility. In
   conclusion, we expect generative large language models to play a pivotal
   role in facilitating precise diagnostics, personalized treatment in
   clinical fields, and fostering innovation in education and research
   within East Asian medicine.
ZR 0
ZB 0
Z8 0
TC 1
ZS 0
ZA 0
Z9 1
DA 2024-05-25
UT KJD:ART003073519
ER

PT J
AU Wang, Xu
   Mao, April W.
   Pan, Sirui
   Wang, Dawei
   He, Lili
   Vogel, Hannes
   Mao, Jian-Hua
   Weiss, William
   Li, Tao
   Chang, Hang
TI Cellular morphometric biomarkers and large language model predict
   prognosis and treatment response in neuroblastoma patients: A
   retrospective and double-blind prospective single arm clinical study
SO EUROPEAN JOURNAL OF CANCER
VL 218
AR 115273
DI 10.1016/j.ejca.2025.115273
EA FEB 2025
DT Article
PD MAR 11 2025
PY 2025
AB Background: The heterogeneity of Neuroblastoma (NB) leads to variation
   in response to treatment , outcomes. The aim of the current study is to
   discover AI-empowered cellular morphometric biomarkers (CMBs), to
   establish the corresponding CMB risk score (CMBRS), CMB risk group
   (CMBRG), large language model driven CMB risk score (CMB-LLM-RS) , large
   language model driven CMB risk group (CMB-LLM-RG), and to investigate
   and validate their prognostic and predictive power in NB. Methods: In
   this study, the retrospective cohort enrolled 84 primary NBs between
   1/2020 and 12/2021, followed up through 11/22/2024; the prospective
   cohort enrolled 67 primary NBs between 1/2022 and 7/2023, followed up
   through 11/22/2024. Results: We identified 9 CMBs from a retrospective
   NB cohort, enabling the CMBRS, CMBRG, CMB-LLM-RS, and CMB-LLM-RG. Both
   CMBRG and CMB-LLM-RG are significantly associated with prognosis (p <
   0.0001) and treatment response (p < 0.0001). Furthermore, we
   double-blindly validated the predictive power of CMBRG and CMB-LLM-RG in
   a prospective NB cohort, which confirms their potential value in real
   clinical settings. Impor- tantly, CMBRG provides clinical value
   independent of the International Neuroblastoma Risk Group (INRG)
   classification system in both retrospective and prospective NB cohorts
   (p < 0.05); and the combination of CMBRG and INRG significantly
   increases prognostic and predictive performance for NB patients.
   Conclusions: These findings suggest that CMBRG and CMB-LLM-RG have
   prognostic and predictive value for NB and warrants evaluation in larger
   multicenter cohorts.
ZA 0
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-02-23
UT WOS:001423930700001
PM 39908653
ER

PT J
AU Chang, Munyoung
   Ahn, Junyong
   Kang, Bong Gyun
   Yoon, Sungroh
TI Cross-modal embedding integrator for disease-gene/protein association
   prediction using a multi-head attention mechanism
SO PHARMACOLOGY RESEARCH & PERSPECTIVES
VL 12
IS 6
AR e70034
DI 10.1002/prp2.70034
DT Article
PD DEC 2024
PY 2024
AB Knowledge graphs, powerful tools that explicitly transfer knowledge to
   machines, have significantly advanced new knowledge inferences.
   Discovering unknown relationships between diseases and genes/proteins in
   biomedical knowledge graphs can lead to the identification of disease
   development mechanisms and new treatment targets. Generating
   high-quality representations of biomedical entities is essential for
   successfully predicting disease-gene/protein associations. We developed
   a computational model that predicts disease-gene/protein associations
   using the Precision Medicine Knowledge Graph, a biomedical knowledge
   graph. Embeddings of biomedical entities were generated using two
   different methods-a large language model (LLM) and the knowledge graph
   embedding (KGE) algorithm. The LLM utilizes information obtained from
   massive amounts of text data, whereas the KGE algorithm relies on graph
   structures. We developed a disease-gene/protein association prediction
   model, "Cross-Modal Embedding Integrator (CMEI)," by integrating
   embeddings from different modalities using a multi-head attention
   mechanism. The area under the receiver operating characteristic curve of
   CMEI was 0.9662 (+/- 0.0002) in predicting disease-gene/protein
   associations. In conclusion, we developed a computational model that
   effectively predicts disease-gene/protein associations. CMEI may
   contribute to the identification of disease development mechanisms and
   new treatment targets.
Z8 0
ZB 0
ZA 0
ZS 0
ZR 0
TC 0
Z9 0
DA 2024-12-09
UT WOS:001368894600001
PM 39560053
ER

PT J
AU Kotzur, Travis
   Singh, Aaron
   Parker, John
   Peterson, Blaire
   Sager, Brian
   Rose, Ryan
   Corley, Fred
   Brady, Christina
TI Evaluation of a Large Language Model's Ability to Assist in an
   Orthopedic Hand Clinic
SO HAND-AMERICAN ASSOCIATION FOR HAND SURGERY
DI 10.1177/15589447241257643
EA JUN 2024
DT Article; Early Access
PY 2024
AB Background: Advancements in artificial intelligence technology, such as
   OpenAI's large language model, ChatGPT, could transform medicine through
   applications in a clinical setting. This study aimed to assess the
   utility of ChatGPT as a clinical assistant in an orthopedic hand
   clinic.Methods: Nine clinical vignettes, describing various common and
   uncommon hand pathologies, were constructed and reviewed by 4
   fellowship-trained orthopedic hand surgeons and an orthopedic resident.
   ChatGPT was given these vignettes and asked to generate a differential
   diagnosis, potential workup plan, and provide treatment options for its
   top differential. Responses were graded for accuracy and the overall
   utility scored on a 5-point Likert scale.Results: The diagnostic
   accuracy of ChatGPT was 7 out of 9 cases, indicating an overall accuracy
   rate of 78%. ChatGPT was less reliable with more complex pathologies and
   failed to identify an intentionally incorrect presentation. ChatGPT
   received a score of 3.8 +/- 1.4 for correct diagnosis, 3.4 +/- 1.4 for
   helpfulness in guiding patient management, 4.1 +/- 1.0 for appropriate
   workup for the actual diagnosis, 4.3 +/- 0.8 for an appropriate
   recommended treatment plan for the diagnosis, and 4.4 +/- 0.8 for the
   helpfulness of treatment options in managing patients.Conclusion:
   ChatGPT was successful in diagnosing most of the conditions; however,
   the overall utility of its advice was variable. While it performed well
   in recommending treatments, it faced difficulties in providing
   appropriate diagnoses for uncommon pathologies. In addition, it failed
   to identify an obvious error in presenting pathology.
TC 2
ZS 0
ZB 0
ZR 0
Z8 0
ZA 0
Z9 2
DA 2024-06-29
UT WOS:001251801400001
PM 38907651
ER

PT J
AU Franc, Jeffrey Michael
   Hertelendy, Atilla
   Cheng, Lenard
   Hata, Ryan
   Verde, Manuela
TI Repeatability, Reproducibility, and Diagnostic Accuracy of a Commercial
   Large Language Model (ChatGPT) to Perform Disaster Triage Using the
   Simple Triage and Rapid Treatment (START) Protocol
SO DISASTER MEDICINE AND PUBLIC HEALTH PREPAREDNESS
VL 18
AR e183
DI 10.1017/dmp.2024.194
DT Article
PD OCT 31 2024
PY 2024
AB Objective: The release of ChatGPT in November 2022 drastically lowered
   the barrier to artificial intelligence with an intuitive web-based
   interface to a large language model. This study addressed the research
   problem: " Can ChatGPT adequately triage simulated disaster patients
   using the Simple Triage and Rapid Treatment (START) tool?" Methods: Five
   trained disaster medicine physicians developed nine prompts. A Python
   script queried ChatGPT Version 4 with each prompt combined with 391
   validated patient vignettes. Ten repetitions of each combination were
   performed: 35190 simulated triages. Results: A valid START score was
   returned In 35102 queries (99.7%). There was considerable variability in
   the results. Repeatability (use of the same prompt repeatedly) was
   responsible for 14.0% of overall variation. Reproducibility (use of
   different prompts) was responsible for 4.1% of overall variation.
   Accuracy of ChatGPT for START was 61.4% with a 5.0% under-triage rate
   and a 33.6% over-triage rate. Accuracy varied by prompt between 45.8%
   and 68.6%. Conclusions: This study suggests that the current ChatGPT
   large language model is not sufficient for triage of simulated patients
   using START due to poor repeatability and accuracy. Medical
   practitioners should be aware that while ChatGPT can be a valuable tool,
   it may lack consistency and may provide false information.
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
ZA 0
Z9 0
DA 2024-11-11
UT WOS:001346192900001
ER

PT J
AU Jaskari, Joel
   Sahlsten, Jaakko
   Summanen, Paula
   Moilanen, Jukka
   Lehtola, Erika
   Aho, Marjo
   Sapyska, Elina
   Hietala, Kustaa
   Kaski, Kimmo
TI DR-GPT: A large language model for medical report analysis of diabetic
   retinopathy patients
SO PLOS ONE
VL 19
IS 10
AR e0297706
DI 10.1371/journal.pone.0297706
DT Article
PD OCT 11 2024
PY 2024
AB Diabetic retinopathy (DR) is a sight-threatening condition caused by
   diabetes. Screening programmes for DR include eye examinations, where
   the patient's fundi are photographed, and the findings, including DR
   severity, are recorded in the medical report. However, statistical
   analyses based on DR severity require structured labels that calls for
   laborious manual annotation process if the report format is
   unstructured. In this work, we propose a large language model DR-GPT for
   classification of the DR severity from unstructured medical reports. On
   a clinical set of medical reports, DR-GPT reaches 0.975 quadratic
   weighted Cohen's kappa using truncated Early Treatment Diabetic
   Retinopathy Study scale. When DR-GPT annotations for unlabeled data are
   paired with corresponding fundus images, the additional data improves
   image classifier performance with statistical significance. Our analysis
   shows that large language models can be applied for unstructured medical
   report databases to classify diabetic retinopathy with a variety of
   applications.
ZR 0
Z8 0
ZA 0
ZS 0
TC 1
ZB 0
Z9 1
DA 2024-10-30
UT WOS:001336670500022
PM 39392790
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT J
AU Dougherty, Robert
   Clarke, Patrick
   Atli, Merve
   Kuk, Joanna
   Dunlop, Boadie
   Young, Allan
   Goodwin, Guy
   Ryslik, Gregory
TI Psilocybin Therapy for Treatment Resistant Depression: Prediction of
   Clinical Outcome by Natural Language Processing
SO NEUROPSYCHOPHARMACOLOGY
VL 48
MA P328
BP 255
EP 255
SU 1
DT Meeting Abstract
PD DEC 2023
PY 2023
CT 62nd Annual Meeting American-College-of-Neuropsychopharmacology (ACNP)
CY DEC 03-06, 2023
CL Tampa, FL
SP Amer Coll Neuropsychopharmacol
ZR 0
ZA 0
ZS 0
TC 0
Z8 0
ZB 0
Z9 0
DA 2024-01-21
UT WOS:001126640300080
ER

PT J
AU Luchinin, Alexander S.
   Gevorkyan, Tigran G.
   Semenova, Anastasia A.
TI Multiple myeloma as a challenging multidimensional random process: a
   data-driven web-based application for treatment selection
SO BLOOD CANCER JOURNAL
VL 15
IS 1
AR 26
DI 10.1038/s41408-025-01238-4
DT Editorial Material
PD FEB 27 2025
PY 2025
TC 1
ZA 0
ZR 0
ZB 1
ZS 0
Z8 0
Z9 1
DA 2025-03-07
UT WOS:001435080300001
PM 40016177
ER

PT J
AU Segal, Scott
   Saha, Amit K.
   Khanna, Ashish K.
TI Appropriateness of Answers to Common Preanesthesia Patient Questions
   Composed by the Large Language Model GPT-4 Compared to Human Authors
SO ANESTHESIOLOGY
VL 140
IS 2
BP 333
EP 335
DI 10.1097/ALN.0000000000004824
DT Letter
PD FEB 2024
PY 2024
ZS 0
ZB 1
ZA 0
TC 1
Z8 0
ZR 0
Z9 1
DA 2024-04-21
UT WOS:001177663100028
PM 38193737
ER

PT J
AU Duan, Yuchen
   Zhou, Qingqing
   Li, Yu
   Qin, Chi
   Wang, Ziyang
   Kan, Hongxing
   Hu, Jili
TI Research on a traditional Chinese medicine case-based question-answering
   system integrating large language models and knowledge graphs
SO FRONTIERS IN MEDICINE
VL 11
AR 1512329
DI 10.3389/fmed.2024.1512329
DT Article
PD JAN 7 2025
PY 2025
AB Introduction Traditional Chinese Medicine (TCM) case records encapsulate
   vast clinical experiences and theoretical insights, holding significant
   research and practical value. However, traditional case studies face
   challenges such as large data volumes, complex information, and
   difficulties in efficient retrieval and analysis. This study aimed to
   address these issues by leveraging modern data techniques to improve
   access and analysis of TCM case records.Methods A total of 679 case
   records from Wang Zhongqi, a renowned physician of Xin'an Medicine, a
   branch of TCM, covering 41 diseases, were selected. The study involved
   four stages: pattern layer construction, knowledge extraction,
   integration, and data storage and visualization. A large language model
   (LLM) was employed to automatically extract key entities, including
   symptoms, pathogenesis, treatment principles, and prescriptions. These
   were structured into a TCM case knowledge graph.Results The LLM
   successfully identified and extracted relevant entities, which were then
   organized into relational triples. A TCM case query system based on
   natural language input was developed. The system's performance,
   evaluated using the RAGAS framework, achieved high scores: 0.9375 in
   faithfulness, 0.9686 in answer relevancy, and 0.9500 in context recall;
   In human evaluations, the levels of safety and usability are
   significantly higher than those of LLMs without using RAG.Discussion The
   results demonstrate that integrating LLMs with a knowledge graph
   significantly enhances the efficiency and accuracy of retrieving TCM
   case information. This approach could play a crucial role in modernizing
   TCM research and improving access to clinical insights. Future research
   may explore expanding the dataset and refining the query system for
   broader applications.
ZR 0
TC 1
Z8 0
ZS 0
ZB 0
ZA 0
Z9 1
DA 2025-01-25
UT WOS:001400611400001
PM 39839612
ER

PT J
AU Li, Shusheng
   Tan, Wenjun
   Zhang, Changshuai
   Li, Jiale
   Ren, Haiyan
   Guo, Yanliang
   Jia, Jing
   Liu, Yangyang
   Pan, Xingfang
   Guo, Jing
   Meng, Wei
   He, Zhaoshui
TI Taming large language models to implement diagnosis and evaluating the
   generation of LLMs at the semantic similarity level in acupuncture and
   moxibustion
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 264
AR 125920
DI 10.1016/j.eswa.2024.125920
EA DEC 2024
DT Article
PD MAR 10 2025
PY 2025
AB With the rapid advancement of artificial intelligence and deep learning
   technologies, large language models (LLMs) such as ChatGPT and GPT-4
   have made significant progress in comprehending and responding to human
   instructions. Acupuncture and moxibustion, therapeutic modalities in
   Traditional Chinese Medicine (TCM), possess extensive knowledge
   beneficial for patient treatment. Currently, acupuncture diagnosis
   relies on the experience and skills of individual acupuncturists,
   emphasizing the need for research to improve diagnostic accuracy through
   objective methods. Therefore, the integration of LLMs into the field of
   acupuncture can facilitate the recommendation of personalized
   acupuncture treatment programs. However, the application of general LLMs
   to the field of acupuncture diagnosis often yields suboptimal results.
   In addition, most LLM evaluation metrics depend solely on literal
   overlap and fail to capture semantic similarity. To address these
   challenges, this paper introduces AcupunctureGPT, a specialized large
   language model for acupuncture diagnosis, aimed at exploring the
   potential application of LLMs in this field. Patient Diagnostic
   Acupuncture Data is constructed to enhance the diagnostic capabilities
   of AcupunctureGPT in acupuncture. The Generated Knowledge Filter
   Prompting approach is proposed to improve the accuracy of LLMs in
   identifying similar diseases through the development and filtering of
   knowledge statements. The Sentence Similarity Evaluation Module (SSEM)
   is employed to assess the generation quality of LLMs at the semantic
   level. The Sentence Adaptive Enhancement Fusion Module (SAEFM), proposed
   within SSEM, enhances the adaptive fusion of output features at various
   levels. Experimental results demonstrate that AcupunctureGPT outperforms
   other large language models in diagnosing diseases and devising
   reasonable treatment plans. Furthermore, the evaluation metrics proposed
   in this paper have been validated for effectiveness.
TC 0
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
Z9 0
DA 2024-12-13
UT WOS:001372992400001
ER

PT J
AU Wang, P.
   Liu, Z.
   Li, Y.
   Holmes, J.
   Shu, P.
   Zhang, L.
   Li, X.
   Li, Q.
   Vora, S. A.
   Patel, S. H.
   Sio, T. T. W.
   Liu, T.
   Liu, W.
TI Fine-Tuning Large Language Models for Radiation Oncology, A Specialized
   Health Care Domain
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3452
BP E664
EP E664
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
Z8 0
ZB 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302131
ER

PT J
AU Han, B.
   Chen, Y.
   Buyyounouski, M. K.
   Gensheimer, M. F.
   Xing, L.
TI RadAlonc: Enhancing Decision-Making in Radiation Oncology with a
   GPT-4-Based Prompt-Driven Large Language Model
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 2297
BP E134
EP E134
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
Z8 0
ZR 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892300029
ER

PT J
AU Sinha, Rooma
   Raina, Rohit
   Bag, Moumita
   Rupa, Bana
TI Empowering gynaecologists with Artificial Intelligence: Tailoring
   surgical solutions for fibroids
SO EUROPEAN JOURNAL OF OBSTETRICS & GYNECOLOGY AND REPRODUCTIVE BIOLOGY
VL 299
BP 72
EP 77
DI 10.1016/j.ejogrb.2024.06.001
EA JUN 2024
DT Article
PD AUG 2024
PY 2024
AB Background: In recent years, the integration of Artificial intelligence
   (AI) into various fields of medicine including Gynaecology, has shown
   promising potential. Surgical treatment of fibroid is myomectomy if
   uterine preservation and fertility are the primary aims. AI usage begins
   with the involvement of LLM (Large Language Model) from the point when a
   patient visits a gynecologist, from identifying signs and symptoms to
   reaching a diagnosis, providing treatment plans, and patient counseling.
   Objective: Use of AI (ChatGPT versus Google Bard) in the surgical
   management of fibroid. Study design: Identifying the patient's problems
   using LLMs like ChatGPT and Google Bard and giving a treatment option in
   8 clinical scenarios of fibroid. Data entry was done using M.S. Excel
   and was statistically analyzed using Statistical Package for Social
   Sciences (SPSS Version 26) for M.S. Windows 2010. All results were
   presented in tabular form. Data were analyzed using nonparametric tests
   Chi-square tests or Fisher exact test. p values < 0.05 were considered
   statistically significant. The sensitivity of both techniques was
   calculated. We have used Cohen's Kappa to know the degree of agreement.
   Results: We found that on the first attempt, ChatGPT gave general
   answers in 62.5 % of cases and specific answers in 37.5 % of cases.
   ChatGPT showed improved sensitivity on successive prompts 37.5 % to 62.5
   % on the third prompt. Google Bard could not identify the clinical
   question in 50 % of cases and gave incorrect answers in 12.5 % of cases
   (p = 0.04). Google Bard showed the same sensitivity of 25 % on all
   prompts. Conclusion: AI helps to reduce the time to diagnose and plan a
   treatment strategy for fibroid and acts as a powerful tool in the hands
   of a gynecologist. However, the usage of AI by patients for
   self-treatment is to be avoided and should be used only for education
   and counseling about fibroids.
ZS 0
ZR 0
ZB 0
ZA 0
Z8 0
TC 2
Z9 2
DA 2024-06-29
UT WOS:001251789000001
PM 38838389
ER

PT J
AU Kreimeyer, Kory
   Canzoniero, Jenna V
   Fatteh, Maria
   Anagnostou, Valsamo
   Botsis, Taxiarchis
TI Using Retrieval-Augmented Generation to Capture Molecularly-Driven
   Treatment Relationships for Precision Oncology.
SO Studies in health technology and informatics
VL 316
BP 983
EP 987
DI 10.3233/SHTI240575
DT Journal Article
PD 2024-Aug-22
PY 2024
AB Modern generative artificial intelligence techniques like
   retrieval-augmented generation (RAG) may be applied in support of
   precision oncology treatment discussions. Experts routinely review
   published literature for evidence and recommendations of treatments in a
   labor-intensive process. A RAG pipeline may help reduce this effort by
   providing chunks of text from these publications to an off-the-shelf
   large language model (LLM), allowing it to answer related questions
   without any fine-tuning. This potential application is demonstrated by
   retrieving treatment relationships from a trusted data source (OncoKB)
   and reproducing over 80% of them by asking simple questions to an
   untrained Llama 2 model with access to relevant abstracts.
ZA 0
ZB 1
ZR 0
Z8 0
TC 2
ZS 0
Z9 2
DA 2024-08-24
UT MEDLINE:39176956
PM 39176956
ER

PT J
AU Kral, Jan
   Hradis, Michal
   Buzga, Marek
   Kunovsky, Lumir
TI Exploring the benefits and challenges of AI-driven large language models
   in gastroenterology: Think out of the box
SO BIOMEDICAL PAPERS-OLOMOUC
VL 168
IS 4
BP 277
EP 283
DI 10.5507/bp.2024.027
EA SEP 2024
DT Review
PD DEC 2024
PY 2024
AB Artificial Intelligence (AI) has evolved significantly over the past
   decades, from its early concepts in the 1950s to the present era of deep
   learning and natural language processing. Advanced large language models
   (LLMs), such as Chatbot Generative Pre-Trained Transformer (ChatGPT) is
   trained to generate human-like text responses. This technology has the
   potential to revolutionize various aspects of gastroenterology,
   including diagnosis, treatment, education, and The benefits of using
   LLMs in gastroenterology could include accelerating diagnosis and
   treatment, providing personalized care, enhancing education and
   training, assisting in decision-making, and improving communication with
   patients. However, drawbacks and challenges such as limited AI
   capability, training on possibly biased data, data errors, security and
   privacy concerns, and implementation costs must be addressed to ensure
   the responsible and effective use of this technology. The future of LLMs
   in gastroenterology relies on the ability to process and analyse large
   amounts of data, identify patterns, and summarize information and thus
   assist physicians in creating personalized treatment plans. As AI
   advances, LLMs will become more accurate and efficient, allowing for
   faster diagnosis and treatment of gastroenterological conditions.
   Ensuring effective collaboration between AI developers, healthcare
   professionals, and regulatory bodies is essential for the responsible
   and effective use of this technology. By finding the right balance
   between AI and human expertise and addressing the limitations and risks
   associated with its use, LLMs can play an increasingly significant role
   in gastroenterology, contributing to better patient care and supporting
   doctors in their work.
ZR 0
ZS 0
Z8 0
ZA 0
TC 2
ZB 0
Z9 2
DA 2024-09-12
UT WOS:001306654600001
PM 39234774
ER

PT J
AU Liang, Shufan
   Zhang, Jiangjiang
   Liu, Xingting
   Huang, Yinkui
   Shao, Jun
   Liu, Xiaohong
   Li, Weimin
   Wang, Guangyu
   Wang, Chengdi
TI The potential of large language models to advance precision oncology
SO EBIOMEDICINE
VL 115
AR 105695
DI 10.1016/j.ebiom.2025.105695
EA APR 2025
DT Review
PD MAY 2025
PY 2025
AB With the rapid development of artificial intelligence (AI) within
   medicine, the emergence of large language models (LLMs) has gradually
   reached the forefront of clinical research. In oncology, by mining the
   underlying connection between a text or image input and the desired
   output, LLMs demonstrate great potential for managing tumours. In this
   review, we provide a brief description of the development of LLMs,
   followed by model construction strategies and general medical functions.
   We then elaborate on the role of LLMs in cancer screening and diagnosis,
   metastasis identification, tumour staging, treatment recommendation, and
   documentation processing tasks by decoding various types of clinical
   data. Moreover, the current barriers faced by LLMs, such as
   hallucinations, ethical problems, limited application, and so on, are
   outlined along with corresponding solutions, where the further purpose
   is to inspire improvement and innovation in this field with respect to
   harnessing LLMs for advancing precision oncology. Copyright (c) 2025 The
   Author(s). Published by Elsevier B.V. This is an open access article
   under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).
TC 0
Z8 0
ZR 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-05-15
UT WOS:001485098500001
PM 40305985
ER

PT J
AU Su, L X
   Weng, L
   Li, W X
   Long, Y
TI [Applications and challenges of large language models in critical care
   medicine].
SO Zhonghua yi xue za zhi
VL 103
IS 31
BP 2361
EP 2364
DI 10.3760/cma.j.cn112137-20230524-00847
DT English Abstract; Journal Article
PD 2023-Aug-22
PY 2023
AB The rapid development of big data methods and technologies has provided
   more and more new ideas and methods for clinical diagnosis and
   treatment. The emergence of large language models (LLM) has made it
   possible for human-computer interactive dialogues and applications in
   complex medical scenarios. Critical care medicine is a process of
   continuous dynamic targeted treatment. The huge data generated in this
   process needs to be integrated and optimized through models for clinical
   application, interaction in teaching simulation, and assistance in
   scientific research. Using the LLM represented by generative pre-trained
   transformer ChatGPT can initially realize the application in the
   diagnosis of severe diseases, the prediction of death risk and the
   management of medical records. At the same time, the time and space
   limitations, illusions and ethical and moral issues of ChatGPT emerged
   as the times require. In the future, it is undeniable that it may play a
   huge role in the diagnosis and treatment of critical care medicine, but
   the current application should be combined with more clinical knowledge
   reserves of critical care medicine to carefully judge its conclusions.
AB 大数据方法和技术发展日新月异，给临床诊疗提供了越来越多的新的思路和方法。大语言模型的出现使得人机交互式的对话和复杂的医疗场景下的应用成为了可能。
   重症医学是一个连续动态目标性治疗的过程，这个过程中产生的庞大数据需要通过模型进行整合与优化并在临床应用，在教学模拟中互动，在科学研究中助力。使用
   以生成式预训练转换模型（ChatGPT）为代表的大语言模型可初步实现在重症疾病的诊断、死亡风险预测和病案管理方面的应用。同时ChatGPT的时空
   局限性、幻象和伦理道德问题应运而生。ChatGPT在未来的重症医学诊疗中可能会发挥巨大作用，但目前需要结合更多的重症医学临床知识储备并谨慎对待其
   作出的结论进行判断。.
ZR 0
TC 1
ZB 0
Z8 3
ZS 0
ZA 0
Z9 4
DA 2023-08-23
UT MEDLINE:37599212
PM 37599212
ER

PT J
AU Zhuang, Yi
   Yu, Lingkai
   Jiang, Nan
   Ge, Yujia
TI TCM-KLLaMA: Intelligent generation model for Traditional Chinese
   Medicine Prescriptions based on knowledge graph and large language
   model.
SO Computers in biology and medicine
VL 189
BP 109887
EP 109887
DI 10.1016/j.compbiomed.2025.109887
DT Journal Article
PD 2025-May
PY 2025
AB Traditional Chinese medicine (TCM) prescriptions are a basic component
   of TCM treatment, developed by assessing patient symptoms and
   prescribing a mix of herbs. Accurate prescription generation is critical
   for enhancing treatment outcomes and maintaining patient safety.
   However, conventional methods based on Large Language Models (LLMs)
   focus mainly on symptom information, neglecting other TCM diagnostic
   expertise, such as tongue and pulse diagnosis, and are prone to
   hallucination, which is unacceptable in medical applications. To address
   these challenges, the paper proposes an effective prescription
   generation model enriched by a TCM knowledge graph (KG) called the
   TCM-KLLaMA model. In this model, the Chinese-LLaMA2-7B model is provided
   with a new output layer and loss function to suppress hallucinations and
   increase recommendation accuracy. A TCM KG including symptoms, tongue
   diagnosis, and pulse diagnosis was developed, and the model was
   fine-tuned utilizing the suggested synonym and matching knowledge
   injection (SMKI) mechanism. Extensive experiments demonstrate that the
   TCM- KLLaMA outperforms baseline models in both Precision and F1 Score,
   proving its superior performance in prescription generation tasks.
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-03-11
UT MEDLINE:40056842
PM 40056842
ER

PT J
AU Hua, Rui
   Dong, Xin
   Wei, Yu
   Shu, Zixin
   Yang, Pengcheng
   Hu, Yunhui
   Zhou, Shuiping
   Sun, He
   Yan, Kaijing
   Yan, Xijun
   Chang, Kai
   Li, Xiaodong
   Bai, Yuning
   Zhang, Runshun
   Wang, Wenjia
   Zhou, Xuezhong
TI Lingdan: enhancing encoding of traditional Chinese medicine knowledge
   for clinical reasoning tasks with large language models
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
DI 10.1093/jamia/ocae087
EA JUL 2024
DT Article; Early Access
PY 2024
AB Objective The recent surge in large language models (LLMs) across
   various fields has yet to be fully realized in traditional Chinese
   medicine (TCM). This study aims to bridge this gap by developing a large
   language model tailored to TCM knowledge, enhancing its performance and
   accuracy in clinical reasoning tasks such as diagnosis, treatment, and
   prescription recommendations.Materials and Methods This study harnessed
   a wide array of TCM data resources, including TCM ancient books,
   textbooks, and clinical data, to create 3 key datasets: the TCM
   Pre-trained Dataset, the Traditional Chinese Patent Medicine (TCPM)
   Question Answering Dataset, and the Spleen and Stomach Herbal
   Prescription Recommendation Dataset. These datasets underpinned the
   development of the Lingdan Pre-trained LLM and 2 specialized models: the
   Lingdan-TCPM-Chat Model, which uses a Chain-of-Thought process for
   symptom analysis and TCPM recommendation, and a Lingdan Prescription
   Recommendation model (Lingdan-PR) that proposes herbal prescriptions
   based on electronic medical records.Results The Lingdan-TCPM-Chat and
   the Lingdan-PR Model, fine-tuned on the Lingdan Pre-trained LLM,
   demonstrated state-of-the art performances for the tasks of TCM clinical
   knowledge answering and herbal prescription recommendation. Notably,
   Lingdan-PR outperformed all state-of-the-art baseline models, achieving
   an improvement of 18.39% in the Top@20 F1-score compared with the best
   baseline.Conclusion This study marks a pivotal step in merging advanced
   LLMs with TCM, showcasing the potential of artificial intelligence to
   help improve clinical decision-making of medical diagnostics and
   treatment strategies. The success of the Lingdan Pre-trained LLM and its
   derivative models, Lingdan-TCPM-Chat and Lingdan-PR, not only
   revolutionizes TCM practices but also opens new avenues for the
   application of artificial intelligence in other specialized medical
   fields. Our project is available at
   https://github.com/TCMAI-BJTU/LingdanLLM.
Z8 4
ZR 0
ZA 0
ZS 0
TC 7
ZB 0
Z9 11
DA 2024-07-28
UT WOS:001273695100001
PM 39038795
ER

PT J
AU Liad, Brettler
   Eden, Berman
   M, Jagodnik Kathleen
   Alon, Bartal
TI DruGNNosis-MoA: Elucidating Drug Mechanisms as Etiological or Palliative
   with Graph Neural Networks Employing a Large Language Model.
SO IEEE journal of biomedical and health informatics
VL PP
DI 10.1109/JBHI.2025.3565553
DT Journal Article
PD 2025-Apr-29
PY 2025
AB Understanding the complex mechanisms of drugs' therapeutic effects is
   essential for advancing precision medicine and optimizing treatment
   strategies. However, systematically distinguishing between drugs that
   address root causes (etiological mechanisms) and those that alleviate
   symptoms (palliative mechanisms) using modern Artificial Intelligence
   (AI)-based strategies remains underexplored. We present a novel
   computational framework for classifying drug Mechanisms of Action (MoA)
   as etiological or palliative, comparing three approaches: (i)
   Fine-tuning Science Bidirectional Encoder Representations from
   Transformers (SciBERT) with drug descriptions; (ii) Training various
   Graph Neural Networks (GNNs) on a constructed heterogeneous network of
   drugs, genes, and diseases; and (iii) Developing DruGNNosis-MoA, which
   integrates GNN with our fine-tuned SciBERT embeddings as node features.
   DruGNNosis-MoA excelled (F1-score 0.94) in identifying drug MoA.
   DruGNNosis-MoA characterizes drug mechanisms for subsequent
   pharmacological studies, thereby advancing precision medicine and
   therapeutic development.
ZA 0
TC 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 0
DA 2025-05-02
UT MEDLINE:40299745
PM 40299745
ER

PT J
AU Gerstung, Moritz
   Liu, David
   Ghassemi, Marzyeh
   Zou, James
   Chowell, Diego
   Teuwen, Jonas
   Mahmood, Faisal
   Kather, Jakob Nikolas
TI Artificial intelligence
SO CANCER CELL
VL 42
IS 6
BP 915
EP 918
DT Editorial Material
PD JUN 10 2024
PY 2024
ZS 0
ZR 0
ZA 0
Z8 0
TC 2
ZB 1
Z9 2
DA 2025-02-12
UT WOS:001412853800001
PM 38861926
ER

PT J
AU Zakka, Cyril
   Chaurasia, Akash
   Shad, Rohan
   Dalal, Alex R
   Kim, Jennifer L
   Moor, Michael
   Alexander, Kevin
   Ashley, Euan
   Boyd, Jack
   Boyd, Kathleen
   Hirsch, Karen
   Langlotz, Curt
   Nelson, Joanna
   Hiesinger, William
TI Almanac: Retrieval-Augmented Language Models for Clinical Medicine.
SO Research square
DI 10.21203/rs.3.rs-2883198/v1
DT Preprint
PD 2023 May 02
PY 2023
AB Large-language models have recently demonstrated impressive zero-shot
   capabilities in a variety of natural language tasks such as
   summarization, dialogue generation, and question-answering. Despite many
   promising applications in clinical medicine, adoption of these models in
   real-world settings has been largely limited by their tendency to
   generate incorrect and sometimes even toxic statements. In this study,
   we develop Almanac, a large language model framework augmented with
   retrieval capabilities for medical guideline and treatment
   recommendations. Performance on a novel dataset of clinical scenarios
   (n= 130) evaluated by a panel of 5 board-certified and resident
   physicians demonstrates significant increases in factuality (mean of 18%
   at p-value < 0.05) across all specialties, with improvements in
   completeness and safety. Our results demonstrate the potential for large
   language models to be effective tools in the clinical decision-making
   process, while also emphasizing the importance of careful testing and
   deployment to mitigate their shortcomings.
Z8 0
ZA 0
ZB 2
ZS 0
TC 8
ZR 0
Z9 8
DA 2023-05-21
UT MEDLINE:37205549
PM 37205549
ER

PT J
AU Ren, Yaxuan
   Luo, Xufei
   Wang, Ye
   Li, Haodong
   Zhang, Hairong
   Li, Zeming
   Lai, Honghao
   Li, Xuanlin
   Ge, Long
   Estill, Janne
   Zhang, Lu
   Yang, Shu
   Chen, Yaolong
   Wen, Chengping
   Bian, Zhaoxiang
   ADVANCED Working Group
TI Large Language Models in Traditional Chinese Medicine: A Scoping Review
SO JOURNAL OF EVIDENCE BASED MEDICINE
VL 18
IS 1
DI 10.1111/jebm.12658
EA DEC 2024
DT Review
PD MAR 2025
PY 2025
AB BackgroundThe application of large language models (LLMs) in medicine
   has received increasing attention, showing significant potential in
   teaching, research, and clinical practice, especially in knowledge
   extraction, management, and understanding. However, the use of LLMs in
   Traditional Chinese Medicine (TCM) has not been thoroughly studied. This
   study aims to provide a comprehensive overview of the status and
   challenges of LLM applications in TCM.MethodsA systematic search of five
   electronic databases and Google Scholar was conducted between November
   2022 and April 2024, using the Arksey and O'Malley five-stage framework
   to identify relevant studies. Data from eligible studies were
   comprehensively extracted and organized to describe LLM applications in
   TCM and assess their performance accuracy.ResultsA total of 29 studies
   were identified: 24 peer-reviewed articles, 1 review, and 4 preprints.
   Two core application areas were found: the extraction, management, and
   understanding of TCM knowledge, and assisted diagnosis and treatment.
   LLMs developed specifically for TCM achieved 70% accuracy in the TCM
   Practitioner Exam, while general-purpose Chinese LLMs achieved 60%
   accuracy. Common international LLMs did not pass the exam. Models like
   EpidemicCHAT and MedChatZH, trained on customized TCM corpora,
   outperformed general LLMs in TCM consultation.ConclusionDespite their
   potential, LLMs in TCM face challenges such as data quality and security
   issues, the specificity and complexity of TCM data, and the
   nonquantitative nature of TCM diagnosis and treatment. Future efforts
   should focus on interdisciplinary talent cultivation, enhanced data
   standardization and protection, and exploring LLM potential in
   multimodal interaction and intelligent diagnosis and treatment.
ZR 0
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001373936900001
PM 39651543
ER

PT J
AU Ahmed, Saad
   Sood, Aditya
   Wright, Jervon
   Hou, Lilly
   Marvil, Charles
   Samaddar, Ashish
   Lin, Justin
   Berman, Ethan
   Sangari, Anish
   Sood, Nitish
TI Improvements in Treatment of Pancreatic Cancers Over the Last Forty
   Years
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
VL 119
IS 10S
MA S35
BP S27
EP S28
DI 10.14309/01.ajg.0001028508.75243.72
SU 10
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Annual Meeting of the American-College-of-Gastroenterology (ACG)
CY OCT 25-30, 2024
CL Pennsylvania Convention Cent, Philadelphia, PA
HO Pennsylvania Convention Cent
SP Amer Coll Gastroenterol
ZA 0
ZS 0
Z8 0
ZB 0
TC 0
ZR 0
Z9 0
DA 2024-12-01
UT WOS:001359393800021
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Farhat, Faiza
TI ChatGPT as a Complementary Mental Health Resource: A Boon or a Bane
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 5
BP 1111
EP 1114
DI 10.1007/s10439-023-03326-7
EA JUL 2023
DT Article
PD MAY 2024
PY 2024
AB The launch of Open AI's chatbot, ChatGPT, has generated a lot of
   attention and discussion among professionals in several fields. Many
   concerns and challenges have been brought up by researchers from various
   fields, particularly in relation to the harm that using these tools for
   medical diagnosis and treatment recommendations can cause. In addition,
   it has been debated if ChatGPT is dependable, efficient, and helpful for
   clinicians and medical professionals. Therefore, in this study, we
   assess ChatGPT's effectiveness in providing mental health support,
   particularly for issues related to anxiety and depression, based on the
   chatbot's responses and cross-questioning. The findings indicate that
   there are significant inconsistencies and that ChatGPT's reliability is
   low in this specific domain. As a result, care must be used when using
   ChatGPT as a complementary mental health resource.
Z8 0
ZS 0
ZR 0
ZB 4
ZA 0
TC 33
Z9 33
DA 2023-08-10
UT WOS:001035550600001
PM 37477707
ER

PT J
AU Geraci, Joseph
   Qorri, Bessi
   Tsay, Mike
   Cumbaa, Christian
   Leonchyk, Paul
   Alphs, Larry
   Pani, Luca
TI An AI approach to unraveling treatment response in pancreatic cancer:
   Insights from the COMPASS trial leveraging large language models (LLMs)
SO CANCER RESEARCH
VL 84
IS 17
MA B066
DI 10.1158/1538-7445.PANCREATIC24-B066
SU 2
DT Meeting Abstract
PD SEP 1 2024
PY 2024
CT AACR Special Conference in Cancer Research: Advances in Pancreatic
   Cancer Research
CY SEP 15-18, 2024
CL Boston, MA
SP Amer Assoc Cancer Res
ZB 0
TC 0
Z8 0
ZR 0
ZS 0
ZA 0
Z9 0
DA 2024-09-29
UT WOS:001317590000140
ER

PT J
AU Gokbulut, Puren
   Kuskonmaz, Serife Mehlika
   Onder, Cagatay Emir
   Taskaldiran, Isilay
   Koc, Gonul
TI Evaluation of ChatGPT-4 Performance in Answering Patients' Questions
   About the Management of Type 2 Diabetes
SO MEDICAL BULLETIN OF SISLI ETFAL HOSPITAL
VL 58
IS 4
BP 483
EP 490
DI 10.14744/SEMB.2024.23697
DT Article
PD 2024
PY 2024
AB Objectives: Type 2 diabetes mellitus is a disease with a rising
   prevalence worldwide. Person-centered treatment factors, including
   comorbidities and treatment goals, should be considered in determining
   the pharmacological treatment of type 2 diabetes. ChatGPT-4 (Generative
   Pre-trained Transformer), a large language model, holds the potential
   performance in various fields, including medicine. We aimed to examine
   the reliability, quality, reproducibility, and readability of
   ChatGPT-4's responses to clinical scenarios about the medical treatment
   approach and management of type 2 diabetes patients. Methods:
   ChatGPT-4's responses to 24 questions were independently graded by two
   endocrinologists with clinical experience in endocrinology and resolved
   by a third reviewer based on the ADA(American Diabetes Association) 2023
   guidelines. DISCERN (Quality Criteria for Consumer Health Information)
   Measurement Tool was used to evaluate the reliability and quality of
   information. Results: Responses to questions by ChatGPT-4 were fairly
   consistent in both sessions. No false or misleading information was
   found in any ChatGPT-4 responses. In terms of reliability, most of the
   answers showed good (87.5%), followed by excellent (12.5%) reliability.
   Reading Level was classified as fairly difficult to read (8.3%),
   difficult to read (50%), and very difficult to read (41.7%). Conclusion:
   ChatGPT-4 may have a role as an additional informative tool for type 2
   diabetes patients for medical treatment approaches.
ZB 0
ZS 0
ZR 0
TC 1
ZA 0
Z8 0
Z9 1
DA 2025-01-05
UT WOS:001386512800013
PM 39816417
ER

PT J
AU Pordzik, Johannes
   Bahr-Hamm, Katharina
   Huppertz, Tilman
   Gouveris, Haralampos
   Seifen, Christopher
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Eckrich, Jonas
   Buhr, Christoph R.
TI Patient Support in Obstructive Sleep Apnoea by a Large Language Model -
   ChatGPT 4o on Answering Frequently Asked Questions on First Line
   Positive Airway Pressure and Second Line Hypoglossal Nerve Stimulation
   Therapy: A Pilot Study
SO NATURE AND SCIENCE OF SLEEP
VL 16
BP 2269
EP 2277
DI 10.2147/NSS.S495654
DT Article
PD 2024
PY 2024
AB Purpose: Obstructive sleep apnoea (OSA) is a common disease that
   benefits from early treatment and patient support in order to prevent
   secondary illnesses. This study assesses the capability of the large
   language model (LLM) ChatGPT-4o to offer patient support regarding first
   line positive airway pressure (PAP) and second line hypoglossal nerve
   stimulation (HGNS) therapy. Methods: Seventeen questions, each regarding
   PAP and HGNS therapy, were posed to ChatGPT-4o. Answers were rated by
   experienced experts in sleep medicine on a 6-point Likert scale in the
   categories of medical adequacy, conciseness, coherence, and
   comprehensibility. Completeness of medical information and potential
   hazard for patients were rated using a binary system. Results: Overall,
   ChatGPT-4o achieved reasonably high ratings in all categories. In
   medical adequacy, it performed significantly better on PAP questions
   (mean 4.9) compared to those on HGNS (mean 4.6) (p < 0.05). Scores for
   coherence, comprehensibility and conciseness showed similar results for
   both HGNS and PAP answers. Raters confirmed completeness of responses in
   45 of 51 ratings (88.24%) for PAP answers and 28 of 51 ratings (54.9%)
   for HGNS answers. Potential hazards for patients were stated in 2 of 52
   ratings (0.04%) for PAP answers and none for HGNS answers. Conclusion:
   ChatGPT-4o has potential as a valuable patient-oriented support tool in
   sleep medicine therapy that can enhance subsequent face-to-face
   consultations with a sleep specialist. However, some substantial flaws
   regarding second line HGNS therapy are most likely due to recent
   advances in HGNS therapy and the consequent limited information
   available in LLM training data.
ZS 0
ZR 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
DA 2025-01-03
UT WOS:001385851000001
PM 39741798
ER

PT J
AU Liu, Jialin
   Wang, Changyu
   Liu, Siru
TI Utility of ChatGPT in Clinical Practice
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 25
AR e48568
DI 10.2196/48568
DT Article
PD JUN 28 2023
PY 2023
AB ChatGPT is receiving increasing attention and has a variety of
   application scenarios in clinical practice. In clinical decision
   support, ChatGPT has been used to generate accurate differential
   diagnosis lists, support clinical decision-making, optimize clinical
   decision support, and provide insights for cancer screening decisions.
   In addition, ChatGPT has been used for intelligent question-answering to
   provide reliable information about diseases and medical queries. In
   terms of medical documentation, ChatGPT has proven effective in
   generating patient clinical letters, radiology reports, medical notes,
   and discharge summaries, improving efficiency and accuracy for health
   care providers. Future research directions include real-time monitoring
   and predictive analytics, precision medicine and personalized treatment,
   the role of ChatGPT in telemedicine and remote health care, and
   integration with existing health care systems. Overall, ChatGPT is a
   valuable tool that complements the expertise of health care providers
   and improves clinical decision-making and patient care. However, ChatGPT
   is a double-edged sword. We need to carefully consider and study the
   benefits and potential dangers of ChatGPT. In this viewpoint, we discuss
   recent advances in ChatGPT research in clinical practice and suggest
   possible risks and challenges of using ChatGPT in clinical practice. It
   will help guide and support future artificial intelligence research
   similar to ChatGPT in health.
ZS 1
ZR 0
Z8 5
TC 230
ZB 25
ZA 0
Z9 234
DA 2023-08-24
UT WOS:001045687800005
PM 37379067
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   Croce, Lory
   Shung, Dennis
TI TRANSFORMING HEPATITIS C TREATMENT: THE POWER OF LARGE LANGUAGE MODEL-
   BASED INTELLIGENT AGENTS IN CLINICAL DECISION SUPPORT
SO HEPATOLOGY
VL 80
MA 557
BP S406
EP S407
SU 1
DT Meeting Abstract
PD OCT 2024
PY 2024
CT The Liver Meeting
CY NOV 15-19, 2024
CL San Diego, CA
ZS 0
TC 0
ZR 0
ZA 0
ZB 0
Z8 0
Z9 0
DA 2025-01-07
UT WOS:001366004001049
ER

PT J
AU Franc, Jeffrey Micheal
   Med, Dip Sport
   Hertelendy, Attila Julius
   Cheng, Lenard
   Hata, Ryan
   Verde, Manuela
TI Accuracy of a Commercial Large Language Model (ChatGPT) toPerform
   Disaster Triage of Simulated Patients Using the SimpleTriage and Rapid
   Treatment (START) Protocol:Gage Repeatabilityand Reproducibility Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 26
AR e55648
DI 10.2196/55648
DT Article
PD SEP 30 2024
PY 2024
AB Background: The release of ChatGPT (OpenAI) in November 2022 drastically
   reduced the barrier to using artificial intelligence by allowing a
   simple web-based text interface to a large language model (LLM). One use
   case where ChatGPT could be useful is in triaging patients at the site
   of a disaster using the Simple Triage and Rapid Treatment (START)
   protocol. However, LLMs experience several common errors including
   hallucinations (also called confabulations) and prompt dependency.
   Objective: This study addresses the research problem: "Can ChatGPT
   adequately triage simulated disaster patients using the START protocol?"
   by measuring three outcomes: repeatability, reproducibility, and
   accuracy. Methods: Nine prompts were developed by 5 disaster medicine
   physicians. A Python script queried ChatGPT Version 4 for each prompt
   combined with 391 validated simulated patient vignettes. Ten repetitions
   of each combination were performed for a total of 35,190 simulated
   triages. A reference standard START triage code for each simulated case
   was assigned by 2 disaster medicine specialists (JMF and MV), with a
   third specialist (LC) added if the first two did not agree. Results were
   evaluated using a gage repeatability and reproducibility study (gage R
   and R). Repeatability was defined as variation due to repeated use of
   the same prompt. Reproducibility was defined as variation due to the use
   of different prompts on the same patient vignette. Accuracy was defined
   as agreement with the reference standard. Results: Although 35,102
   (99.7%) queries returned a valid START score, there was considerable
   variability. Repeatability (use of the same prompt repeatedly) was 14%
   of the overall variation. Reproducibility (use of different prompts) was
   4.1% of the overall variation. The accuracy of ChatGPT for START was
   63.9% with a 32.9% overtriage rate and a 3.1% undertriage rate. Accuracy
   varied by prompt with a maximum of 71.8% and a minimum of 46.7%.
   Conclusions: This study indicates that ChatGPT version 4 is insufficient
   to triage simulated disaster patients via the START protocol. It
   demonstrated suboptimal repeatability and reproducibility. The overall
   accuracy of triage was only 63.9%. Health care professionals are advised
   to exercise caution while using commercial LLMs for vital medical
   determinations, given that these tools may commonly produce inaccurate
   data, colloquially referred to as hallucinations or confabulations.
   Artificial intelligence-guided tools should undergo rigorous statistical
   evaluation-using methods such as gage R and R-before implementation into
   clinical settings.
ZS 0
TC 2
ZA 0
ZR 0
ZB 0
Z8 0
Z9 2
DA 2024-10-24
UT WOS:001334857400004
PM 39348189
ER

PT J
AU Zalikha, Abdul K
   Hong, Thomas S
   Small, Easton A
   Constant, Michael
   Harris, Alex H S
   Giori, Nicholas J
TI Can a Large Language Model Interpret Data in the Electronic Health
   Record to Infer Minimum Clinically Important Difference Achievement of
   Knee Osteoarthritis Outcome Score-Joint Replacement Score Following
   Total Knee Arthroplasty?
SO The Journal of arthroplasty
VL 40
IS 7S1
BP S153
EP S157
DI 10.1016/j.arth.2025.03.049
DT Journal Article
PD 2025-Jul
PY 2025
AB BACKGROUND: Obtaining total knee arthroplasty patient-reported outcomes
   for quality assessment is costly and difficult. We asked whether a large
   language model (LLM) could interpret electronic health record notes to
   differentiate patients attaining a 1-year minimum clinically important
   difference (MCID) for the Knee Osteoarthritis Outcome Score-Joint
   Replacement (KOOS-JR) from those who did not. We also investigated
   whether sufficient information to infer MCID achievement exists in the
   chart by having a blinded orthopaedic surgeon make the same
   determination.
   METHODS: In this retrospective case-control study, we selected 40 total
   knee arthroplasty patients who achieved 1-year KOOS-JR MCID and 40 who
   did not. Orthopaedic, emergency medicine, and primary care notes from
   zero to six months preoperatively and nine to 15 months postoperatively
   were deidentified. ChatGPT 3.5 (ChatGPT) interpreted these notes to
   determine whether the patient improved after surgery. A blinded
   orthopaedic surgeon classified these patients using all chart
   information. The sensitivity, specificity, and accuracy of ChatGPT and
   the surgeon's responses were calculated.
   RESULTS: ChatGPT classified 78 of 80 cases with 97% sensitivity, but
   only 33% specificity. The surgeon's assessment had 90% sensitivity and
   63% specificity. Given the equal distribution of patients meeting or not
   meeting MCID, Chat GPT's accuracy was 65%. The surgeon's was 76%.
   CONCLUSIONS: ChatGPT's assessment of KOOS-JR MCID attainment had 97%
   sensitivity, but only 33% specificity. False positives were commonly due
   to the LLM not having access to, or not properly interpreting, signs of
   problems in the chart. This was an initial evaluation of the current
   ability of a general-purpose LLM to evaluate patient outcomes based on
   information in chart notes. An orthopaedic surgeon's assessment of the
   full chart suggests an opportunity to improve on this baseline
   performance, possibly enabling quality monitoring and identification of
   best practices across a large health care system. Additional work is
   needed to optimize model performance and confirm the utility of this
   approach.
Z8 0
ZB 0
ZS 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2025-03-30
UT MEDLINE:40139476
PM 40139476
ER

PT J
AU Lee, Won-Yung
   Han, Sang-Yun
   Kim, Ji-Hwan
   Lee, Byung-Wook
   Han, Yejin
   Lee, Seungho
TI Gen-SynDi: Leveraging Knowledge-Guided Generative AI for Dual Education
   of Syndrome Differentiation and Disease Diagnosis
SO APPLIED SCIENCES-BASEL
VL 15
IS 9
AR 4862
DI 10.3390/app15094862
DT Article
PD APR 27 2025
PY 2025
AB Syndrome differentiation and disease diagnosis are central to
   Traditional Asian Medicine (TAM) because they guide personalized
   treatment. Yet, most TAM courses give students few structured
   opportunities to practise these paired skills. We developed Gen-SynDi, a
   knowledge-guided generative-AI framework that links syndrome
   differentiation with disease diagnosis to improve training. Using
   standardized patient files from the National Institute for Korean
   Medicine Development, we built a fatigue-focused dataset covering five
   Western-defined diseases and seven TAM syndromes. Carefully designed
   prompts and a large language model produced 28 virtual patient cases by
   joining compatible disease-syndrome pairs while preserving clinical
   realism. Inside an interactive web simulation, students conduct
   history-taking, receive free-text answers, and propose both syndrome and
   disease diagnoses; immediate feedback highlights missing questions,
   reasoning gaps, and overall accuracy. A built-in scoring module supplies
   quantitative measures of inquiry coverage and diagnostic precision, plus
   brief explanations of overlooked clues. A prompt-component role analysis
   confirmed that our prompt design improves response fidelity, and
   external experts endorsed the scenarios' realism and educational value.
   Gen-SynDi therefore offers a scalable bridge between textbook knowledge
   and clinical practice, strengthening learners' skills in differential
   diagnosis and syndrome differentiation.
Z8 0
ZR 0
ZS 0
TC 0
ZB 0
ZA 0
Z9 0
DA 2025-05-16
UT WOS:001485983700001
ER

PT J
AU Kesty, Chelsea E.
   Kesty, Katarina R.
TI Treatment of Porphyria Cutanea Tarda Scarring With Combination Laser
   Treatment and a Pilot Use of Artificial Intelligence to Quantify Laser
   Results
SO JOURNAL OF COSMETIC DERMATOLOGY
VL 24
IS 4
AR e70056
DI 10.1111/jocd.70056
DT Editorial Material
PD APR 2025
PY 2025
AB Background: Porphyria cutanea tarda (PCT) is the most common subtype of
   porphyria and results from a deficiency of the enzyme uroporphyrinogen
   decarboxylase. Even after successful treatment, patients can be left
   with significant scarring, and there is little published data on the
   safety and efficacy of light-based or laser-based therapies. Methods:
   This report examines a case of a 47-year-old male with PCT secondary to
   HCV, treated with a combination of fractionated erbium-doped
   yttrium-aluminum-garnet (Er:YAG), intense pulsed light (IPL), and carbon
   dioxide (CO2) lasers to address significant scarring and residual skin
   damage. An artificial intelligence model was used to quantify the
   results of the laser procedures. Results: After combination laser
   treatment, the patient exhibited marked improvements in skin texture,
   reduction in scar visibility, and diminished hyperpigmentation. The
   artificial intelligence algorithm quantified the laser results and
   showed improvements in the scores used in the large language model.
   Conclusion: In this patient, customizing a combination of lasers to
   target different layers of the skin to achieve comprehensive
   improvement: erbium primarily addressed superficial irregularities and
   pigmentation, while CO2 promoted deeper collagen remodeling. The use of
   artificial intelligence to quantify the positive results in this case is
   in line with the clinical evaluations and photos.
Z8 0
TC 0
ZS 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2025-04-06
UT WOS:001456943500001
PM 40167326
ER

PT J
AU Nielsen, Jacob P. S.
   Gronhoj, Christian
   Skov, Lone
   Gyldenlove, Mette
TI Usefulness of the large language model ChatGPT (GPT-4) as a diagnostic
   tool and information source in dermatology
SO JEADV CLINICAL PRACTICE
VL 3
IS 5
BP 1570
EP 1575
DI 10.1002/jvc2.459
EA JUN 2024
DT Article
PD DEC 2024
PY 2024
AB BackgroundThe field of artificial intelligence is rapidly evolving. As
   an easily accessible platform with vast user engagement, the Chat
   Generative Pre-Trained Transformer (ChatGPT) holds great promise in
   medicine, with the latest version, GPT-4, capable of analyzing clinical
   images.ObjectivesTo evaluate ChatGPT as a diagnostic tool and
   information source in clinical dermatology.MethodsA total of 15 clinical
   images were selected from the Danish web atlas, Danderm, depicting
   various common and rare skin conditions. The images were uploaded to
   ChatGPT version GPT-4, which was prompted with 'Please provide a
   description, a potential diagnosis, and treatment options for the
   following dermatological condition'. The generated responses were
   assessed by senior registrars in dermatology and consultant
   dermatologists in terms of accuracy, relevance, and depth (scale 1-5),
   and in addition, the image quality was rated (scale 0-10). Demographic
   and professional information about the respondents was
   registered.ResultsA total of 23 physicians participated in the study.
   The majority of the respondents were consultant dermatologists (83%),
   and 48% had more than 10 years of training. The overall image quality
   had a median rating of 10 out of 10 [interquartile range (IQR): 9-10].
   The overall median rating of the ChatGPT generated responses was 2 (IQR:
   1-4), while overall median ratings in terms of relevance, accuracy, and
   depth were 2 (IQR: 1-4), 3 (IQR: 2-4) and 2 (IQR: 1-3),
   respectively.ConclusionsDespite the advancements in ChatGPT, including
   newly added image processing capabilities, the chatbot demonstrated
   significant limitations in providing reliable and clinically useful
   responses to illustrative images of various dermatological conditions.
ZA 0
TC 1
ZR 0
ZB 0
Z8 0
ZS 0
Z9 1
DA 2024-06-08
UT WOS:001237597700001
ER

PT J
AU Erdogan, Esra Kayacan
   Babaoglu, Hakan
TI Clinical Reasoning and Knowledge Assessment of Rheumatology Residents
   Compared to AI Models: A Pilot Study
SO JOURNAL OF CLINICAL MEDICINE
VL 13
IS 23
AR 7405
DI 10.3390/jcm13237405
DT Article
PD DEC 2024
PY 2024
AB Background: The integration of artificial intelligence (AI) in medicine
   has progressed from rule-based systems to advanced models and is showing
   potential in clinical decision-making. In this study, the psychological
   impact of AI collaboration in clinical practice is assessed,
   highlighting its role as a support tool for medical residents. This
   study aimed to compare clinical decision-making approaches of junior
   rheumatology residents with both trained and untrained AI models in
   clinical reasoning, pre-diagnosis, first-line, and second-line
   management stages. Methods: Ten junior rheumatology residents and two
   GPT-4 models (trained and untrained) responded to 10 clinical cases,
   encompassing diagnostic and treatment challenges in inflammatory
   arthritis. The cases were evaluated using the Revised-IDEA (R-IDEA)
   scoring system and additional case management metrics. In addition to
   scoring clinical case performance, residents' attitudes toward AI
   integration in clinical practice were assessed through a structured
   questionnaire, focusing on perceptions of AI's potential after reviewing
   the trained GPT-4's answers. Results: Trained GPT-4 outperformed
   residents across all stages, achieving significantly higher median
   R-IDEA scores and superior performance in pre-diagnosis, first-line, and
   second-line management phases. Residents expressed a positive attitude
   toward AI integration, with 60% favoring AI as a supportive tool in
   clinical practice, anticipating benefits in competence, fatigue, and
   burnout. Conclusions: Trained GPT-4 models outperform junior residents
   in clinical reasoning and management of rheumatology cases. Residents'
   positive attitudes toward AI suggest its potential as a supportive tool
   to enhance confidence and reduce uncertainty in clinical practice.
   Trained GPT-4 may be used as a supplementary tool during the early years
   of residency.
ZR 0
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-12-21
UT WOS:001376610600001
PM 39685863
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU Zhu, Libing
   Rong, Yi
   Mcgee, Lisa A.
   Rwigema, Jean-Claude M.
   Patel, Samir H.
TI Testing and Validation of a Custom Retrained Large Language Model for
   the Supportive Care of HN Patients with External Knowledge Base
SO CANCERS
VL 16
IS 13
AR 2311
DI 10.3390/cancers16132311
DT Article
PD JUL 2024
PY 2024
AB Simple Summary Cancer patients, especially long-distance patients, often
   struggle to receive timely and precise medical information and support
   for their symptom management and survivorship care. ChatGPT-4's
   responses to queries concerning head and neck (HN) cancer remain
   questionable. The purpose of this study was to develop and validate a
   retrained large language model (LLM) for HN cancer patients. In this
   cross-sectional study, the presented LLM was retrained with a
   high-quality user-defined knowledge base. The responses from the LLM to
   patients' questions were validated against human responses, and the
   model showed a superior performance, with average scores of 4.25 for
   accuracy, 4.35 for clarity, 4.22 for completeness, and 4.32 for
   relevance, on a 5-point scale. The confined-trained LLM with a
   high-quality user-defined knowledge base demonstrates high accuracy,
   clarity, completeness, and relevance in offering evidence-based
   information and guidance on the symptom management and survivorship care
   for head and neck cancer patients.Abstract Purpose: This study aimed to
   develop a retrained large language model (LLM) tailored to the needs of
   HN cancer patients treated with radiotherapy, with emphasis on symptom
   management and survivorship care. Methods: A comprehensive external
   database was curated for training ChatGPT-4, integrating
   expert-identified consensus guidelines on supportive care for HN
   patients and correspondences from physicians and nurses within our
   institution's electronic medical records for 90 HN patients. The
   performance of our model was evaluated using 20 patient post-treatment
   inquiries that were then assessed by three Board certified radiation
   oncologists (RadOncs). The rating of the model was assessed on a scale
   of 1 (strongly disagree) to 5 (strongly agree) based on accuracy,
   clarity of response, completeness s, and relevance. Results: The average
   scores for the 20 tested questions were 4.25 for accuracy, 4.35 for
   clarity, 4.22 for completeness, and 4.32 for relevance, on a 5-point
   scale. Overall, 91.67% (220 out of 240) of assessments received scores
   of 3 or higher, and 83.33% (200 out of 240) received scores of 4 or
   higher. Conclusion: The custom-trained model demonstrates high accuracy
   in providing support to HN patients offering evidence-based information
   and guidance on their symptom management and survivorship care.
ZA 0
ZS 0
Z8 0
ZR 0
TC 1
ZB 1
Z9 1
DA 2024-07-22
UT WOS:001269842700001
PM 39001375
ER

PT J
AU Ding, Sirui
   Ye, Jiancheng
   Hu, Xia
   Zou, Na
TI Distilling the knowledge from large-language model for health event
   prediction
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30675
DI 10.1038/s41598-024-75331-2
DT Article
PD DEC 28 2024
PY 2024
AB Health event prediction is empowered by the rapid and wide application
   of electronic health records (EHR). In the Intensive Care Unit (ICU),
   precisely predicting the health related events in advance is essential
   for providing treatment and intervention to improve the patients
   outcomes. EHR is a kind of multi-modal data containing clinical text,
   time series, structured data, etc. Most health event prediction works
   focus on a single modality, e.g., text or tabular EHR. How to
   effectively learn from the multi-modal EHR for health event prediction
   remains a challenge. Inspired by the strong capability in text
   processing of large language model (LLM), we propose the framework CKLE
   for health event prediction by distilling the knowledge from LLM and
   learning from multi-modal EHR. There are two challenges of applying LLM
   in the health event prediction, the first one is most LLM can only
   handle text data rather than other modalities, e.g., structured data.
   The second challenge is the privacy issue of health applications
   requires the LLM to be locally deployed, which may be limited by the
   computational resource. CKLE solves the challenges of LLM scalability
   and portability in the healthcare domain by distilling the
   cross-modality knowledge from LLM into the health event predictive
   model. To fully take advantage of the strong power of LLM, the raw
   clinical text is refined and augmented with prompt learning. The
   embedding of clinical text are generated by LLM. To effectively distill
   the knowledge of LLM into the predictive model, we design a
   cross-modality knowledge distillation (KD) method. A specially designed
   training objective will be used for the KD process with the
   consideration of multiple modality and patient similarity. The KD loss
   function consists of two parts. The first one is cross-modality
   contrastive loss function, which models the correlation of different
   modalities from the same patient. The second one is patient similarity
   learning loss function to model the correlations between similar
   patients. The cross-modality knowledge distillation can distill the rich
   information in clinical text and the knowledge of LLM into the
   predictive model on structured EHR data. To demonstrate the
   effectiveness of CKLE, we evaluate CKLE on two health event prediction
   tasks in the field of cardiology, heart failure prediction and
   hypertension prediction. We select the 7125 patients from MIMIC-III
   dataset and split them into train/validation/test sets. We can achieve a
   maximum 4.48% improvement in accuracy compared to state-of-the-art
   predictive model designed for health event prediction. The results
   demonstrate CKLE can surpass the baseline prediction models
   significantly on both normal and limited label settings. We also conduct
   the case study on cardiology disease analysis in the heart failure and
   hypertension prediction. Through the feature importance calculation, we
   analyse the salient features related to the cardiology disease which
   corresponds to the medical domain knowledge. The superior performance
   and interpretability of CKLE pave a promising way to leverage the power
   and knowledge of LLM in the health event prediction in real-world
   clinical settings.
Z8 0
ZA 0
TC 2
ZS 0
ZB 0
ZR 0
Z9 2
DA 2025-01-09
UT WOS:001386137300038
PM 39730390
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on a Large Language Model Chatbot
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1636
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
TC 0
ZB 0
Z8 0
ZA 0
ZS 0
Z9 0
DA 2024-12-01
UT WOS:001312227704264
ER

PT J
AU Hooshangnejad, Hamed
   Huang, Gaofeng
   Kelly, Katelyn
   Feng, Xue
   Luo, Yi
   Zhang, Rui
   Xu, Ziyue
   Chen, Quan
   Ding, Kai
TI EXACT-Net: Framework for EHR-Guided Lung Tumor Auto-Segmentation for
   Non-Small Cell Lung Cancer Radiotherapy
SO CANCERS
VL 16
IS 23
AR 4097
DI 10.3390/cancers16234097
DT Article
PD DEC 2024
PY 2024
AB Background/Objectives: Lung cancer is a devastating disease with the
   highest mortality rate among cancer types. Over 60% of non-small cell
   lung cancer (NSCLC) patients, accounting for 87% of lung cancer
   diagnoses, require radiation therapy. Rapid treatment initiation
   significantly increases the patient's survival rate and reduces the
   mortality rate. Accurate tumor segmentation is a critical step in
   diagnosing and treating NSCLC. Manual segmentation is time- and
   labor-consuming and causes delays in treatment initiation. Although many
   lung nodule detection methods, including deep learning-based models,
   have been proposed. Most of these methods still have a long-standing
   problem of high false positives (FPs). Methods: Here, we developed an
   electronic health record (EHR)-guided lung tumor auto-segmentation
   called EXACT-Net (EHR-enhanced eXACtitude in Tumor segmentation), where
   the extracted information from EHRs using a pre-trained large language
   model (LLM) was used to remove the FPs and keep the TP nodules only.
   Results: The auto-segmentation model was trained on NSCLC patients'
   computed tomography (CT), and the pre-trained LLM was used with the
   zero-shot learning approach. Our approach resulted in a 250% boost in
   successful nodule detection using the data from ten NSCLC patients
   treated in our institution. Conclusions: We demonstrated that combining
   vision-language information in EXACT-Net multi-modal AI framework
   greatly enhances the performance of vision only models, paving the road
   to multimodal AI framework for medical image processing.
ZS 0
ZA 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2024-12-19
UT WOS:001376131100001
PM 39682283
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT J
AU Okada, Yohei
   Mertens, Mayli
   Liu, Nan
   Lam, Sean Shao Wei
   Ong, Marcus Eng Hock
TI AI and machine learning in resuscitation: Ongoing research, new
   concepts, and key challenges
SO RESUSCITATION PLUS
VL 15
AR 100435
DI 10.1016/j.resplu.2023.100435
EA JUL 2023
DT Article
PD SEP 2023
PY 2023
AB Aim: Artificial intelligence (AI) and machine learning (ML) are
   important areas of computer science that have recently attracted
   attention for their application to medicine. However, as techniques
   continue to advance and become more complex, it is increasingly
   challenging for clinicians to stay abreast of the latest research. This
   overview aims to translate research concepts and potential concerns to
   healthcare professionals interested in applying AI and ML to
   resuscitation research but who are not experts in the field.Main text:
   We present various research including prediction models using structured
   and unstructured data, exploring treatment heterogeneity, reinforcement
   learning, language processing, and large-scale language models. These
   studies potentially offer valuable insights for optimizing treatment
   strategies and clinical workflows. However, implementing AI and ML in
   clinical settings presents its own set of challenges. The availability
   of high quality and reliable data is crucial for developing accurate ML
   models. A rigorous validation process and the integration of ML into
   clinical practice is essential for practical implementation. We
   furthermore highlight the potential risks associated with
   self-fulfilling prophecies and feedback loops, emphasizing the
   importance of transparency, interpretability, and trustworthiness in AI
   and ML models. These issues need to be addressed in order to establish
   reliable and trustworthy AI and ML models.Conclusion: In this article,
   we overview concepts and examples of AI and ML research in the
   resuscitation field. Moving forward, appropriate understanding of ML and
   collaboration with relevant experts will be essential for researchers
   and clinicians to overcome the challenges and harness the full potential
   of AI and ML in resuscitation.
Z8 0
ZS 0
ZR 0
ZB 2
TC 20
ZA 0
Z9 20
DA 2023-09-01
UT WOS:001051946400001
PM 37547540
ER

PT J
AU Xu, Peng
TI Multi-layered data framework for enhancing postoperative outcomes and
   anaesthesia management through natural language processing
SO SLAS TECHNOLOGY
VL 32
AR 100294
DI 10.1016/j.slast.2025.100294
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Anaesthesia management is a critical aspect of perioperative care,
   directly influencing postoperative recovery, pain management, and
   patient outcomes. Despite advancements in anaesthesia techniques,
   variability in patient responses and unexpected postoperative
   complications remain significant challenges. The research proposes a
   multi-layered architecture named Anaesthesia CareNet for analyzing data
   from diverse sources to enhance personalized anaesthesia management and
   postoperative outcome prediction. The architecture is structured into
   two primary layers: Data processing and Predictive Modeling. In the Data
   processing layer, advanced Natural Language Processing (NLP) techniques
   such as Named Entity Recognition (NER), normalization, lemmatization,
   and stemming are applied to clean and standardize the unstructured
   clinical data. Generative Pre-trained Transformer 3 (GPT-3), a Large
   Language Model (LLM) is employed as a feature extraction method,
   allowing the system to process and analyze complex clinical narratives
   and unstructured textual data from patient records. This enables more
   precise and personalized predictions, not only improving anaesthesia
   management but also laying the groundwork for broader applications in
   life sciences. The extracted data is passed into the predictive modeling
   layer, where the Intelligent Golden Eagle Fine-Tuned Logistic Regression
   (IGE-LR) model is applied. By analyzing correlations between patient
   characteristics, surgical details, and postoperative recovery patterns,
   IGELR enables the prediction of complications, pain management
   requirements, and recovery trajectories beyond anaesthesia; the
   methodology has potential applications in diverse areas such as
   diagnostics, drug discovery, and personalized medicine, where
   large-scale data analysis, predictive modeling, and real-time
   adaptability are crucial for improving patient outcomes. The proposed
   IGE-LR method achieves higher performance with 91.7 % accuracy, 90.6 %
   specificity, and 90 % AUC, with a recall of 91.3 %, precision of 90.1 %,
   and an F1-Score of 90.4 %. By leveraging advanced NLP and predictive
   analytics, Anaesthesia CareNet exemplifies how AI-driven frameworks can
   transform life sciences, advancing personalized healthcare and creating
   a more precise, efficient, and dynamic approach to treatment management.
ZR 0
ZS 0
TC 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-10
UT WOS:001479823100001
PM 40252977
ER

PT J
AU Sun, Virginia
   Heemelaar, Julius
   Hadzic, Ibrahim
   Raghu, Vineet
   Wu, Chia-Yun
   Zubiri, Leyre
   Ghamari, Azin
   Suero-Abreu, Giselle
   Wu, Jessica
   Hathaway, Nora
   Gilman, Hannah
   Villani, Alexandra-Chloe
   Ho, Sam
   Zlotoff, Daniel
   Blum, Steven
   Sullivan, Ryan
   Reynolds, Kerry
   Neilan, Tomas
TI Enhancing early detection of ICI myocarditis cases during
   hospitalization: A role for large language models
SO CIRCULATION
VL 150
MA 4119426
DI 10.1161/circ.150.suppl_1.4119426
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
TC 0
ZA 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
DA 2025-02-10
UT WOS:001398742700200
ER

PT J
AU Qu, Roy W. W.
   Qureshi, Uneeb
   Petersen, Garrett
   Lee, Steve C. C.
TI Diagnostic and Management Applications of ChatGPT in Structured
   Otolaryngology Clinical Scenarios
SO OTO OPEN
VL 7
IS 3
AR e67
DI 10.1002/oto2.67
DT Article
PD JUL 2023
PY 2023
AB ObjectiveTo evaluate the clinical applications and limitations of chat
   generative pretrained transformer (ChatGPT) in otolaryngology. Study
   DesignCross-sectional survey. SettingTertiary academic center.
   MethodsChatGPT 4.0 was queried for diagnoses and management plans for 20
   physician-written clinical vignettes in otolaryngology. Attending
   physicians were then asked to rate the difficulty of the clinical
   vignettes and agreement with the differential diagnoses and management
   plans of ChatGPT responses on a 5-point Likert scale. Summary statistics
   were calculated. Univariate ordinal regression was then performed
   between vignette difficulty and quality of the diagnoses and management
   plans. ResultsEleven attending physicians completed the survey (61%
   response rate). Overall, vignettes were rated as very easy to neutral
   difficulty (range of median score: 1.00-4.00; overall median 2.00).
   There was a high agreement with the differential diagnosis provided by
   ChatGPT (range of median score: 3.00-5.00; overall median: 5.00). There
   was also high agreement with treatment plans (range of median score:
   3.00-5.00; overall median: 5.00). There was no association between
   vignette difficulty and agreement with differential diagnosis or
   treatment. Lower diagnosis scores had greater odds of having lower
   treatment scores. ConclusionGenerative artificial intelligence models
   like ChatGPT are being rapidly adopted in medicine. Performance with
   curated, easy-to-moderate difficulty otolaryngology scenarios indicate
   high agreement with physicians for diagnosis and management. However, a
   decreased quality in diagnosis is associated with decreased quality in
   management. Further research is necessary on ChatGPT's ability to handle
   unstructured clinical information.
ZB 8
ZS 0
Z8 0
ZR 0
ZA 0
TC 42
Z9 42
DA 2023-08-31
UT WOS:001051927400001
PM 37614494
ER

PT J
AU Ho, Cindy N.
   Tian, Tiffany
   Ayers, Alessandra T.
   Aaron, Rachel E.
   Phillips, Vidith
   Wolf, Risa M.
   Mathioudakis, Nestoras
   Dai, Tinglong
   Klonoff, David C.
TI Qualitative metrics from the biomedical literature for evaluating large
   language models in clinical decision-making: a narrative review
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
VL 24
IS 1
AR 357
DI 10.1186/s12911-024-02757-z
DT Article
PD NOV 26 2024
PY 2024
AB BackgroundThe large language models (LLMs), most notably ChatGPT,
   released since November 30, 2022, have prompted shifting attention to
   their use in medicine, particularly for supporting clinical
   decision-making. However, there is little consensus in the medical
   community on how LLM performance in clinical contexts should be
   evaluated.MethodsWe performed a literature review of PubMed to identify
   publications between December 1, 2022, and April 1, 2024, that discussed
   assessments of LLM-generated diagnoses or treatment plans.ResultsWe
   selected 108 relevant articles from PubMed for analysis. The most
   frequently used LLMs were GPT-3.5, GPT-4, Bard, LLaMa/Alpaca-based
   models, and Bing Chat. The five most frequently used criteria for
   scoring LLM outputs were "accuracy", "completeness", "appropriateness",
   "insight", and "consistency".ConclusionsThe most frequently used
   criteria for defining high-quality LLMs have been consistently selected
   by researchers over the past 1.5 years. We identified a high degree of
   variation in how studies reported their findings and assessed LLM
   performance. Standardized reporting of qualitative evaluation metrics
   that assess the quality of LLM outputs can be developed to facilitate
   research studies on LLMs in healthcare.
ZS 0
TC 4
ZA 0
ZB 0
Z8 0
ZR 0
Z9 4
DA 2024-12-03
UT WOS:001364059400003
PM 39593074
ER

PT J
AU Chen, Xi
   Wang, Li
   You, Mingke
   Liu, Weizhi
   Fu, Yu
   Xu, Jie
   Zhang, Shaoting
   Chen, Gang
   Li, Kang
   Li, Jian
TI Evaluating and Enhancing Large Language Models'Performancein
   Domain-Specific Medicine:Development and Usability StudyWith DocOA
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 26
AR e58158
DI 10.2196
DT Article
PD JUL 24 2024
PY 2024
AB Background: The efficacy of large language models (LLMs) in
   domain-specific medicine, particularly for managing complex diseases
   such as osteoarthritis (OA), remains largely unexplored. Objective: This
   study focused on evaluating and enhancing the clinical capabilities and
   explain ability of LLMs in specific domains, using OA management as a
   case study. Methods: A domain-specific benchmark framework was developed
   to evaluate LLMs across a spectrum from domain-specific knowledge to
   clinical applications in real-world clinical scenarios. DocOA, a
   specialized LLM designed for OA management integrating
   retrieval-augmented generation and instructional prompts, was developed.
   It can identify the clinical evidence upon which its answers are based
   through retrieval-augmented generation, thereby demonstrating the
   explain ability of those answers. The study compared the performance of
   GPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and
   human evaluations. Results: Results showed that general LLMs such as
   GPT-3.5 and GPT-4 were less effective in the specialized domain of OA
   management, particularly in providing personalized treatment
   recommendations. However, DocOA showed significant improvements.
   Conclusions: This study introduces a novel benchmark framework that
   assesses the domain-specific abilities of LLMs in multiple aspects,
   highlights the limitations of generalized LLMs in clinical contexts, and
   demonstrates the potential of tailored approaches for developing
   domain-specific medical LLMs
TC 4
ZR 0
Z8 1
ZS 0
ZA 0
ZB 1
Z9 4
DA 2024-09-15
UT WOS:001297028800003
PM 38833165
ER

PT J
AU Ozkan, Ecem
   Tekin, Aysun
   Ozkan, Mahmut Can
   Cabrera, Daniel
   Niven, Alexander
   Dong, Yue
TI Global Health care Professionals' Perceptions of Large Language Model
   Use In Practice: Cross-Sectional Survey Study
SO JMIR MEDICAL EDUCATION
VL 11
AR e58801
DI 10.2196/58801
DT Article
PD 2025
PY 2025
AB Background: ChatGPT is a large language model-based chatbot developed by
   OpenAI. ChatGPT has many potential applications to health care,
   including enhanced diagnostic accuracy and efficiency, improved
   treatment planning, and better patient outcomes. However, health care
   professionals' perceptions of ChatGPT and similar artificial
   intelligence tools are not well known. Understanding these attitudes is
   important to inform the best approaches to exploring their use in
   medicine. Objective: Our aim was to evaluate the health care
   professionals' awareness and perceptions regarding potential
   applications of ChatGPT in the medical field, including potential
   benefits and challenges of adoption. Methods: We designed a 33-question
   online survey that was distributed among health care professionals via
   targeted emails and professional Twitter and LinkedIn accounts. The
   survey included a range of questions to define respondents' demographic
   characteristics, familiarity with ChatGPT, perceptions of this tool's
   usefulness and reliability, and opinions on its potential to improve
   patient care, research, and education efforts. Results: One hundred and
   fifteen health care professionals from 21 countries responded to the
   survey, including physicians, nurses, researchers, and educators. Of
   these, 101 (87.8%) had heard of ChatGPT, mainly from peers, social
   media, and news, and 77 (76.2%) had used ChatGPT at least once.
   Participants found ChatGPT to be helpful for writing manuscripts (n=31,
   45.6%), emails (n=25, 36.8%), and grants (n=12, 17.6%); accessing the
   latest research and evidence-based guidelines (n=21, 30.9%); providing
   suggestions on diagnosis or treatment (n=15, 22.1%); and improving
   patient communication (n=12, 17.6%). Respondents also felt that the
   ability of ChatGPT to access and summarize research articles (n=22,
   46.8%), provide quick answers to clinical questions (n=15, 31.9%), and
   generate patient education materials (n=10, 21.3%) was helpful. However,
   there are concerns regarding the use of ChatGPT, for example, the
   accuracy of responses (n=14, 29.8%), limited applicability in specific
   practices (n=18, 38.3%), and legal and ethical considerations (n=6,
   12.8%), mainly related to plagiarism or copyright violations.
   Participants stated that safety protocols such as data encryption (n=63,
   62.4%) and access control (n=52, 51.5%) could assist in ensuring patient
   privacy and data security. Conclusions: Our findings show that ChatGPT
   use is widespread among health care professionals in daily clinical,
   research, and educational activities. The majority of our participants
   found ChatGPT to be useful; however, there are concerns about patient
   privacy, data security, and its legal and ethical issues as well as the
   accuracy of its information. Further studies are required to understand
   the impact of ChatGPT and other large language models on clinical,
   educational, and research outcomes, and the concerns regarding its use
   must be addressed systematically and through appropriate methods.
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-23
UT WOS:001490640700001
PM 40354644
ER

PT J
AU Dronkers, Emilie A C
   Geneid, Ahmed
   Al Yaghchi, Chadwan
   Lechien, Jerome R
TI Evaluating the Potential of AI Chatbots in Treatment Decision-making for
   Acquired Bilateral Vocal Fold Paralysis in Adults.
SO Journal of voice : official journal of the Voice Foundation
DI 10.1016/j.jvoice.2024.02.020
DT Journal Article
PD 2024-Apr-06
PY 2024
AB OBJECTIVES: The development of artificial intelligence-powered language
   models, such as Chatbot Generative Pre-trained Transformer (ChatGPT) or
   Large Language Model Meta AI (Llama), is emerging in medicine. Patients
   and practitioners have full access to chatbots that may provide medical
   information. The aim of this study was to explore the performance and
   accuracy of ChatGPT and Llama in treatment decision-making for bilateral
   vocal fold paralysis (BVFP).
   METHODS: Data of 20 clinical cases, treated between 2018 and 2023, were
   retrospectively collected from four tertiary laryngology centers in
   Europe. The cases were defined as the most common or most challenging
   scenarios regarding BVFP treatment. The treatment proposals were
   discussed in their local multidisciplinary teams (MDT). Each case was
   presented to ChatGPT-4.0 and Llama Chat-2.0, and potential treatment
   strategies were requested. The Artificial Intelligence Performance
   Instrument (AIPI) treatment subscore was used to compare both Chatbots'
   performances to MDT treatment proposal.
   RESULTS: Most common etiology of BVFP was thyroid surgery. A form of
   partial arytenoidectomy with or without posterior transverse cordotomy
   was the MDT proposal for most cases. The accuracy of both Chatbots was
   very low regarding their treatment proposals, with a maximum AIPI
   treatment score in 5% of the cases. In most cases even harmful
   assertions were made, including the suggestion of vocal fold
   medialisation to treat patients with stridor and dyspnea. ChatGPT-4.0
   performed significantly better in suggesting the correct treatment as
   part of the treatment proposal (50%) compared to Llama Chat-2.0 (15%).
   CONCLUSION: ChatGPT and Llama are judged as inaccurate in proposing
   correct treatment for BVFP. ChatGPT significantly outperformed Llama.
   Treatment decision-making for a complex condition such as BVFP is
   clearly beyond the Chatbot's knowledge expertise. This study highlights
   the complexity and heterogeneity of BVFP treatment, and the need for
   further guidelines dedicated to the management of BVFP.
ZA 0
TC 10
ZR 0
Z8 0
ZS 0
ZB 0
Z9 10
DA 2024-04-09
UT MEDLINE:38584026
PM 38584026
ER

PT J
AU Hueso, Miguel
   Alvarez, Rafael
   Mari, David
   Ribas-Ripoll, Vicent
   Lekadir, Karim
   Vellido, Alfredo
TI IS GENERATIVE ARTIFICIAL INTELLIGENCE THE NEXT STEP TOWARD A
   PERSONALIZED HEMODIALYSIS?
SO REVISTA DE INVESTIGACION CLINICA-CLINICAL AND TRANSLATIONAL
   INVESTIGATION
VL 75
IS 6
BP 309
EP 317
DI 10.24875/RIC.23000162
EA JUL 2023
DT Review
PD NOV-DEC 2023
PY 2023
AB Artificial intelligence (AI) generative models driven by the integration
   of AI and natural language processing technologies, such as OpenAI's
   chatbot generative pre-trained transformer large language model (LLM),
   are receiving much public attention and have the potential to transform
   personalized medicine. Dialysis patients are highly dependent on
   technology and their treatment generates a challenging large volume of
   data that has to be analyzed for knowledge extraction. We argue that, by
   integrating the data acquired from hemodialysis treatments with the
   powerful conversational capabilities of LLMs, nephrologists could
   personalize treatments adapted to patients' lifestyles and preferences.
   We also argue that this new conversational AI integrated with a
   personalized patient-computer interface will enhance patients'
   engagement and self-care by providing them with a more personalized
   experience. However, generative AI models require continuous and
   accurate updates of data, and expert supervision and must address
   potential biases and limitations. Dialysis patients can also benefit
   from other new emerging technologies such as Digital Twins with which
   patients' care can also be addressed from a personalized medicine
   perspective. In this paper, we will revise LLMs potential strengths in
   terms of their contribution to personalized medicine, and, in
   particular, their potential impact, and limitations in nephrology.
   Nephrologists' collaboration with AI academia and companies, to develop
   algorithms and models that are more transparent, understandable, and
   trustworthy, will be crucial for the next generation of dialysis
   patients. The combination of technology, patient-specific data, and AI
   should contribute to create a more personalized and interactive dialysis
   process, improving patients' quality of life.
Z8 0
ZS 0
ZB 1
ZR 0
ZA 0
TC 5
Z9 5
DA 2023-10-16
UT WOS:001072108900001
PM 37734067
ER

PT J
AU Chang, Ying
   Yin, Jian-ming
   Li, Jian-min
   Liu, Chang
   Cao, Ling-yong
   Lin, Shu-yuan
TI Applications and Future Prospects of Medical LLMs: A Survey Based on the
   M-KAT Conceptual Framework
SO JOURNAL OF MEDICAL SYSTEMS
VL 48
IS 1
AR 112
DI 10.1007/s10916-024-02132-5
DT Review
PD DEC 27 2024
PY 2024
AB The success of large language models (LLMs) in general areas have
   sparked a wave of research into their applications in the medical field.
   However, enhancing the medical professionalism of these models remains a
   major challenge. This study proposed a novel model training theoretical
   framework, the M-KAT framework, which integrated domain-specific
   training methods for LLMs with the unique characteristics of the medical
   discipline. This framework aimed to improve the medical professionalism
   of the models from three perspectives: general knowledge acquisition,
   specialized skill development, and alignment with clinical thinking.
   This study summarized the outcomes of medical LLMs across four tasks:
   clinical diagnosis and treatment, medical question answering, medical
   research, and health management. Using the M-KAT framework, we analyzed
   the contribution to enhancement of professionalism of models through
   different training stages. At the same time, for some of the potential
   risks associated with medical LLMs, targeted solutions can be achieved
   through pre-training, SFT, and model alignment based on cultivated
   professional capabilities. Additionally, this study identified main
   directions for future research on medical LLMs: advancing professional
   evaluation datasets and metrics tailored to the needs of medical tasks,
   conducting in-depth studies on medical multimodal large language models
   (MLLMs) capable of integrating diverse data types, and exploring the
   forms of medical agents and multi-agent frameworks that can interact
   with real healthcare environments and support clinical decision-making.
   It is hoped that predictions of work can provide a reference for
   subsequent research.
ZS 0
Z8 0
TC 1
ZB 0
ZR 0
ZA 0
Z9 1
DA 2024-12-30
UT WOS:001383525300001
PM 39725770
ER

PT J
AU Li, Haotian
   Xia, Congmin
   Hou, Youjuan
   Hu, Sile
   Liu, Yanjun
   Jiang, Quan
TI TCMRD - KG: innovative design and development of rheumatology knowledge
   graph in ancient Chinese literature assisted by large language models
SO FRONTIERS IN PHARMACOLOGY
VL 16
AR 1535596
DI 10.3389/fphar.2025.1535596
DT Article
PD FEB 19 2025
PY 2025
AB Introduction Rheumatic immune diseases are a type of immune-inflammatory
   disease that affects muscles, bones, joints, and surrounding soft
   tissues. They have a long course and a high disability rate, seriously
   affecting the quality of life of patients. Traditional Chinese medicine
   plays an important role in the diagnosis and treatment of rheumatic
   immune diseases. The unique theoretical system and rich treatment
   methods of traditional Chinese medicine are preserved in ancient Chinese
   medical books.Methods This study takes the content related to rheumatism
   in ancient traditional Chinese medicine books as the research object,
   integrates ontology theory and technology into the knowledge graph, and
   realizes the reconstruction of traditional Chinese medicine information
   knowledge. It provides a basic data structure for data mining and
   knowledge discovery.Results This study is the first rheumatism-specific
   knowledge graph constructed based on ancient traditional Chinese
   medicine books. It has explored the construction method of a knowledge
   graph from ancient books by combining automatic labeling of mainstream
   large language models with manual review. Considering the knowledge
   characteristics of ancient traditional Chinese medicine books, where
   existing word segmentation technology struggles to accurately reproduce
   the original meaning, a new type of entity extraction method is
   proposed.Discussion This provides an important foundation for improving
   the clinical diagnosis and treatment level of traditional Chinese
   medicine in treating rheumatism, further exploring the knowledge
   representation and application of traditional Chinese medicine in
   rheumatism treatment, and it has potential for future expansion and
   improvement.
ZS 0
TC 1
ZA 0
Z8 0
ZR 0
ZB 0
Z9 1
DA 2025-03-09
UT WOS:001436847300001
PM 40046747
ER

PT J
AU Agrawal, Anjali
TI Fairness in AI-Driven Oncology: Investigating Racial and Gender Biases
   in Large Language Models
SO CUREUS JOURNAL OF MEDICAL SCIENCE
VL 16
IS 9
AR e69541
DI 10.7759/cureus.69541
DT Article
PD SEP 16 2024
PY 2024
AB Introduction: Large language model (LLM) chatbots have many applications
   in medical settings. However, these tools can potentially perpetuate
   racial and gender biases through their responses, worsening disparities
   in healthcare. With the ongoing discussion of LLM chatbots in oncology
   and the widespread goal of addressing cancer disparities, this study
   focuses on biases propagated by LLM chatbots in oncology. Methods: Chat
   Generative Pre-trained Transformer (Chat GPT; OpenAI, San Francisco, CA,
   USA) was asked to determine what occupation a generic description of
   "assesses cancer patients" would correspond to for different
   demographics. Chat GPT, Gemini (Alphabet Inc., Mountain View, CA, USA),
   and Bing Chat (Microsoft Corp., Redmond, WA, USA) were prompted to
   provide oncologist recommendations in the top U.S. cities and
   demographic information (race, gender) of recommendations was compared
   against national distributions. Chat GPT was also asked to generate a
   job description for oncologists with different demographic backgrounds.
   Finally, Chat GPT, Gemini, and Bing Chat were asked to generate
   hypothetical cancer patients with race, smoking, and drinking histories.
   Results: LLM chatbots are about two times more likely to predict Blacks
   and Native Americans as oncology nurses than oncologists, compared to
   Asians (p < 0.01 and < 0.001, respectively). Similarly, they are also
   significantly more likely to predict females than males as oncology
   nurses (p < 0.001). Chat GPT's real-world oncologist recommendations
   overrepresent Asians by almost double and underrepresent Blacks by
   double and Hispanics by seven times. Chatbots also generate different
   job descriptions based on demographics, including cultural competency
   and advocacy and excluding treatment administration for underrepresented
   backgrounds. AI-generated cancer cases are not fully representative of
   real-world demographic distributions and encode stereotypes on substance
   abuse, such as Hispanics having a greater proportion of smokers than
   Whites by about 20% in Chat GPT breast cancer cases. Conclusion: To our
   knowledge, this is the first study of its kind to investigate racial and
   gender biases of such a diverse set of AI chatbots, and that too, within
   oncology. The methodology presented in this study provides a framework
   for targeted bias evaluation of LLMs in various fields across medicine.
ZB 0
Z8 0
ZA 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2024-09-29
UT WOS:001318056600011
PM 39416584
ER

PT J
AU Zhang, Sainan
   Song, Jisung
TI A chatbot based question and answer system for the auxiliary diagnosis
   of chronic diseases based on large language model
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 17118
DI 10.1038/s41598-024-67429-4
DT Article
PD JUL 25 2024
PY 2024
AB In recent years, artificial intelligence has made remarkable strides,
   improving various aspects of our daily lives. One notable application is
   in intelligent chatbots that use deep learning models. These systems
   have shown tremendous promise in the medical sector, enhancing
   healthcare quality, treatment efficiency, and cost-effectiveness.
   However, their role in aiding disease diagnosis, particularly chronic
   conditions, remains underexplored. Addressing this issue, this study
   employs large language models from the GPT series, in conjunction with
   deep learning techniques, to design and develop a diagnostic system
   targeted at chronic diseases. Specifically, performed transfer learning
   and fine-tuning on the GPT-2 model, enabling it to assist in accurately
   diagnosing 24 common chronic diseases. To provide a user-friendly
   interface and seamless interactive experience, we further developed a
   dialog-based interface, naming it Chat Ella. This system can make
   precise predictions for chronic diseases based on the symptoms described
   by users. Experimental results indicate that our model achieved an
   accuracy rate of 97.50% on the validation set, and an area under the
   curve (AUC) value reaching 99.91%. Moreover, conducted user satisfaction
   tests, which revealed that 68.7% of participants approved of Chat Ella,
   while 45.3% of participants found the system made daily medical
   consultations more convenient. It can rapidly and accurately assess a
   patient's condition based on the symptoms described and provide timely
   feedback, making it of significant value in the design of medical
   auxiliary products for household use.
ZB 0
ZR 0
ZA 0
TC 6
ZS 0
Z8 0
Z9 6
DA 2024-08-03
UT WOS:001278002800002
PM 39054346
ER

PT J
AU Yousefi, Siamak
   Huang, Xiaoqin
   Raja, Hina
   Madadi, Yeganeh
   Delsoz, Mohammad
   Poursoroush, Asma
   Kahook, Malik
TI Predicting glaucoma before onset using a large language model chatbot
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1643
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
Z8 0
ZR 0
ZB 0
TC 1
ZA 0
ZS 0
Z9 1
DA 2024-12-01
UT WOS:001312227704271
ER

PT J
AU Romano, Michael F.
   Shih, Ludy C.
   Paschalidis, Ioannis C.
   Au, Rhoda
   Kolachalama, Vijaya B.
TI Large Language Models in Neurology Research and Future Practice
SO NEUROLOGY
VL 101
IS 23
BP 1058
EP 1067
DI 10.1212/WNL.0000000000207967
DT Article
PD DEC 5 2023
PY 2023
AB Recent advancements in generative artificial intelligence, particularly
   using large language models (LLMs), are gaining increased public
   attention. We provide a perspective on the potential of LLMs to analyze
   enormous amounts of data from medical records and gain insights on
   specific topics in neurology. In addition, we explore use cases for
   LLMs, such as early diagnosis, supporting patient and caregivers, and
   acting as an assistant for clinicians. We point to the potential ethical
   and technical challenges raised by LLMs, such as concerns about privacy
   and data security, potential biases in the data for model training, and
   the need for careful validation of results. Researchers must consider
   these challenges and take steps to address them to ensure that their
   work is conducted in a safe and responsible manner. Despite these
   challenges, LLMs offer promising opportunities for improving care and
   treatment of various neurologic disorders.
TC 22
ZR 0
ZB 4
ZA 0
ZS 0
Z8 0
Z9 22
DA 2024-01-14
UT WOS:001110273400014
PM 37816646
ER

PT J
AU Chervenak, Joseph
   Lieman, Harry
   Blanco-Breindel, Miranda
   Jindal, Sangita
TI The promise and peril of using a large language model to obtain clinical
   information: ChatGPT performs strongly as a fertility counseling tool
   with limitations
SO FERTILITY AND STERILITY
VL 120
IS 3
BP 575
EP 583
DI 10.1016/j.fertnstert.2023.05.151
EA AUG 2023
PN 2
DT Article
PD SEP 2023
PY 2023
AB Objective: To compare the responses of the large language model-based
   "ChatGPT"to reputable sources when given fertility-related clinical
   prompts. Design: The "Feb 13"version of ChatGPT by OpenAI was tested
   against established sources relating to patient-oriented clinical
   information: 17 "frequently asked questions (FAQs)"about infertility on
   the Centers for Disease Control (CDC) Website, 2 validated fertility
   knowledge surveys, the Cardiff Fertility Knowledge Scale and the
   Fertility and Infertility Treatment Knowledge Score, as well as the
   American Society for Reproductive Medicine committee opinion "optimizing
   natural fertility."Setting: Academic medical center. Patient(s): Online
   AI Chatbot. Intervention(s): Frequently asked questions, survey
   questions and rephrased summary statements were entered as prompts in
   the chatbot over a 1-week period in February 2023. Main Outcome
   Measure(s): For FAQs from CDC: words/response, sentiment analysis
   polarity and objectivity, total factual statements, rate of statements
   that were incorrect, referenced a source, or noted the value of
   consulting providers. For fertility knowledge surveys: Percentile
   according to published population data. For Committee Opinion: Whether
   response to conclusions rephrased as questions identified missing facts.
   Result(s): When administered the CDC's 17 infertility FAQ's, ChatGPT
   produced responses of similar length (207.8 ChatGPT vs. 181.0 CDC
   words/response), factual content (8.65 factual statements/response vs.
   10.41), sentiment polarity (mean 0.11 vs. 0.11 on a scale of-1
   (negative) to 1 (positive)), and subjectivity (mean 0.42 vs. 0.35 on a
   scale of 0 (objective) to 1 (subjective)). In total, 9 (6.12%) of 147
   ChatGPT factual statements were categorized as incorrect, and only 1
   (0.68%) statement cited a reference. ChatGPT would have been at the 87th
   percentile of Bunting's 2013 international cohort for the Cardiff
   Fertility Knowledge Scale and at the 95th percentile on the basis of
   Kudesia's 2017 cohort for the Fertility and Infertility Treatment
   Knowledge Score. ChatGPT reproduced the missing facts for all 7 summary
   statements from "optimizing natural fertility."Conclusion(s): A February
   2023 version of "ChatGPT"demonstrates the ability of generative
   artificial intelligence to produce relevant, meaningful responses to
   fertility-related clinical queries comparable to established sources.
   Although performance may improve with medical domain-specific training,
   limitations such as the inability to reliably cite sources and the
   unpredictable possibility of fabricated information may limit its
   clinical use. (Fertil Sterile 2023;120:575-83. (c) 2023 by American
   Society for Reproductive Medicine.)
ZR 0
ZB 7
ZS 0
ZA 0
TC 47
Z8 1
Z9 48
DA 2023-11-11
UT WOS:001093006600001
PM 37217092
ER

PT J
AU Meyer, Bastian
   Kfuri-Rubens, Raphael
   Schmidt, Georg
   Tariq, Maliha
   Riedel, Caroline
   Recker, Florian
   Riedel, Fabian
   Kiechle, Marion
   Riedel, Maximilian
TI Exploring the potential of AI-powered applications for clinical
   decision-making in gynecologic oncology.
SO International journal of gynaecology and obstetrics: the official organ
   of the International Federation of Gynaecology and Obstetrics
DI 10.1002/ijgo.70251
DT Journal Article
PD 2025-Jun-13
PY 2025
AB OBJECTIVE: The rise of artificial intelligence (AI) and large language
   models like Llama, Gemini, or Generative Pretraining Transformer (GPT)
   signals a promising new era in natural language processing and has
   significant potential for application in medical care. This study seeks
   to investigate the potential of GPT-4 for automated therapy
   recommendations by examining individual patient health record data with
   a focus on gynecologic malignancies and breast cancer.
   METHODS: We tasked GPT-4 with generating independent treatment proposals
   for 60 randomly selected patient cases presented at gynecologic and
   senologic multidisciplinary tumor boards (MDTs). The treatment
   recommendations by GPT-4 were compared with those of the MDTs using a
   novel clinical concordance score and were reviewed both qualitatively
   and quantitatively by experienced gynecologic oncologists.
   RESULTS: GPT-4 generated coherent therapeutic recommendations for all
   clinical cases. Overall, these recommendations were assessed by clinical
   experts as moderately sufficient for real-word clinical application.
   Deficiencies in both accuracy and completeness were especially noted.
   Using a quantitative clinical concordance score, GPT-4 consistently
   demonstrated superior performance in managing the senologic cases
   compared with the gynecologic cases. Iterative prompting substantially
   enhanced treatment recommendations in both categories, increasing
   concordance with MDT decisions to up to 84% in senologic cases.
   CONCLUSION: GPT-4 is capable of processing complex patient cases and
   generates detailed treatment recommendations; however, differences
   persist in surgical approaches and the use of systemic therapies, and
   there is a tendency toward recommending excessive genetic testing. As
   AI-powered solutions continue to be integrated into medicine, we
   envision the potential for automated therapy recommendations to play a
   supportive role in human clinical decision-making in the future.
Z8 0
TC 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 0
DA 2025-06-15
UT MEDLINE:40512143
PM 40512143
ER

PT J
AU Wang, Calvin
   Ong, Joshua
   Wang, Chara
   Ong, Hannah
   Cheng, Rebekah
   Ong, Dennis
TI Potential for GPT Technology to Optimize Future Clinical Decision-Making
   Using Retrieval-Augmented Generation
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 5
BP 1115
EP 1118
DI 10.1007/s10439-023-03327-6
EA AUG 2023
DT Letter
PD MAY 2024
PY 2024
AB Advancements in artificial intelligence (AI) provide many helpful tools
   for healthcare, one of which includes AI chatbots that use natural
   language processing to create humanlike, conversational dialog. These
   chatbots have general cognitive skills and are able to engage with
   clinicians and patients to discuss patients' health conditions and what
   they may be at risk for. While chatbot engines have access to a wide
   range of medical texts and research papers, they currently provide
   high-level, generic responses and are limited in their ability to
   provide diagnostic guidance and clinical advice to patients on an
   individual level. The essay discusses the use of retrieval-augmented
   generation (RAG), which can be used to improve the specificity of
   user-entered prompts and thereby enhance the detail in AI chatbot
   responses. By embedding more recent clinical data and trusted medical
   sources, such as clinical guidelines, into the chatbot models, AI
   chatbots can provide more patient-specific guidance, faster diagnoses
   and treatment recommendations, and greater improvement of patient
   outcomes.
ZA 0
TC 27
ZS 0
ZR 0
ZB 5
Z8 0
Z9 27
DA 2023-08-17
UT WOS:001041791700003
PM 37530906
ER

PT J
AU Yeo, Yee Hui
   Samaan, Jamil S.
   Ng, Wee Han
   Ting, Peng-Sheng
   Trivedi, Hirsh
   Vipani, Aarshi
   Ayoub, Walid
   Yang, Ju Dong
   Liran, Omer
   Spiegel, Brennan
   Kuo, Alexander
TI Assessing the performance of ChatGPT in answer- ing questions regarding
   cirrhosis and hepatocellu- lar carcinoma
SO CLINICAL AND MOLECULAR HEPATOLOGY
VL 29
IS 3
BP 721
EP 732
DI 10.3350/cmh.2023.0089
DT Article
PD JUL 2023
PY 2023
AB Background/Aims: Patients with cirrhosis and hepatocellular carcinoma
   (HCC) require extensive and personalized care to improve outcomes.
   ChatGPT (Generative Pre-trained Transformer), a large language model,
   holds the potential to provide professional yet patient-friendly
   support. We aimed to examine the accuracy and reproducibility of ChatGPT
   in answering questions regarding knowledge, management, and emotional
   support for cirrhosis and HCC. Methods: ChatGPT's responses to 164
   questions were independently graded by two transplant hepatologists and
   resolved by a third reviewer. The performance of ChatGPT was also
   assessed using two published questionnaires and 26 questions formulated
   from the quality measures of cirrhosis management. Finally, its
   emotional support capacity was tested. Results: We showed that ChatGPT
   regurgitated extensive knowledge of cirrhosis (79.1% correct) and HCC
   (74.0% cor-rect), but only small proportions (47.3% in cirrhosis, 41.1%
   in HCC) were labeled as comprehensive. The performance was better in
   basic knowledge, lifestyle, and treatment than in the domains of
   diagnosis and preventive medicine. For the quality measures, the model
   answered 76.9% of questions correctly but failed to specify
   decision-making cut-off s and treatment durations. ChatGPT lacked
   knowledge of regional guidelines variations, such as HCC screening
   criteria. How-ever, it provided practical and multifaceted advice to
   patients and caregivers regarding the next steps and adjusting to a new
   diagnosis. Conclusions: We analyzed the areas of robustness and
   limitations of ChatGPT's responses on the management of cirrhosis and
   HCC and relevant emotional support. ChatGPT may have a role as an
   adjunct informational tool for patients and physicians to improve
   outcomes. (Clin Mol Hepatol 2023;29:721-732)
ZS 1
Z8 6
ZR 0
ZA 0
ZB 60
TC 343
Z9 346
DA 2023-08-26
UT WOS:001042245200002
PM 36946005
ER

PT J
AU Scaff, Simone P. S.
   Reis, Felipe J. J.
   Ferreira, Giovanni E.
   Jacob, Maria Fernanda
   Saragiotto, Bruno T.
TI Assessing the performance of AI chatbots in answering patients' common
   questions about low back pain
SO ANNALS OF THE RHEUMATIC DISEASES
VL 84
IS 1
BP 143
EP 149
DI 10.1136/ard-2024-226202
EA SEP 2024
DT Article
PD JAN 2025
PY 2025
AB Objectives: The aim of this study was to assess the accuracy and
   readability of the answers generated by large language model
   (LLM)-chatbots to common patient questions about low back pain (LBP).
   Methods: This cross-sectional study analysed responses to 30 LBP-related
   questions, covering self-management, risk factors and treatment. The
   questions were developed by experienced clinicians and researchers and
   were piloted with a group of consumer representatives with lived
   experience of LBP. The inquiries were inputted in prompt form into
   ChatGPT 3.5, Bing, Bard (Gemini) and ChatGPT 4.0. Responses were
   evaluated in relation to their accuracy, readability and presence of
   disclaimers about health advice. The accuracy was assessed by comparing
   the recommendations generated with the main guidelines for LBP. The
   responses were analysed by two independent reviewers and classified as
   accurate, inaccurate or unclear. Readability was measured with the
   Flesch Reading Ease Score (FRES). Results: Out of 120 responses yielding
   1069 recommendations, 55.8% were accurate, 42.1% inaccurate and 1.9%
   unclear. Treatment and self-management domains showed the highest
   accuracy while risk factors had the most inaccuracies. Overall,
   LLM-chatbots provided answers that were 'reasonably difficult' to read,
   with a mean (SD) FRES score of 50.94 (3.06). Disclaimer about health
   advice was present around 70%-100% of the responses produced.
   Conclusions: The use of LLM-chatbots as tools for patient education and
   counselling in LBP shows promising but variable results. These chatbots
   generally provide moderately accurate recommendations. However, the
   accuracy may vary depending on the topic of each question. The
   reliability level of the answers was inadequate, potentially affecting
   the patient's ability to comprehend the information.
Z8 0
TC 5
ZB 1
ZR 0
ZS 0
ZA 0
Z9 5
DA 2024-09-30
UT WOS:001319686500001
PM 39874229
ER

PT J
AU Anonymous
TI Meeting of the Anaesthetic-Research-Society, London, UK, May 16 -17,
   2024 
SO British Journal of Anaesthesia
VL 133
IS 2
BP 458
EP 472
DT Meeting
PD AUG 2024
PY 2024
AB This "Abstracts from Anesthetic Research Society Meeting", which focuses
   on different anesthesia treatments to patient during various treatment
   interventions like surgery or other diagnostic or therapeutic
   procedures, contains approximately 23 abstract presentations, written in
   English. Topics include local anaesthetic treatment, cancer surgery,
   perioperative management, cell apoptosis, cell proliferation, general
   anaesthesia, colorectal cancer, quality-of-life, length of hospital
   stay, patient-reported ethnicity, postpartum hemorrhage. Other topics
   include large language model, hallucination, questionnaire,
   perioperative medication advice, proteomic analysis, lung resection,
   cardiac magnetic resonance imaging, extracellular volume, plasma
   protein, lung protective ventilation, conventional ventilation,
   postoperative pulmonary complication, major noncardiac surgery:,
   myocardial inflammation.
CT Meeting of the Anaesthetic-Research-Society
CY May 16 -17, 2024
CL London, UK
HO London, UK
SP Anaesthet Res Soc
Z8 0
TC 0
ZA 0
ZB 0
ZR 0
ZS 0
Z9 0
DA 2024-08-30
UT BCI:BCI202400741698
ER

PT J
AU Ghorbian, Mohsen
   Ghobaei-Arani, Mostafa
   Ghorbian, Saied
TI Transforming breast cancer diagnosis and treatment with large language
   Models: A comprehensive survey
SO METHODS
VL 239
BP 85
EP 110
DI 10.1016/j.ymeth.2025.04.001
EA APR 2025
DT Article
PD JUL 2025
PY 2025
AB Breast cancer (BrCa), being one of the most prevalent forms of cancer in
   women, poses many challenges in the field of treatment and diagnosis due
   to its complex biological mechanisms. Early and accurate diagnosis plays
   a fundamental role in improving survival rates, but the limitations of
   existing imaging methods and clinical data interpretation often prevent
   optimal results. Large Language Models (LLMs), which are developed based
   on advanced architectures such as transformers, have brought about a
   significant revolution in data processing and medical decision-making.
   By analyzing a large volume of medical and clinical data, these models
   enable early diagnosis by identifying patterns in images and medical
   records and provide personalized treatment strategies by integrating
   genetic markers and clinical guidelines. Despite the transformative
   potential of these models, their use in BrCa management faces challenges
   such as data sensitivity, algorithm transparency, ethical
   considerations, and model compatibility with the details of medical
   applications that need to be addressed to achieve reliable results. This
   review systematically reviews the impact of LLMs on BrCa treatment and
   diagnosis. This study's objectives include analyzing the role of LLM
   technology in diagnosing and treating this disease. The findings
   indicate that the application of LLMs has resulted in significant
   improvements in various aspects of BrCa management, such as a 35%
   increase in the Efficiency of Diagnosis and BrCa Treatment (EDBC), a 30%
   enhancement in the System's Clinical Trust and Reliability (SCTR), and a
   20% improvement in the quality of patient education and information
   (IPEI). Ultimately, this study demonstrates the importance of LLMs in
   advancing precision medicine for BrCa and paves the way for effective
   patient-centered care solutions.
ZS 0
ZR 0
TC 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001466448900001
PM 40199412
ER

PT J
AU Gunning, Jordan A.
   Gilman, Kristy E.
   Zuniga, Tiffany M.
   Simpson, Richard J.
   Limesand, Kirsten H.
TI Parotid glands have a dysregulated immune response following radiation
   therapy
SO PLOS ONE
VL 19
IS 3
AR e0297387
DI 10.1371/journal.pone.0297387
DT Article
PD MAR 12 2024
PY 2024
AB Head and neck cancer treatment often consists of surgical resection of
   the tumor followed by ionizing radiation (IR), which can damage
   surrounding tissues and cause adverse side effects. The underlying
   mechanisms of radiation-induced salivary gland dysfunction are not fully
   understood, and treatment options are scarce and ineffective. The wound
   healing process is a necessary response to tissue injury, and broadly
   consists of inflammatory, proliferative, and redifferentiation phases
   with immune cells playing key roles in all three phases. In this study,
   select immune cells were phenotyped and quantified, and certain cytokine
   and chemokine concentrations were measured in mouse parotid glands after
   IR. Further, we used a model where glandular function is restored to
   assess the immune phenotype in a regenerative response. These data
   suggest that irradiated parotid tissue does not progress through a
   typical inflammatory response observed in wounds that heal.
   Specifically, total immune cells (CD45+) decrease at days 2 and 5
   following IR, macrophages (F4/80+CD11b+) decrease at day 2 and 5 and
   increase at day 30, while neutrophils (Ly6G+CD11b+) significantly
   increase at day 30 following IR. Additionally, radiation treatment
   reduces CD3- cells at all time points, significantly increases
   CD3+/CD4+CD8+ double positive cells, and significantly reduces
   CD3+/CD4-CD8- double negative cells at day 30 after IR. Previous data
   indicate that post-IR treatment with IGF-1 restores salivary gland
   function at day 30, and IGF-1 injections attenuate the increase in
   macrophages, neutrophils, and CD4+CD8+ T cells observed at day 30
   following IR. Taken together, these data indicate that parotid salivary
   tissue exhibits a dysregulated immune response following radiation
   treatment which may contribute to chronic loss of function phenotype in
   head and neck cancer survivors.
Z8 0
ZS 0
ZR 0
ZB 1
TC 2
ZA 0
Z9 2
DA 2024-05-02
UT WOS:001192362300028
PM 38470874
ER

PT J
AU Zhu, L.
   Anand, A.
   Gevorkyan, G.
   Mcgee, L. A.
   Rwigema, J. C.
   Rong, Y.
   Patel, S. H.
TI Testing and Validation of a Custom Trained Large Language Model for HN
   Patients with Guardrails
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 118
IS 5
MA 182
BP E52
EP E53
DT Meeting Abstract
PD APR 1 2024
PY 2024
CT Multidisciplinary Head and Neck Cancers Symposium
CY FEB 29-MAR 02, 2024
CL Phoenix, AZ
TC 1
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
Z9 1
DA 2024-10-18
UT WOS:001300212900102
ER

PT C
AU Bandara, Eranga
   Foytik, Peter
   Shetty, Sachin
   Mukkamala, Ravi
   Rahman, Abdul
   Liang, Xueping
   Keon, Ng Wee
   De Zoysa, Kasun
GP IEEE
TI WedaGPT - Generative-AI (with Custom-Trained Meta's Llama2 LLM),
   Blockchain, Self Sovereign Identity, NFT and Model Card Enabled
   Indigenous Medicine Platform
SO 2024 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, ISCC 2024
SE IEEE Symposium on Computers and Communications ISCC
DI 10.1109/ISCC61673.2024.10733674
DT Proceedings Paper
PD 2024
PY 2024
AB Traditional and indigenous medicine, deeply rooted in ancient traditions
   and wisdom, plays a crucial role in global healthcare and cultural
   identity. These practices provide treatments for illnesses such as
   cancer and bone injuries, which often lack effective remedies in Western
   medicine. However, these valuable systems face challenges like potential
   knowledge loss, undervaluation of practitioners' expertise, and the risk
   of fraud due to the absence of credential verification mechanisms. In
   this research, we introduce "WedaGPT," a Generative AI-enabled platform
   that utilizes a custom-trained Meta's Llama2 Large Language Model (LLM),
   Blockchain, self-sovereign identity (SSI), Non-Fungible Tokens (NFTs),
   and model cards to share traditional medical knowledge and address these
   issues. WedaGPT creates a collaborative ecosystem connecting doctors,
   medicine providers, therapists, patients, and technology experts, all
   committed to preserving and advancing traditional healing practices.
   This platform enables secure and transparent contributions from all
   stakeholders to patient well-being. Ancient medical recipe books are
   translated into English and digitized into PDF formats to enrich the
   platform's knowledge base. These texts are used to fine-tune the Llama2
   LLM, which has been quantized and optimized with Qlora for performance
   on consumer-grade hardware. Through a chat-based interface in the
   SSI-enabled mobile wallet, users can interact with the LLM and access
   detailed information on treatments, recipes, prescriptions, and healing
   methods. Additionally, users can consult remotely with doctors who
   prescribe treatments through this wallet. A key feature of WedaGPT is
   transforming ancient medicinal recipes into NFT tokens for sale on NFT
   marketplaces, giving traditional knowledge digital authenticity and
   economic value. Revenue from these sales is distributed among platform
   contributors, promoting equitable ownership and recognition. Medical
   recipe data, including treatment histories and physician details, are
   encapsulated in Model Cards and securely stored on the blockchain. This
   system offers mechanisms to verify doctors and treatments in a
   privacy-preserving way, potentially reducing fraud and medication
   errors.
CT 29th IEEE Symposium on Computers and Communications (IEEE ISCC)
CY JUN 26-29, 2024
CL Paris, FRANCE
SP IEEE
Z8 0
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-01-03
UT WOS:001363176200111
ER

PT J
AU Rajendran, Praveenbalaji
   Chen, Yizheng
   Qiu, Liang
   Niedermayr, Thomas
   Liu, Wu
   Buyyounouski, Mark
   Bagshaw, Hilary
   Han, Bin
   Yang, Yong
   Kovalchuk, Nataliya
   Gu, Xuejun
   Hancock, Steven
   Xing, Lei
   Dai, Xianjin
TI Autodelineation of Treatment Target Volume for Radiation Therapy Using
   Large Language Model-Aided Multimodal Learning
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 121
IS 1
BP 230
EP 240
DI 10.1016/j.ijrobp.2024.07.2149
EA DEC 2024
DT Article
PD JAN 1 2025
PY 2025
AB Purpose: Artificial intelligence-aided methods have made significant
   progress in the auto-delineation of normal tissues. However, these
   approaches struggle with the auto-contouring of radiation therapy target
   volume. Our goal was to model the delineation of target volume as a
   clinical decision-making problem, resolved by leveraging large language
   model-aided multimodal learning approaches. Methods and Materials: A
   vision-language model, termed Medformer, has been developed, employing
   the hierarchical vision transformer as its backbone and incorporating
   large language models to extract text-rich features. The contextually
   embedded linguistic features are seamlessly integrated into visual
   features for language-aware visual encoding through the visual language
   attention module. Metrics, including Dice similarity coefficient (DSC),
   intersection over union (IOU), and 95th percentile Hausdorff distance
   (HD95), were used to quantitatively evaluate the performance of our
   model. The evaluation was conducted on an in-house prostate cancer data
   set and a public oropharyngeal carcinoma data set, totaling 668
   subjects. Results: Our Medformer achieved a DSC of 0.81 f 0.10 versus
   0.72 f 0.10, IOU of 0.73 f 0.12 versus 0.65 f 0.09, and HD95 of 9.86 f
   9.77 mm versus 19.13 f 12.96 mm for delineation of gross tumor volume on
   the prostate cancer dataset. Similarly, on the oropharyngeal carcinoma
   dataset, it achieved a DSC of 0.77 f 0.11 versus 0.72 f 0.09, IOU of
   0.70 f 0.09 versus 0.65 f 0.07, and HD95 of 7.52 f 4.8 mm versus 13.63 f
   7.13 mm, representing significant improvements (P <0.05). For
   delineating the clinical target volume, Medformer achieved a DSC of 0.91
   f 0.04, IOU of 0.85 f 0.05, and HD95 of 2.98 f 1.60 mm, comparable with
   other state-of-the-art algorithms. Conclusions: Auto-delineation of the
   treatment target based on multimodal learning outperforms conventional
   approaches that rely purely on visual features. Our method could be
   adopted into routine practice to rapidly contour clinical target
   volume/gross tumor volume. (c) 2024 Elsevier Inc. All rights are
   reserved, including those for text and data mining, AI training, and
   similar technologies.
ZR 0
TC 3
ZA 0
ZB 0
ZS 0
Z8 0
Z9 3
DA 2025-02-10
UT WOS:001413606000001
PM 39117164
ER

PT J
AU Schmidt, Kurt W.
   Lechner, Fabian
TI ChatGPT: aid to medical ethics decision making?
SO ANAESTHESIOLOGIE
VL 73
IS 3
SI SI
BP 177
EP 185
DI 10.1007/s00101-024-01385-6
DT Review
PD MAR 2024
PY 2024
AB Background: Physicians have to make countless decisions every day. The
   medical, ethical and legal aspects are often intertwined and subject to
   change over time. Involving an ethics committee or arranging an ethical
   consultation are examples of potential aids to decision making. Whether
   and how artificial intelligence (AI) and the large language model (LLM)
   of the company OpenAI (San Francisco, CA, USA), known under the name
   ChatGPT, can also help and support ethical decision making is
   increasingly becoming a matter of controversial debate. Material and
   methods: Based on a case example, in which a female physician is
   confronted with ethical and legal issues and presents these to ChatGPT
   to come up with answers, the first indications of the strengths and
   weaknesses are ascertained. Conclusion: Due to the rapid technical
   development and access to ever increasing quantities of data, the
   utilization should be closely observed and evaluated.
TC 1
ZA 0
ZR 0
ZS 0
ZB 0
Z8 0
Z9 1
DA 2024-10-27
UT WOS:001230024600003
PM 38315183
ER

PT C
AU Oduro-Afriyie, Joel
   Jamil, Hasan M.
GP ACM
TI Enabling the Informed Patient Paradigm with Secure and Personalized
   Medical Question Answering
SO 14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH
   INFORMATICS, BCB 2023
DI 10.1145/3584371.3613016
DT Proceedings Paper
PD 2023
PY 2023
AB Quality patient care is a complex and multifaceted problem requiring the
   integration of data from multiple sources. We propose Medicient, a
   knowledge-graph-based question answering system that processes
   heterogeneous data sources, including patient health records, drug
   databases, and medical literature, into a unified knowledge graph with
   zero training. The knowledge graph is then utilized to provide
   personalized recommendations for treatment or medication. The system
   leverages the power of large language models for question understanding
   and natural language response generation, while hiding sensitive patient
   information. We compare our system to a large language model (ChatGPT),
   which does not have access to patient health records, and show that our
   system provides better recommendations. This study contributes to a
   growing body of research on knowledge graphs and their applications in
   healthcare.
CT 14th ACM Conference on Bioinformatics, Computational Biology, and Health
   Informatics (ACM-BCB)
CY SEP 03-06, 2023
CL Houston, TX
SP Assoc Comp Machinery; ACM Special Interest Grp Bioinformat, Computat
   Biol, & Biomed Informat
ZR 0
ZA 0
Z8 0
TC 2
ZB 0
ZS 0
Z9 3
DA 2024-03-19
UT WOS:001143941200033
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT J
AU Chen, Zikang
   Wang, Qinchuan
   Sun, Yaoqian
   Cai, Hailing
   Lu, Xudong
TI Chat-ePRO: Development and pilot study of an electronic patient-reported
   outcomes system based on ChatGPT
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 154
AR 104651
DI 10.1016/j.jbi.2024.104651
EA MAY 2024
DT Article
PD JUN 2024
PY 2024
AB Objective: Chatbots have the potential to improve user compliance in
   electronic Patient-Reported Outcome (ePRO) system. Compared to
   rule-based chatbots, Large Language Model (LLM) offers advantages such
   as simplifying the development process and increasing conversational
   flexibility. However, there is currently a lack of practical
   applications of LLMs in ePRO systems. Therefore, this study utilized
   ChatGPT to develop the ChatePRO system and designed a pilot study to
   explore the feasibility of building an ePRO system based on LLM.
   Materials and Methods: This study employed prompt engineering and
   offline knowledge distillation to design a dialogue algorithm and built
   the Chat-ePRO system on the WeChat Mini Program platform. In order to
   compare Chat-ePRO with the form-based ePRO and rule-based chatbot ePRO
   used in previous studies, we conducted a pilot study applying the three
   ePRO systems sequentially at the Sir Run Run Shaw Hospital to collect
   patients' PRO data. Result: Chat-ePRO is capable of correctly generating
   conversation based on PRO forms (success rate: 95.7 %) and accurately
   extracting the PRO data instantaneously from conversation (Macro-F1:
   0.95). The majority of subjective evaluations from doctors (>70 %)
   suggest that Chat-ePRO is able to comprehend questions and consistently
   generate responses. Pilot study shows that Chat-ePRO demonstrates higher
   response rate (9/10, 90 %) and longer interaction time (10.86 s/turn)
   compared to the other two methods. Conclusion: Our study demonstrated
   the feasibility of utilizing algorithms such as prompt engineering to
   drive LLM in completing ePRO data collection tasks, and validated that
   the Chat-ePRO system can effectively enhance patient compliance.
Z8 0
ZA 0
ZR 0
ZS 0
TC 1
ZB 0
Z9 1
DA 2024-06-17
UT WOS:001243033900001
PM 38703936
ER

PT J
AU Zarfati, Mor
   Soffer, Shelly
   Nadkarni, Girish N.
   Klang, Eyal
TI Retrieval-Augmented Generation: Advancing personalized care and research
   in oncology
SO EUROPEAN JOURNAL OF CANCER
VL 220
AR 115341
DI 10.1016/j.ejca.2025.115341
EA MAR 2025
DT Article
PD MAY 2 2025
PY 2025
AB Retrieval-Augmented Generation (RAG) pairs large language models (LLMs)
   with recent data to produce more accurate, context-aware outputs. By
   converting text into numeric embeddings, RAG locates and retrieves
   relevant "chunks" of data, that along with the query, ground the model's
   responses in current, specific information. This process helps reduce
   outdated or fabricated answers. In oncology, RAG has shown particular
   promise. Studies have demonstrated its ability to improve treatment
   recommendations by integrating genetic profiles, strengthened clinical
   trial matching through biomarker analysis, and accelerated drug
   development by clarifying modeldriven insights. Despite its advantages,
   RAG depends on high-quality data. Biased or incomplete sources can lead
   to inaccurate outcomes. Careful implementation and human oversight are
   crucial for ensuring the effectiveness and reliability of RAG in
   oncology.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-03-21
UT WOS:001444559600001
PM 40068371
ER

PT J
AU Xiong, Yichun
   Li, Jiaqi
   Jin, Wang
   Sheng, Xiaoran
   Peng, Hui
   Wang, Zhiyi
   Jia, Caifeng
   Zhuo, Lili
   Zhang, Yibo
   Huang, Jingzhe
   Zhai, Modi
   Lyu, Beibei
   Sun, Jie
   Zhou, Meng
TI PCMR: a comprehensive precancerous molecular resource
SO SCIENTIFIC DATA
VL 12
IS 1
AR 551
DI 10.1038/s41597-025-04899-9
DT Article
PD APR 1 2025
PY 2025
AB Early detection and intervention of precancerous lesions are crucial in
   reducing cancer morbidity and mortality. Comprehensive analysis of
   genomic, transcriptomic, proteomic and epigenomic alterations can
   provide insights into the early stages of carcinogenesis. However, the
   lacke of an integrated, well-curated data resource of molecular
   signatures limits our understanding of precancerous processes. Here, we
   introduce a comprehensive PreCancerous Molecular Resource (PCMR), which
   compiles 25,828 molecular profiles of precancerous samples paired with
   normal or malignant counterparts. These profiles cover precancerous
   lesions of 35 cancer types across 20 organs and tissues, derived from
   tissue samples, liquid biopsies, cell lines and organoids, with data
   from transcriptomics, proteomics and epigenomics. PCMR includes 62,566
   precancer-gene associations derived from differential analysis and
   text-mining using the ChatGPT large language model. We examined PCMR
   dataset reliability and significance by the authoritative precancerous
   molecular signature, along with its biological and clinical relevance.
   Overall, PCMR will serve as a valuable resource for advancing precancer
   research and ultimately improving patient outcomes.
ZR 0
ZB 0
ZS 0
ZA 0
Z8 0
TC 0
Z9 0
DA 2025-04-11
UT WOS:001459759400009
PM 40169679
ER

PT J
AU Giuffre, Mauro
   Shung, Dennis
TI INTERACTIVE CLINICAL GUIDELINES WITH LARGE LANGUAGE MODELS: THE GUTGPT
   SERIES ON AMERICAN GASTROENTEROLOGY ASSOCIATION GUIDELINES
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1987
BP S892
EP S893
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
Z8 0
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z9 0
DA 2024-10-30
UT WOS:001282837703488
ER

PT C
AU Shi, Wenqi
   Zhuang, Yuchen
   Zhu, Yuanda
   Iwinski, Henry J.
   Wattenbarger, J. Michael
   Wang, May D.
GP ACM
TI Retrieval-Augmented Large Language Models for Adolescent Idiopathic
   Scoliosis Patients in Shared Decision-Making
SO 14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH
   INFORMATICS, BCB 2023
DI 10.1145/3584371.3612956
DT Proceedings Paper
PD 2023
PY 2023
AB As health-related decision-making evolves, patients increasingly seek
   help from additional online resources such as "Dr. Google" and ChatGPT.
   Despite their potential, these tools encounter limitations, including
   the risk of potentially inaccurate information, a lack of specialized
   medical knowledge, the risk of generating unrealistic outputs
   (hallucinations), and significant computational demands. In this study,
   we develop and validate an innovative shared decision-making (SDM) tool,
   Chat-Orthopedist, for adolescent idiopathic scoliosis (AIS) patients and
   families to prepare a meaningful discussion with clinicians based on
   retrieval-augmented large language models. Firstly, we establish an
   external knowledge base with information on AIS disease and treatment
   options. Secondly, we develop a retrieval-augmented ChatGPT to feed LLMs
   with AIS domain knowledge, providing accurate and comprehensible
   responses to patient inquiries. In addition, we perform a cyclical
   process of human-in-the-loop evaluations for system validation and
   improvement. Chat-Orthopedist may optimize SDM workflow by enabling
   better interactive learning experiences, more effective clinical visits,
   and better-informed treatment decision-making.
CT 14th ACM Conference on Bioinformatics, Computational Biology, and Health
   Informatics (ACM-BCB)
CY SEP 03-06, 2023
CL Houston, TX
SP Assoc Comp Machinery; ACM Special Interest Grp Bioinformat, Computat
   Biol, & Biomed Informat
TC 9
Z8 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 9
DA 2024-03-19
UT WOS:001143941200014
ER

PT J
AU Marchi, Filippo
   Bellini, Elisa
   Iandelli, Andrea
   Sampieri, Claudio
   Peretti, Giorgio
TI Exploring the landscape of AI-assisted decision-making in head and neck
   cancer treatment: a comparative analysis of NCCN guidelines and ChatGPT
   responses
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 2123
EP 2136
DI 10.1007/s00405-024-08525-z
EA FEB 2024
DT Article
PD APR 2024
PY 2024
AB PurposeRecent breakthroughs in natural language processing and machine
   learning, exemplified by ChatGPT, have spurred a paradigm shift in
   healthcare. Released by OpenAI in November 2022, ChatGPT rapidly gained
   global attention. Trained on massive text datasets, this large language
   model holds immense potential to revolutionize healthcare. However,
   existing literature often overlooks the need for rigorous validation and
   real-world applicability.MethodsThis head-to-head comparative study
   assesses ChatGPT's capabilities in providing therapeutic recommendations
   for head and neck cancers. Simulating every NCCN Guidelines scenarios.
   ChatGPT is queried on primary treatments, adjuvant treatment, and
   follow-up, with responses compared to the NCCN Guidelines. Performance
   metrics, including sensitivity, specificity, and F1 score, are employed
   for assessment.ResultsThe study includes 68 hypothetical cases and 204
   clinical scenarios. ChatGPT exhibits promising capabilities in
   addressing NCCN-related queries, achieving high sensitivity and overall
   accuracy across primary treatment, adjuvant treatment, and follow-up.
   The study's metrics showcase robustness in providing relevant
   suggestions. However, a few inaccuracies are noted, especially in
   primary treatment scenarios.ConclusionOur study highlights the
   proficiency of ChatGPT in providing treatment suggestions. The model's
   alignment with the NCCN Guidelines sets the stage for a nuanced
   exploration of AI's evolving role in oncological decision support.
   However, challenges related to the interpretability of AI in clinical
   decision-making and the importance of clinicians understanding the
   underlying principles of AI models remain unexplored. As AI continues to
   advance, collaborative efforts between models and medical experts are
   deemed essential for unlocking new frontiers in personalized cancer
   care.
ZB 4
ZA 0
TC 18
Z8 0
ZR 0
ZS 0
Z9 18
DA 2024-04-24
UT WOS:001172712200001
PM 38421392
ER

PT J
AU Warren, Christopher J.
   Payne, Nicolette G.
   Edmonds, Victoria S.
   Voleti, Sandeep S.
   Choudry, Mouneeb M.
   Punjani, Nahid
   Abdul-Muhsin, Haider M.
   Humphreys, Mitchell R.
TI Quality of Chatbot Information Related to Benign Prostatic Hyperplasia
SO PROSTATE
VL 85
IS 2
BP 175
EP 180
DI 10.1002/pros.24814
EA NOV 2024
DT Article
PD FEB 2025
PY 2025
AB Background: Large language model (LLM) chatbots, a form of artificial
   intelligence (AI) that excels at prompt-based interactions and mimics
   human conversation, have emerged as a tool for providing patients with
   information about urologic conditions. We aimed to examine the quality
   of information related to benign prostatic hyperplasia surgery from four
   chatbots and how they would respond to sample patient messages. Methods:
   We identified the top three queries in Google Trends related to
   "treatment for enlarged prostate." These were entered into ChatGPT
   (OpenAI), Bard (Google), Bing AI (Microsoft), and Doximity GPT
   (Doximity), both unprompted and prompted for specific criteria
   (optimized). The chatbot-provided answers to each query were evaluated
   for overall quality by three urologists using the DISCERN instrument.
   Readability was measured with the built-in Flesch-Kincaid reading level
   tool in Microsoft Word. To assess the ability of chatbots to answer
   patient questions, we prompted the chatbots with a clinical scenario
   related to holmium laser enucleation of the prostate, followed by 10
   questions that the National Institutes of Health recommends patients ask
   before surgery. Accuracy and completeness of responses were graded with
   Likert scales. Results: Without prompting, the quality of information
   was moderate across all chatbots but improved significantly with
   prompting (mean [SD], 3.3 [1.2] vs. 4.4 [0.7] out of 5; p < 0.001). When
   answering simulated patient messages, the chatbots were accurate (mean
   [SD], 5.6 [0.4] out of 6) and complete (mean [SD], 2.8 [0.3] out of 3).
   Additionally, 98% (39/40) had a median score of 5 or higher for
   accuracy, which corresponds to "nearly all correct." The readability was
   poor, with a mean (SD) Flesch-Kincaid reading level grade of 12.1 (1.3)
   (unprompted). Conclusions: LLM chatbots hold promise for patient
   education, but their effectiveness is limited by the need for careful
   prompting from the user and by responding at a reading level higher than
   that of most Americans (grade 8). Educating patients and physicians on
   optimal LLM interaction is crucial to unlock the full potential of
   chatbots.
ZB 0
ZA 0
ZR 0
ZS 0
TC 3
Z8 0
Z9 3
DA 2024-11-23
UT WOS:001355317000001
PM 39513562
ER

PT J
AU Essis, Maritza Diane
   Hartman, Hayden
   Tung, Wei Shao
   Oh, Irvin
   Peden, Sean
   Gianakos, Arianna L
TI Comparison of ChatGPT's Diagnostic and Management Accuracy of Foot and
   Ankle Bone-Related Pathologies to Orthopaedic Surgeons.
SO The Journal of the American Academy of Orthopaedic Surgeons
DI 10.5435/JAAOS-D-24-01049
DT Journal Article
PD 2025-Apr-10
PY 2025
AB INTRODUCTION: The steep rise in utilization of large language model
   chatbots, such as ChatGPT, has spilled into medicine in recent years.
   The newest version of ChatGPT, ChatGPT-4, has passed medical licensure
   examinations and, specifically in orthopaedics, has performed at the
   level of a postgraduate level three orthopaedic surgery resident on the
   Orthopaedic In-Service Training Examination question bank sets. The
   purpose of this study was to evaluate ChatGPT-4's diagnostic and
   decision-making capacity in the clinical management of bone-related
   injuries of the foot and ankle.
   METHODS: Eight bone-related foot and ankle orthopaedic cases were
   presented to ChatGPT-4 and subsequently evaluated by three
   fellowship-trained foot and ankle orthopaedic surgeons. Cases were
   scored using criteria on a Likert scale, graded from a total score of 5
   (lowest) to 25 (highest) across five criteria. ChatGPT-4 was referred to
   as "Dr. GPT," establishing a peer dynamic so that the role of an
   orthopaedic surgeon was emulated by the chatbot.
   RESULTS: The average score across all criteria for each case was 4.53 of
   5, noting an overall average sum score of 22.7 of 25 for all cases. The
   pathology with the highest score was the second metatarsal stress
   fracture (24.3), whereas the case with the lowest score was hallux
   rigidus (21.3). Kendall correlation analysis of interrater reliability
   showed variable correlation among surgeons, without statistical
   significance.
   CONCLUSION: ChatGPT-4 effectively diagnosed and provided appropriate
   treatment options for simple bone-related foot and ankle cases.
   Importantly, ChatGPT did not fabricate treatment options (ie,
   hallucination phenomenon), which has been previously well-documented in
   the literature, notably receiving its second-highest overall average
   score in this criterion. ChatGPT struggled to provide comprehensive
   information beyond standard treatment options. Overall, ChatGPT has the
   potential to serve as a widely accessible resource for patients and
   nonorthopaedic clinicians, although limitations may exist in the
   delivery of comprehensive information.
ZB 0
TC 0
Z8 0
ZA 0
ZS 0
ZR 0
Z9 0
DA 2025-04-18
UT MEDLINE:40233367
PM 40233367
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik Y.
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on the Ocular Hypertension Treatment Study
   Dataset Using Chat Generative Pre-Trained Transformer as a Large
   Language Model
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100599
DI 10.1016/j.xops.2024.100599
EA SEP 2024
DT Article
PD JAN-FEB 2025
PY 2025
AB Purpose: To evaluate the capabilities of Chat Generative Pre-Trained
   Transformer (ChatGPT), as a large language model (LLM), for diagnosing
   glaucoma using the Ocular Hypertension Treatment Study (OHTS) dataset,
   and comparing the diagnostic capability of ChatGPT 3.5 and ChatGPT 4.0.
   Design: Prospective data collection study. Participants: A total of 3170
   eyes of 1585 subjects from the OHTS were included in this study.
   Methods: We selected demographic, clinical, ocular, visual field, optic
   nerve head photo, and history of disease parameters of each participant
   and developed case reports by converting tabular data into textual
   format based on information from both eyes of all subjects. We then
   developed a procedure using the application programming interface of
   ChatGPT, a LLM-based chatbot, to automatically input prompts into a chat
   box. This was followed by querying 2 different generations of ChatGPT
   (versions 3.5 and 4.0) regarding the underlying diagnosis of each
   subject. We then evaluated the output responses based on several
   objective metrics. Main Outcome Measures: Area under the receiver
   operating characteristic curve (AUC), accuracy, specificity,
   sensitivity, and F1 score. Results: Chat Generative Pre-Trained
   Transformer 3.5 achieved AUC of 0.74, accuracy of 66%, specificity of
   64%, sensitivity of 85%, and F1 score of 0.72. Chat Generative
   Pre-Trained Transformer 4.0 obtained AUC of 0.76, accuracy of 87%,
   specificity of 90%, sensitivity of 61%, and F1 score of 0.92.
   Conclusions: The accuracy of ChatGPT 4.0 in diagnosing glaucoma based on
   input data from OHTS was promising. The overall accuracy of ChatGPT 4.0
   was higher than ChatGPT 3.5. However, ChatGPT 3.5 was found to be more
   sensitive than ChatGPT 4.0. In its current forms, ChatGPT may serve as a
   useful tool in exploring disease status of ocular hypertensive eyes when
   specific data are available for analysis. In the future, leveraging LLMs
   with multimodal capabilities, allowing for integration of imaging and
   diagnostic testing as part of the analyses, could further enhance
   diagnostic capabilities and enhance diagnostic accuracy. Financial
   Disclosures: Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100599 (c) 2024 by the American Academy of Ophthalmology.
   This is an open access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-ncnd/4.0/).
ZR 0
ZB 0
ZA 0
Z8 0
TC 3
ZS 0
Z9 3
DA 2024-10-16
UT WOS:001330416200001
PM 39346574
ER

PT J
AU Mora, J.
   Chen, S.
   Mak, R. H.
   Bitterman, D. S.
TI Cancer Treatment Information Differences by Bilingual Prompting in Large
   Language Model Chatbots
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3415
BP E645
EP E646
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001325892302096
ER

PT J
AU Muntean, George Adrian
   Marginean, Anca
   Groza, Adrian
   Damian, Ioana
   Roman, Sara Alexia
   Hapca, Madalina Claudia
   Sere, Anca Madalina
   Manoiu, Roxana Mihaela
   Muntean, Maximilian Vlad
   Nicoara, Simona Delia
TI A Qualitative Evaluation of ChatGPT4 and PaLM2's Response to Patient's
   Questions Regarding Age-Related Macular Degeneration
SO DIAGNOSTICS
VL 14
IS 14
AR 1468
DI 10.3390/diagnostics14141468
DT Article
PD JUL 2024
PY 2024
AB Patient compliance in chronic illnesses is essential for disease
   management. This also applies to age-related macular degeneration (AMD),
   a chronic acquired retinal degeneration that needs constant monitoring
   and patient cooperation. Therefore, patients with AMD can benefit by
   being properly informed about their disease, regardless of the
   condition's stage. Information is essential in keeping them compliant
   with lifestyle changes, regular monitoring, and treatment. Large
   language models have shown potential in numerous fields, including
   medicine, with remarkable use cases. In this paper, we wanted to assess
   the capacity of two large language models (LLMs), ChatGPT4 and PaLM2, to
   offer advice to questions frequently asked by patients with AMD. After
   searching on AMD-patient-dedicated websites for frequently asked
   questions, we curated and selected a number of 143 questions. The
   questions were then transformed into scenarios that were answered by
   ChatGPT4, PaLM2, and three ophthalmologists. Afterwards, the answers
   provided by the two LLMs to a set of 133 questions were evaluated by two
   ophthalmologists, who graded each answer on a five-point Likert scale.
   The models were evaluated based on six qualitative criteria: (C1)
   reflects clinical and scientific consensus, (C2) likelihood of possible
   harm, (C3) evidence of correct reasoning, (C4) evidence of correct
   comprehension, (C5) evidence of correct retrieval, and (C6) missing
   content. Out of 133 questions, ChatGPT4 received a score of five from
   both reviewers to 118 questions (88.72%) for C1, to 130 (97.74%) for C2,
   to 131 (98.50%) for C3, to 133 (100%) for C4, to 132 (99.25%) for C5,
   and to 122 (91.73%) for C6, while PaLM2 to 81 questions (60.90%) for C1,
   to 114 (85.71%) for C2, to 115 (86.47%) for C3, to 124 (93.23%) for C4,
   to 113 (84.97%) for C5, and to 93 (69.92%) for C6. Despite the overall
   high performance, there were answers that are incomplete or inaccurate,
   and the paper explores the type of errors produced by these LLMs. Our
   study reveals that ChatGPT4 and PaLM2 are valuable instruments for
   patient information and education; however, since there are still some
   limitations to these models, for proper information, they should be used
   in addition to the advice provided by the physicians.
ZA 0
ZR 0
TC 1
ZS 0
ZB 0
Z8 0
Z9 1
DA 2024-08-01
UT WOS:001276597300001
PM 39061606
ER

PT J
AU Hermann, Catherine E.
   Patel, Jharna M.
   Boyd, Leslie
   Aviki, Emeline
   Stasenko, Marina
TI Let's chat about cervical cancer: Assessing the accuracy of ChatGPT
   responses to cervical cancer questions
SO GYNECOLOGIC ONCOLOGY
VL 179
BP 164
EP 168
DI 10.1016/j.ygyno.2023.11.008
EA NOV 2023
DT Article
PD DEC 2023
PY 2023
AB Objective. To quantify the accuracy of ChatGPT in answering commonly
   asked questions pertaining to cervical cancer prevention, diagnosis,
   treatment, and survivorship/quality-of-life (QOL). Methods. ChatGPT was
   queried with 64 questions adapted from professional society websites and
   the au-thors' clinical experiences. The answers were scored by two
   attending Gynecologic Oncologists according to the following scale: 1)
   correct and comprehensive, 2) correct but not comprehensive, 3) some
   correct, some in-correct, and 4) completely incorrect. Scoring
   discrepancies were resolved by additional reviewers as needed. The
   proportion of responses earning each score were calculated overall and
   within each question category.Results. ChatGPT provided correct and
   comprehensive answers to 34 (53.1%) questions, correct but not
   com-prehensive answers to 19 (29.7%) questions, partially incorrect
   answers to 10 (15.6%) questions, and completely incorrect answers to 1
   (1.6%) question. Prevention and survivorship/QOL had the highest
   proportion of "correct" scores (scores of 1 or 2) at 22/24 (91.7%) and
   15/16 (93.8%), respectively. ChatGPT performed less well in the
   treatment category, with 15/21 (71.4%) correct scores. It performed the
   worst in the diagnosis category with only 1/3 (33.3%) correct
   scores.Conclusion. ChatGPT accurately answers questions about cervical
   cancer prevention, survivorship, and QOL. It performs less accurately
   for cervical cancer diagnosis and treatment. Further development of this
   immensely popular large language model should include physician input
   before it can be utilized as a tool for Gynecologists or recommended as
   a patient resource for information on cervical cancer diagnosis and
   treatment.(c) 2023 Elsevier Inc. All rights reserved.
TC 21
ZR 0
ZA 0
Z8 0
ZB 6
ZS 0
Z9 21
DA 2023-12-23
UT WOS:001122497400001
PM 37988948
ER

PT J
AU Rajendran, Praveenbalaji
   Yang, Yong
   Niedermayr, Thomas R.
   Gensheimer, Michael
   Beadle, Beth
   Le, Quynh-Thu
   Xing, Lei
   Dai, Xianjin
TI Large language model-augmented learning for auto-delineation of
   treatment targets in head-and-neck cancer radiotherapy
SO RADIOTHERAPY AND ONCOLOGY
VL 205
AR 110740
DI 10.1016/j.radonc.2025.110740
EA JAN 2025
DT Article
PD APR 2025
PY 2025
AB Background and Purpose: Radiation therapy (RT) is highly effective, but
   its success depends on accurate, manual target delineation, which is
   time-consuming, labor-intensive, and prone to variability. Despite AI
   advancements in auto-contouring normal tissues, accurate RT target
   volume delineation remains challenging. This study presents Radformer, a
   novel visual language model that integrates text-rich clinical data with
   medical imaging for accurate automated RT target volume delineation.
   Materials and Methods: We developed Radformer, an innovative network
   that utilizes a hierarchical vision transformer as its backbone and
   integrates large language models (LLMs) to extract and embed clinical
   data in text-rich form. The model features a novel visual language
   attention module (VLAM) to combine visual and linguistic features,
   enabling language-aware visual encoding (LAVE). The Radformer was
   evaluated on a dataset of 2985 patients with head-and-neck cancer who
   underwent RT. Quantitative evaluations were performed utilizing metrics
   such as the Dice similarity coefficient (DSC), intersection over union
   (IOU), and 95th percentile Hausdorff distance (HD95). Results: The
   Radformer demonstrated superior performance in segmenting RT target
   volumes compared to stateof-the-art models. On the head-and-neck cancer
   dataset, Radformer achieved a mean DSC of 0.76 f 0.09 versus 0.66 f
   0.09, a mean IOU of 0.69 f 0.08 versus 0.59 f 0.07, and a mean HD95 of
   7.82 f 6.87 mm versus 14.28 f 6.85 mm for gross tumor volume
   delineation, compared to the baseline 3D-UNETR. Conclusions: The
   Radformer model offers a clinically optimal means of RT target
   auto-delineation by integrating both imaging and clinical data through a
   visual language model. This approach improves the accuracy of RT target
   volume delineation, facilitating broader AI-assisted automation in RT
   treatment planning.
TC 1
ZR 0
ZA 0
Z8 0
ZS 0
ZB 0
Z9 1
DA 2025-03-06
UT WOS:001433650900001
PM 39855601
ER

PT J
AU Dai, Jiayi
   Kim, Mi-Young
   Sutton, Reed T.
   Mitchell, Joseph R.
   Goebel, Randolph G.
   Baumgart, Daniel C.
TI DEVELOPMENT OF IBDBERT - NATURAL LANGUAGE PROCESSING ANALYSIS OF CROHN'S
   DISEASE COMPUTED TOMOGRAPHY ENTEROGRAPHY (CTE) REPORTS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Sa2032
BP S612
EP S612
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZR 0
TC 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837702379
ER

PT J
AU Li, Xingyu
   Peng, Lu
   Wang, Yu-Ping
   Zhang, Weihua
TI Open challenges and opportunities in federated foundation models towards
   biomedical healthcare
SO BIODATA MINING
VL 18
IS 1
AR 2
DI 10.1186/s13040-024-00414-9
DT Review
PD JAN 4 2025
PY 2025
AB This survey explores the transformative impact of foundation models
   (FMs) in artificial intelligence, focusing on their integration with
   federated learning (FL) in biomedical research. Foundation models such
   as ChatGPT, LLaMa, and CLIP, which are trained on vast datasets through
   methods including unsupervised pretraining, self-supervised learning,
   instructed fine-tuning, and reinforcement learning from human feedback,
   represent significant advancements in machine learning. These models,
   with their ability to generate coherent text and realistic images, are
   crucial for biomedical applications that require processing diverse data
   forms such as clinical reports, diagnostic images, and multimodal
   patient interactions. The incorporation of FL with these sophisticated
   models presents a promising strategy to harness their analytical power
   while safeguarding the privacy of sensitive medical data. This approach
   not only enhances the capabilities of FMs in medical diagnostics and
   personalized treatment but also addresses critical concerns about data
   privacy and security in healthcare. This survey reviews the current
   applications of FMs in federated settings, underscores the challenges,
   and identifies future research directions including scaling FMs,
   managing data diversity, and enhancing communication efficiency within
   FL frameworks. The objective is to encourage further research into the
   combined potential of FMs and FL, laying the groundwork for healthcare
   innovations.
ZB 1
ZR 0
TC 2
ZA 0
Z8 0
ZS 0
Z9 2
DA 2025-01-09
UT WOS:001389407500001
PM 39755653
ER

PT J
AU Griewing, Sebastian
   Lechner, Fabian
   Gremke, Niklas
   Lukac, Stefan
   Janni, Wolfgang
   Wallwiener, Markus
   Wagner, Uwe
   Hirsch, Martin
   Kuhn, Sebastian
TI Proof-of-concept study of a small language model chatbot for breast
   cancer decision support - a transparent, source-controlled, explainable
   and data-secure approach
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 10
AR 451
DI 10.1007/s00432-024-05964-3
DT Article
PD OCT 9 2024
PY 2024
AB Purpose Large language models (LLM) show potential for decision support
   in breast cancer care. Their use in clinical care is currently
   prohibited by lack of control over sources used for decision-making,
   explainability of the decision-making process and health data security
   issues. Recent development of Small Language Models (SLM) is discussed
   to address these challenges. This preclinical proof-of-concept study
   tailors an open-source SLM to the German breast cancer guideline
   (BC-SLM) to evaluate initial clinical accuracy and technical
   functionality in a preclinical simulation. Methods A multidisciplinary
   tumor board (MTB) is used as the gold-standard to assess the initial
   clinical accuracy in terms of concordance of the BC-SLM with MTB and
   comparing it to two publicly available LLM, ChatGPT3.5 and 4. The study
   includes 20 fictional patient profiles and recommendations for 5
   treatment modalities, resulting in 100 binary treatment recommendations
   (recommended or not recommended). Statistical evaluation includes
   concordance with MTB in % including Cohen's Kappa statistic (kappa).
   Technical functionality is assessed qualitatively in terms of local
   hosting, adherence to the guideline and information retrieval. Results
   The overall concordance amounts to 86% for BC-SLM (kappa = 0.721, p <
   0.001), 90% for ChatGPT4 (kappa = 0.820, p < 0.001) and 83% for
   ChatGPT3.5 (kappa = 0.661, p < 0.001). Specific concordance for each
   treatment modality ranges from 65 to 100% for BC-SLM, 85-100% for
   ChatGPT4, and 55-95% for ChatGPT3.5. The BC-SLM is locally functional,
   adheres to the standards of the German breast cancer guideline and
   provides referenced sections for its decision-making. Conclusion The
   tailored BC-SLM shows initial clinical accuracy and technical
   functionality, with concordance to the MTB that is comparable to
   publicly-available LLMs like ChatGPT4 and 3.5. This serves as a
   proof-of-concept for adapting a SLM to an oncological disease and its
   guideline to address prevailing issues with LLM by ensuring decision
   transparency, explainability, source control, and data security, which
   represents a necessary step towards clinical validation and safe use of
   language models in clinical oncology.
ZR 0
ZA 0
Z8 0
TC 1
ZB 1
ZS 0
Z9 1
DA 2024-10-24
UT WOS:001335902900001
PM 39382778
ER

PT J
AU Hu, Chuanbo
   Li, Wenqi
   Ruan, Mindi
   Yu, Xiangxu
   Paul, Lynn K
   Wang, Shuo
   Li, Xin
TI Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders
   and Identifying Distinct Features.
SO Research square
DI 10.21203/rs.3.rs-4359726/v1
DT Journal Article; Preprint
PD 2024 May 21
PY 2024
AB Diagnosing language disorders associated with autism is a complex and
   nuanced challenge, often hindered by the subjective nature and
   variability of traditional assessment methods. Traditional diagnostic
   methods not only require intensive human effort but also often result in
   delayed interventions due to their lack of speed and specificity. In
   this study, we explored the application of ChatGPT, a state-of-the-art
   large language model, to overcome these obstacles by enhancing
   diagnostic accuracy and profiling specific linguistic features
   indicative of autism. Leveraging ChatGPT's advanced natural language
   processing capabilities, this research aims to streamline and refine the
   diagnostic process. Specifically, we compared ChatGPT's performance with
   that of conventional supervised learning models, including BERT, a model
   acclaimed for its effectiveness in various natural language processing
   tasks. We showed that ChatGPT substantially outperformed these models,
   achieving over 13% improvement in both accuracy and F1-score in a
   zero-shot learning configuration. This marked enhancement highlights the
   model's potential as a superior tool for neurological diagnostics.
   Additionally, we identified ten distinct features of autism-associated
   language disorders that vary significantly across different experimental
   scenarios. These features, which included echolalia, pronoun reversal,
   and atypical language usage, were crucial for accurately diagnosing ASD
   and customizing treatment plans. Together, our findings advocate for
   adopting sophisticated AI tools like ChatGPT in clinical settings to
   assess and diagnose developmental disorders. Our approach not only
   promises greater diagnostic precision but also aligns with the goals of
   personalized medicine, potentially transforming the evaluation landscape
   for autism and similar neurological conditions.
ZR 0
ZS 0
ZA 0
Z8 0
TC 0
ZB 0
Z9 0
DA 2024-06-05
UT MEDLINE:38826194
PM 38826194
ER

PT J
AU Yang, Z.
   Kazemimoghadam, M.
   Wang, L.
   Szalkowski, G. A.
   Chuang, C. F.
   Liu, L.
   Soltys, S. G.
   Pollom, E.
   Rahimy, E.
   Jiang, H.
   Park, D.
   Persad, A.
   Hori, Y.
   Fu, J.
   Romero, I. O.
   Zalavari, L.
   Chen, M.
   Lu, W.
   Gu, X.
TI A Deep Learning-Driven Framework for Large Language Model -Assisted
   Automatic Target Volume Localization and Delineation for Enhancing
   Spinal Metastases Stereotactic Body Radiotherapy Workflow
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 195
BP S61
EP S62
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302564
ER

PT J
AU Ge, Jin
   Sun, Steve
   Owens, Joseph
   Galvez, Victor
   Gologorskaya, Oksana
   Lai, Jennifer C
   Pletcher, Mark J
   Lai, Ki
TI Development of a Liver Disease-Specific Large Language Model Chat
   Interface using Retrieval Augmented Generation.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2023.11.10.23298364
DT Preprint
PD 2023 Nov 10
PY 2023
AB Background: Large language models (LLMs) have significant capabilities
   in clinical information processing tasks. Commercially available LLMs,
   however, are not optimized for clinical uses and are prone to generating
   incorrect or hallucinatory information. Retrieval-augmented generation
   (RAG) is an enterprise architecture that allows embedding of customized
   data into LLMs. This approach "specializes" the LLMs and is thought to
   reduce hallucinations.
   Methods: We developed "LiVersa," a liver disease-specific LLM, by using
   our institution's protected health information (PHI)-complaint text
   embedding and LLM platform, "Versa." We conducted RAG on 30 publicly
   available American Association for the Study of Liver Diseases (AASLD)
   guidelines and guidance documents to be incorporated into LiVersa. We
   evaluated LiVersa's performance by comparing its responses versus those
   of trainees from a previously published knowledge assessment study
   regarding hepatitis B (HBV) treatment and hepatocellular carcinoma (HCC)
   surveillance.
   Results: LiVersa answered all 10 questions correctly when forced to
   provide a "yes" or "no" answer. Full detailed responses with
   justifications and rationales, however, were not completely correct for
   three of the questions.
   Discussions: In this study, we demonstrated the ability to build
   disease-specific and PHI-compliant LLMs using RAG. While our LLM,
   LiVersa, demonstrated more specificity in answering questions related to
   clinical hepatology - there were some knowledge deficiencies due to
   limitations set by the number and types of documents used for RAG. The
   LiVersa prototype, however, is a proof of concept for utilizing RAG to
   customize LLMs for clinical uses and a potential strategy to realize
   personalized medicine in the future.
ZR 0
ZA 0
ZB 2
TC 5
Z8 0
ZS 0
Z9 5
DA 2023-11-22
UT MEDLINE:37986764
PM 37986764
ER

PT J
AU Huang, Yixing
   Gomaa, Ahmed
   Semrau, Sabine
   Haderlein, Marlen
   Lettmaier, Sebastian
   Weissmann, Thomas
   Grigo, Johanna
   Tkhayat, Hassen Ben
   Frey, Benjamin
   Gaipl, Udo
   Distel, Luitpold
   Maier, Andreas
   Fietkau, Rainer
   Bert, Christoph
   Putz, Florian
TI Benchmarking ChatGPT-4 on a radiation oncology in-training exam and Red
   Journal Gray Zone cases: potentials and challenges for ai-assisted
   medical education and decision making in radiation oncology
SO FRONTIERS IN ONCOLOGY
VL 13
AR 1265024
DI 10.3389/fonc.2023.1265024
DT Article
PD SEP 14 2023
PY 2023
AB PurposeThe potential of large language models in medicine for education
   and decision-making purposes has been demonstrated as they have achieved
   decent scores on medical exams such as the United States Medical
   Licensing Exam (USMLE) and the MedQA exam. This work aims to evaluate
   the performance of ChatGPT-4 in the specialized field of radiation
   oncology.MethodsThe 38th American College of Radiology (ACR) radiation
   oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone
   cases are used to benchmark the performance of ChatGPT-4. The TXIT exam
   contains 300 questions covering various topics of radiation oncology.
   The 2022 Gray Zone collection contains 15 complex clinical
   cases.ResultsFor the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved
   the scores of 62.05% and 78.77%, respectively, highlighting the
   advantage of the latest ChatGPT-4 model. Based on the TXIT exam,
   ChatGPT-4's strong and weak areas in radiation oncology are identified
   to some extent. Specifically, ChatGPT-4 demonstrates better knowledge of
   statistics, CNS & eye, pediatrics, biology, and physics than knowledge
   of bone & soft tissue and gynecology, as per the ACR knowledge domain.
   Regarding clinical care paths, ChatGPT-4 performs better in diagnosis,
   prognosis, and toxicity than brachytherapy and dosimetry. It lacks
   proficiency in in-depth details of clinical trials. For the Gray Zone
   cases, ChatGPT-4 is able to suggest a personalized treatment approach to
   each case with high correctness and comprehensiveness. Importantly, it
   provides novel treatment aspects for many cases, which are not suggested
   by any human experts.ConclusionBoth evaluations demonstrate the
   potential of ChatGPT-4 in medical education for the general public and
   cancer patients, as well as the potential to aid clinical
   decision-making, while acknowledging its limitations in certain domains.
   Owing to the risk of hallucinations, it is essential to verify the
   content generated by models such as ChatGPT for accuracy.
ZA 0
ZR 0
TC 56
ZB 10
Z8 0
ZS 1
Z9 56
DA 2023-12-23
UT WOS:001119288400001
PM 37790756
ER

PT J
AU McLean, Aaron Lawson
   Wu, Yonghui
   McLean, Anna C. Lawson
   Hristidis, Vagelis
TI Large language models as decision aids in neuro-oncology: a review of
   shared decision-making applications
SO JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY
VL 150
IS 3
AR 139
DI 10.1007/s00432-024-05673-x
DT Review
PD MAR 19 2024
PY 2024
AB Shared decision-making (SDM) is crucial in neuro-oncology, fostering
   collaborations between patients and healthcare professionals to navigate
   treatment options. However, the complexity of neuro-oncological
   conditions and the cognitive and emotional burdens on patients present
   significant barriers to achieving effective SDM. This discussion
   explores the potential of large language models (LLMs) such as OpenAI's
   ChatGPT and Google's Bard to overcome these barriers, offering a means
   to enhance patient understanding and engagement in their care. LLMs, by
   providing accessible, personalized information, could support but not
   supplant the critical insights of healthcare professionals. The
   hypothesis suggests that patients, better informed through LLMs, may
   participate more actively in their treatment choices. Integrating LLMs
   into neuro-oncology requires navigating ethical considerations,
   including safeguarding patient data and ensuring informed consent,
   alongside the judicious use of AI technologies. Future efforts should
   focus on establishing ethical guidelines, adapting healthcare workflows,
   promoting patient-oriented research, and developing training programs
   for clinicians on the use of LLMs. Continuous evaluation of LLM
   applications will be vital to maintain their effectiveness and alignment
   with patient needs. Ultimately, this exploration contends that the
   thoughtful integration of LLMs into SDM processes could significantly
   enhance patient involvement and strengthen the patient-physician
   relationship in neuro-oncology care.
ZR 0
ZB 1
ZA 0
ZS 0
TC 8
Z8 1
Z9 8
DA 2024-04-01
UT WOS:001187667700003
PM 38503921
ER

PT J
AU Perlis, Roy H.
   Goldberg, Joseph F.
   Ostacher, Michael J.
   Schneck, Christopher D.
TI Clinical decision support for bipolar depression using large language
   models
SO NEUROPSYCHOPHARMACOLOGY
VL 49
IS 9
BP 1412
EP 1416
DI 10.1038/s41386-024-01841-2
EA MAR 2024
DT Article
PD AUG 2024
PY 2024
AB Management of depressive episodes in bipolar disorder remains
   challenging for clinicians despite the availability of treatment
   guidelines. In other contexts, large language models have yielded
   promising results for supporting clinical decisionmaking. We developed
   50 sets of clinical vignettes reflecting bipolar depression and
   presented them to experts in bipolar disorder, who were asked to
   identify 5 optimal next-step pharmacotherapies and 5 poor or
   contraindicated choices. The same vignettes were then presented to a
   large language model (GPT4-turbo; gpt-4-1106-preview), with or without
   augmentation by prompting with recent bipolar treatment guidelines, and
   asked to identify the optimal next-step pharmacotherapy. Overlap between
   model output and gold standard was estimated. The augmented model
   prioritized the expert-designated optimal choice for 508/1000 vignettes
   (50.8%, 95% CI 47.7-53.9%; Cohen's kappa = 0.31, 95% CI 0.28-0.35). For
   120 vignettes (12.0%), at least one model choice was among the poor or
   contraindicated treatments. Results were not meaningfully different when
   gender or race of the vignette was permuted to examine risk for bias. By
   comparison, an un-augmented model identified the optimal treatment for
   234 (23.0%, 95% CI 20.8-26.0%; McNemar's p < 0.001 versus augmented
   model) of the vignettes. A sample of community clinicians scoring the
   same vignettes identified the optimal choice for 23.1% (95% CI
   15.7-30.5%) of vignettes, on average; McNemar's p < 0.001 versus
   augmented model. Large language models prompted with evidence-based
   guidelines represent a promising, scalable strategy for clinical
   decision support. In addition to prospective studies of efficacy,
   strategies to avoid clinician overreliance on such models, and address
   the possibility of bias, will be needed.
TC 10
ZB 1
Z8 0
ZS 0
ZR 0
ZA 0
Z9 10
DA 2024-03-28
UT WOS:001182357900004
PM 38480911
ER

PT J
AU Huang, Andy S.
   Hirabayashi, Kyle
   Barna, Laura
   Parikh, Deep
   Pasquale, Louis R.
TI Assessment of a Large Language Model's Responses to Questions and Cases
   About Glaucoma and Retina Management
SO JAMA OPHTHALMOLOGY
VL 142
IS 4
BP 371
EP 375
DI 10.1001/jamaophthalmol.2023.6917
EA APR 2024
DT Article
PD APR 2024
PY 2024
AB Importance: Large language models (LLMs) are revolutionizing medical
   diagnosis and treatment, offering unprecedented accuracy and ease
   surpassing conventional search engines. Their integration into medical
   assistance programs will become pivotal for ophthalmologists as an
   adjunct for practicing evidence-based medicine. Therefore, the
   diagnostic and treatment accuracy of LLM-generated responses compared
   with fellowship-trained ophthalmologists can help assess their accuracy
   and validate their potential utility in ophthalmic subspecialties.
   Objective: To compare the diagnostic accuracy and comprehensiveness of
   responses from an LLM chatbot with those of fellowship-trained glaucoma
   and retina specialists on ophthalmological questions and real patient
   case management. Design, Setting, and Participants: This comparative
   cross-sectional study recruited 15 participants aged 31 to 67 years,
   including 12 attending physicians and 3 senior trainees, from eye
   clinics affiliated with the Department of Ophthalmology at Icahn School
   of Medicine at Mount Sinai, New York, New York. Glaucoma and retina
   questions (10 of each type) were randomly selected from the American
   Academy of Ophthalmology's Commonly Asked Questions. Deidentified
   glaucoma and retinal cases (10 of each type) were randomly selected from
   ophthalmology patients seen at Icahn School of Medicine at Mount
   Sinai-affiliated clinics. The LLM used was GPT-4 (version dated May 12,
   2023). Data were collected from June to August 2023. Main Outcomes and
   Measures: Responses were assessed via a Likert scale for medical
   accuracy and completeness. Statistical analysis involved the
   Mann-Whitney U test and the Kruskal-Wallis test, followed by pairwise
   comparison. Results: The combined question-case mean rank for accuracy
   was 506.2 for the LLM chatbot and 403.4 for glaucoma specialists (n =
   831; Mann-Whitney U = 27976.5; P < .001), and the mean rank for
   completeness was 528.3 and 398.7, respectively (n = 828; Mann-Whitney U
   = 25218.5; P < .001). The mean rank for accuracy was 235.3 for the LLM
   chatbot and 216.1 for retina specialists (n = 440; Mann-Whitney U =
   15518.0; P = .17), and the mean rank for completeness was 258.3 and
   208.7, respectively (n = 439; Mann-Whitney U = 13123.5; P = .005). The
   Dunn test revealed a significant difference between all pairwise
   comparisons, except specialist vs trainee in rating chatbot
   completeness. The overall pairwise comparisons showed that both trainees
   and specialists rated the chatbot's accuracy and completeness more
   favorably than those of their specialist counterparts, with specialists
   noting a significant difference in the chatbot's accuracy (z = 3.23; P =
   .007) and completeness (z = 5.86; P < .001). Conclusions and Relevance:
   This study accentuates the comparative proficiency of LLM chatbots in
   diagnostic accuracy and completeness compared with fellowship-trained
   ophthalmologists in various clinical scenarios. The LLM chatbot
   outperformed glaucoma specialists and matched retina specialists in
   diagnostic and treatment accuracy, substantiating its role as a
   promising diagnostic adjunct in ophthalmology.
Z8 1
ZS 0
ZR 0
ZA 0
TC 53
ZB 8
Z9 53
DA 2024-03-21
UT WOS:001174564400007
PM 38386351
ER

PT J
AU Yang, Kuo
   Dong, Xin
   Zhang, Shuhan
   Yu, Haibin
   Zhong, Liqun
   Zhang, Lei
   Zhao, He
   Hou, Yutong
   Song, Xinpeng
   Zhou, Xuezhong
TI PresRecRF: Herbal prescription recommendation via the representation
   fusion of large TCM semantics and molecular knowledge
SO PHYTOMEDICINE
VL 135
AR 156116
DI 10.1016/j.phymed.2024.156116
EA OCT 2024
DT Article
PD DEC 2024
PY 2024
AB Background: Herbal prescription recommendation (HPR) is a hotspot in the
   research of clinical intelligent decision support. Recently plentiful
   HPR models based on deep neural networks have been proposed. Owing to
   insufficient data, e.g., lack of knowledge of molecular, TCM theory, and
   herbal dosage in HPR modeling, the existing models suffer from
   challenges, e.g., plain prediction precision, and are far from
   real-world clinics. Purpose: To address these problems, we proposed a
   novel herbal prescription recommendation model with the representation
   fusion of large TCM semantics and molecular knowledge (termed
   PresRecRF). Study Design and Methods: PresRecRF comprises three key
   modules. The representation learning module consists of two key
   components: a molecular knowledge representation component, integrating
   molecular knowledge into the herbsymptom-protein knowledge graph to
   enhance representations for herbs and symptoms; and a TCM knowledge
   representation component, leveraging BERT and ChatGPT to acquire TCM
   knowledge-enriched semantic representations. We introduced a
   representation fusion module to effectively merge molecular and TCM
   semantic representations. In the herb recommendation module, a
   multi-task objective loss is implemented to predict both herbs and
   dosages simultaneously. Results: The experimental results on two
   clinical datasets show that PresRecRF can achieve the optimal
   performance. Further analysis of ablation, hyper-parameters, and case
   studies indicate the effectiveness and reliability of the proposed
   model, suggesting that it can help precision medicine and treatment
   recommendations. Conclusion: The entire process of the proposed
   PresRecRF model closely mirrors the actual diagnosis and treatment
   procedures carried out by doctors, which are better applied in real
   clinical scenarios. The source codes of PresRecRF is available at
   https://github.com/2020MEAI/PresRecRF.
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
TC 0
Z9 0
DA 2024-12-07
UT WOS:001368283600001
PM 39396402
ER

PT J
AU Lai, Yongkang
   Liao, Foqiang
   Zhao, Jiulong
   Zhu, Chunping
   Hu, Yi
   Li, Zhaoshen
TI Exploring the capacities of ChatGPT: A comprehensive evaluation of its
   accuracy and repeatability in addressing helicobacter
   pylori-related queries
SO HELICOBACTER
VL 29
IS 3
AR e13078
DI 10.1111/hel.13078
DT Article
PD MAY 2024
PY 2024
AB Background: Educational initiatives on Helicobacter pylori (H. pylori)
   constitute a highly effective approach for preventing its infection and
   establishing standardized protocols for its eradication. ChatGPT, a
   large language model, is a potentially patient-friendly online tool
   capable of providing health-related knowledge. This study aims to assess
   the accuracy and repeatability of ChatGPT in responding to questions
   related to H. pylori. Materials and Methods: Twenty-one common questions
   about H. pylori were collected and categorized into four domains: basic
   knowledge, diagnosis, treatment, and prevention. ChatGPT was utilized to
   individually answer the aforementioned 21 questions. Its responses were
   independently assessed by two experts on H. pylori. Questions with
   divergent ratings were resolved by a third reviewer. Cohen's kappa
   coefficient was calculated to assess the consistency between the scores
   of the two reviewers. Results: The responses of ChatGPT on H.
   pylori-related questions were generally satisfactory, with 61.9% marked
   as "completely correct" and 33.33% as "correct but inadequate." The
   repeatability of the responses of ChatGPT to H. pylori-related questions
   was 95.23%. Among the responses, those related to prevention
   (comprehensive: 75%) had the best response, followed by those on
   treatment (comprehensive: 66.7%), basic knowledge (comprehensive: 60%),
   and diagnosis (comprehensive: 50%). In the "treatment" domain, 16.6% of
   the ChatGPT responses were categorized as "mixed with correct or
   incorrect/outdated data." However, ChatGPT still lacks relevant
   knowledge regarding H. pylori resistance and the use of sensitive
   antibiotics. Conclusions: ChatGPT can provide correct answers to the
   majority of H. pylori-related queries. It exhibited good reproducibility
   and delivered responses that were easily comprehensible to patients.
   Further enhancement of real-time information updates and correction of
   inaccurate information will make ChatGPT an essential auxiliary tool for
   providing accurate H. pylori-related health information to patients.
ZR 0
ZB 1
ZS 0
Z8 0
TC 12
ZA 0
Z9 12
DA 2024-06-21
UT WOS:001247019800001
PM 38867649
ER

PT J
AU McCoy, Thomas H.
   Castro, Victor M.
   Perlis, Roy H.
TI Estimating depression severity in narrative clinical notes using large
   language models
SO JOURNAL OF AFFECTIVE DISORDERS
VL 381
BP 270
EP 274
DI 10.1016/j.jad.2025.04.014
EA APR 2025
DT Article
PD JUL 15 2025
PY 2025
AB Background: Depression treatment guidelines emphasize measurement-based
   care using patient-reported outcome measures, yet their impact on
   narrative documentation quality remains underexplored. Methods: We
   sampled 15,000 narrative clinical outpatient notes from the electronic
   health record of a large academic medical center, reflecting visits
   between January 2, 2019 and January 30, 2024, for which a 9-item Patient
   Health Questionnaire (PHQ-9) was completed at the same time. After
   censoring PHQ-9 scores from notes, we estimated severity of depressive
   symptoms with a foundational large language model (gpt4o-08-06) in a
   HIPAA-compliant enclave. We estimated correlation between true PHQ-9 and
   model-estimated score and examined the predictive performance of the
   model for moderate or greater depressive symptoms. Results: Mean age was
   46.3 years (SD 14.9); 9083 (60.6 %) identified as female. 925 (6.2 %)
   identified as Asian, 638 (4.3 %) as Black, 853 (5.7 %) as another race,
   and 12,187 (81.2 %) as White. A total of 1044 (7.0 %) identified as
   Hispanic ethnicity, while 12,699 (84.7 %) were non-Hispanic. Mean
   measured PHQ-9 score was 1.23 (SD 3.45); 721 (4.8 %) met criteria for
   moderate or greater depressive symptoms. LLM-predicted PHQ-9 scores were
   modestly correlated with actual scores (r2 = 0.264 (95 % CI
   0.252-0.276)); PPV for moderate or greater depression was 0.309 (95 % CI
   0.302-0.317). Performance was consistent across demographic subgroups,
   with modest differences identified by race, ethnicity, and sex.
   Conclusion: A foundational LLM performed poorly but consistently across
   subgroups in imputing PHQ-9 scores from notes when actual PHQ-9
   reporting was ablated. This result suggests the extent to which
   inclusion of PROMs may impoverish documentation of psychiatric symptoms.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-04-26
UT WOS:001469145100001
PM 40187432
ER

PT J
AU Dhodapkar, Rahul M.
   Jung, Eric
   Lee, Sun Young
TI An Eye on Extracellular Vesicles: Trends and Clinical Translations in
   Vision Research
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100619
DI 10.1016/j.xops.2024.100619
EA NOV 2024
DT Article
PD JAN-FEB 2025
PY 2025
AB Purpose: To perform a review of research, funding, and clinical
   translation efforts for extracellular vesicles (EVs) within vision
   science. Design: Retrospective analysis of publication, funding, and
   clinical trials data. Methods: A pretrained large language model (Jina2)
   was used to create semantic embeddings for 41 282 abstracts from
   articles related to EVs archived on EMBASE and published between January
   1966 and January 2024. The articles were projected and clustered
   according to semantic embedding similarity, and research sub- domains
   for EVs were determined through inspection of term frequency-inverse
   document frequency weighted word clouds. Mann-Kendall trend analysis was
   performed to identify current areas of growth within EV research.
   Additionally, National Institutes of Health funding data from RePORT
   Expenditures and Results and clinical trials data from
   ClinicalTrials.gov were analyzed to correlate publication trends with
   funding support and clinical translation efforts. Results: Unsupervised
   clustering and Mann-Kendall trend analysis identified wound
   healing/regeneration (P = 0.030) and neurodegenerative disease (P =
   0.049) as significantly accelerating in growth of publication over time.
   Ophthalmology-restricted subset analysis identified that publications in
   age-related macular degeneration (P = 0.191) and clinical applications
   (P = 0.086) are no longer growing at a significant rate. Analysis of
   funding data identified that the National Cancer Institute was the top
   funding institution overall, but that the National Institute on Aging is
   rapidly advancing in terms of funding EV research and trials. Analysis
   of ClinicalTrials.gov data highlights a dearth of clinical trials within
   ophthalmology despite a growing number of studies in other medical
   subfields. Conclusions: Extracellular vesicles remain a promising
   substrate for both the identification and treatment of
   vision-threatening diseases. A better understanding of the current
   landscape of research and funding trends should help to inform future
   funding and translational efforts. Financial Disclosures: Proprietary or
   commercial disclosure may be found in the Footnotes and Disclosures at
   the end of this article. Ophthalmology Science 2025;5:100619 (c) 2024 by
   the American Academy of Ophthalmology. This is an open access article
   under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-ncnd/4.0/).
Z8 0
ZS 0
ZA 0
ZB 1
TC 1
ZR 0
Z9 1
DA 2024-11-23
UT WOS:001355802600001
PM 39584184
ER

PT J
AU Rosich, A.
   Ferrer, J. C.
   Guerreros, S. M.
   Rivero, E.
   Torres, M.
   Roldan, S.
   Giordano, Sr M.
   Paolini, G.
   Ochandorena, K.
   Ricagni, L.
   Lorenzo, F.
TI Artificial Intelligence in Oncologic Radiotherapy: A New Tool for
   Treatment Selection in Patients with Early-Stage Breast Cancer
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3432
BP E654
EP E654
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
Z8 0
ZS 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302113
ER

PT J
AU Yang, Xintian
   Li, Tongxin
   Su, Qin
   Liu, Yaling
   Kang, Chenxi
   Lyu, Yong
   Zhao, Lina
   Nie, Yongzhan
   Pan, Yanglin
TI Application of large language models in disease diagnosis and treatment
SO CHINESE MEDICAL JOURNAL
VL 138
IS 2
BP 130
EP 142
DI 10.1097/CM9.0000000000003456
DT Review
PD JAN 20 2025
PY 2025
AB Large language models (LLMs) such as ChatGPT, Claude, Llama, and Qwen
   are emerging as transformative technologies for the diagnosis and
   treatment of various diseases. With their exceptional long-context
   reasoning capabilities, LLMs are proficient in clinically relevant
   tasks, particularly in medical text analysis and interactive dialogue.
   They can enhance diagnostic accuracy by processing vast amounts of
   patient data and medical literature and have demonstrated their utility
   in diagnosing common diseases and facilitating the identification of
   rare diseases by recognizing subtle patterns in symptoms and test
   results. Building on their image-recognition abilities, multimodal LLMs
   (MLLMs) show promising potential for diagnosis based on radiography,
   chest computed tomography (CT), electrocardiography (ECG), and common
   pathological images. These models can also assist in treatment planning
   by suggesting evidence-based interventions and improving clinical
   decision support systems through integrated analysis of patient records.
   Despite these promising developments, significant challenges persist
   regarding the use of LLMs in medicine, including concerns regarding
   algorithmic bias, the potential for hallucinations, and the need for
   rigorous clinical validation. Ethical considerations also underscore the
   importance of maintaining the function of supervision in clinical
   practice. This paper highlights the rapid advancements in research on
   the diagnostic and therapeutic applications of LLMs across different
   medical disciplines and emphasizes the importance of policymaking,
   ethical supervision, and multidisciplinary collaboration in promoting
   more effective and safer clinical applications of LLMs. Future
   directions include the integration of proprietary clinical knowledge,
   the investigation of open-source and customized models, and the
   evaluation of real-time effects in clinical diagnosis and treatment
   practices.
TC 2
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
Z9 2
DA 2025-01-25
UT WOS:001400214400011
PM 39722188
ER

PT J
AU Ra, Sinyoung
   Kim, Jonghun
   Na, Inye
   Ko, Eun Sook
   Park, Hyunjin
TI Enhancing radiomics features via a large language model for classifying
   benign and malignant breast tumors in mammography
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 265
AR 108765
DI 10.1016/j.cmpb.2025.108765
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Background and Objectives: Radiomics is widely used to assist in
   clinical decision-making, disease diagnosis, and treatment planning for
   various target organs, including the breast. Recent advances in large
   language models (LLMs) have helped enhance radiomics analysis. Materials
   and Methods: Herein, we sought to improve radiomics analysis by
   incorporating LLM-learned clinical knowledge, to classify benign and
   malignant tumors in breast mammography. We extracted radiomics features
   from the mammograms based on the region of interest and retained the
   features related to the target task. Using prompt engineering, we
   devised an input sequence that reflected the selected features and the
   target task. The input sequence was fed to the chosen LLM (LLaMA
   variant), which was fine-tuned using low-rank adaptation to enhance
   radiomics features. This was then evaluated on two mammogram datasets
   (VinDr-Mammo and INbreast) against conventional baselines. Results: The
   enhanced radiomics-based method performed better than baselines using
   conventional radiomics features tested on two mammogram datasets,
   achieving accuracies of 0.671 for the VinDr-Mammo dataset and 0.839 for
   the INbreast dataset. Conventional radiomics models require retraining
   from scratch for an unseen dataset using a new set of features. In
   contrast, the model developed in this study effectively reused the
   common features between the training and unseen datasets by explicitly
   linking feature names with feature values, leading to extensible
   learning across datasets. Our method performed better than the baseline
   method in this retraining setting using an unseen dataset. Conclusions:
   Our method, one of the first to incorporate LLM into radiomics, has the
   potential to improve radiomics analysis.
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
ZB 0
Z9 0
DA 2025-04-21
UT WOS:001466026900001
PM 40203779
ER

PT J
AU Liu, Jonathan
   Segal, Kathryn
   Daher, Mohammad
   Ozolin, Jordan
   Binder, William
   Bergen, Michael
   McDonald, Christopher L.
   Owens, Brett
   Antoci, Valentin
TI Artificial intelligence versus orthopedic surgeons as an orthopedic
   consultant in the emergency department
SO INJURY-INTERNATIONAL JOURNAL OF THE CARE OF THE INJURED
VL 56
IS 4
AR 112297
DI 10.1016/j.injury.2025.112297
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB Introduction: ChatGPT, a widely accessible AI program, has demonstrated
   potential in various healthcare applications, including emergency
   department (ED) triage, differential diagnosis, and patient education.
   However, its potential in providing recommendations to emergency
   department providers with orthopedic consultations has not been
   evaluated yet. Methods: This study compared the performance of four
   board certified orthopedic surgeons, two attendings and two trauma
   fellows who take independent call at the same institution and ChatGPT-4
   in responding to clinical scenarios commonly encountered in emergency
   departments. Five common orthopedic ED scenarios were developed (lateral
   malleolar ankle fractures, distal radius fractures, septic arthritis of
   the knee, shoulder dislocations, and Achilles tendon ruptures), each
   with four questions related to diagnosis, management, surgical
   indication, and patient counseling, totaling 20 questions. Responses
   were anonymized, coded, and evaluated by independent reviewers including
   emergency medicine physicians using a five-point Likert scale across
   five criteria: accuracy, completeness, helpfulness, specificity, and
   overall quality. Results: When comparing the ratings of AI answers to
   non-AI responders, the AI answers were shown to be superior in
   completeness, helpfulness, specificity, and overall quality with no
   difference in regards to accuracy (p < 0.05). When considering question
   subtypes including diagnosis, management, treatment, and patient
   counseling, AI was shown to have superior scores in helpfulness, and
   specificity in diagnostic questions(p < 0.05). In addition, AI responses
   were superior in all the assessed categories when looking at the patient
   counseling questions (p < 0.05). When considering different clinical
   scenarios, AI outperformed non-AI groups in completeness in the distal
   radius fracture scenario. Furthermore, AI outperformed non-AI groups in
   helpfulness in the lateral malleolus fracture scenario. In the shoulder
   dislocation scenario, AI responses were more complete, helpful, and had
   a better overall quality. AI responses were non-inferior in the
   remaining categories of the different scenarios. Conclusion: Artificial
   intelligence exhibited non-inferior and often superior performance in
   common orthopedic-ED consultations compared to board certified
   orthopedic surgeons While current AI models are limited in their ability
   to integrate specific images and patient scenarios, our findings suggest
   AI can provide high quality recommendations for generic orthopedic
   consultations and with further development, will likely have an
   increasing role in the future.
ZA 0
TC 0
ZS 0
ZB 0
ZR 0
Z8 0
Z9 0
DA 2025-05-21
UT WOS:001489449700001
PM 40147063
ER

PT J
AU Cohen, Natalie D.
   Ho, Milan
   Mcintire, Donald
   Smith, Katherine
   Kho, Kimberly A.
TI A comparative analysis of generative artificial intelligence responses
   from leading chatbots to questions about endometriosis
SO AJOG GLOBAL REPORTS
VL 5
IS 1
AR 100405
DI 10.1016/j.xagr.2024.100405
EA DEC 2024
DT Article
PD FEB 2025
PY 2025
AB INTRODUCTION: The use of generative artificial intelligence (AI) has
   begun to permeate most industries, including medicine, and patients will
   inevitably start using these large language model (LLM) chatbots as a
   modality for education. As healthcare information technology evolves, it
   is imperative to evaluate chatbots and the accuracy of the information
   they provide to patients and to determine if there is variability
   between them. OBJECTIVE: This study aimed to evaluate the accuracy and
   comprehensiveness of three chatbots in addressing questions related to
   endometriosis and determine the level of variability between them. STUDY
   DESIGN: Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic),
   and Bard (Google) were asked to generate answers to 10 commonly asked
   questions about endometriosis. The responses were qualitatively compared
   to current guidelines and expert opinion on endometriosis and rated on a
   scale by nine gynecologists. The grading scale included the following:
   (1) Completely incorrect, (2) mostly incorrect and some correct, (3)
   mostly correct and some incorrect, (4) correct but inadequate, (5)
   correct and comprehensive. Final scores were averaged between the nine
   reviewers. Kendall's Wand the related chi-square test were used to
   evaluate the reviewers' strength of agreement in ranking the LLMs'
   responses for each item. RESULTS: Average scores for the 10 answers
   amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7,
   respectively. Two questions showed significant disagreement between the
   nine reviewers. There were no questions the models could answer
   comprehensively or correctly across the reviewers. The model most
   associated with comprehensive and correct responses was ChatGPT.
   Chatbots showed an improved ability to accurately answer questions about
   symptoms and pathophysiology over treatment and risk of recurrence.
   CONCLUSION: The analysis of LLMs revealed that, on average, they mainly
   provided correct but inadequate responses to commonly asked patient
   questions about endometriosis. While chatbot responses can serve as
   valuable supplements to information provided by licensed medical
   professionals, it is crucial to maintain a thorough ongoing evaluation
   process for outputs to provide the most comprehensive and accurate
   information to patients. Further research into this technology and its
   role in patient education and treatment is crucial as generative AI
   becomes more embedded in the medical field.
ZA 0
Z8 0
TC 1
ZS 0
ZB 0
ZR 0
Z9 1
DA 2025-05-06
UT WOS:001476609200001
PM 39810943
ER

PT J
AU Zhang, Yapei
   Shi, Min
   Liebman, Daniel L.
   Barna, Laura
   Pasquale, Louis R.
   Elze, Tobias
   Friedman, David S.
   Boland, Michael V.
   Shen, Lucy Q.
   Wang, Mengyu
TI Evaluation of the accuracy of AIgenerated clinical summaries from
   Glaucoma outpatient visits.
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1641
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
DA 2024-12-01
UT WOS:001312227704269
ER

PT J
AU Sezgin, Emre
   Jackson, Daniel I.
   Kocaballi, A. Baki
   Bibart, Mindy
   Zupanec, Sue
   Landier, Wendy
   Audino, Anthony
   Ranalli, Mark
   Skeens, Micah
TI Can Large Language Models Aid Caregivers of Pediatric Cancer Patients in
   Information Seeking? A Cross-Sectional Investigation
SO CANCER MEDICINE
VL 14
IS 1
AR e70554
DI 10.1002/cam4.70554
DT Article
PD JAN 2025
PY 2025
AB PurposeCaregivers in pediatric oncology need accurate and understandable
   information about their child's condition, treatment, and side effects.
   This study assesses the performance of publicly accessible large
   language model (LLM)-supported tools in providing valuable and reliable
   information to caregivers of children with cancer. MethodsIn this
   cross-sectional study, we evaluated the performance of the four
   LLM-supported tools-ChatGPT (GPT-4), Google Bard (Gemini Pro), Microsoft
   Bing Chat, and Google SGE-against a set of frequently asked questions
   (FAQs) derived from the Children's Oncology Group Family Handbook and
   expert input (In total, 26 FAQs and 104 generated responses). Five
   pediatric oncology experts assessed the generated LLM responses using
   measures including accuracy, clarity, inclusivity, completeness,
   clinical utility, and overall rating. Additionally, the content quality
   was evaluated including readability, AI disclosure, source credibility,
   resource matching, and content originality. We used descriptive analysis
   and statistical tests including Shapiro-Wilk, Levene's, Kruskal-Wallis
   H-tests, and Dunn's post hoc tests for pairwise comparisons.
   ResultsChatGPT shows high overall performance when evaluated by the
   experts. Bard also performed well, especially in accuracy and clarity of
   the responses, whereas Bing Chat and Google SGE had lower overall
   scores. Regarding the disclosure of responses being generated by AI, it
   was observed less frequently in ChatGPT responses, which may have
   affected the clarity of responses, whereas Bard maintained a balance
   between AI disclosure and response clarity. Google SGE generated the
   most readable responses whereas ChatGPT answered with the most
   complexity. LLM tools varied significantly (p < 0.001) across all expert
   evaluations except inclusivity. Through our thematic analysis of expert
   free-text comments, emotional tone and empathy emerged as a unique theme
   with mixed feedback on expectations from AI to be empathetic.
   ConclusionLLM-supported tools can enhance caregivers' knowledge of
   pediatric oncology. Each model has unique strengths and areas for
   improvement, indicating the need for careful selection based on specific
   clinical contexts. Further research is required to explore their
   application in other medical specialties and patient demographics,
   assessing broader applicability and long-term impacts.
ZA 0
TC 2
Z8 0
ZS 0
ZB 1
ZR 0
Z9 2
DA 2025-01-13
UT WOS:001391811100001
PM 39776222
ER

PT J
AU Zhu, Zirui
   Zeng, Zhuo
   Zeng, Huiqing
   Luo, Xiongbiao
TI Research progress on artificial intelligence driving precision diagnosis
   and treatment of chronic obstructive pulmonary disease
SO Xiamen Daxue Xuebao (Ziran Kexue Ban)
VL 63
IS 5
BP 894
EP 905
DI 10.6043/j.issn.0438-0479.202402019
DT Article
PD SEP 2024
PY 2024
AB [Background] Chronic obstructive pulmonary disease (COPD) is a complex
   and prevalent respiratory disorder with irreversible airflow limitation
   worldwide, Precision diagnosis and treatment at its early stage
   significantly improve the quality of life of patients, COPD symptoms are
   diverse and progressive, e. g. chronic cough, sputum production, dyspnea
   and chest tightness. indicating advances in COPD, While the
   pathophysiology of COPD is multifaceted with persistent airway
   inflammation, airway remodeling, and alveolar destruction, the etiology
   of COPD is multifactorial, including prolonged smoking, environmental
   pollutants. occupational hazards, and genetic predispositions. These
   factors collectively result in airflow obstruction and pathological
   changes in the respiratory tract, Specifically, the progression of COPD
   is often accompanied with persistent inflammatory responses, oxidative
   stress and intensive pulmonary damage, [Progress] Pulmonary function
   tests (PFTs) are routinely performed to examine COPD. providing
   physicians with a ratio of the forced expiratory volume in one second by
   the forced vital capacity to evaluate COPD, Unfortunately, the results
   of PFTs critically affected by the effort of patients, and the
   interpretation of PFTs also depends on experience and skills of
   physicians. While PFTs allow physicians to quantify the severity of
   COPD, they do not reach a specific diagnosis and are commonly associated
   with medical history, physical examination such as CT imaging,
   functional MR imaging and respiratory sound, and laboratory data to
   determine a diagnosis. Therefore, physicians expect more precise COPD
   diagnosis and treatment methods than conventional ones to improve
   patient's quality of life. Nowadays artificial intelligence (AI) is
   widely discussed in precision medicine. Specifically, Al techniques or
   mathematical models also increasingly used in COPD diagnosis, treatment,
   monitoring, and management, These models are generally categorized into
   unimodal and multimodal Al models in accordance with clinical COPD data.
   While the unimodal model uses only a single one modality such as PFTs or
   CT images, the multimodal model fuses a diversity of data ineluding
   imaging, biomedical information, and clinical records, All these models
   generally provide physicians with a holistic assessment of COPD,
   patient-specific treatment for precision medicine, [Perspective] In
   general, Al techniques provide a promising way to precisely diagnose and
   treat COPD in its early stage, as well as COPD management and
   monitoring. Specifically, artificial general intelligence, generative
   artificial intelligence, multimodal large language models are innovating
   clinical methods in diagnosis, treatment, monitoring, and management of
   pulmonary diseases, although they still suffer from medical data privacy
   and security, model generalizability, interpretability and complexity,
   legal and ethical issues. Future research should address these issues in
   various angles, It is essential to strengthen privacy protection and
   security measures, Moreover, it is vital to improve the
   generalizability, transparency and interpretability and reduce the
   complexity of various Al models in clinical applications, Additionally,
   medical ethics are important when applying Al techniques to precision
   pulmonary medicine.
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
DA 2025-03-21
UT BCI:BCI202500316530
ER

PT J
AU Gasparovic, Michal
   Jungova, Petra
   Tomasik, Juraj
   Mrinakova, Bela
   Hirjak, Dusan
   Timkova, Silvia
   Danisovic, Lubos
   Janek, Marian
   Baca, Lubos
   Peciar, Peter
   Thurzo, Andrej
TI Evolving Strategies and Materials for Scaffold Development in
   Regenerative Dentistry
SO APPLIED SCIENCES-BASEL
VL 14
IS 6
AR 2270
DI 10.3390/app14062270
DT Review
PD MAR 2024
PY 2024
AB Regenerative dentistry has experienced remarkable advancement in recent
   years. The interdisciplinary discoveries in stem cell applications and
   scaffold design and fabrication, including novel techniques and
   biomaterials, have demonstrated immense potential in the field of tissue
   engineering and regenerative therapy. Scaffolds play a pivotal role in
   regenerative dentistry by facilitating tissue regeneration and restoring
   damaged or missing dental structures. These biocompatible and biomimetic
   structures serve as a temporary framework for cells to adhere,
   proliferate, and differentiate into functional tissues. This review
   provides a concise overview of the evolution of scaffold strategies in
   regenerative dentistry, along with a novel analysis (Bard v2.0 based on
   the Gemini neural network architecture) of the most commonly employed
   materials used for scaffold fabrication during the last 10 years.
   Additionally, it delves into bioprinting, stem cell colonization
   techniques and procedures, and outlines the prospects of regenerating a
   whole tooth in the future. Moreover, it discusses the optimal conditions
   for maximizing mesenchymal stem cell utilization and optimizing scaffold
   design and personalization through precise 3D bioprinting. This review
   highlights the recent advancements in scaffold development, particularly
   with the advent of 3D bioprinting technologies, and is based on a
   comprehensive literature search of the most influential recent
   publications in this field.
TC 16
Z8 0
ZB 1
ZR 0
ZA 0
ZS 0
Z9 16
DA 2024-04-03
UT WOS:001191807800001
ER

PT J
AU Scuricini, Alessandro
   Ramoni, Davide
   Liberale, Luca
   Montecucco, Fabrizio
   Carbone, Federico
TI The role of artificial intelligence in cardiovascular research: Fear
   less and live bolder
SO EUROPEAN JOURNAL OF CLINICAL INVESTIGATION
VL 55
SI SI
AR e14364
DI 10.1111/eci.14364
SU 1
DT Review
PD APR 2025
PY 2025
AB BackgroundArtificial intelligence (AI) has captured the attention of
   everyone, including cardiovascular (CV) clinicians and scientists.
   Moving beyond philosophical debates, modern cardiology cannot overlook
   AI's growing influence but must actively explore its potential
   applications in clinical practice and research methodology.Methods and
   ResultsAI offers exciting possibilities for advancing CV medicine by
   uncovering disease heterogeneity, integrating complex multimodal data,
   and enhancing treatment strategies. In this review, we discuss the
   innovative applications of AI in cardiac electrophysiology, imaging,
   angiography, biomarkers, and genomic data, as well as emerging tools
   like face recognition and speech analysis. Furthermore, we focus on the
   expanding role of machine learning (ML) in predicting CV risk and
   outcomes, outlining a roadmap for the implementation of AI in CV care
   delivery. While the future of AI holds great promise, technical
   limitations and ethical challenges remain significant barriers to its
   widespread clinical adoption.ConclusionsAddressing these issues through
   the development of high-quality standards and involving key stakeholders
   will be essential for AI to transform cardiovascular care safely and
   effectively.
ZS 0
ZR 0
TC 1
ZB 0
Z8 0
ZA 0
Z9 1
DA 2025-04-12
UT WOS:001460920400008
PM 40191936
ER

PT J
AU Fu, Sidney W.
   Tang, Cong
   Tan, Xiaohui
   Srivastava, Sudhir
TI Liquid biopsy for early cancer detection: technological revolutions and
   clinical dilemma
SO EXPERT REVIEW OF MOLECULAR DIAGNOSTICS
VL 24
IS 10
BP 937
EP 955
DI 10.1080/14737159.2024.2408744
EA OCT 2024
DT Review
PD OCT 2 2024
PY 2024
AB IntroductionLiquid biopsy is an innovative advancement in oncology,
   offering a noninvasive method for early cancer detection and monitoring
   by analyzing circulating tumor cells, DNA, RNA, and other biomarkers in
   bodily fluids. This technique has the potential to revolutionize
   precision oncology by providing real-time analysis of tumor dynamics,
   enabling early detection, monitoring treatment responses, and tailoring
   personalized therapies based on the molecular profiles of individual
   patients.Areas coveredIn this review, the authors discuss current
   methodologies, technological challenges, and clinical applications of
   liquid biopsy. This includes advancements in detecting minimal residual
   disease, tracking tumor evolution, and combining liquid biopsy with
   other diagnostic modalities for precision oncology. Key areas explored
   are the sensitivity, specificity, and integration of multi-omics, AI,
   ML, and LLM technologies.Expert opinionLiquid biopsy holds great
   potential to revolutionize cancer care through early detection and
   personalized treatment strategies. However, its success depends on
   overcoming technological and clinical hurdles, such as ensuring high
   sensitivity and specificity, interpreting results amidst tumor
   heterogeneity, and making tests accessible and affordable. Continued
   innovation and collaboration are crucial to fully realize the potential
   of liquid biopsy in improving early cancer detection, treatment, and
   monitoring.
ZR 0
ZA 0
Z8 0
ZB 2
TC 6
ZS 0
Z9 6
DA 2024-10-09
UT WOS:001325602700001
PM 39360748
ER

PT J
AU Morcilla, Jericho
   Cao, Jessica Anning
   Fan, Kenneth
   Rahman, Effie
   Khang Ngo
   Patel, Sagar
   Chaudhary, Varun
   Wykoff, Charles Clifton
TI A Potential Role for AI: Evaluating ChatGPT's Efficacy in Prioritizing
   Medical Waiting Lists
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 5668
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZB 0
ZS 0
Z8 0
ZA 0
TC 0
ZR 0
Z9 0
DA 2024-11-30
UT WOS:001313316206237
ER

PT J
AU Castro, Victor M
   McCoy, Thomas H
   Verhaak, Pilar
   Ramachandiran, Anudeepa K
   Perlis, Roy H
TI Changes in psychiatric documentation and treatment in primary care with
   artificial intelligence scribe use.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2025.05.14.25327620
DT Journal Article; Preprint
PD 2025 May 15
PY 2025
AB Importance: Despite increasingly widespread use of artificial
   intelligence-driven ambient scribes in medicine, the extent to which
   they may impact clinician practice is not well-studied.
   Objective: To characterize differences in documentation and treatment of
   psychiatric symptoms in primary care outpatient notes generated using
   ambient scribes.
   Design: Case-control electronic health records.
   Setting: Primary care annual visit notes from the Massachusetts General
   and Brigham and Women's Hospital systems between February 2023 and
   February 2023.
   Participants: Random sample of 20,302 notes from 4 types of visits,
   matching 1:1 using sociodemographic and clinical features: those using
   an ambient scribe, those using a human scribe, those occurring during
   the same period without a scribe, and those occurring prior to scribe
   deployment.
   Exposure: Use of an artificial intelligence-driven ambient scribe.
   Main Outcome and Measures: Neuropsychiatric symptom documentation, in
   terms of estimated Research Domain Criteria, using a HIPAA-compliant
   large language model (GPT4o; gpt-4o-11-20); incident antidepressant
   prescriptions and diagnostic codes; referral for mental health
   follow-up.
   Results: In the ambient scribe group, mean age was 48 (SD 14) years; 59%
   of notes reflected individuals of female sex, and 5.0% met criteria for
   moderate or greater depressive symptoms by PHQ-9. Estimated levels of
   RDoC symptomatology in all 6 domains were significantly greater in the
   ambient-scribed notes (p <.001 for all contrasts). In a logistic
   regression model, likelihood of a psychiatric intervention (referral,
   new diagnosis, or antidepressant prescription) was significantly lower
   among ambient-scribed visits compared to unscribed (aOR 0.83, 95% CI
   0.72-0.95), but not for human-scribed compared to unscribed (aOR 1.01,
   95% CI 0.87-1.17).
   Conclusion and Relevance: In this case-control design examining
   outpatient primary care notes, we found that incorporation of artificial
   intelligence-driven ambient scribes in primary care was associated with
   greater levels of neuropsychiatric symptom documentation but lesser
   likelihood of acting on psychiatric symptoms. Further study will be
   required to determine whether these changes are associated with
   differential outcomes.
   Trial registration: n/a.
   Key Points: Question: How is documentation and treatment of psychiatric
   symptoms in primary care different for outpatient visits using
   artificial intelligence (AI)-driven ambient scribes.Findings: In more
   than 20,000 routine annual visits, ambient scribe use was associated
   with greater documentation of neuropsychiatric symptoms but less
   likelihood of a depression-related intervention or diagnostic
   code.Meaning: The extent to which use of ambient scribes may alter
   response to psychiatric symptoms by clinicians merits further
   investigation.
ZB 0
TC 0
ZA 0
ZR 0
ZS 0
Z8 0
Z9 0
DA 2025-06-06
UT MEDLINE:40463564
PM 40463564
ER

PT J
AU Zheng, Jie
   Ding, Xiaoqian
   Pu, Jingya Jane
   Chung, Sze Man
   Ai, Qi Yong H.
   Hung, Kuo Feng
   Shan, Zhiyi
TI Unlocking the Potentials of Large Language Models in Orthodontics: A
   Scoping Review
SO BIOENGINEERING-BASEL
VL 11
IS 11
AR 1145
DI 10.3390/bioengineering11111145
DT Review
PD NOV 2024
PY 2024
AB (1) Background: In recent years, large language models (LLMs) such as
   ChatGPT have gained significant attention in various fields, including
   dentistry. This scoping review aims to examine the current applications
   and explore potential uses of LLMs in the orthodontic domain, shedding
   light on how they might improve dental healthcare. (2) Methods: We
   carried out a comprehensive search in five electronic databases, namely
   PubMed, Scopus, Embase, ProQuest and Web of Science. Two authors
   independently screened articles and performed data extraction according
   to the eligibility criteria, following the PRISMA-ScR guideline. The
   main findings from the included articles were synthesized and analyzed
   in a narrative way. (3) Results: A total of 706 articles were searched,
   and 12 papers were eventually included. The applications of LLMs include
   improving diagnostic and treatment efficiency in orthodontics as well as
   enhancing communication with patients. (4) Conclusions: There is
   emerging research in countries worldwide on the use of LLMs in
   orthodontics, suggesting an upward trend in their acceptance within this
   field. However, the potential application of LLMs remains in its early
   stage, with a noticeable lack of extensive studies and tailored products
   to address specific clinical needs.
Z8 0
TC 0
ZB 0
ZA 0
ZR 0
ZS 0
Z9 0
DA 2024-12-07
UT WOS:001366774600001
PM 39593805
ER

PT J
AU Gwon, Yong Nam
   Kim, Jae Heon
   Chung, Hyun Soo
   Jung, Eun Jee
   Chun, Joey
   Lee, Serin
   Shim, Sung Ryul
TI The Use of Generative AI for Scientific Literature Searches for
   Systematic Reviews: ChatGPT and Microsoft Bing AI Performance Evaluation
SO JMIR MEDICAL INFORMATICS
VL 12
AR e51187
DI 10.2196/51187
DT Article
PD 2024
PY 2024
AB Background: A large language model is a type of artificial intelligence
   (AI) model that opens up great possibilities for health care practice,
   research, and education, although scholars have emphasized the need to
   proactively address the issue of unvalidated and inaccurate information
   regarding its use. One of the best-known large language models is
   ChatGPT (OpenAI). It is believed to be of great help to medical
   research, as it facilitates more efficient data set analysis, code
   generation, and literature review, allowing researchers to focus on
   experimental design as well as drug discovery and development.
   Objective: This study aims to explore the potential of ChatGPT as a
   real-time literature search tool for systematic reviews and clinical
   decision support systems, to enhance their efficiency and accuracy in
   health care settings. Methods: The search results of a published
   systematic review by human experts on the treatment of Peyronie disease
   were selected as a benchmark, and the literature search formula of the
   study was applied to ChatGPT and Microsoft Bing AI as a comparison to
   human researchers. Peyronie disease typically presents with discomfort,
   curvature, or deformity of the penis in association with palpable
   plaques and erectile dysfunction. To evaluate the quality of individual
   studies derived from AI answers, we created a structured rating system
   based on bibliographic information related to the publications. We
   classified its answers into 4 grades if the title existed: A, B, C, and
   F. No grade was given for a fake title or no answer. Results: From
   ChatGPT, 7 (0.5%) out of 1287 identified studies were directly relevant,
   whereas Bing AI resulted in 19 (40%) relevant studies out of 48,
   compared to the human benchmark of 24 studies. In the qualitative
   evaluation, ChatGPT had 7 grade A, 18 grade B, 167 grade C, and 211
   grade F studies, and Bing AI had 19 grade A and 28 grade C studies.
   Conclusions: This is the first study to compare AI and conventional
   human systematic review methods as a real-time literature collection
   tool for evidence -based medicine. The results suggest that the use of
   ChatGPT as a tool for real-time evidence generation is not yet accurate
   and feasible. Therefore, researchers should be cautious about using such
   AI. The limitations of this study using the generative pre -trained
   transformer model are that the search for research topics was not
   diverse and that it did not prevent the hallucination of generative AI.
   However, this study will serve as a standard for future studies by
   providing an index to verify the reliability and consistency of
   generative AI from a user's point of view. If the reliability and
   consistency of AI literature search services are verified, then the use
   of these technologies will help medical research greatly.
Z8 0
ZS 0
TC 12
ZA 0
ZR 0
ZB 2
Z9 12
DA 2024-06-07
UT WOS:001233902800001
PM 38771247
ER

PT J
AU Maida, Marcello
   Celsa, Ciro
   Lau, Louis H. S.
   Ligresti, Dario
   Baraldo, Stefano
   Ramai, Daryl
   Di Maria, Gabriele
   Cannemi, Marco
   Facciorusso, Antonio
   Camma, Calogero
TI The Application of Large Language Models in Gastroenterology: A Review
   of the Literature
SO CANCERS
VL 16
IS 19
AR 3328
DI 10.3390/cancers16193328
DT Review
PD OCT 2024
PY 2024
AB Simple Summary Large language models (LLMs) are revolutionizing the
   field of medicine, particularly in Gastroenterology, by improving access
   to information, diagnostics, treatment customization, and medical
   education. They analyze extensive medical data to enhance
   decision-making, patient outcomes, and educational tasks. While LLMs
   face challenges such as incomplete data, varying response accuracy, and
   reliance on specific input wording, they have shown promising results.
   However, their full integration into medical practice requires further
   research and regulation. Moreover, the successful integration of LLMs
   into medical practice necessitates customization to specific medical
   contexts and adherence to guidelines. This review focuses on the current
   evidence supporting the use of LLMs in Gastroenterology, emphasizing
   their potential and limitations.Abstract Large language models (LLMs)
   are transforming the medical landscape by enhancing access to
   information, diagnostics, treatment customization, and medical
   education, especially in areas like Gastroenterology. LLMs utilize
   extensive medical data to improve decision-making, leading to better
   patient outcomes and personalized medicine. These models are
   instrumental in interpreting medical literature and synthesizing patient
   data, facilitating real-time knowledge for physicians and supporting
   educational pursuits in medicine. Despite their potential, the complete
   integration of LLMs in real-life remains ongoing, particularly requiring
   further study and regulation. This review highlights the existing
   evidence supporting LLMs' use in Gastroenterology, addressing both their
   potential and limitations. Recent studies demonstrate LLMs' ability to
   answer questions from physicians and patients accurately. Specific
   applications in this field, such as colonoscopy, screening for
   colorectal cancer, and hepatobiliary and inflammatory bowel diseases,
   underscore LLMs' promise in improving the communication and
   understanding of complex medical scenarios. Moreover, the review
   discusses LLMs' efficacy in clinical contexts, providing guideline-based
   recommendations and supporting decision-making processes. Despite these
   advancements, challenges such as data completeness, reference
   suitability, variability in response accuracy, dependency on input
   phrasing, and a lack of patient-generated questions underscore
   limitations in reproducibility and generalizability. The effective
   integration of LLMs into medical practice demands refinement tailored to
   specific medical contexts and guidelines. Overall, while LLMs hold
   significant potential in transforming medical practice, ongoing
   development and contextual training are essential to fully realize their
   benefits.
ZB 0
ZA 0
ZR 0
ZS 0
TC 2
Z8 0
Z9 2
DA 2024-10-19
UT WOS:001331756500001
PM 39409948
ER

PT J
AU Challa, Nayanika
   Luskey, Nina
   Wang, Daniel
TI Appropriateness and Readability of ChatGPT-3.5 Responses to Common
   Patient Questions on Age-Related Macular Degeneration
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA OD78
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
ZB 0
ZA 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2024-12-01
UT WOS:001312227700072
ER

PT J
AU Kunze, Kyle N.
   Varady, Nathan H.
   Mazzucco, Michael
   Lu, Amy Z.
   Chahla, Jorge
   Martin, R. Kyle
   Ranawat, Anil S.
   Pearle, Andrew D.
   Williams Iii, Riley J.
TI The Large Language Model ChatGPT-4 Exhibits Excellent Triage
   Capabilities and Diagnostic Performance for Patients Presenting With
   Various Causes of Knee Pain
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 5
DI 10.1016/j.arthro.2024.06.021
DT Article
PD MAY 2025
PY 2025
AB Purpose: To provide a proof-of-concept analysis of the appropriateness
   and performance of ChatGPT-4 to triage, synthesize differential
   diagnoses, and generate treatment plans concerning common presentations
   of knee pain. Methods: Twenty knee complaints warranting triage and
   expanded scenarios were input into ChatGPT-4, with memory cleared prior
   to each new input to mitigate bias. For the 10 triage complaints,
   ChatGPT-4 was asked to generate a differential diagnosis that was graded
   for accuracy and suitability in comparison to a differential created by
   2 orthopaedic sports medicine physicians. For the 10 clinical scenarios,
   ChatGPT-4 was prompted to provide treatment guidance for the patient,
   which was again graded. To test the higher-order capabilities of
   ChatGPT-4, further inquiry into these specific management
   recommendations was performed and graded. Results: All ChatGPT-4
   diagnoses were deemed appropriate within the spectrum of potential
   pathologies on a differential. The top diagnosis on the differential was
   identical between surgeons and ChatGPT-4 for 70% of scenarios, and the
   top diagnosis provided by the surgeon appeared as either the first or
   second diagnosis in 90% of scenarios. Overall, 16 of 30 diagnoses
   (53.3%) in the differential were identical. When provided with 10
   expanded vignettes with a single diagnosis, the accuracy of ChatGPT-4
   increased to 100%, with the suitability of management graded as
   appropriate in 90% of cases. Specific information pertaining to
   conservative management, surgical approaches, and related treatments was
   appropriate and accurate in 100% of cases. Conclusions: ChatGPT-4
   provided clinically reasonable diagnoses to triage patient complaints of
   knee pain due to various underlying conditions that were generally
   consistent with differentials provided by sports medicine physicians.
   Diagnostic performance was enhanced when providing additional
   information, allowing ChatGPT-4 to reach high predictive accuracy for
   recommendations concerning management and treatment options. However,
   ChatGPT-4 may show clinically important error rates for diagnosis
   depending on prompting strategy and information provided; therefore,
   further refinements are necessary prior to implementation into clinical
   workflows. Clinical Relevance: Although ChatGPT-4 is increasingly being
   used by patients for health information, the potential for ChatGPT-4 to
   serve as a clinical support tool is unclear. In this study, we found
   that ChatGPT-4 was frequently able to diagnose and triage knee
   complaints appropriately as rated by sports medicine surgeons,
   suggesting that it may eventually be a useful clinical support tool.
ZB 0
Z8 0
ZR 0
ZA 0
ZS 0
TC 6
Z9 6
DA 2025-05-28
UT WOS:001493899100001
PM 38925234
ER

PT J
AU Savage, Thomas
   Wang, John
   Gallo, Robert
   Boukil, Abdessalem
   Patel, Vishwesh
   Safavi-Naini, Seyed Amir Ahmad
   Soroush, Ali
   Chen, Jonathan H.
TI Large language model uncertainty proxies: discrimination and calibration
   for medical diagnosis and treatment
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 32
IS 1
BP 139
EP 149
DI 10.1093/jamia/ocae254
EA OCT 2024
DT Article
PD OCT 12 2024
PY 2024
AB Introduction The inability of large language models (LLMs) to
   communicate uncertainty is a significant barrier to their use in
   medicine. Before LLMs can be integrated into patient care, the field
   must assess methods to estimate uncertainty in ways that are useful to
   physician-users.Objective Evaluate the ability for uncertainty proxies
   to quantify LLM confidence when performing diagnosis and treatment
   selection tasks by assessing the properties of discrimination and
   calibration.Methods We examined confidence elicitation (CE), token-level
   probability (TLP), and sample consistency (SC) proxies across GPT3.5,
   GPT4, Llama2, and Llama3. Uncertainty proxies were evaluated against 3
   datasets of open-ended patient scenarios.Results SC discrimination
   outperformed TLP and CE methods. SC by sentence embedding achieved the
   highest discriminative performance (ROC AUC 0.68-0.79), yet with poor
   calibration. SC by GPT annotation achieved the second-best
   discrimination (ROC AUC 0.66-0.74) with accurate calibration. Verbalized
   confidence (CE) was found to consistently overestimate model
   confidence.Discussion and Conclusions SC is the most effective method
   for estimating LLM uncertainty of the proxies evaluated. SC by sentence
   embedding can effectively estimate uncertainty if the user has a set of
   reference cases with which to re-calibrate their results, while SC by
   GPT annotation is the more effective method if the user does not have
   reference cases and requires accurate raw calibration. Our results
   confirm LLMs are consistently over-confident when verbalizing their
   confidence (CE).
ZS 0
ZA 0
ZB 2
TC 6
ZR 0
Z8 0
Z9 6
DA 2024-10-17
UT WOS:001330240100001
PM 39396184
ER

PT J
AU Sun, Di
   Hadjiiski, Lubomir
   Gormley, John
   Chan, Heang-Ping
   Caoili, Elaine
   Cohan, Richard
   Alva, Ajjai
   Bruno, Grace
   Mihalcea, Rada
   Zhou, Chuan
   Gulani, Vikas
TI Outcome Prediction Using Multi-Modal Information: Integrating Large
   Language Model-Extracted Clinical Information and Image Analysis
SO CANCERS
VL 16
IS 13
AR 2402
DI 10.3390/cancers16132402
DT Article
PD JUL 2024
PY 2024
AB Simple Summary: Predicting the survival of bladder cancer patients
   following cystectomy can offer valuable information for treatment
   planning, decision-making, patient counseling, and resource allocation.
   Our aim was to develop large language model (LLM)-aided multi-modal
   predictive models, based on clinical information and CT images. These
   models achieved performances comparable to those of multi-modal
   predictive models that rely on manually extracted clinical information.
   This study demonstrates the potential of employing LLMs to process
   medical data, and of integrating LLM-processed data into modeling for
   prognosis.
   Survival prediction post-cystectomy is essential for the follow-up care
   of bladder cancer patients. This study aimed to evaluate artificial
   intelligence (AI)-large language models (LLMs) for extracting clinical
   information and improving image analysis, with an initial application
   involving predicting five-year survival rates of patients after radical
   cystectomy for bladder cancer. Data were retrospectively collected from
   medical records and CT urograms (CTUs) of bladder cancer patients
   between 2001 and 2020. Of 781 patients, 163 underwent chemotherapy, had
   pre- and post-chemotherapy CTUs, underwent radical cystectomy, and had
   an available post-surgery five-year survival follow-up. Five AI-LLMs
   (Dolly-v2, Vicuna-13b, Llama-2.0-13b, GPT-3.5, and GPT-4.0) were used to
   extract clinical descriptors from each patient's medical records. As a
   reference standard, clinical descriptors were also extracted manually.
   Radiomics and deep learning descriptors were extracted from CTU images.
   The developed multi-modal predictive model, CRD, was based on the
   clinical (C), radiomics (R), and deep learning (D) descriptors. The LLM
   retrieval accuracy was assessed. The performances of the survival
   predictive models were evaluated using AUC and Kaplan-Meier analysis.
   For the 163 patients (mean age 64 +/- 9 years; M:F 131:32), the LLMs
   achieved extraction accuracies of 74%similar to 87% (Dolly), 76%similar
   to 83% (Vicuna), 82%similar to 93% (Llama), 85%similar to 91% (GPT-3.5),
   and 94%similar to 97% (GPT-4.0). For a test dataset of 64 patients, the
   CRD model achieved AUCs of 0.89 +/- 0.04 (manually extracted
   information), 0.87 +/- 0.05 (Dolly), 0.83 +/- 0.06 similar to 0.84 +/-
   0.05 (Vicuna), 0.81 +/- 0.06 similar to 0.86 +/- 0.05 (Llama), 0.85 +/-
   0.05 similar to 0.88 +/- 0.05 (GPT-3.5), and 0.87 +/- 0.05 similar to
   0.88 +/- 0.05 (GPT-4.0). This study demonstrates the use of LLM
   model-extracted clinical information, in conjunction with imaging
   analysis, to improve the prediction of clinical outcomes, with bladder
   cancer as an initial example.
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
TC 4
Z9 4
DA 2024-07-24
UT WOS:001270395100001
PM 39001463
ER

PT J
AU Lee, Aric
   Ong, Wilson
   Makmur, Andrew
   Ting, Yong Han
   Tan, Wei Chuan
   Lim, Shi Wei Desmond
   Low, Xi Zhen
   Tan, Jonathan Jiong Hao
   Kumar, Naresh
   Hallinan, James T. P. D.
TI Applications of Artificial Intelligence and Machine Learning in Spine
   MRI
SO BIOENGINEERING-BASEL
VL 11
IS 9
AR 894
DI 10.3390/bioengineering11090894
DT Review
PD SEP 2024
PY 2024
AB Diagnostic imaging, particularly MRI, plays a key role in the evaluation
   of many spine pathologies. Recent progress in artificial intelligence
   and its subset, machine learning, has led to many applications within
   spine MRI, which we sought to examine in this review. A literature
   search of the major databases (PubMed, MEDLINE, Web of Science,
   ClinicalTrials.gov) was conducted according to the Preferred Reporting
   Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The
   search yielded 1226 results, of which 50 studies were selected for
   inclusion. Key data from these studies were extracted. Studies were
   categorized thematically into the following: Image Acquisition and
   Processing, Segmentation, Diagnosis and Treatment Planning, and Patient
   Selection and Prognostication. Gaps in the literature and the proposed
   areas of future research are discussed. Current research demonstrates
   the ability of artificial intelligence to improve various aspects of
   this field, from image acquisition to analysis and clinical care. We
   also acknowledge the limitations of current technology. Future work will
   require collaborative efforts in order to fully exploit new technologies
   while addressing the practical challenges of generalizability and
   implementation. In particular, the use of foundation models and
   large-language models in spine MRI is a promising area, warranting
   further research. Studies assessing model performance in real-world
   clinical settings will also help uncover unintended consequences and
   maximize the benefits for patient care.
ZB 0
ZS 0
Z8 0
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-10-07
UT WOS:001322923600001
PM 39329636
ER

PT J
AU Porebski, Benjamin T.
   Balmforth, Matthew
   Browne, Gareth
   Riley, Aidan
   Jamali, Kiarash
   Furst, Maximillian J. L. J.
   Velic, Mirko
   Buchanan, Andrew
   Minter, Ralph
   Vaughan, Tristan
   Holliger, Philipp
TI Rapid discovery of high-affinity antibodies via massively parallel
   sequencing, ribosome display and affinity screening
SO NATURE BIOMEDICAL ENGINEERING
VL 8
IS 3
DI 10.1038/s41551-023-01093-3
EA OCT 2023
DT Article
PD MAR 2024
PY 2024
AB Developing therapeutic antibodies is laborious and costly. Here we
   report a method for antibody discovery that leverages the Illumina HiSeq
   platform to, within 3 days, screen in the order of 108 antibody-antigen
   interactions. The method, which we named 'deep screening', involves the
   clustering and sequencing of antibody libraries, the conversion of the
   DNA clusters into complementary RNA clusters covalently linked to the
   instrument's flow-cell surface on the same location, the in situ
   translation of the clusters into antibodies tethered via ribosome
   display, and their screening via fluorescently labelled antigens. By
   using deep screening, we discovered low-nanomolar nanobodies to a model
   antigen using 4 x 106 unique variants from yeast-display-enriched
   libraries, and high-picomolar single-chain antibody fragment leads for
   human interleukin-7 directly from unselected synthetic repertoires. We
   also leveraged deep screening of a library of 2.4 x 105 sequences of the
   third complementarity-determining region of the heavy chain of an
   anti-human epidermal growth factor receptor 2 (HER2) antibody as input
   for a large language model that generated new single-chain antibody
   fragment sequences with higher affinity for HER2 than those in the
   original library.
   A high-throughput method leveraging the Illumina HiSeq platform to
   screen in the order of 108 individual antibody-antigen interactions
   within 3 days facilitates the rapid discovery of antibodies to
   clinically relevant targets.
ZR 0
ZS 0
TC 20
ZA 0
ZB 11
Z8 1
Z9 21
DA 2023-10-18
UT WOS:001078085500002
PM 37814006
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT J
AU Gwon, Yong Nam
   Kim, Jae Heon
   Chung, Hyun Soo
   Jung, Eun Jee
   Chun, Joey
   Lee, Serin
   Shim, Sung Ryul
TI The Use of Generative AI for Scientific Literature Searches for
   Systematic Reviews: ChatGPT and Microsoft Bing AI Performance Evaluation
SO JMIR MEDICAL INFORMATICS
VL 12
AR e51187
DI 10.2024/1/e51187
DT Article
PD 2024
PY 2024
AB Background: A large language model is a type of artificial intelligence
   (AI) model that opens up great possibilities for health care practice,
   research, and education, although scholars have emphasized the need to
   proactively address the issue of unvalidated and inaccurate information
   regarding its use. One of the best-known large language models is
   ChatGPT (OpenAI). It is believed to be of great help to medical
   research, as it facilitates more efficient data set analysis, code
   generation, and literature review, allowing researchers to focus on
   experimental design as well as drug discovery and development.
   Objective: This study aims to explore the potential of ChatGPT as a real
   -time literature search tool for systematic reviews and clinical
   decision support systems, to enhance their efficiency and accuracy in
   health care settings. Methods: The search results of a published
   systematic review by human experts on the treatment of Peyronie disease
   were selected as a benchmark, and the literature search formula of the
   study was applied to ChatGPT and Microsoft Bing AI as a comparison to
   human researchers. Peyronie disease typically presents with discomfort,
   curvature, or deformity of the penis in association with palpable
   plaques and erectile dysfunction. To evaluate the quality of individual
   studies derived from AI answers, we created a structured rating system
   based on bibliographic information related to the publications. We
   classified its answers into 4 grades if the title existed: A, B, C, and
   F. No grade was given for a fake title or no answer. Results: From
   ChatGPT, 7 (0.5%) out of 1287 identified studies were directly relevant,
   whereas Bing AI resulted in 19 (40%) relevant studies out of 48,
   compared to the human benchmark of 24 studies. In the qualitative
   evaluation, ChatGPT had 7 grade A, 18 grade B, 167 grade C, and 211
   grade F studies, and Bing AI had 19 grade A and 28 grade C studies.
   Conclusions: This is the first study to compare AI and conventional
   human systematic review methods as a real -time literature collection
   tool for evidence-based medicine. The results suggest that the use of
   ChatGPT as a tool for real -time evidence generation is not yet accurate
   and feasible. Therefore, researchers should be cautious about using such
   AI. The limitations of this study using the generative pre-trained
   transformer model are that the search for research topics was not
   diverse and that it did not prevent the hallucination of generative AI.
   However, this study will serve as a standard for future studies by
   providing an index to verify the reliability and consistency of
   generative AI from a user's point of view. If the reliability and
   consistency of AI literature search services are verified, then the use
   of these technologies will help medical research greatly.
ZR 0
TC 0
ZA 0
ZB 0
ZS 0
Z8 0
Z9 0
DA 2024-06-07
UT WOS:001226395600002
ER

PT J
AU Hurley, Eoghan T.
   Crook, Bryan S.
   Lorentz, Samuel G.
   Danilkowicz, Richard M.
   Lau, Brian C.
   Taylor, Dean C.
   Dickens, Jonathan F.
   Anakwenze, Oke
   Klifto, Christopher S.
TI Evaluation High-Quality of Information from ChatGPT (Artificial
   IntelligencedLarge Language Model) Artificial Intelligence on Shoulder
   Stabilization Surgery
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 40
IS 3
DI 10.1016/j.arthro.2023.07.048
EA FEB 2024
DT Article
PD MAR 2024
PY 2024
AB Purpose: To analyze the quality and readability of information regarding
   shoulder stabilization surgery available using an online AI software
   (ChatGPT), using standardized scoring systems, as well as to report on
   the given answers by the AI. Methods: An open AI model (ChatGPT) was
   used to answer 23 commonly asked questions from patients on shoulder
   stabilization surgery. These answers were evaluated for medical
   accuracy, quality, and readability using The JAMA Benchmark criteria,
   DISCERN score, Flesch-Kincaid Reading Ease Score (FRES) & Grade Level
   (FKGL). Results: The JAMA Benchmark criteria score was 0, which is the
   lowest score, indicating no reliable resources cited. The DISCERN score
   was 60, which is considered a good score. The areas that open AI model
   did not achieve full marks were also related to the lack of available
   source material used to compile the answers, and finally some
   shortcomings with information not fully supported by the literature. The
   FRES was 26.2, and the FKGL was considered to be that of a college
   graduate. Conclusions: There was generally high quality in the answers
   given on questions relating to shoulder stabilization surgery, but there
   was a high reading level required to comprehend the information
   presented. However, it is unclear where the answers came from with no
   source material cited. It is important to note that the ChatGPT software
   repeatedly references the need to discuss these questions with an
   orthopaedic surgeon and the importance of shared discussion making, as
   well as compliance with surgeon treatment recommendations. Clinical
   Relevance: As shoulder instability is an injury that predominantly
   affects younger individuals who may use the Internet for information,
   this study shows what information patients may be getting online.
ZA 0
ZS 0
TC 48
ZB 9
ZR 0
Z8 0
Z9 48
DA 2024-04-12
UT WOS:001196995100001
PM 37567487
ER

PT J
AU Nazar, Wojciech
   Nazar, Grzegorz
   Kaminska, Aleksandra
   Danilowicz-Szymanowicz, Ludmila
TI How to Design, Create, and Evaluate an Instruction-Tuning Dataset for
   Large Language Model Training in Health Care: Tutorial From a Clinical
   Perspective
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e70481
DI 10.2196/70481
DT Article
PD MAR 18 2025
PY 2025
AB High-quality data are critical in health care, forming the cornerstone
   for accurate diagnoses, effective treatment plans, and reliable
   conclusions. Similarly, high-quality datasets underpin the development
   and performance of large language models (LLMs). Among these,
   instruction-tuning datasets (ITDs) used for instruction fine-tuning have
   been pivotal in enhancing LLM performance and generalization
   capabilities across diverse tasks. This tutorial provides a
   comprehensive guide to designing, creating, and evaluating ITDs for
   health care applications. Written from a clinical perspective, it aims
   to make the concepts accessible to a broad audience, especially medical
   practitioners. Key topics include identifying useful data sources,
   defining the characteristics of well-designed datasets, and crafting
   high-quality instruction-input-output examples. We explore practical
   approaches to dataset construction, examining the advantages and
   limitations of 3 primary methods: fully manual preparation by expert
   annotators, fully synthetic generation using artificial intelligence
   (AI), and an innovative hybrid approach in which experts draft the
   initial dataset and AI generates additional data. Moreover, we discuss
   strategies for metadata selection and human evaluation to ensure the
   quality and effectiveness of ITDs. By integrating these elements, this
   tutorial provides a structured framework for establishing ITDs. It
   bridges technical and clinical domains, supporting the continued
   interdisciplinary advancement of AI in medicine. Additionally, we
   address the limitations of current practices and propose future
   directions, emphasizing the need for a global, unified frameworkfor
   ITDs. We also arguethat artificial general intelligence (AGI), if
   realized, will not replace empirical research in medicine. AGI will
   depend on human-curated datasets to process and apply medical knowledge.
   At the same time, ITDs will likely remain the most effective method of
   supplying this knowledge to AGI, positioning them as a critical tool in
   AI-driven health care.
ZA 0
Z8 0
ZB 0
ZS 0
TC 0
ZR 0
Z9 0
DA 2025-04-27
UT WOS:001469527400010
PM 40100270
ER

PT J
AU Xu, Shenbo
   Cobzaru, Raluca
   Finkelstein, Stan N
   Welsch, Roy E
   Ng, Kenney
   Middleton, Lefkos
TI Foundational model aided automatic high-throughput drug screening using
   self-controlled cohort study.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2024.08.04.24311480
DT Journal Article; Preprint
PD 2024 Sep 16
PY 2024
AB Background: Developing medicine from scratch to governmental
   authorization and detecting adverse drug reactions (ADR) have barely
   been economical, expeditious, and risk-averse investments. The
   availability of large-scale observational healthcare databases and the
   popularity of large language models offer an unparalleled opportunity to
   enable automatic high-throughput drug screening for both repurposing and
   pharmacovigilance.
   Objectives: To demonstrate a general workflow for automatic
   high-throughput drug screening with the following advantages: (i) the
   association of various exposure on diseases can be estimated; (ii) both
   repurposing and pharmacovigilance are integrated; (iii) accurate
   exposure length for each prescription is parsed from clinical texts;
   (iv) intrinsic relationship between drugs and diseases are removed
   jointly by bioinformatic mapping and large language model - ChatGPT; (v)
   causal-wise interpretations for incidence rate contrasts are provided.
   Methods: Using a self-controlled cohort study design where subjects
   serve as their own control group, we tested the intention-to-treat
   association between medications on the incidence of diseases. Exposure
   length for each prescription is determined by parsing common dosages in
   English free text into a structured format. Exposure period starts from
   initial prescription to treatment discontinuation. A same exposure
   length preceding initial treatment is the control period. Clinical
   outcomes and categories are identified using existing phenotyping
   algorithms. Incident rate ratios (IRR) are tested using uniformly most
   powerful (UMP) unbiased tests.
   Results: We assessed 3,444 medications on 276 diseases on 6,613,198
   patients from the Clinical Practice Research Datalink (CPRD), an UK
   primary care electronic health records (EHR) spanning from 1987 to 2018.
   Due to the built-in selection bias of self-controlled cohort studies,
   ingredients-disease pairs confounded by deterministic medical
   relationships are removed by existing map from RxNorm and nonexistent
   maps by calling ChatGPT. A total of 16,901 drug-disease pairs reveals
   significant risk reduction, which can be considered as candidates for
   repurposing, while a total of 11,089 pairs showed significant risk
   increase, where drug safety might be of a concern instead.
   Conclusions: This work developed a data-driven, nonparametric,
   hypothesis generating, and automatic high-throughput workflow, which
   reveals the potential of natural language processing in
   pharmacoepidemiology. We demonstrate the paradigm to a large
   observational health dataset to help discover potential novel therapies
   and adverse drug effects. The framework of this study can be extended to
   other observational medical databases.
ZS 0
TC 0
ZR 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-08-17
UT MEDLINE:39148849
PM 39148849
ER

PT J
AU Dhanasekaran, Renumathy
   Daugherty, Tami
   Kwo, Paul Yien
   Ghaziani, T. Tara
   Masuoka, Howard
   Elango, Vetri Venthan
TI DEVELOPING A HIGH-PERFORMING CUSTOMIZED AI TUMOR BOARD TOOL FOR HCC
   STAGING AND MANAGEMENT
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1965
BP S884
EP S884
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
TC 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837703466
ER

PT J
AU Huang, Xiaoqin
   Raja, Hina
   Madadi, Yeganeh
   Delsoz, Mohammad
   Poursoroush, Asma
   Kahook, Malik Y.
   Yousefi, Siamak
TI Predicting Glaucoma Before Onset Using a Large Language Model Chatbot
SO AMERICAN JOURNAL OF OPHTHALMOLOGY
VL 266
BP 289
EP 299
DI 10.1016/j.ajo.2024.05.022
EA SEP 2024
DT Article
PD OCT 2024
PY 2024
AB center dot PURPOSE: To investigate the capability of ChatGPT for
   forecasting the conversion from ocular hypertension (OHT) to glaucoma
   based on the Ocular Hypertension Treatment Study (OHTS). center dot
   DESIGN: Retrospective case-control study. center dot PARTICIPANTS: A
   total of 3008 eyes of 1504 subjects from the OHTS were included in the
   study. center dot METHODS: We selected demographic, clinical, ocular,
   optic nerve head, and visual field (VF) parameters 1 year before
   glaucoma development from the OHTS participants. Subsequently, we
   developed queries by converting tabular parameters into textual format
   based on both eyes of all participants. We used the ChatGPT application
   program interface (API) to automatically perform ChatGPT prompting for
   all subjects. We then investigated whether ChatGPT can accurately
   forecast conversion from OHT to glaucoma based on various objective
   metrics. center dot MAIN OUTCOME MEASURE: Accuracy, area under the
   receiver operating characteristic curve (AUC), sensitivity, specificity,
   and weighted F1 score. center dot RESULTS: ChatGPT4.0 demonstrated an
   accuracy of 75%, AUC of 0.67, sensitivity of 56%, specificity of 78%,
   and weighted F1 score of 0.77 in predicting conversion to glaucoma 1
   year before onset. ChatGPT3.5 provided an accuracy of 61%, AUC of 0.62,
   sensitivity of 64%, specificity of 59%, and weighted F1 score of 0.63 in
   predicting conversion to glaucoma 1 year before onset. center dot
   CONCLUSIONS: The performance of ChatGPT4.0 in forecasting development of
   glaucoma 1 year before onset was reasonable. The overall performance of
   ChatGPT4.0 was consistently higher than ChatGPT3.5. Large language
   models (LLMs) hold great promise for augmenting glaucoma research
   capabilities and enhancing clinical care. Future efforts in creating
   ophthalmology-specific LLMs that leverage multimodal data in combination
   with active learning may lead to more useful integration with clinical
   practice and deserve further investigations. (Am J Ophthalmol 2024;266:
   289-299. (c) 2024 Elsevier Inc. All rights are reserved, including those
   for text and data mining, AI training, and similar technologies.)
ZS 0
ZA 0
ZR 0
Z8 0
TC 9
ZB 1
Z9 9
DA 2024-09-25
UT WOS:001316319200001
PM 38823673
ER

PT J
AU Schaden, Eva
   Dier, Helga
   Weixler, Dietmar
   Hasibeder, Walter
   Lenhart-Orator, Andrea
   Roden, Christian
   Fruhwald, Sonja
   Friesenecker, Barbara
CA OGARI
TI Comfort Terminal Care in the intensive care unit: recommendations for
   practice
SO Anaesthesiologie
VL 73
IS 3, Sp. Iss. SI
BP 186
EP 192
DI 10.1007/s00101-024-01382-9
DT Article
PD MAR 2024
PY 2024
AB Background and objective The Working Group on Ethics in Anesthesia and
   Intensive Care Medicine of the Austrian Society for Anesthesiology
   Resuscitation and Intensive Care Medicine (& Ouml;GARI) already
   developed documentation tools for the adaption of therapeutic goals 10
   years ago. Since then the practical implementation of Comfort Terminal
   Care in the daily routine in particular has raised numerous questions,
   which are discussed in this follow-up paper and answered in an
   evidence-based manner whenever possible. Results The practical
   implementation of pain therapy and reduction of anxiety, stress and
   respiratory distress that are indicated in the context of Comfort
   Terminal Care are described in more detail. The measures that are not
   (or no longer) indicated, such as oxygen administration and ventilation
   as well as the administration of fluids and nutrition, are also
   commented on. Furthermore, recommendations are given regarding
   monitoring, (laboratory) findings and drug treatment and the importance
   of nursing actions in the context of Comfort Terminal Care is mentioned.
   Finally, the support for the next of kin and the procedure in the time
   after death are presented. Discussion A change in treatment goals with a
   timely switch to Comfort Terminal Care enables good and humane care for
   seriously ill patients and their relatives at the end of life and the
   appreciation of their previous life with the possibility of positive
   experiences until the end.
TC 0
ZB 0
ZA 0
ZS 0
Z8 0
ZR 0
Z9 0
DA 2024-07-04
UT BCI:BCI202400562911
PM 38315182
ER

PT J
AU Chiang, Chia-Chun
   Luo, Man
   Dumkrieger, Gina
   Trivedi, Shubham
   Chen, Yi-Chieh
   Chao, Chieh-Ju
   Schwedt, Todd J.
   Sarker, Abeed
   Banerjee, Imon
TI A large language model-based generative natural language processing
   framework fine-tuned on clinical notes accurately extracts headache
   frequency from electronic health records
SO HEADACHE
VL 64
IS 4
BP 400
EP 409
DI 10.1111/head.14702
EA MAR 2024
DT Article
PD APR 2024
PY 2024
AB ObjectiveTo develop a natural language processing (NLP) algorithm that
   can accurately extract headache frequency from free-text clinical
   notes.BackgroundHeadache frequency, defined as the number of days with
   any headache in a month (or 4 weeks), remains a key parameter in the
   evaluation of treatment response to migraine preventive medications.
   However, due to the variations and inconsistencies in documentation by
   clinicians, significant challenges exist to accurately extract headache
   frequency from the electronic health record (EHR) by traditional NLP
   algorithms.MethodsThis was a retrospective cross-sectional study with
   patients identified from two tertiary headache referral centers, Mayo
   Clinic Arizona and Mayo Clinic Rochester. All neurology consultation
   notes written by 15 specialized clinicians (11 headache specialists and
   4 nurse practitioners) between 2012 and 2022 were extracted and 1915
   notes were used for model fine-tuning (90%) and testing (10%). We
   employed four different NLP frameworks: (1) ClinicalBERT (Bidirectional
   Encoder Representations from Transformers) regression model, (2)
   Generative Pre-Trained Transformer-2 (GPT-2) Question Answering (QA)
   model zero-shot, (3) GPT-2 QA model few-shot training fine-tuned on
   clinical notes, and (4) GPT-2 generative model few-shot training
   fine-tuned on clinical notes to generate the answer by considering the
   context of included text.ResultsThe mean (standard deviation) headache
   frequency of our training and testing datasets were 13.4 (10.9) and 14.4
   (11.2), respectively. The GPT-2 generative model was the best-performing
   model with an accuracy of 0.92 (0.91, 0.93, 95% confidence interval
   [CI]) and R2 score of 0.89 (0.87, 0.90, 95% CI), and all GPT-2-based
   models outperformed the ClinicalBERT model in terms of exact matching
   accuracy. Although the ClinicalBERT regression model had the lowest
   accuracy of 0.27 (0.26, 0.28), it demonstrated a high R2 score of 0.88
   (0.85, 0.89), suggesting the ClinicalBERT model can reasonably predict
   the headache frequency within a range of <= +/- 3 days, and the R2 score
   was higher than the GPT-2 QA zero-shot model or GPT-2 QA model few-shot
   training fine-tuned model.ConclusionWe developed a robust information
   extraction model based on a state-of-the-art large language model, a
   GPT-2 generative model that can extract headache frequency from EHR
   free-text clinical notes with high accuracy and R2 score. It overcame
   several challenges related to different ways clinicians document
   headache frequency that were not easily achieved by traditional NLP
   models. We also showed that GPT-2-based frameworks outperformed
   ClinicalBERT in terms of accuracy in extracting headache frequency from
   clinical notes. To facilitate research in the field, we released the
   GPT-2 generative model and inference code with open-source license of
   community use in GitHub. Additional fine-tuning of the algorithm might
   be required when applied to different health-care systems for various
   clinical use cases.
   We developed a novel artificial intelligence program that can
   automatically and accurately extract headache frequency from doctors'
   notes. Figuring out how often someone gets headaches is important as it
   helps doctors see how bad the problem is and if treatments are working.
   Our method, using a powerful program called Generative Pre-Trained
   Transformer-2, worked better than older ways and could make big data
   migraine research easier.
ZB 5
ZS 0
Z8 0
ZR 0
ZA 0
TC 9
Z9 9
DA 2024-04-04
UT WOS:001189935500001
PM 38525734
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Sahin, Bahadir
   Genc, Yunus Emre
   Dogan, Kader
   Sener, Tarik Emre
   Sekerci, Cagri Akin
   Tanidir, Yiloeren
   Yuecel, Selcuk
   Tarcan, Tufan
   Cam, Haydar Kamil
TI Evaluating the Performance of ChatGPT in Urology: A Comparative Study of
   Knowledge Interpretation and Patient Guidance
SO JOURNAL OF ENDOUROLOGY
VL 38
IS 8
SI SI
BP 799
EP 808
DI 10.1089/end.2023.0413
EA MAY 2024
DT Article
PD AUG 1 2024
PY 2024
AB Background/Aim: To evaluate the performance of Chat Generative
   Pre-trained Transformer (ChatGPT), a large language model trained by
   Open artificial intelligence. Materials and Methods: This study has
   three main steps to evaluate the effectiveness of ChatGPT in the
   urologic field. The first step involved 35 questions from our
   institution's experts, who have at least 10 years of experience in their
   fields. The responses of ChatGPT versions were qualitatively compared
   with the responses of urology residents to the same questions. The
   second step assesses the reliability of ChatGPT versions in answering
   current debate topics. The third step was to assess the reliability of
   ChatGPT versions in providing medical recommendations and directives to
   patients' commonly asked questions during the outpatient and inpatient
   clinic. Results: In the first step, version 4 provided correct answers
   to 25 questions out of 35 while version 3.5 provided only 19 (71.4% vs
   54%). It was observed that residents in their last year of education in
   our clinic also provided a mean of 25 correct answers, and 4th year
   residents provided a mean of 19.3 correct responses. The second step
   involved evaluating the response of both versions to debate situations
   in urology, and it was found that both versions provided variable and
   inappropriate results. In the last step, both versions had a similar
   success rate in providing recommendations and guidance to patients based
   on expert ratings. Conclusion: The difference between the two versions
   of the 35 questions in the first step of the study was thought to be due
   to the improvement of ChatGPT's literature and data synthesis abilities.
   It may be a logical approach to use ChatGPT versions to inform the
   nonhealth care providers' questions with quick and safe answers but
   should not be used to as a diagnostic tool or make a choice among
   different treatment modalities.
ZS 0
TC 3
ZA 0
ZR 0
ZB 1
Z8 0
Z9 3
DA 2024-06-08
UT WOS:001235063000004
PM 38815140
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Hur, Jihyun K.
   Heffner, Joseph
   Feng, Gloria W.
   Joormann, Jutta
   Rutledge, Robb B.
TI Language sentiment predicts changes in depressive symptoms
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
VL 121
IS 39
AR e2321321121
DI 10.1073/pnas.2321321121
DT Article
PD SEP 16 2024
PY 2024
AB The prevalence of depression is a major societal health concern, and
   there is an ongoing need to develop tools that predict who will become
   depressed. Past research suggests that depression changes the language
   we use, but it is unclear whether language is predictive of worsening
   symptoms. Here, we test whether the sentiment of brief written
   linguistic responses predicts changes in depression. Across two studies
   (N = 467), participants provided responses to neutral open-ended
   questions, narrating aspects of their lives relevant to depression
   (e.g., mood, motivation, sleep). Participants also completed the Patient
   Health Questionnaire (PHQ-9) to assess depressive symptoms and a risky
   decision-making task with periodic measurements of momentary happiness
   to quantify mood dynamics. The sentiment of written responses was
   evaluated by human raters (N = 470), Large Language Models (LLMs;
   ChatGPT 3.5 and 4.0), and the Linguistic Inquiry and Word Count (LIWC)
   tool. We found that language sentiment evaluated by human raters and
   LLMs, but not LIWC, predicted changes in depressive symptoms at a
   three-week follow-up. Using computational modeling, we found that
   language sentiment was associated with current mood, but language
   sentiment predicted symptom changes even after controlling for current
   mood. In summary, we demonstrate a scalable tool that combines brief
   written responses with sentiment analysis by AI tools that matches human
   performance in the prediction of future psychiatric symptoms.
ZA 0
TC 1
ZS 0
ZR 0
ZB 1
Z8 0
Z9 1
DA 2025-03-23
UT WOS:001392568800001
PM 39284070
ER

PT J
AU Luedtke, Nando F.
   Shung, Dennis
TI AUTOMATED EXTRACTION OF RANDOMIZED CONTROLLED TRIAL DATA USING LARGE
   LANGUAGE MODELS: A PILOT STUDY WITH VEDOLIZUMAB META-ANALYSIS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Mo1181
BP S967
EP S967
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
Z8 0
ZA 0
TC 0
ZR 0
ZS 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837704056
ER

PT J
AU Aubreville, Marc
   Ganz, Jonathan
   Ammeling, Jonas
   Rosbach, Emely
   Gehrke, Thomas
   Scherzad, Agmal
   Hackenberg, Stephan
   Goncalves, Miguel
TI Prediction of tumor board procedural recommendations using large
   language models
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1619
EP 1629
DI 10.1007/s00405-024-08947-9
EA SEP 2024
DT Article
PD MAR 2025
PY 2025
AB IntroductionMultidisciplinary tumor boards are meetings where a team of
   medical specialists, including medical oncologists, radiation
   oncologists, radiologists, surgeons, and pathologists, collaborate to
   determine the best treatment plan for cancer patients. While
   decision-making in this context is logistically and cost-intensive, it
   has a significant positive effect on overall cancer survival.Methods We
   evaluated the quality and accuracy of predictions by several large
   language models for recommending procedures by a Head and Neck Oncology
   tumor board, which we adapted for the task using parameter-efficient
   fine-tuning or in-context learning. Records were divided into two sets:
   n=229 used for training and n=100 records for validation of our
   approaches. Randomized, blinded, manual human expert classification was
   used to evaluate the different models.Results Treatment line congruence
   varied depending on the model, reaching up to 86%, with medically
   justifiable recommendations up to 98%. Parameter-efficient fine-tuning
   yielded better outcomes than in-context learning, and larger/commercial
   models tend to perform better.ConclusionProviding precise, medically
   justifiable procedural recommendations for complex oncology patients is
   feasible. Extending the data corpus to a larger patient cohort and
   incorporating the latest guidelines, assuming the model can handle
   sufficient context length, could result in more factual and
   guideline-aligned responses and is anticipated to enhance model
   performance. We, therefore, encourage further research in this direction
   to improve the efficacy and reliability of large language models as
   support in medical decision-making processes.
ZR 0
Z8 0
ZS 0
TC 0
ZA 0
ZB 0
Z9 0
DA 2024-09-19
UT WOS:001310590700001
PM 39266750
ER

PT J
AU Ying, Lingwen
   Li, Sichen
   Chen, Chunyang
   Yang, Fan
   Li, Xin
   Chen, Yao
   Ding, Yu
   Chang, Guoying
   Li, Juan
   Wang, Xiumin
TI Screening/diagnosis of pediatric endocrine disorders through the
   artificial intelligence model in different language settings
SO EUROPEAN JOURNAL OF PEDIATRICS
VL 183
IS 6
BP 2655
EP 2661
DI 10.1007/s00431-024-05527-1
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB This study is aimed at examining the impact of ChatGPT on pediatric
   endocrine and metabolic conditions, particularly in the areas of
   screening and diagnosis, in both Chinese and English modes. A
   40-question questionnaire covering the four most common pediatric
   endocrine and metabolic conditions was posed to ChatGPT in both Chinese
   and English three times each. Six pediatric endocrinologists evaluated
   the responses. ChatGPT performed better when responding to questions in
   English, with an unreliable rate of 7.5% compared to 27.5% for Chinese
   questions, indicating a more consistent response pattern in English.
   Among the reliable questions, the answers were more comprehensive and
   satisfactory in the English mode. We also found disparities in ChatGPT's
   performance when interacting with different target groups and diseases,
   with improved performance for questions posed by clinicians in English
   and better performance for questions related to diabetes and
   overweight/obesity in Chinese for both clinicians and patients. Language
   comprehension, providing incomprehensive answers, and errors in key data
   were the main contributors to the low scores, according to reviewer
   feedback.Conclusion: Despite these limitations, as ChatGPT continues to
   evolve and expand its network, it has significant potential as a
   practical and effective tool for clinical diagnosis and treatment. What
   is Known:center dot The deep learning-based large-language model ChatGPT
   holds great promise for improving clinical practice for both physicians
   and patients and has the potential to increase the speed and accuracy of
   disease screening and diagnosis, as well as enhance the overall
   efficiency of the medical process. However, the reliability and
   appropriateness of AI model responses in specific field remains
   unclear.center dot This study focused on the reliability and
   appropriateness of AI model responses to straightforward and fundamental
   questions related to the four most prevalent pediatric endocrine and
   metabolic disorders, for both healthcare providers and patients, in
   different language scenarios.What is New:center dot The AI model
   performed better when responding to questions in English, with more
   consistent, as well as more comprehensive and satisfactory responses. In
   addition, we also found disparities in ChatGPT's performance when
   interacting with different target groups and different diseases.center
   dot Despite these limitations, as ChatGPT continues to evolve and expand
   its network, it has significant potential as a practical and effective
   tool for clinical diagnosis and treatment.
Z8 0
ZS 0
ZB 0
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-04-01
UT WOS:001187459700002
PM 38502320
ER

PT J
AU Tustumi, Francisco
   Andreollo, Nelson Adami
   de Aguilar-Nascimento, Jose Eduardo
TI FUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT
SO ABCD-ARQUIVOS BRASILEIROS DE CIRURGIA DIGESTIVA-BRAZILIAN ARCHIVES OF
   DIGESTIVE SURGERY
VL 36
IS 1
AR e1727
DI 10.1590/0102-672020230002e1727
DT Review
PD 2023
PY 2023
AB The field of medicine has always been at the forefront of technological
   innovation, Fabricio Ferreira COELHO3 , Paulo HERMAN3 constantly seeking
   new strategies to diagnose, treat, and prevent diseases. Guidelines for
   clinical practice to orientate medical teams regarding diagnosis,
   treatment, and prevention measures have increased over the years. The
   purpose is to gather the most medical knowledge to construct an
   orientation for practice. Evidence-based guidelines follow several main
   characteristics of a systematic RESUMO -Racmonal: O tratamento de
   escolha para pacientes com ipertensao portal review, including
   systematic and unbiased search, selection, and extraction of the source
   of evidence. esquistossomotica com sangramento de varizes e a desconexao
   azigo-portal mais In recent years, the rapid advancement of artificial
   intelligence has provided clinicians and patients esplenetomia (DAPE)
   associad a terapa endoscoica. Porem, estuds mostram aumento with access
   to personalized, data-driven insights, suport and new opportunities for
   healthcare do calibre das varizes em alguns pacientes durante o
   seguimento em longo prazo. Objetmvo: professionals to improve patient
   outcomes, increase efficiency, and reduce costs. One of the most Avaliar
   o impacto da DAPE e tratamento endoscopico pos-operatorio no
   comportamento exciting developments in Artificial Intelligence has been
   the emergence of chatbots. A chatbot is a computer program used to
   simulate conversations with human users. Recently, OpenAI, a research
   das varizes esofagicas e recidiva hemorragica, de pacientes
   esquistossomoticos. Metodos: organization focused on machine learning,
   developed ChatGPT, a large language model that Foram estudados 36
   pacientes com eguimento superior a cinco anos, distribuidos em generates
   human-like text. ChatGPT uses a type of AI known as a deep learning
   model. ChatGPT dois grupos: qued a prssao portal abaixo de 30% e acima
   de 30% compaados com o can quickly search a nd select pieces of evidence
   through numerous databases to provide answers calibre das varizes
   esofagicas no pos-operatorio precoce e tardio alem do indice de recidiva
   to complex questions, reducing the time and effort required to research
   a particular topic manually. hemorragica. Resultados Consequently,
   language models can accelerate the creation of clinical practice
   guidelines. While there is no doubt that ChatGPT has the potential to
   revolutionize the way healthcare is delivered, esofagicas que, durante o
   seguimento aumentaram de calibre e foram controladas com it is essential
   to note that it should not be used as a substitute for human healthcare
   professionals. Instead, ChatGPT should be considered a tool that can be
   used to augment and support the work of o comportamento do calibre das
   varizes no pos-opeatorio precoce nem tardio nem os healthcare
   professionals, helping them to provide better care to their patients.
ZB 6
TC 41
ZR 0
ZA 0
Z8 0
ZS 1
Z9 41
DA 2023-06-08
UT WOS:000993819100001
PM 37162073
ER

PT J
AU Jinia, A. J.
   Chapman, K. L.
   Liu, S.
   Della Biancia, C.
   Li, A.
   Moran, J. M.
TI Challenges in Developing an Al -Based Analysis System for Incident
   Learning
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3198
BP E542
EP E542
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
ZS 0
Z8 0
ZA 0
ZR 0
TC 0
Z9 0
DA 2024-12-16
UT WOS:001325892301523
ER

PT J
AU Bellamkonda, Nikhil
   Farlow, Janice L.
   Haring, Catherine T.
   Sim, Michael W.
   Seim, Nolan B.
   Cannon, Richard B.
   Monroe, Marcus M.
   Agrawal, Amit
   Rocco, James W.
   McCrary, Hilary C.
TI Evaluating the Accuracy of ChatGPT in Common Patient Questions Regarding
   HPV plus Oropharyngeal Carcinoma
SO ANNALS OF OTOLOGY RHINOLOGY AND LARYNGOLOGY
VL 133
IS 9
BP 814
EP 819
DI 10.1177/00034894241259137
EA JUL 2024
DT Article
PD SEP 2024
PY 2024
AB Objectives: Large language model (LLM)-based chatbots such as ChatGPT
   have been publicly available and increasingly utilized by the general
   public since late 2022. This study sought to investigate ChatGPT
   responses to common patient questions regarding Human Papilloma Virus
   (HPV) positive oropharyngeal cancer (OPC). Methods: This was a
   prospective, multi-institutional study, with data collected from high
   volume institutions that perform >50 transoral robotic surgery cases per
   year. The 100 most recent discussion threads including the term "HPV" on
   the American Cancer Society's Cancer Survivors Network's Head and Neck
   Cancer public discussion board were reviewed. The 11 most common
   questions were serially queried to ChatGPT 3.5; answers were recorded. A
   survey was distributed to fellowship trained head and neck oncologic
   surgeons at 3 institutions to evaluate the responses. Results: A total
   of 8 surgeons participated in the study. For questions regarding HPV
   contraction and transmission, ChatGPT answers were scored as clinically
   accurate and aligned with consensus in the head and neck surgical
   oncology community 84.4% and 90.6% of the time, respectively. For
   questions involving treatment of HPV+ OPC, ChatGPT was clinically
   accurate and aligned with consensus 87.5% and 91.7% of the time,
   respectively. For questions regarding the HPV vaccine, ChatGPT was
   clinically accurate and aligned with consensus 62.5% and 75% of the
   time, respectively. When asked about circulating tumor DNA testing, only
   12.5% of surgeons thought responses were accurate or consistent with
   consensus. Conclusion: ChatGPT 3.5 performed poorly with questions
   involving evolving therapies and diagnostics-thus, caution should be
   used when using a platform like ChatGPT 3.5 to assess use of advanced
   technology. Patients should be counseled on the importance of consulting
   their surgeons to receive accurate and up to date recommendations, and
   use LLM's to augment their understanding of these important
   health-related topics.
ZB 0
Z8 0
ZR 0
ZA 0
TC 1
ZS 0
Z9 1
DA 2024-08-06
UT WOS:001280661600001
PM 39075853
ER

PT J
AU Goldenholz, Daniel M.
   Goldenholz, Shira R.
   Habib, Sara
   Westover, M. Brandon
TI Inductive reasoning with large language models: A simulated randomized
   controlled trial for epilepsy
SO EPILEPSY RESEARCH
VL 211
AR 107532
DI 10.1016/j.eplepsyres.2025.107532
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
AB Introduction: To investigate the potential of using artificial
   intelligence (AI), specifically large language models (LLMs), for
   synthesizing information in a simulated randomized clinical trial (RCT)
   for an anti-seizure medication, cenobamate, demonstrating the
   feasibility of inductive reasoning via medical chart review. Methods: An
   LLM-generated simulated RCT was conducted, featuring a placebo arm and a
   full-strength drug arm with a cohort of 240 patients divided 1:1.
   Seizure counts were simulated using a realistic seizure diary simulator.
   The study utilized LLMs to generate clinical notes with four neurologist
   writing styles and random extraneous details. A secondary LLM pipeline
   synthesized data from these notes. The efficacy and safety of cenobamate
   in seizure control were evaluated by both an LLM-based pipeline and a
   human reader. Results: The AI analysis closely mirrored human analysis,
   demonstrating the drug's efficacy with marginal differences (<3 %) in
   identifying both drug efficacy and reported symptoms. The AI
   successfully identified the number of seizures, symptom reports, and
   treatment efficacy, with statistical analysis comparing the 50
   %responder rate and median percentage change between the placebo and
   drug arms, as well as side effect rates in each arm. Discussion: This
   study highlights the potential of AI to accurately analyze noisy
   clinical notes to inductively produce clinical knowledge. Here,
   treatment effect sizes and symptom frequencies derived from unstructured
   simulated notes were inferred despite many distractors. The findings
   emphasize the relevance of AI in future clinical research, offering a
   scalable and efficient alternative to traditional labor-intensive data
   mining.
TC 0
ZS 0
ZB 0
ZR 0
ZA 0
Z8 0
Z9 0
DA 2025-03-10
UT WOS:001437276700001
PM 40020525
ER

PT J
AU Jang, B. S.
   Alcorn, S. R.
   McNutt, T. R.
   Ehsan, U.
TI Hype or Reality: Utility of Large Language Models in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3382
BP E629
EP E630
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZB 0
Z8 0
ZR 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302063
ER

PT J
AU Baumgaertner, Kilian
   Byczkowski, Michael
   Schmid, Tamara
   Muschko, Marc
   Woessner, Philipp
   Gerlach, Axel
   Bonekamp, David
   Schlemmer, Heinz-Peter
   Hohenfellner, Markus
   Goertz, Magdalena
TI Effectiveness of the Medical Chatbot PROSCA to Inform Patients About
   Prostate Cancer: Results of a Randomized Controlled Trial
SO EUROPEAN UROLOGY OPEN SCIENCE
VL 69
BP 80
EP 88
DI 10.1016/j.euros.2024.08.022
EA SEP 2024
DT Article
PD NOV 2024
PY 2024
AB Background and objective: Artificial intelligence (AI)-powered
   conversational agents are increasingly finding application in health
   care, as these can provide patient education at any time. However, their
   effectiveness in medical settings remains largely unexplored. This study
   aimed to assess the impact of the chatbot "PROState cancer
   Conversational Agent"(PROSCA), which was trained to provide validated
   support from diagnostic tests to treatment options for men facing
   prosate cancer (PC) diagnosis. Methods: The chatbot PROSCA, developed by
   urologists at Heidelberg University Hospital and SAP SE, was evaluated
   through a randomized controlled trial (RCT). Patients were assigned to
   either the chatbot group, receiving additional access to PROSCA
   alongside standard information by urologists, or the control group
   (1:1), receiving standard information. A total of 112 men were included,
   of whom 103 gave feedback at study completion. Key findings and
   limitations: Overtime, patients' information needs decreased
   significantly more in the chatbot group than in the control group (p =
   0.035). In the chatbot group, 43/54 men (79.6%) used PROSCA, and all of
   them found it easy to use. Of the men, 71.4% agreed that the chatbot
   improved their informedness about PC and 90.7% would like to use PROSCA
   again. Limitations are study sample size, singlecenter design, and
   specific clinical application. Conclusions and clinical implications:
   With the introduction of the PROSCA chatbot, we created and evaluated an
   innovative, evidence-based AI health information tool as an additional
   source of information for PC. Our RCT results showed significant
   benefits of the chatbot in reducing patients' information needs and
   enhancing their understanding of PC. This easy-to-use AI tool provides
   accurate, timely, and accessible support, demonstrating its value in the
   PC diagnosis process. Future steps include further customization of the
   chatbot's responses and integration with the existing health care
   systems to maximize its impact on patient outcomes. Patient summary:
   This study evaluated an artificial intelligence-powered chatbot- PROSCA,
   a digital tool designed to support men facing prostate cancer diagnosis
   by providing validated information from diagnosis to treatment. Results
   showed that patients who used the chatbot as an additional tool felt
   better informed than those who received standard information from
   urologists. The majority of users appreciated the ease of use of the
   chatbot and expressed a desire to use it again; this suggests that
   PROSCA could be a valuable resource to improve patient understanding in
   prostate cancer diagnosis. (c) 2024 The Author(s). Published by Elsevier
   B.V. on behalf of European Association of Urology. This is an open
   access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZB 0
ZA 0
TC 1
ZS 0
Z8 0
ZR 0
Z9 1
DA 2024-09-29
UT WOS:001318013100001
PM 39329071
ER

PT J
AU Li, Caixia
   Zhao, Yina
   Bai, Yang
   Zhao, Baoquan
   Tola, Yetunde Oluwafunmilayo
   Chan, Carmen W. H.
   Zhang, Meifen
   Fu, Xia
TI Unveiling the Potential of Large Language Models in Transforming Chronic
   Disease Management: Mixed Methods Systematic Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e70535
DI 10.2196/70535
DT Review
PD APR 16 2025
PY 2025
AB Background: Chronic diseases are a major global health burden,
   accounting for nearly three-quarters of the deaths worldwide. Large
   language models (LLMs) are advanced artificial intelligence systems with
   transformative potentialto optimize chronic disease management; however,
   robust evidence is lacking. Objective: This review aims to synthesize
   evidence on the feasibility, opportunities, and challenges of LLMs
   across the disease management spectrum, from prevention to screening,
   diagnosis, treatment, and long-term care. Methods: Following the PRISMA
   (Preferred Reporting Items for Systematic Reviews and Meta-Analysis)
   guidelines, 11 databases (Cochrane Central Register of Controlled
   Trials, CINAHL, Embase, IEEE Xplore, MEDLINE via Ovid, ProQuest Health &
   MedicineCollection, ScienceDirect, Scopus, Web of Science Core
   Collection, China National KnowledgeInternet, and SinoMed) were searched
   on April 17, 2024. Intervention and simulation studies that examined
   LLMs in the management of chronic diseases were included. The
   methodological quality of the included studies was evaluated using a
   rating rubric designed for simulation-based research and the risk of
   bias in nonrandomized studies of interventions tool for
   quasi-experimental studies. Narrative analysis with descriptivefigures
   was used to synthesizethe study findings. Random-effects meta-analyses
   were conducted to assess the pooled effect estimates of the feasibility
   of LLMs in chronic disease management. Results: A total of 20 studies
   examined general-purpose (n=17) and retrieval-augmented
   generation-enhanced LLMs (n=3) for the management of chronic diseases,
   including cancer, cardiovascular diseases, and metabolic disorders. LLMs
   demonstrated feasibility across the chronic disease management spectrum
   by generating relevant, comprehensible, and accurate health
   recommendations (pooled accurate rate 71%, 95% CI 0.59-0.83; I2=88.32%)
   with retrieval-augmented generation-enhanced LLMs having higher accuracy
   rates compared to general-purpose LLMs (odds ratio 2.89, 95% CI
   1.83-4.58; I2=54.45%). LLMs facilitated equitable information access;
   increased patient awareness regarding ailments, preventive measures, and
   treatment options; and promoted self-management behaviors in lifestyle
   modification and symptom coping. Additionally, LLMs facilitate
   compassionate emotional support, social connections, and health care
   resources to improve the health outcomesof chronic diseases. However,
   LLMs face challenges in addressing privacy, language, and cultural
   issues; undertaking advanced tasks, including diagnosis, medication, and
   comorbidity management; and generating personalized regimens with
   real-timeadjustments and multiple modalities. Conclusions:LLMs have
   demonstrated the potentialto transform chronic disease management at the
   individual, social, and health care levels; however, their direct
   application in clinical settings is still in its infancy. A multifaceted
   approach that incorporates robust data security, domain-specific model
   fine-tuning, multimodal data integration, and wearables is crucial for
   the evolution of LLMs into invaluable adjuncts for health care
   professionals to transform chronic disease management. Trial
   Registration: PROSPERO CRD42024545412;
   https://www.crd.york.ac.uk/PROSPERO/view/CRD42024545412
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
TC 0
Z9 0
DA 2025-05-09
UT WOS:001478857800005
PM 40239198
ER

PT J
AU Sabanayagam, Charumathi
   Banu, Riswana
   Lim, Cynthia
   Tham, Yih Chung
   Cheng, Ching-Yu
   Tan, Gavin
   Ekinci, Elif
   Sheng, Bin
   Mckay, Gareth
   Shaw, Jonathan E.
   Matsushita, Kunihiro
   Tangri, Navdeep
   Choo, Jason
   Wong, Tien Y.
TI Artificial intelligence in chronic kidney disease management: a scoping
   review
SO THERANOSTICS
VL 15
IS 10
BP 4566
EP 4578
DI 10.7150/thno.108552
DT Review
PD 2025
PY 2025
AB Rationale: Chronic kidney disease (CKD) is a major public health problem
   worldwide associated with cardiovascular disease, renal failure, and
   mortality. To effectively address this growing burden, innovative
   solutions to management are urgently required. We conducted a scoping
   review to identify key use cases in which artificial intelligence (AI)
   could be leveraged for improving management of CKD. Additionally, we
   examined the challenges faced by AI in CKD management, proposed
   potential solutions to overcome these barriers. Methods: We reviewed 41
   articles published between 2014-2024 which examined various AI
   techniques including machine learning (ML) and deep learning (DL),
   unsupervised clustering, digital twin, natural language processing (NLP)
   and large language models (LLMs) in CKD management. We focused on four
   areas: early detection, risk stratification and prediction, treatment
   recommendations and patient care and communication. Results: We
   identified 41 articles published between 2014-2024 that assessed
   image-based DL models for early detection (n = 6), ML models for risk
   stratification and prediction (n = 14) and treatment recommendations (n
   = 4), and NLP and LLMs for patient care and communication (n = 17). Key
   challenges in integrating AI models into healthcare include technical
   issues such as data quality and access, model accuracy, and
   interpretability, alongside adoption barriers like workflow integration,
   user training, and regulatory approval. Conclusions: There is tremendous
   potential of integrating AI into clinical care of CKD patients to enable
   early detection, prediction, and improved patient outcomes.
   Collaboration among healthcare providers, researchers, regulators, and
   industries is crucial to developing robust protocols that ensure
   compliance with legal standards, while minimizing risks and maintaining
   patient
Z8 0
ZA 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-05-02
UT WOS:001473295700018
PM 40225559
ER

PT J
AU Schwartz, Ilan S.
   Link, Katherine E.
   Daneshjou, Roxana
   Cortes-Penfield, Nicolas
TI Black Box Warning: Large Language Models and the Future of Infectious
   Diseases Consultation
SO CLINICAL INFECTIOUS DISEASES
VL 78
IS 4
BP 860
EP 866
DI 10.1093/cid/ciad633
EA NOV 2023
DT Article
PD APR 10 2024
PY 2024
AB Large language models (LLMs) are artificial intelligence systems trained
   by deep learning algorithms to process natural language and generate
   text responses to user prompts. Some approach physician performance on a
   range of medical challenges, leading some proponents to advocate for
   their potential use in clinical consultation and prompting some
   consternation about the future of cognitive specialties. However, LLMs
   currently have limitations that preclude safe clinical deployment in
   performing specialist consultations, including frequent confabulations,
   lack of contextual awareness crucial for nuanced diagnostic and
   treatment plans, inscrutable and unexplainable training data and
   methods, and propensity to recapitulate biases. Nonetheless, considering
   the rapid improvement in this technology, growing calls for clinical
   integration, and healthcare systems that chronically undervalue
   cognitive specialties, it is critical that infectious diseases
   clinicians engage with LLMs to enable informed advocacy for how they
   should-and shouldn't-be used to augment specialist care.
   Large language models (LLMs), advanced artificial intelligence systems
   capable of generating natural language, could revolutionize healthcare,
   including current models of specialist consultation. Infectious diseases
   clinicians must urgently engage with and understand limitations of LLMs
   to advocate for their responsible integration.
   Graphical Abstract
   https://tidbitapp.io/tidbits/black-box-warning-large-language-models-and
   -clinical-consultation-in-infectious-disease
ZB 10
ZR 0
TC 50
Z8 1
ZS 0
ZA 0
Z9 51
DA 2023-11-30
UT WOS:001102860600001
PM 37971399
ER

PT J
AU Chuang, Yu-Neng
   Tang, Ruixiang
   Jiang, Xiaoqian
   Hu, Xia
TI SPeC: A Soft Prompt-Based Calibration on Performance Variability of
   Large Language Model in Clinical Notes Summarization
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 151
AR 104606
DI 10.1016/j.jbi.2024.104606
EA FEB 2024
DT Article
PD MAR 2024
PY 2024
AB Electronic health records (EHRs) store an extensive array of patient
   information, encompassing medical histories, diagnoses, treatments, and
   test outcomes. These records are crucial for enabling healthcare
   providers to make well-informed decisions regarding patient care.
   Summarizing clinical notes further assists healthcare professionals in
   pinpointing potential health risks and making better -informed
   decisions. This process contributes to reducing errors and enhancing
   patient outcomes by ensuring providers have access to the most pertinent
   and current patient data. Recent research has shown that incorporating
   instruction prompts with large language models (LLMs) substantially
   boosts the efficacy of summarization tasks. However, we show that this
   approach also leads to increased performance variance, resulting in
   significantly distinct summaries even when instruction prompts share
   similar meanings. To tackle this challenge, we introduce a model
   -agnostic Soft Prompt-BasedCalibration (SPeC) pipeline that employs soft
   prompts to lower variance while preserving the advantages of prompt
   -based summarization. Experimental findings on multiple clinical note
   tasks and LLMs indicate that our method not only bolsters performance
   but also effectively regulates variance across different LLMs, providing
   a more consistent and reliable approach to summarizing critical medical
   information.
TC 9
ZB 2
ZS 0
Z8 1
ZA 0
ZR 0
Z9 9
DA 2024-04-01
UT WOS:001187921900001
PM 38325698
ER

PT J
AU Garcia, Danilo
   Granjard, Alexandre
   Vanhee, Lois
   Berg, Matilda
   Andersson, Gerhard
   Lasota, Marta
   Sikstrom, Sverker
TI AI-driven analyzes of open-ended responses to assess outcomes of
   internet-based cognitive behavioral therapy (ICBT) in adolescents with
   anxiety and depression comorbidity
SO JOURNAL OF AFFECTIVE DISORDERS
VL 381
BP 659
EP 668
DI 10.1016/j.jad.2025.04.003
EA APR 2025
DT Article
PD JUL 15 2025
PY 2025
AB Objective: Although patients prefer describing their problems using
   words, mental health interventions are commonly evaluated using rating
   scales. Fortunately, recent advances in natural language processing
   (i.e., AI-methods) yield new opportunities to quantify people's own
   mental health descriptions. Our aim was to explore whether responses to
   open-ended questions, quantified using AI, provide additional value in
   measuring intervention outcomes compared to traditional rating scales.
   Method: Swedish adolescents (N = 44) who received Internet-based
   Cognitive Behavioral Therapy (ICBT) for eight weeks completed (pre/post)
   scales measuring anxiety and depression and three open-ended questions
   (related to depression, anxiety and general mental health). The language
   responses were quantified using a large language model and quantitative
   methods to predict mental health as measured by rating scales, valence
   (i.e., words' positive/negative affectivity), and semantic content
   (i.e., meaning). Results: Similar to the rating scales, language
   measures revealed statistically significant health improvements between
   pre and post measures such as reduced depression and anxiety symptoms
   and an increase in the use of words conveying positive emotions and
   different meanings (e.g., pre-intervention: "anxious", depressed;
   post-intervention: "happy", "the future"). Notably, the health changes
   identified through semantic content measures remained statistically
   significant even after accounting for the changes captured by the rating
   scales. Conclusion: Language responses analyzed using AI-methods
   assessed outcomes with fewer items, demonstrating effectiveness and
   accuracy comparable to traditional rating scales. Additionally, this
   approach provided valuable insights into patients' well-being beyond
   mere symptom reduction, thus highlighting areas of improvement that
   rating scales often overlook. Since patients often prefer using natural
   language to express their mental health, this method could complement,
   and address comprehension issues associated fixed-item questionnaires.
ZS 0
Z8 0
TC 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2025-05-06
UT WOS:001476641800001
PM 40187428
ER

PT J
AU Del Buono, Milan
   Wu, Gloria
   Lee, David A.
   Wong, Adrial
   Zhao, Weichen
TI Do AI models provide medically accurate guidance for glaucoma patients?
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1642
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZS 0
TC 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 0
DA 2024-12-01
UT WOS:001312227704270
ER

PT J
AU Collins, Louis
   Pinero, Lisa
   Keenan, Emily
   Finkel, Diana
TI USING AI-GENERATED PATIENT INFORMATION SHEETS ON COLONOSCOPIES TO
   IMPROVE DOCTOR-PATIENT COMMUNICATION
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1988
BP S893
EP S893
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZA 0
ZB 0
ZR 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2024-10-30
UT WOS:001282837703489
ER

PT J
AU Silverman, Anna L.
   Sushil, Madhumita
   Bhasuran, Balu
   Ludwig, Dana
   Buchanan, James
   Racz, Rebecca
   Parakala, Mahalakshmi
   El-Kamary, Samer
   Ahima, Ohenewaa
   Belov, Artur
   Choi, Lauren
   Billings, Monisha
   Li, Yan
   Habal, Nadia
   Liu, Qi
   Tiwari, Jawahar
   Butte, Atul J.
   Rudrapatna, Vivek A.
TI Algorithmic Identification of Treatment-Emergent Adverse Events From
   Clinical Notes Using Large Language Models: A Pilot Study in
   Inflammatory Bowel Disease
SO CLINICAL PHARMACOLOGY & THERAPEUTICS
VL 115
IS 6
BP 1391
EP 1399
DI 10.1002/cpt.3226
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB Outpatient clinical notes are a rich source of information regarding
   drug safety. However, data in these notes are currently underutilized
   for pharmacovigilance due to methodological limitations in text mining.
   Large language models (LLMs) like Bidirectional Encoder Representations
   from Transformers (BERT) have shown progress in a range of natural
   language processing tasks but have not yet been evaluated on adverse
   event (AE) detection. We adapted a new clinical LLM, University of
   California - San Francisco (UCSF)-BERT, to identify serious AEs (SAEs)
   occurring after treatment with a non-steroid immunosuppressant for
   inflammatory bowel disease (IBD). We compared this model to other
   language models that have previously been applied to AE detection. We
   annotated 928 outpatient IBD notes corresponding to 928 individual
   patients with IBD for all SAE-associated hospitalizations occurring
   after treatment with a non-steroid immunosuppressant. These notes
   contained 703 SAEs in total, the most common of which was failure of
   intended efficacy. Out of eight candidate models, UCSF-BERT achieved the
   highest numerical performance on identifying drug-SAE pairs from this
   corpus (accuracy 88-92%, macro F1 61-68%), with 5-10% greater accuracy
   than previously published models. UCSF-BERT was significantly superior
   at identifying hospitalization events emergent to medication use (P <
   0.01). LLMs like UCSF-BERT achieve numerically superior accuracy on the
   challenging task of SAE detection from clinical notes compared with
   prior methods. Future work is needed to adapt this methodology to
   improve model performance and evaluation using multicenter data and
   newer architectures like Generative pre-trained transformer (GPT). Our
   findings support the potential value of using large language models to
   enhance pharmacovigilance.
Z8 0
ZB 0
ZR 0
ZA 0
ZS 0
TC 6
Z9 6
DA 2024-03-28
UT WOS:001181392200001
PM 38459719
ER

PT J
AU Hager, Paul
   Jungmann, Friederike
   Holland, Robbie
   Bhagat, Kunal
   Hubrecht, Inga
   Knauer, Manuel
   Vielhauer, Jakob
   Makowski, Marcus
   Braren, Rickmer
   Kaissis, Georgios
   Rueckert, Daniel
TI Evaluation and mitigation of the limitations of large language models in
   clinical decision-making
SO NATURE MEDICINE
VL 30
IS 9
DI 10.1038/s41591-024-03097-1
EA JUL 2024
DT Article
PD SEP 2024
PY 2024
AB Clinical decision-making is one of the most impactful parts of a
   physician's responsibilities and stands to benefit greatly from
   artificial intelligence solutions and large language models (LLMs) in
   particular. However, while LLMs have achieved excellent performance on
   medical licensing exams, these tests fail to assess many skills
   necessary for deployment in a realistic clinical decision-making
   environment, including gathering information, adhering to guidelines,
   and integrating into clinical workflows. Here we have created a curated
   dataset based on the Medical Information Mart for Intensive Care
   database spanning 2,400 real patient cases and four common abdominal
   pathologies as well as a framework to simulate a realistic clinical
   setting. We show that current state-of-the-art LLMs do not accurately
   diagnose patients across all pathologies (performing significantly worse
   than physicians), follow neither diagnostic nor treatment guidelines,
   and cannot interpret laboratory results, thus posing a serious risk to
   the health of patients. Furthermore, we move beyond diagnostic accuracy
   and demonstrate that they cannot be easily integrated into existing
   workflows because they often fail to follow instructions and are
   sensitive to both the quantity and order of information. Overall, our
   analysis reveals that LLMs are currently not ready for autonomous
   clinical decision-making while providing a dataset and framework to
   guide future studies.
   Using a curated dataset of 2,400 cases and a framework to simulate a
   realistic clinical setting, current large language models are shown to
   incur substantial pitfalls when used for autonomous clinical
   decision-making.
ZA 0
TC 80
Z8 0
ZR 0
ZB 13
ZS 0
Z9 80
DA 2024-07-12
UT WOS:001262233500004
PM 38965432
ER

PT J
AU Goh, Ethan
   Gallo, Robert J.
   Strong, Eric
   Weng, Yingjie
   Kerman, Hannah
   Freed, Jason A.
   Cool, Josephine A.
   Kanjee, Zahir
   Lane, Kathleen P.
   Parsons, Andrew S.
   Ahuja, Neera
   Horvitz, Eric
   Yang, Daniel
   Milstein, Arnold
   Olson, Andrew P. J.
   Hom, Jason
   Chen, Jonathan H.
   Rodman, Adam
TI GPT-4 assistance for improvement of physician performance on patient
   care tasks: a randomized controlled trial
SO NATURE MEDICINE
VL 31
IS 4
DI 10.1038/s41591-024-03456-y
EA FEB 2025
DT Article
PD APR 2025
PY 2025
AB While large language models (LLMs) have shown promise in diagnostic
   reasoning, their impact on management reasoning, which involves
   balancing treatment decisions and testing strategies while managing
   risk, is unknown. This prospective, randomized, controlled trial
   assessed whether LLM assistance improves physician performance on
   open-ended management reasoning tasks compared to conventional
   resources. From November 2023 to April 2024, 92 practicing physicians
   were randomized to use either GPT-4 plus conventional resources or
   conventional resources alone to answer five expert-developed clinical
   vignettes in a simulated setting. All cases were based on real,
   de-identified patient encounters, with information revealed sequentially
   to mirror the nature of clinical environments. The primary outcome was
   the difference in total score between groups on expert-developed scoring
   rubrics. Secondary outcomes included domain-specific scores and time
   spent per case. Physicians using the LLM scored significantly higher
   compared to those using conventional resources (mean difference = 6.5%,
   95% confidence interval (CI) = 2.7 to 10.2, P < 0.001). LLM users spent
   more time per case (mean difference = 119.3 s, 95% CI = 17.4 to 221.2, P
   = 0.02). There was no significant difference between LLM-augmented
   physicians and LLM alone (-0.9%, 95% CI = -9.0 to 7.2, P = 0.8). LLM
   assistance can improve physician management reasoning in complex
   clinical vignettes compared to conventional resources and should be
   validated in real clinical practice.
ZS 0
ZB 1
ZR 0
TC 8
Z8 0
ZA 0
Z9 8
DA 2025-02-14
UT WOS:001415955000001
PM 39910272
ER

PT J
AU Jin, Qiao
   Wang, Zifeng
   Floudas, Charalampos S.
   Chen, Fangyuan
   Gong, Changlin
   Bracken-Clarke, Dara
   Xue, Elisabetta
   Yang, Yifan
   Sun, Jimeng
   Lu, Zhiyong
TI Matching patients to clinical trials with large language models
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 9074
DI 10.1038/s41467-024-53081-z
DT Article
PD NOV 18 2024
PY 2024
AB Patient recruitment is challenging for clinical trials. We introduce
   TrialGPT, an end-to-end framework for zero-shot patient-to-trial
   matching with large language models. TrialGPT comprises three modules:
   it first performs large-scale filtering to retrieve candidate trials
   (TrialGPT-Retrieval); then predicts criterion-level patient eligibility
   (TrialGPT-Matching); and finally generates trial-level scores
   (TrialGPT-Ranking). We evaluate TrialGPT on three cohorts of 183
   synthetic patients with over 75,000 trial annotations.
   TrialGPT-Retrieval can recall over 90% of relevant trials using less
   than 6% of the initial collection. Manual evaluations on 1015
   patient-criterion pairs show that TrialGPT-Matching achieves an accuracy
   of 87.3% with faithful explanations, close to the expert performance.
   The TrialGPT-Ranking scores are highly correlated with human judgments
   and outperform the best-competing models by 43.8% in ranking and
   excluding trials. Furthermore, our user study reveals that TrialGPT can
   reduce the screening time by 42.6% in patient recruitment. Overall,
   these results have demonstrated promising opportunities for
   patient-to-trial matching with TrialGPT.
   Patient recruitment is challenging for clinical trials. Here, the
   authors introduce TrialGPT, an end-to-end framework for zero-shot
   patient-to-trial matching with large language models.
ZA 0
ZR 0
ZS 0
ZB 2
Z8 3
TC 27
Z9 29
DA 2025-02-14
UT WOS:001359289300020
PM 39557832
ER

PT J
AU Griewing, Sebastian
   Knitza, Johannes
   Boekhoff, Jelena
   Hillen, Christoph
   Lechner, Fabian
   Wagner, Uwe
   Wallwiener, Markus
   Kuhn, Sebastian
TI Evolution of publicly available large language models for complex
   decision-making in breast cancer care
SO ARCHIVES OF GYNECOLOGY AND OBSTETRICS
VL 310
IS 1
BP 537
EP 550
DI 10.1007/s00404-024-07565-4
EA MAY 2024
DT Article
PD JUL 2024
PY 2024
AB Purpose This study investigated the concordance of five different
   publicly available Large Language Models (LLM) with the recommendations
   of a multidisciplinary tumor board regarding treatment recommendations
   for complex breast cancer patient profiles.Methods Five LLM, including
   three versions of ChatGPT (version 4 and 3.5, with data access until
   September 3021 and January 2022), Llama2, and Bard were prompted to
   produce treatment recommendations for 20 complex breast cancer patient
   profiles. LLM recommendations were compared to the recommendations of a
   multidisciplinary tumor board (gold standard), including surgical,
   endocrine and systemic treatment, radiotherapy, and genetic testing
   therapy options.Results GPT4 demonstrated the highest concordance
   (70.6%) for invasive breast cancer patient profiles, followed by GPT3.5
   September 2021 (58.8%), GPT3.5 January 2022 (41.2%), Llama2 (35.3%) and
   Bard (23.5%). Including precancerous lesions of ductal carcinoma in
   situ, the identical ranking was reached with lower overall concordance
   for each LLM (GPT4 60.0%, GPT3.5 September 2021 50.0%, GPT3.5 January
   2022 35.0%, Llama2 30.0%, Bard 20.0%). GPT4 achieved full concordance
   (100%) for radiotherapy. Lowest alignment was reached in recommending
   genetic testing, demonstrating a varying concordance (55.0% for GPT3.5
   January 2022, Llama2 and Bard up to 85.0% for GPT4).Conclusion This
   early feasibility study is the first to compare different LLM in breast
   cancer care with regard to changes in accuracy over time, i.e., with
   access to more data or through technological upgrades. Methodological
   advancement, i.e., the optimization of prompting techniques, and
   technological development, i.e., enabling data input control and secure
   data processing, are necessary in the preparation of large-scale and
   multicenter studies to provide evidence on their safe and reliable
   clinical application. At present, safe and evidenced use of LLM in
   clinical breast cancer care is not yet feasible.
ZB 3
Z8 0
ZA 0
ZR 0
ZS 0
TC 14
Z9 14
DA 2024-06-04
UT WOS:001233695900001
PM 38806945
ER

PT J
AU Li, Yiming
   Zhao, Jeff
   Li, Manqi
   Dang, Yifang
   Yu, Evan
   Li, Jianfu
   Sun, Zenan
   Hussein, Usama
   Wen, Jianguo
   Abdelhameed, Ahmed M.
   Mai, Junhua
   Li, Shenduo
   Yu, Yue
   Hu, Xinyue
   Yang, Daowei
   Feng, Jingna
   Li, Zehan
   He, Jianping
   Tao, Wei
   Duan, Tiehang
   Lou, Yanyan
   Li, Fang
   Tao, Cui
TI RefAI: a GPT-powered retrieval-augmented generative tool for biomedical
   literature recommendation and summarization
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 9
BP 2030
EP 2039
DI 10.1093/jamia/ocae129
EA JUN 2024
DT Article
PD JUN 10 2024
PY 2024
AB Objectives: Precise literature recommendation and summarization are
   crucial for biomedical professionals. While the latest iteration of
   generative pretrained transformer (GPT) incorporates 2 distinct
   modes-real-time search and pretrained model utilization-it encounters
   challenges in dealing with these tasks. Specifically, the real-time
   search can pinpoint some relevant articles but occasionally provides
   fabricated papers, whereas the pretrained model excels in generating
   well-structured summaries but struggles to cite specific sources. In
   response, this study introduces RefAI, an innovative retrieval-augmented
   generative tool designed to synergize the strengths of large language
   models (LLMs) while overcoming their limitations. Materials and Methods:
   RefAI utilized PubMed for systematic literature retrieval, employed a
   novel multivariable algorithm for article recommendation, and leveraged
   GPT-4 turbo for summarization. Ten queries under 2 prevalent topics
   ("cancer immunotherapy and target therapy" and "LLMs in medicine") were
   chosen as use cases and 3 established counterparts (ChatGPT-4,
   ScholarAI, and Gemini) as our baselines. The evaluation was conducted by
   10 domain experts through standard statistical analyses for performance
   comparison. Results: The overall performance of RefAI surpassed that of
   the baselines across 5 evaluated dimensions-relevance and quality for
   literature recommendation, accuracy, comprehensiveness, and reference
   integration for summarization, with the majority exhibiting
   statistically significant improvements (P-values <.05). Discussion:
   RefAI demonstrated substantial improvements in literature recommendation
   and summarization over existing tools, addressing issues like fabricated
   papers, metadata inaccuracies, restricted recommendations, and poor
   reference integration. Conclusion: By augmenting LLM with external
   resources and a novel ranking algorithm, RefAI is uniquely capable of
   recommending high-quality literature and generating well-structured
   summaries, holding the potential to meet the critical needs of
   biomedical professionals in navigating and synthesizing vast amounts of
   scientific literature.
Z8 1
ZA 0
ZS 0
ZR 0
ZB 3
TC 13
Z9 14
DA 2024-06-17
UT WOS:001243328800001
PM 38857454
ER

PT J
AU Giannuzzi, Federico
   Carla, Matteo Mario
   Hu, Lorenzo
   Cestrone, Valentina
   Caputo, Carmela Grazia
   Sammarco, Maria Grazia
   Savino, Gustavo
   Rizzo, Stanislao
   Blasi, Maria Antonietta
   Pagliara, Monica Maria
TI Artificial intelligence with ChatGPT 4: a large language model in
   support of ocular oncology cases
SO INTERNATIONAL OPHTHALMOLOGY
VL 45
IS 1
AR 59
DI 10.1007/s10792-024-03399-w
DT Article
PD FEB 7 2025
PY 2025
AB PurposeTo evaluate ChatGPT's ability to analyze comprehensive case
   descriptions of patients with uveal melanoma and provide recommendations
   for the most appropriate management.DesignRetrospective analysis of
   ocular oncology patients' medical records.Subjects.Forty patients
   treated for uveal melanoma between May 2019 and October
   2023.DesignRetrospective analysis of ocular oncology patients' medical
   records.Subjects.Forty patients treated for uveal melanoma between May
   2019 and October 2023.DesignRetrospective analysis of ocular oncology
   patients' medical records.Subjects.Forty patients treated for uveal
   melanoma between May 2019 and October 2023.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.MethodsWe uploaded each case description into the ChatGPT
   interface (version 4.0) and asked the model to provide realistic
   treatment options by asking the question, "What type of treatment do you
   recommend?" The accuracy of decisions produced by ChatGPT was compared
   to those recorded in patients' files and the treatment recommendations
   provided by three ocular oncologists, each with more than 10 years of
   experience.Main outcome measures.The primary objective of this research
   was to assess the accuracy of ChatGPT replies in ocular oncology cases,
   analyzing its competence in both straightforward and intricate
   situations. Our secondary purpose was to assess the concordance between
   the responses of ChatGPT and those of ocular oncology specialists when
   faced with analogous clinical scenarios.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.ResultsChatGPT's surgical choices matched those in patients'
   files in 55% of cases (22 out of 40). ChatGPT options were agreed upon
   by 50%, 55%, and 57% of the three ocular oncology specialists. The
   investigation revealed significant differences between ChatGPT's
   responses and those of the three cancer specialists when compared to
   patients' files (p = 0.003, p = 0.001, and p = 0.001). ChatGPT's
   surgical responses matched with patient data in 18 out of 24 cases
   (75%), excluding enucleation cases.
   The decisions matched with the three ocular oncology specialists in
   17/24, 18/24, and 18/24 cases, reflecting agreements of 70%, 75%, and
   75%, respectively. The decisions made by ChatGPT were not significantly
   different from those of the three professionals in this cohort (p =
   0.50, p = 0.36, and p = 0.36 for ChatGPT compared to specialists 1, 2,
   and 3).ConclusionChatGPT exhibited a level of proficiency that was
   comparable to that of trained ocular oncology specialists. However, it
   exhibited its limitations when evaluating more complex scenarios, such
   as extrascleral extension or infiltration of the optic nerve, when a
   comprehensive evaluation of the patient is therefore necessary.
ZS 0
Z8 0
ZB 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-04-25
UT WOS:001468330700001
PM 39918656
ER

PT J
AU Shaheen, Abdulla
   Afflitto, Gabriele Gallo
   Swaminathan, Swarup S.
TI ChatGPT-Assisted Classification fi cation of Postoperative Bleeding
   Following Microinvasive Glaucoma Surgery Using Electronic Health Record
   Data
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100602
DI 10.1016/j.xops.2024.100602
EA SEP 2024
DT Article
PD FEB 2025
PY 2025
AB Purpose: To evaluate the performance of a large language model (LLM) in
   classifying electronic health record (EHR) text, and to use this
   classification to evaluate the type and resolution of hemorrhagic events
   (HEs) after microinvasive glaucoma surgery (MIGS). Design: Retrospective
   cohort study. Participants: Eyes from the Bascom Palmer Glaucoma
   Repository. Methods: Eyes that underwent MIGS between July 1, 2014 and
   February 1, 2022 were analyzed. Chat Generative Pre-trained Transformer
   (ChatGPT) was used to classify deidentified EHR anterior chamber
   examination text into HE categories (no hyphema, microhyphema, clot, and
   hyphema). Agreement between classifications by ChatGPT and a glaucoma
   specialist was evaluated using Cohen's Kappa and precision-recall (PR)
   curve. Time to resolution of HEs was assessed using Cox
   proportional-hazards models. Goniotomy HE resolution was evaluated by
   degree of angle treatment (90 degrees-179 degrees,180 degrees-269
   degrees, 270 degrees-360 degrees). degrees-360 degrees ). Logistic
   regression was used to identify HE risk factors. Main Outcome Measures:
   Accuracy of ChatGPT HE classification and incidence and resolution of
   HEs. Results: The study included 434 goniotomy eyes (368 patients) and
   528 Schlemm's canal stent (SCS) eyes (390 patients). Chat Generative
   Pre-trained Transformer facilitated excellent HE classification (Cohen's
   kappa 0.93, area under PR curve 0.968). Using ChatGPT classifications,
   at postoperative day 1, HEs occurred in 67.8% of goniotomy and 25.2% of
   SCS eyes (P < 0.001). The 270 degrees degrees to 360 degrees degrees
   goniotomy group had the highest HE rate (84.0%, P < 0.001). At
   postoperative week 1, HEs were observed in 43.4% and 11.3% of goniotomy
   and SCS eyes, respectively (P < 0.001). By postoperative month 1, HE
   rates were 13.3% and 1.3% among goniotomy and SCS eyes, respectively (P
   < 0.001). Time to HE resolution differed between the goniotomy angle
   groups (log-rank P = 0.034); median time to resolution was 10, 10, and
   15 days for the 90 degrees degrees to 179 degrees, 180 degrees to 269
   degrees, and 270 degrees to 360 degrees groups, respectively. Risk
   factor analysis demonstrated greater goniotomy angle was the only
   significant predictor of HEs (odds ratio for 270 degrees-360 degrees:
   360 degrees : 4.08, P < 0.001). Conclusions: Large language models can
   be effectively used to classify longitudinal EHR free-text examination
   data with high accuracy, highlighting a promising direction for future
   LLM-assisted research and clinical decision support. Hemorrhagic events
   are relatively common self-resolving complications that occur more often
   in goniotomy cases and with larger goniotomy treatments. Time to HE
   resolution differs significantly between goniotomy groups. Financial
   Disclosure(s):Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100602<feminine ordinal indicator>2024 by the American
   Academy of Ophthalmology. This is an open access article under the CC
   BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
DA 2024-10-05
UT WOS:001321792000001
PM 39380881
ER

PT J
AU Wu, Gloria
   Del Buono, Milan
   Wong, Adrial
   Zhao, Weichen
   Nguyen, Mary
   Satheesh, Swetha
   Lee, David A.
TI Can Al Large Language Models and Al Assistants help educate our
   Retinitis Pigmentosa (RP) patients?
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 2327
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-12-01
UT WOS:001312227706289
ER

PT J
AU Nwachukwu, Benedict U.
   Varady, Nathan H.
   Allen, Answorth A.
   Dines, Joshua S.
   Altchek, David W.
   Williams III, Riley J.
   Kunze, Kyle N.
TI Currently Available Large Language Models Do Not Provide Musculoskeletal
   Treatment Recommendations That Are Concordant With Evidence-Based
   Clinical Practice Guidelines
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 2
DI 10.1016/j.arthro.2024.07.040
EA JAN 2025
DT Article
PD FEB 2025
PY 2025
AB Purpose: To determine whether several leading, commercially available
   large language models (LLMs) provide treatment recommendations
   concordant with evidence-based clinical practice guidelines (CPGs)
   developed by the American Academy of Orthopaedic Surgeons (AAOS).
   Methods: All CPGs concerning the management of rotator cuff tears (n =
   33) and anterior cruciate ligament injuries (n = 15) were extracted from
   the AAOS. Treatment recommendations from ChatGenerative Pretrained
   Transformer version 4 (ChatGPT-4), Gemini, Mistral-7B, and Claude-3 were
   graded by 2 blinded physicians as being concordant, discordant, or
   indeterminate (i.e., neutral response without definitive recommendation)
   with respect to AAOS CPGs. The overall concordance between LLM and AAOS
   recommendations was quantified, and the comparative overall concordance
   of recommendations among the 4 LLMs was evaluated through the Fisher
   exact test. Results: Overall, 135 responses (70.3%) were concordant, 43
   (22.4%) were indeterminate, and 14 (7.3%) were discordant. Inter-rater
   reliability for concordance classification was excellent (K = 0.92).
   Concordance with AAOS CPGs was most frequently observed with ChatGPT-4
   (n = 38, 79.2%) and least frequently observed with Mistral-7B (n = 28,
   58.3%). Indeterminate recommendations were most frequently observed with
   Mistral-7B (n = 17, 35.4%) and least frequently observed with Claude-3
   (n = 8, 6.7%). Discordant recommendations were most frequently observed
   with Gemini (n = 6, 12.5%) and least frequently observed with ChatGPT-4
   (n = 1, 2.1%). Overall, no statistically significant difference in
   concordant recommendations was observed across LLMs (P = .12). Of all
   recommendations, only 20 (10.4%) were transparent and provided
   references with full bibliographic details or links to specific
   peer-reviewed content to support recommendations. Conclusions: Among
   leading commercially available LLMs, more than 1-in-4 recommendations
   concerning the evaluation and management of rotator cuff and anterior
   cruciate ligament injuries do not reflect current evidence-based CPGs.
   Although ChatGPT-4 showed the highest performance, clinically
   significant rates of recommendations without concordance or supporting
   evidence were observed. Only 10% of responses by LLMs were transparent,
   precluding users from fully interpreting the sources from which
   recommendations were provided. Clinical Relevance: Although leading LLMs
   generally provide recommendations concordant with CPGs, a substantial
   error rate exists, and the proportion of recommendations that do not
   align with these CPGs suggests that LLMs are not trustworthy clinical
   support tools at this time. Each off-the-shelf, closed-source LLM has
   strengths and weaknesses. Future research should evaluate and compare
   multiple LLMs to avoid bias associated with narrow evaluation of few
   models as observed in the current literature.
TC 14
ZS 0
ZA 0
ZR 0
ZB 2
Z8 0
Z9 14
DA 2025-02-05
UT WOS:001407460300001
PM 39173690
ER

PT J
AU Peng, Jing-Jie
   Zhang, Yi-Yue
   Li, Rui-Feng
   Zhu, Wen-Jun
   Liu, Hong-Rui
   Li, Hui-Yin
   Liu, Bin
   Cao, Dong-Sheng
   Peng, Jun
   Luo, Xiu-Ju
TI Hybrid approach for drug-target interaction predictions in ischemic
   stroke models
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
VL 161
AR 103067
DI 10.1016/j.artmed.2025.103067
EA JAN 2025
DT Article
PD MAR 2025
PY 2025
AB Multiple cell death mechanisms are triggered during ischemic stroke and
   they are interconnected in a complex network with extensive crosstalk,
   complicating the development of targeted therapies. We therefore propose
   a novel framework for identifying disease-specific drug-target
   interaction (DTI), named strokeDTI, to extract key nodes within an
   interconnected graph network of activated pathways via leveraging
   transcriptomic sequencing data. Our findings reveal that the drugs a
   model can predict are highly representative of the characteristics of
   the database the model is trained on. However, models with comparable
   performance yield diametrically opposite predictions in real testing
   scenarios. Our analysis reveals a correlation between the reported
   literature on drugtarget pairs and their binding scores. Leveraging this
   correlation, we introduced an additional module to assess the predictive
   validity of our model for each unique target, thereby improving the
   reliability of the framework's predictions. Our framework identified
   Cerdulatinib as a potential anti-stroke drug via targeting multiple cell
   death pathways, particularly necroptosis and apoptosis. Experimental
   validation in in vitro and in vivo models demonstrated that Cerdulatinib
   significantly attenuated stroke-induced brain injury via inhibiting
   multiple cell death pathways, improving neurological function, and
   reducing infarct volume. This highlights strokeDTI's potential for
   disease-specific drug-target identification and Cerdulatinib's potential
   as a potent anti-stroke drug.
TC 0
ZS 0
ZR 0
ZA 0
ZB 0
Z8 0
Z9 0
DA 2025-02-12
UT WOS:001413881900001
PM 39956766
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   Pugliese, Nicola
   You, Kisung
   Shung, Dennis L.
TI Optimizing large language models in digestive disease: strategies and
   challenges to improve clinical outcomes
SO LIVER INTERNATIONAL
VL 44
IS 9
BP 2114
EP 2124
DI 10.1111/liv.15974
EA MAY 2024
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs) are transformer-based neural networks with
   billions of parameters trained on very large text corpora from diverse
   sources. LLMs have the potential to improve healthcare due to their
   capability to parse complex concepts and generate context-based
   responses. The interest in LLMs has not spared digestive disease
   academics, who have mainly investigated foundational LLM accuracy, which
   ranges from 25% to 90% and is influenced by the lack of standardized
   rules to report methodologies and results for LLM-oriented research. In
   addition, a critical issue is the absence of a universally accepted
   definition of accuracy, varying from binary to scalar interpretations,
   often tied to grader expertise without reference to clinical guidelines.
   We address strategies and challenges to increase accuracy. In
   particular, LLMs can be infused with domain knowledge using Retrieval
   Augmented Generation (RAG) or Supervised Fine-Tuning (SFT) with
   reinforcement learning from human feedback (RLHF). RAG faces challenges
   with in-context window limits and accurate information retrieval from
   the provided context. SFT, a deeper adaptation method, is
   computationally demanding and requires specialized knowledge. LLMs may
   increase patient quality of care across the field of digestive diseases,
   where physicians are often engaged in screening, treatment and
   surveillance for a broad range of pathologies for which in-context
   learning or SFT with RLHF could improve clinical decision-making and
   patient outcomes. However, despite their potential, the safe deployment
   of LLMs in healthcare still needs to overcome hurdles in accuracy,
   suggesting a need for strategies that integrate human feedback with
   advanced model training.
ZR 0
TC 16
ZA 0
Z8 2
ZS 0
ZB 3
Z9 16
DA 2024-06-06
UT WOS:001235783300001
PM 38819632
ER

PT J
AU Djulbegovic, Mak B.
   Bair, Henry
   Gonzalez, David J. Taylor
   Ishikawa, Hiroshi
   Wollstein, Gadi
   Schuman, Joel S.
TI Artificial Intelligence for Optical Coherence Tomography in Glaucoma
SO TRANSLATIONAL VISION SCIENCE & TECHNOLOGY
VL 14
IS 1
AR 27
DI 10.1167/tvst.14.1.27
DT Review
PD JAN 2025
PY 2025
AB Purpose: The integration of artificial intelligence (AI), particularly
   deep learning (DL), with optical coherence tomography (OCT) offers
   significant opportunities in the diagnosis and management of glaucoma.
   This article explores the application of various DL models in enhancing
   OCT capabilities and addresses the challenges associated with their
   clinical implementation. Methods: A review of articles utilizing DL
   models was conducted, including convolutional neural networks (CNNs),
   recurrent neural networks (RNNs), generative adversarial networks
   (GANs), autoencoders, and large language models (LLMs). Key developments
   and practical applications of these models in OCT image analysis were
   emphasized, particularly in the context of enhancing image quality,
   glaucoma diagnosis, and monitoring progression. Results: CNNs excel in
   segmenting retinal layers and detecting glaucomatous damage, whereas
   RNNs are effective in analyzing sequential OCT scans for disease
   progression. GANs enhance image quality and data augmentation, and
   autoencoders facilitate advanced feature extraction. LLMs show promise
   in integrating textual and visual data for comprehensive diagnostic
   assessments. Despite these advancements, challenges such as data
   availability, variability, potential biases, and the need for extensive
   validation persist. Conclusions: DL models are reshaping glaucoma
   management by enhancing OCT's diagnostic capabilities. However, the
   successful translation into clinical practice requires addressing major
   challenges related to data variability, biases, fairness, and model
   validation to ensure accurate and reliable patient care. Translational
   Relevance: This review bridges the gap between basic research and
   clinical care by demonstrating how AI, particularly DL models, can
   markedly enhance OCT's clinical utility in diagnosis, monitoring, and
   prediction, moving toward more individualized, personalized, and precise
   treatment strategies.
ZR 0
Z8 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
DA 2025-04-11
UT WOS:001461389800004
PM 39854198
ER

PT J
AU Li, Yiming
   Peng, Xueqing
   Li, Jianfu
   Zuo, Xu
   Peng, Suyuan
   Pei, Donghong
   Tao, Cui
   Xu, Hua
   Hong, Na
TI Relation extraction using large language models: a case study on
   acupuncture point locations
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 31
IS 11
BP 2622
EP 2631
DI 10.1093/jamia/ocae233
EA AUG 2024
DT Article
PD AUG 29 2024
PY 2024
AB Objective In acupuncture therapy, the accurate location of acupoints is
   essential for its effectiveness. The advanced language understanding
   capabilities of large language models (LLMs) like Generative Pre-trained
   Transformers (GPTs) and Llama present a significant opportunity for
   extracting relations related to acupoint locations from textual
   knowledge sources. This study aims to explore the performance of LLMs in
   extracting acupoint-related location relations and assess the impact of
   fine-tuning on GPT's performance.Materials and Methods We utilized the
   World Health Organization Standard Acupuncture Point Locations in the
   Western Pacific Region (WHO Standard) as our corpus, which consists of
   descriptions of 361 acupoints. Five types of relations ("direction_of",
   "distance_of", "part_of", "near_acupoint", and "located_near") (n =
   3174) between acupoints were annotated. Four models were compared:
   pre-trained GPT-3.5, fine-tuned GPT-3.5, pre-trained GPT-4, as well as
   pretrained Llama 3. Performance metrics included micro-average exact
   match precision, recall, and F1 scores.Results Our results demonstrate
   that fine-tuned GPT-3.5 consistently outperformed other models in F1
   scores across all relation types. Overall, it achieved the highest
   micro-average F1 score of 0.92.Discussion The superior performance of
   the fine-tuned GPT-3.5 model, as shown by its F1 scores, underscores the
   importance of domain-specific fine-tuning in enhancing relation
   extraction capabilities for acupuncture-related tasks. In light of the
   findings from this study, it offers valuable insights into leveraging
   LLMs for developing clinical decision support and creating educational
   modules in acupuncture.Conclusion This study underscores the
   effectiveness of LLMs like GPT and Llama in extracting relations related
   to acupoint locations, with implications for accurately modeling
   acupuncture knowledge and promoting standard implementation in
   acupuncture training and practice. The findings also contribute to
   advancing informatics applications in traditional and complementary
   medicine, showcasing the potential of LLMs in natural language
   processing.
ZS 0
ZR 0
TC 5
ZB 2
Z8 0
ZA 0
Z9 5
DA 2024-09-02
UT WOS:001300170700001
PM 39208311
ER

PT J
AU Fonseca, Angelo
   Ferreira, Axel
   Ribeiro, Luis
   Moreira, Sandra
   Duque, Cristina
TI Embracing the future-is artificial intelligence already better? A
   comparative study of artificial intelligence performance in diagnostic
   accuracy and decision-making
SO EUROPEAN JOURNAL OF NEUROLOGY
VL 31
IS 4
DI 10.1111/ene.16195
EA JAN 2024
DT Article
PD APR 2024
PY 2024
AB Background and purposeThe integration of artificial intelligence (AI) in
   healthcare has the potential to revolutionize patient care and clinical
   decision-making. This study aimed to explore the reliability of large
   language models in neurology by comparing the performance of an AI
   chatbot with neurologists in diagnostic accuracy and
   decision-making.MethodsA cross-sectional observational study was
   conducted. A pool of clinical cases from the American Academy of
   Neurology's Question of the Day application was used as the basis for
   the study. The AI chatbot used was ChatGPT, based on GPT-3.5. The
   results were then compared to neurology peers who also answered the
   questions-a mean of 1500 neurologists/neurology residents.ResultsThe
   study included 188 questions across 22 different categories. The AI
   chatbot demonstrated a mean success rate of 71.3% in providing correct
   answers, with varying levels of proficiency across different neurology
   categories. Compared to neurology peers, the AI chatbot performed at a
   similar level, with a mean success rate of 69.2% amongst peers.
   Additionally, the AI chatbot achieved a correct diagnosis in 85.0% of
   cases and it provided an adequate justification for its correct
   responses in 96.1%.ConclusionsThe study highlights the potential of AI,
   particularly large language models, in assisting with clinical reasoning
   and decision-making in neurology and emphasizes the importance of AI as
   a complementary tool to human expertise. Future advancements and
   refinements are needed to enhance the AI chatbot's performance and
   broaden its application across various medical specialties.
ZA 0
ZS 0
Z8 0
ZB 0
ZR 0
TC 7
Z9 7
DA 2024-01-24
UT WOS:001144093900001
PM 38235841
ER

PT J
AU Cairns, James
   Frood, Russell
   Patel, Chirag
   Scarsbrook, Andrew
TI The Role of AI in Lymphoma: An Update
SO SEMINARS IN NUCLEAR MEDICINE
VL 55
IS 3
BP 377
EP 386
DI 10.1053/j.semnuclmed.2025.02.007
EA APR 2025
DT Review
PD MAY 2025
PY 2025
AB Malignant lymphomas encompass a range of malignancies with incidence
   rising globally, particularly with age. In younger populations, Hodgkin
   and Burkitt lymphomas predominate, while older populations more commonly
   experience subtypes such as diffuse large B-cell, follicular, marginal
   zone, and mantle cell lymphomas. Positron emission tomography/computed
   tomography (PET/CT) using [18F] fluorodeoxyglucose (FDG) is the gold
   standard for staging, treatment response assessment, and prognostication
   in lymphoma. However, interpretation of PET/CT is complex,
   time-consuming, and reliant on expert imaging specialists, exacerbating
   challenges associated with workforce shortages worldwide. Artificial
   intelligence (AI) offers transformative potential across multiple
   aspects of PET/CT imaging in this setting. AI applications in
   appointment planning have demonstrated utility in reducing nonattendance
   rates and improving departmental efficiency. Advanced reconstruction
   techniques leveraging convolutional neural networks (CNNs) enable
   reduced injected activities of radiopharmaceutical and patient dose
   whilst maintaining diagnostic accuracy, particularly benefiting younger
   patients requiring multiple scans. Automated segmentation tools,
   predominantly using 3D U-Net architectures, have improved quantification
   of metrics such as total metabolic tumour volume (TMTV) and total lesion
   glycolysis (TLG), facilitating prognostication and treatment
   stratification. Despite these advancements, challenges remain, including
   variability in segmentation performance, impact on Deauville Score
   interpretation, and standardization of TMTV/TLG measurements. Emerging
   large language models (LLMs) also show promise in enhancing PET/CT
   reporting, converting free-text reports into structured formats, and
   improving patient communication. Further research is required to address
   limitations such as AI-induced errors, physiological uptake
   differentiation, and the integration of AI models into clinical
   workflows. With robust validation and harmonization, AI integration
   could significantly enhance lymphoma care, improving diagnostic
   precision, workflow efficiency, and patient outcomes. Semin Nucl Med
   55:377-386 (c) 2025 The Author(s). Published by Elsevier Inc. This is an
   open access article under the CC BY license
   (http://creativecommons.org/licenses/by/4.0/)
TC 2
ZR 0
ZS 0
ZB 0
ZA 0
Z8 0
Z9 2
DA 2025-05-01
UT WOS:001472935800001
PM 40069036
ER

PT J
AU Giske, Christian G.
   Bressan, Michelle
   Fiechter, Farah
   Hinic, Vladimira
   Mancini, Stefano
   Nolte, Oliver
   Egli, Adrian
TI GPT-4-based AI agents-the new expert system for detection of
   antimicrobial resistance mechanisms?
SO JOURNAL OF CLINICAL MICROBIOLOGY
VL 62
IS 11
DI 10.1128/jcm.00689-24
EA OCT 2024
DT Article
PD NOV 13 2024
PY 2024
AB The European Committee on Antimicrobial Susceptibility Testing (EUCAST)
   recommends two steps for detecting beta-lactamases in Gram-negative
   bacteria. Screening for potential extended-spectrum beta-lactamase
   (ESBL), plasmid-mediated AmpC beta-lactamase, or carbapenemase
   production is confirmed. We aimed to validate generative pre-trained
   transformer (GPT)-4 and GPT-agent for pre-classification of disk
   diffusion to indicate potential beta-lactamases. We assigned 225
   Gram-negative isolates based on phenotypic resistances against
   beta-lactam antibiotics and additional tests to one or more resistance
   mechanisms as follows: "none," "ESBL," "AmpC," or "carbapenemase." Next,
   we customized a GPT-agent with EUCAST guidelines and breakpoint table
   (v13.1). We compared routine diagnostics (reference) to those of (i)
   EUCAST-GPT-expert, (ii) microbiologists, and (iii) non-customized GPT-4.
   We determined sensitivities and specificities to flag suspect
   resistances. Three microbiologists showed concordance in 814/862 (94.4%)
   phenotypic categories and were used in median eight words (interquartile
   range [IQR] 4-11) for reasoning. Median sensitivity/specificity for
   ESBL, AmpC, and carbapenemase were 98%/99.1%, 96.8%/97.1%, and
   95.5%/98.5%, respectively. Three prompts of EUCAST-GPT-expert showed
   concordance in 706/862 (81.9%) categories but were used in median 158
   words (IQR 140-174) for reasoning. Sensitivity/specificity for ESBL,
   AmpC, and carbapenemase prediction were 95.4%/69.23%, 96.9%/86.3%, and
   100%/98.8%, respectively. Non-customized GPT-4 could interpret 169/862
   (19.6%) categories, and 137/169 (81.1%) agreed with routine diagnostics.
   Non-customized GPT-4 was used in median 85 words (IQR 72-105) for
   reasoning. Microbiologists showed higher concordance and shorter
   argumentations compared to GPT-agents. Humans showed higher
   specificities compared to GPT-agents. GPT-agent's unspecific flagging of
   ESBL and AmpC potentially results in additional testing, diagnostic
   delays, and higher costs. GPT-4 is not approved by regulatory bodies,
   but validation of large language models is needed.IMPORTANCEThe study
   titled "GPT-4-based AI agents-the new expert system for detection of
   antimicrobial resistance mechanisms?" is critically important as it
   explores the integration of advanced artificial intelligence (AI)
   technologies, like generative pre-trained transformer (GPT)-4, into the
   field of laboratory medicine, specifically in the diagnostics of
   antimicrobial resistance (AMR). With the growing challenge of AMR, there
   is a pressing need for innovative solutions that can enhance diagnostic
   accuracy and efficiency. This research assesses the capability of AI to
   support the existing two-step confirmatory process recommended by the
   European Committee on Antimicrobial Susceptibility Testing for detecting
   beta-lactamases in Gram-negative bacteria. By potentially speeding up
   and improving the precision of initial screenings, AI could reduce the
   time to appropriate treatment interventions. Furthermore, this study is
   vital for validating the reliability and safety of AI tools in clinical
   settings, ensuring they meet stringent regulatory standards before they
   can be broadly implemented. This could herald a significant shift in how
   laboratory diagnostics are performed, ultimately leading to better
   patient outcomes.
   The study titled "GPT-4-based AI agents-the new expert system for
   detection of antimicrobial resistance mechanisms?" is critically
   important as it explores the integration of advanced artificial
   intelligence (AI) technologies, like generative pre-trained transformer
   (GPT)-4, into the field of laboratory medicine, specifically in the
   diagnostics of antimicrobial resistance (AMR). With the growing
   challenge of AMR, there is a pressing need for innovative solutions that
   can enhance diagnostic accuracy and efficiency. This research assesses
   the capability of AI to support the existing two-step confirmatory
   process recommended by the European Committee on Antimicrobial
   Susceptibility Testing for detecting beta-lactamases in Gram-negative
   bacteria. By potentially speeding up and improving the precision of
   initial screenings, AI could reduce the time to appropriate treatment
   interventions. Furthermore, this study is vital for validating the
   reliability and safety of AI tools in clinical settings, ensuring they
   meet stringent regulatory standards before they can be broadly
   implemented. This could herald a significant shift in how laboratory
   diagnostics are performed, ultimately leading to better patient
   outcomes.
ZB 0
ZS 0
Z8 0
ZR 0
ZA 0
TC 3
Z9 3
DA 2024-10-23
UT WOS:001333898200001
PM 39417635
ER

PT J
AU Cho, Hyeongmin
   Yoo, Sooyoung
   Kim, Borham
   Jang, Sowon
   Sunwoo, Leonard
   Kim, Sanghwan
   Lee, Donghyoung
   Kim, Seok
   Nam, Sejin
   Chung, Jin-Haeng
TI Extracting lung cancer staging descriptors from pathology reports: A
   generative language model approach
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 157
AR 104720
DI 10.1016/j.jbi.2024.104720
EA SEP 2024
DT Article
PD SEP 2024
PY 2024
AB Background: In oncology, electronic health records contain textual key
   information for the diagnosis, staging, and treatment planning of
   patients with cancer. However, text data processing requires a lot of
   time and effort, which limits the utilization of these data. Recent
   advances in natural language processing (NLP) technology, including
   large language models, can be applied to cancer research. Particularly,
   extracting the information required for the pathological stage from
   surgical pathology reports can be utilized to update cancer staging
   according to the latest cancer staging guidelines. Objectives: This
   study has two main objectives. The first objective is to evaluate the
   performance of extracting information from text-based surgical pathology
   reports and determining pathological stages based on the extracted
   information using fine-tuned generative language models (GLMs) for
   patients with lung cancer. The second objective is to determine the
   feasibility of utilizing relatively small GLMs for information
   extraction in a resource-constrained computing environment. Methods:
   Lung cancer surgical pathology reports were collected from the Common
   Data Model database of Seoul National University Bundang Hospital
   (SNUBH), a tertiary hospital in Korea. We selected 42 descriptors
   necessary for tumor-node (TN) classification based on these reports and
   created a gold standard with validation by two clinical experts. The
   pathology reports and gold standard were used to generate
   prompt-response pairs for training and evaluating GLMs which then were
   used to extract information required for staging from pathology reports.
   Results: We evaluated the information extraction performance of six
   trained models as well as their performance in TN classification using
   the extracted information. The Deductive Mistral-7B model, which was
   pre-trained with the deductive dataset, showed the best performance
   overall, with an exact match ratio of 92.24% in the information
   extraction problem and an accuracy of 0.9876 (predicting T and N
   classification concurrently) in classification. Conclusion: This study
   demonstrated that training GLMs with deductive datasets can improve
   information extraction performance, and GLMs with a relatively small
   number of parameters at approximately seven billion can achieve high
   performance in this problem. The proposed GLM-based information
   extraction method is expected to be useful in clinical decision-making
   support, lung cancer staging and research.
ZS 0
ZA 0
ZR 0
TC 4
ZB 1
Z8 0
Z9 4
DA 2024-09-21
UT WOS:001312772300001
PM 39233209
ER

PT J
AU Sandmann, Sarah
   Riepenhausen, Sarah
   Plagwitz, Lucas
   Varghese, Julian
TI Systematic analysis of ChatGPT, Google search and Llama 2 for clinical
   decision support tasks
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 2050
DI 10.1038/s41467-024-46411-8
DT Article
PD MAR 6 2024
PY 2024
AB It is likely that individuals are turning to Large Language Models
   (LLMs) to seek health advice, much like searching for diagnoses on
   Google. We evaluate clinical accuracy of GPT-3 center dot 5 and GPT-4
   for suggesting initial diagnosis, examination steps and treatment of 110
   medical cases across diverse clinical disciplines. Moreover, two model
   configurations of the Llama 2 open source LLMs are assessed in a
   sub-study. For benchmarking the diagnostic task, we conduct a naive
   Google search for comparison. Overall, GPT-4 performed best with
   superior performances over GPT-3 center dot 5 considering diagnosis and
   examination and superior performance over Google for diagnosis. Except
   for treatment, better performance on frequent vs rare diseases is
   evident for all three approaches. The sub-study indicates slightly lower
   performances for Llama models. In conclusion, the commercial LLMs show
   growing potential for medical question answering in two successive major
   releases. However, some weaknesses underscore the need for robust and
   regulated AI models in health care. Open source LLMs can be a viable
   option to address specific needs regarding data privacy and transparency
   of training.
   People will likely use ChatGPT to seek health advice. Here, the authors
   show promising performance of ChatGPT and open source models, but a lack
   of high accuracy considering medical question answering. Improvements
   are expected over time via domain-specific finetuning and integration of
   regulations.
ZS 0
ZR 0
Z8 3
ZB 11
TC 56
ZA 0
Z9 59
DA 2024-04-03
UT WOS:001180826600013
PM 38448475
ER

PT J
AU Fennig, Uriel
   Yom-Tov, Elad
   Savitsky, Leehe
   Nissan, Johnatan
   Altman, Keren
   Loebenstein, Roni
   Boxer, Marina
   Weinberg, Nitai
   Gofrit, Shany Guly
   Maggio, Nicola
TI Bridging the conversational gap in epilepsy: Using large language models
   to reveal insights into patient behavior and concerns from online
   discussions
SO EPILEPSIA
VL 66
IS 3
BP 686
EP 699
DI 10.1111/epi.18226
EA DEC 2024
DT Article
PD MAR 2025
PY 2025
AB ObjectiveThis study was undertaken to explore the experiences and
   concerns of people living with epilepsy by analyzing discussions in an
   online epilepsy community, using large language models (LLMs) to
   identify themes, demographic patterns, and associations with emotional
   distress, substance use, and suicidal ideation.MethodsWe analyzed 56 970
   posts and responses to them from 21 906 users on the epilepsy forum
   (subreddit) of Reddit and 768 504 posts from the same users in other
   subreddits, between 2010 and 2023. LLMs, validated against human
   labeling, were used to identify 23 recurring themes, assess demographic
   differences, and examine cross-posting to depression- and
   suicide-related subreddits. Hazard ratios (HRs) were calculated to
   assess the association between specific themes and activity in mental
   health forums.ResultsProminent topics included seizure descriptions,
   medication management, stigma, drug and alcohol use, and emotional
   well-being. The posts on topics less likely to be discussed in clinical
   settings had the highest engagement. Younger users focused on stigma and
   emotional issues, whereas older users discussed medical treatments.
   Posts about emotional distress (HR = 1.3), postictal state (HR = 1.4),
   surgical treatment (HR = .7), and work challenges (HR = 1.6) predicted
   activity in a subreddit associated with suicidal ideation, whereas
   emotional distress (HR = 1.5), surgical treatment (HR = .6), and stigma
   (HR = 1.3) predicted activity in the depression subreddit. Substance use
   discussions showed a temporal pattern of association with seizure
   descriptions, implying possible opportunities for
   intervention.SignificanceLLM analysis of online epilepsy communities
   provides novel insights into patient concerns often overlooked in
   clinical settings. These findings may improve patient-provider
   communication, inform personalized interventions, and support the
   development of patient-reported outcome measures. Additionally, hazard
   models can help identify at-risk individuals, offering opportunities for
   early mental health interventions.
ZB 0
ZA 0
Z8 0
TC 1
ZS 0
ZR 0
Z9 1
DA 2024-12-16
UT WOS:001373700400001
PM 39655574
ER

PT J
AU Hao, Boran
   Hu, Yang
   Adams, William G.
   Assoumou, Sabrina A.
   Hsu, Heather E.
   Bhadelia, Nahid
   Paschalidis, Ioannis Ch.
TI A GPT-based EHR modeling system for unsupervised novel disease detection
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 157
AR 104706
DI 10.1016/j.jbi.2024.104706
EA AUG 2024
DT Article
PD SEP 2024
PY 2024
AB Objective: To develop an Artificial Intelligence (AI)-based anomaly
   detection model as a complement of an "astute physician" in detecting
   novel disease cases in a hospital and preventing emerging outbreaks. .
   Methods: Data included hospitalized patients (n = 120,714) at a
   safety-net hospital in Massachusetts. A novel Generative Pre-trained
   Transformer (GPT)-based clinical anomaly detection system was designed
   and further trained using Empirical Risk Minimization (ERM), , which can
   model a hospitalized patient's Electronic Health Records (EHR) and
   detect atypical patients. Methods and performance metrics, similar to
   the ones behind the recent Large Language Models (LLMs), , were
   leveraged to capture the dynamic evolution of the patient's clinical
   variables and compute an Out-Of-Distribution (OOD) anomaly score.
   Results: In a completely unsupervised setting, hospitalizations for
   Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) infection
   could have been predicted by our GPT model at the beginning of the
   COVID-19 pandemic, with an Area Under the Receiver Operating
   Characteristic Curve (AUC) of 92.2 %, using 31 extracted clinical
   variables and a 3-day detection window. Our GPT achieves individual
   patient-level anomaly detection and mortality prediction AUC of 78.3 %
   and 94.7 %, outperforming traditional linear models by 6.6 % and 9 %,
   respectively. Different types of clinical trajectories of a SARS-CoV-2
   infection are captured by our model to make interpretable detections,
   while a trend of over-pessimistic outcome prediction yields a more
   effective detection pathway. Furthermore, our comprehensive GPT model
   can potentially assist clinicians with forecasting patient clinical
   variables and developing personalized treatment plans. Conclusion: This
   study demonstrates that an emerging outbreak can be accurately detected
   within a hospital, by using a GPT to model patient EHR time sequences
   and labeling them as anomalous when actual outcomes are not supported by
   the model. Such a GPT is also a comprehensive model with the
   functionality of generating future patient clinical variables, which can
   potentially assist clinicians in developing personalized treatment
   plans.
ZB 0
TC 1
ZS 0
Z8 0
ZR 0
ZA 0
Z9 1
DA 2024-08-27
UT WOS:001295776900001
PM 39121932
ER

PT J
AU Klarak, Jaromir
   Brito, Ana Caroline M.
   Moreira, Luan F.
   Silva, Filipi N.
   Amancio, Diego R.
   Andok, Robert
   Oliveira, Maria Cristina F.
   Bardosova, Maria
   Oliveira Jr, Osvaldo N.
TI Using network analysis and large-language models to obtain a landscape
   of the literature on dressing materials for wound healing: The
   predominance of chitosan and other biomacromolecules: A review
SO INTERNATIONAL JOURNAL OF BIOLOGICAL MACROMOLECULES
VL 306
AR 141565
DI 10.1016/j.ijbiomac.2025.141565
EA MAR 2025
PN 2
DT Review
PD MAY 2025
PY 2025
AB We present an overview of the literature on dressing materials for wound
   healing, combining network analysis and natural language processing
   using large language models. Contributions to this field come from a
   variety of research areas and journals, so we employed multiple
   strategies for searching the OpenAlex database to ensure that the most
   relevant papers were covered, while also focusing on the specific topic
   of interest. Citation networks were created from the retrieved papers,
   identifying clusters that represent major topics. Starting with broad
   searches on 'wound' and 'wound healing' we refined the focus to dressing
   materials by incorporating expert knowledge into the analysis. This
   approach also allowed for a comparison with fully automated analyses.
   The resulting landscape shows significant growth in this area in recent
   years, with most contributions coming from the Northern Hemisphere,
   particularly China and the USA. The most commonly used materials include
   gauze, hydrocolloids, chitosan-based hydrogels, foams, alginates,
   hydrofibers (e.g., those containing nanomaterials such as silver
   nanoparticles), composites, biomaterials, and skin substitutes. Research
   primarily focuses on the antibacterial properties of these materials and
   their application in treating burn-related wounds, which, along with
   diabetes, are common causes of chronic wounds.
ZA 0
ZB 0
Z8 0
ZS 0
ZR 0
TC 2
Z9 2
DA 2025-03-18
UT WOS:001441448600001
PM 40020798
ER

PT J
AU Beattie, J.
   Neufeld, S.
   Yang, D. X.
   Chukwuma, C.
   Desai, N. B.
   Dohopolski, M.
   Jiang, S. B.
TI Using Large Language Models to Create Patient Centered Consent Forms
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3342
BP E612
EP E612
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
Z8 0
ZR 0
ZB 0
TC 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302026
ER

PT J
AU Busch, Felix
   Hoffmann, Lena
   Rueger, Christopher
   van Dijk, Elon H. C.
   Kader, Rawen
   Ortiz-Prado, Esteban
   Makowski, Marcus R.
   Saba, Luca
   Hadamitzky, Martin
   Kather, Jakob Nikolas
   Truhn, Daniel
   Cuocolo, Renato
   Adams, Lisa C.
   Bressem, Keno K.
TI Current applications and challenges in large language models for patient
   care: a systematic review
SO COMMUNICATIONS MEDICINE
VL 5
IS 1
AR 26
DI 10.1038/s43856-024-00717-2
DT Article
PD JAN 21 2025
PY 2025
AB BackgroundThe introduction of large language models (LLMs) into clinical
   practice promises to improve patient education and empowerment, thereby
   personalizing medical care and broadening access to medical knowledge.
   Despite the popularity of LLMs, there is a significant gap in
   systematized information on their use in patient care. Therefore, this
   systematic review aims to synthesize current applications and
   limitations of LLMs in patient care.MethodsWe systematically searched 5
   databases for qualitative, quantitative, and mixed methods articles on
   LLMs in patient care published between 2022 and 2023. From 4349 initial
   records, 89 studies across 29 medical specialties were included. Quality
   assessment was performed using the Mixed Methods Appraisal Tool 2018. A
   data-driven convergent synthesis approach was applied for thematic
   syntheses of LLM applications and limitations using free line-by-line
   coding in Dedoose.ResultsWe show that most studies investigate
   Generative Pre-trained Transformers (GPT)-3.5 (53.2%, n = 66 of 124
   different LLMs examined) and GPT-4 (26.6%, n = 33/124) in answering
   medical questions, followed by patient information generation, including
   medical text summarization or translation, and clinical documentation.
   Our analysis delineates two primary domains of LLM limitations: design
   and output. Design limitations include 6 second-order and 12 third-order
   codes, such as lack of medical domain optimization, data transparency,
   and accessibility issues, while output limitations include 9
   second-order and 32 third-order codes, for example, non-reproducibility,
   non-comprehensiveness, incorrectness, unsafety, and bias.ConclusionsThis
   review systematically maps LLM applications and limitations in patient
   care, providing a foundational framework and taxonomy for their
   implementation and evaluation in healthcare settings.
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 8
Z9 8
DA 2025-01-29
UT WOS:001402540700001
PM 39838160
ER

PT B
AU Asly, Amneh
Z2  
TI Developing Objective Chronic Pain Assessment Based on Linguistic
   Characteristics of Patients' Narratives
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
TC 0
ZA 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
UT PQDT:119375393
ER

PT J
AU Bhayana, Rajesh
   Alwahbi, Omar
   Ladak, Aly Muhammad
   Deng, Yangqing
   Dias, Adriano Basso
   Elbanna, Khaled
   Gomez, Jorge Abreu
   Jajodia, Ankush
   Jhaveri, Kartik
   Johnson, Sarah
   Kajal, Dilkash
   Wang, David
   Soong, Christine
   Kielar, Ania
   Krishna, Satheesh
TI Leveraging Large Language Models to Generate Clinical Histories for
   Oncologic Imaging Requisitions
SO RADIOLOGY
VL 314
IS 2
AR e242134
DI 10.1148/radiol.242134
DT Article
PD FEB 2025
PY 2025
AB Background: Clinical information improves imaging interpretation, but
   physician-provided histories on requisitions for oncologic imaging often
   lack key details. Purpose: To evaluate large language models (LLMs) for
   automatically generating clinical histories for oncologic imaging
   requisitions from clinical notes and compare them with original
   requisition histories. Materials and Methods: In total, 207 patients
   with CT performed at a cancer center from January to November 2023 and
   with an electronic health record clinical note coinciding with ordering
   date were randomly selected. A multidisciplinary team informed selection
   of 10 parameters important for oncologic imaging history, including
   primary oncologic diagnosis, treatment history, and acute symptoms.
   Clinical notes were independently reviewed to establish the reference
   standard regarding presence of each parameter. After prompt engineering
   with seven patients, GPT-4 (version 0613; OpenAI) was prompted on April
   9, 2024, to automatically generate structured clinical histories for the
   200 remaining patients. Using the reference standard, LLM extraction
   performance was calculated (recall, precision, F1 score). LLM-generated
   and original requisition histories were compared for completeness
   (proportion including each parameter), and 10 radiologists performed
   pairwise comparison for quality, preference, and subjective likelihood
   of harm. Results: For the 200 LLM-generated histories, GPT-4 performed
   well, extracting oncologic parameters from clinical notes (F1 = 0.983).
   Compared with original requisition histories, LLM-generated histories
   more frequently included parameters critical for radiologist
   interpretation, including primary oncologic diagnosis (99.5% vs 89% [199
   and 178 of 200 histories, respectively]; P < .001), acute or worsening
   symptoms (15% vs 4% [29 and seven of 200]; P < .001), and relevant
   surgery (61% vs 12% [122 and 23 of 200]; P < .001). Radiologists
   preferred LLM-generated histories for imaging interpretation (89% vs 5%,
   7% equal; P < .001), indicating they would enable more complete
   interpretation (86% vs 0%, 15% equal; P < .001) and have a lower
   likelihood of harm (3% vs 55%, 42% neither; P < .001). Conclusion: An
   LLM enabled accurate automated clinical histories for oncologic imaging
   from clinical notes. Compared with original requisition histories,
   LLM-generated histories were more complete and were preferred by
   radiologists for imaging interpretation and perceived safety.
ZA 0
Z8 0
ZR 0
ZB 0
ZS 0
TC 1
Z9 1
DA 2025-03-08
UT WOS:001434851700023
PM 39903072
ER

PT J
AU Ostrowska, Magdalena
   Kacala, Paulina
   Onolememen, Deborah
   Vaughan-Lane, Katie
   Sisily Joseph, Anitta
   Ostrowski, Adam
   Pietruszewska, Wioletta
   Banaszewski, Jacek
   Wrobel, Maciej J.
TI To trust or not to trust: evaluating the reliability and safety of AI
   responses to laryngeal cancer queries
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6069
EP 6081
DI 10.1007/s00405-024-08643-8
EA APR 2024
DT Article
PD NOV 2024
PY 2024
AB Purpose As online health information-seeking surges, concerns mount over
   the quality and safety of accessible content, potentially leading to
   patient harm through misinformation. On one hand, the emergence of
   Artificial Intelligence (AI) in healthcare could prevent it; on the
   other hand, questions raise regarding the quality and safety of the
   medical information provided. As laryngeal cancer is a prevalent head
   and neck malignancy, this study aims to evaluate the utility and safety
   of three large language models (LLMs) as sources of patient information
   about laryngeal cancer.Methods A cross-sectional study was conducted
   using three LLMs (ChatGPT 3.5, ChatGPT 4.0, and Bard). A questionnaire
   comprising 36 inquiries about laryngeal cancer was categorised into
   diagnosis (11 questions), treatment (9 questions), novelties and
   upcoming treatments (4 questions), controversies (8 questions), and
   sources of information (4 questions). The population of reviewers
   consisted of 3 groups, including ENT specialists, junior physicians, and
   non-medicals, who graded the responses. Each physician evaluated each
   question twice for each model, while non-medicals only once. Everyone
   was blinded to the model type, and the question order was shuffled.
   Outcome evaluations were based on a safety score (1-3) and a Global
   Quality Score (GQS, 1-5). Results were compared between LLMs. The study
   included iterative assessments and statistical validations.Results
   Analysis revealed that ChatGPT 3.5 scored highest in both safety (mean:
   2.70) and GQS (mean: 3.95). ChatGPT 4.0 and Bard had lower safety scores
   of 2.56 and 2.42, respectively, with corresponding quality scores of
   3.65 and 3.38. Inter-rater reliability was consistent, with less than 3%
   discrepancy. About 4.2% of responses fell into the lowest safety
   category (1), particularly in the novelty category. Non-medical
   reviewers' quality assessments correlated moderately (r = 0.67) with
   response length.Conclusions LLMs can be valuable resources for patients
   seeking information on laryngeal cancer. ChatGPT 3.5 provided the most
   reliable and safe responses among the models evaluated.
TC 11
ZS 1
ZB 1
ZR 0
ZA 0
Z8 0
Z9 10
DA 2024-04-27
UT WOS:001207064800002
PM 38652298
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Yang, Fei
   Li, Xiaochun
   Wang, Xijuan
   Chen, Xuanling
   Niu, Yaqian
   Zhang, Yan
   Zhang, Chengxia
   Liu, Guangfeng
TI Analysis of Optic Disc Morphology and the Peripapillary Retinal and
   Choroidal Thickness by the Swept Source Optical Coherence Tomography in
   Patients with Moyamoya Disease
SO OPHTHALMIC RESEARCH
VL 68
IS 1
BP 61
EP 70
DI 10.1159/000542801
DT Article
PD JAN-DEC 2025
PY 2025
AB Introduction: The study evaluates the performance of large language
   model versions of ChatGPT - ChatGPT-3.5, ChatGPT-4, and ChatGPT-Omni -
   in addressing inquiries related to the diagnosis and treatment of
   gynecological cancers, including ovarian, endometrial, and cervical
   cancers. Methods: A total of 804 questions were equally distributed
   across four categories: true/false, multiple-choice, open-ended, and
   case-scenario, with each question type representing varying levels of
   complexity. Performance was assessed using a six-point Likert scale,
   focusing on accuracy, completeness, and alignment with established
   clinical guidelines. Results: For true/false queries, ChatGPT-Omni
   achieved accuracy rates of 100% for easy, 98% for medium, and 97% for
   complicated questions, higher than ChatGPT-4 (94%, 90%, 85%) and
   ChatGPT-3.5 (90%, 85%, 80%) (p = 0.041, 0.023, 0.014, respectively). In
   multiple-choice, ChatGPT-Omni maintained with 100% for MMD patients was
   significantly less than in controls, while the CDR in MMD patients was
   significantly larger than that in the control group. There was no
   statistically significant difference between the two groups regarding
   disc area, cup area, cup volume, rim volume, vertical and horizontal
   diameter of disc. The retinal thickness at the 7 o'clock position was
   significantly thinner in the MMD group compared to the control group and
   the temporal RNFL thickness, particularly at the 7 o'clock and 9 o'clock
   positions, was significantly reduced in the MMD group (p < 0.05). The
   GCL layer at the 7 o'clock position was thinner in the MMD group than in
   the control group (p < 0.05). The MMD group showed a notably reduced
   average choroidal thickness, particularly in the inferior-temporal
   region (p < 0.05). There was a correlation between peripapillary
   choroidal and GCL layer thickness in the MMD group, but no significant
   correlations were found with rim area, CDR, or RNFL. Conclusions: In
   patients with MMD, there is an increase in the CDR accompanied by a
   decrease in the rim area. Additionally, there is thinning of the
   temporal RNFL, GCL, and choroidal thickness, notably in the
   inferotemporal quadrant of the optic disc.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
DA 2025-02-01
UT WOS:001404667800001
PM 39586258
ER

PT J
AU Kong, Qing-Zhou
   Ju, Kun-Ping
   Wan, Meng
   Liu, Jing
   Wu, Xiao-Qi
   Li, Yue-Yue
   Zuo, Xiu-Li
   Li, Yan-Qing
TI Comparative analysis of large language models in medical counseling: A
   focus on Helicobacter pylori infection
SO HELICOBACTER
VL 29
IS 1
AR e13055
DI 10.1111/hel.13055
DT Article
PD JAN 2024
PY 2024
AB Background: Large language models (LLMs) are promising medical
   counseling tools, but the reliability of responses remains unclear. We
   aimed to assess the feasibility of three popular LLMs as counseling
   tools for Helicobacter pylori infection in different counseling
   languages. Materials and Methods: This study was conducted between
   November 20 and December 1, 2023. Three large language models (ChatGPT
   4.0 [LLM1], ChatGPT 3.5 [LLM2], and ERNIE Bot 4.0 [LLM3]) were input 15
   H. pylori related questions each, once in English and once in Chinese.
   Each chat was conducted using the "New Chat" function to avoid bias from
   correlation interference. Responses were recorded and blindly assigned
   to three reviewers for scoring on three established Likert scales:
   accuracy (ranged 1-6 point), completeness (ranged 1-3 point), and
   comprehensibility (ranged 1-3 point). The acceptable thresholds for the
   scales were set at a minimum of 4, 2, and 2, respectively. Final various
   source and interlanguage comparisons were made. Results: The overall
   mean (SD) accuracy score was 4.80 (1.02), while 1.82 (0.78) for
   completeness score and 2.90 (0.36) for comprehensibility score. The
   acceptable proportions for the accuracy, completeness, and
   comprehensibility of the responses were 90%, 45.6%, and 100%,
   respectively. The acceptable proportion of overall completeness score
   for English responses was better than for Chinese responses (p = 0.034).
   For accuracy, the English responses of LLM3 were better than the Chinese
   responses (p = 0.0055). As for completeness, the English responses of
   LLM1 was better than the Chinese responses (p = 0.0257). For
   comprehensibility, the English responses of LLM1 was better than the
   Chinese responses (p = 0.0496). No differences were found between the
   various LLMs. Conclusions: The LLMs responded satisfactorily to
   questions related to H. pylori infection. But further improving
   completeness and reliability, along with considering language nuances,
   is crucial for optimizing overall performance.
ZA 0
TC 5
Z8 0
ZB 1
ZS 0
ZR 0
Z9 5
DA 2024-02-16
UT WOS:001158133100001
PM 39078641
ER

PT J
AU Delleani, Mattia
   D'Amico, Saverio
   Sauta, Elisabetta
   Asti, Gianluca
   Zazzetti, Elena
   Campagna, Alessia
   Lanino, Luca
   Maggioni, Giulia
   Grondelli, Maria Chiara
   Barrero, Alessandro Forcina
   Morandini, Pierandrea
   Ubezio, Marta
   Todisco, Gabriele
   Russo, Antonio
   Tentori, Cristina Astrid
   Buizza, Alessandro
   Bonometti, Arturo
   Lancellotti, Cesare
   Di Tommaso, Luca
   Rahal, Daoud
   Bicchieri, Marilena
   Savevski, Victor
   Santoro, Armando
   Santini, Valeria
   Sole, Francesc
   Platzbecker, Uwe
   Fenaux, Pierre
   Diez-Campelo, Maria
   Komrokji, Rami S.
   Garcia-Manero, Guillermo
   Haferlach, Torsten
   Kordasti, Shahram
   Zeidan, Amer M.
   Castellani, Gastone
   Della Porta, Matteo Giovanni
TI The "David Vs Goliath" Study: Application of Large
   Language Models (LLM) for Automatic Medical Information Retrieval from
   Multiple Data Sources to Accelerate Clinical and Translational Research
   in Hematology
SO BLOOD
VL 144
BP 3597
EP 3599
DI 10.1182/blood-2024-205621
SU 1
DT Meeting Abstract
PD NOV 5 2024
PY 2024
ZR 0
ZA 0
Z8 0
ZB 0
TC 0
ZS 0
Z9 0
DA 2025-02-20
UT WOS:001412307500014
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

PT J
AU Civettini, Ivan
   Zappaterra, Arianna
   Ramazzotti, Daniele
   Granelli, Bianca Maria
   Rindone, Giovanni
   Aroldi, Andrea
   Bonfanti, Stefano
   Colombo, Federica
   Fedele, Marilena
   Grillo, Giovanni
   Parma, Matteo
   Perfetti, Paola
   Terruzzi, Elisabetta
   Gambacorti-Passerini, Carlo
   Cavalca, Fabrizio
TI Evaluating the Performance of Large Language Models in Hematopoietic
   Stem Cell Transplantation Decision Making
SO BLOOD
VL 142
DI 10.1182/blood-2023-185854
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZB 0
ZS 0
TC 1
Z9 1
DA 2024-03-02
UT WOS:001159740305072
ER

PT J
AU Schwieger, Arne
   Angst, Katrin
   de Bardeci, Mateo
   Burrer, Achim
   Cathomas, Flurin
   Ferrea, Stefano
   Gratz, Franziska
   Knorr, Marius
   Kronenberg, Golo
   Spiller, Tobias
   Troi, David
   Seifritz, Erich
   Weber, Samantha
   Olbrich, Sebastian
TI Large language models can support generation of standardized discharge
   summaries - A retrospective study utilizing ChatGPT-4 and electronic
   health records
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 192
AR 105654
DI 10.1016/j.ijmedinf.2024.105654
EA OCT 2024
DT Article
PD DEC 2024
PY 2024
AB Objective: To evaluate whether psychiatric discharge summaries (DS)
   generated with ChatGPT-4 from electronic health records (EHR) can match
   the quality of DS written by psychiatric residents. Methods: At a
   psychiatric primary care hospital, we compared 20 inpatient DS, written
   by residents, to those written with ChatGPT-4 from pseudonymized
   residents' notes of the patients' EHRs and a standardized prompt. 8
   blinded psychiatry specialists rated both versions on a custom Likert
   scale from 1 to 5 across 15 quality subcategories. The primary outcome
   was the overall rating difference between the two groups. The secondary
   outcomes were the rating differences at the level of individual
   question, case, and rater. Results: Human-written DS were rated
   significantly higher than AI (mean ratings: human 3.78, AI 3.12, p <
   0.05). They surpassed AI significantly in 12/15 questions and 16/20
   cases and were favored significantly by 7/8 raters. For "low expected
   correction effort", human DS were rated as 67 % favorable, 19 % neutral,
   and 14 % unfavorable, whereas AI-DS were rated as 22 % favorable, 33 %
   neutral, and 45 % unfavorable. Hallucinations were present in 40 % of
   AI-DS, with 37.5 % deemed highly clinically relevant. Minor content
   mistakes were found in 30 % of AI and 10 % of human DS. Raters correctly
   identified AI-DS with 81 % sensitivity and 75 % specificity. Discussion:
   Overall, AI-DS did not match the quality of resident-written DS but
   performed similarly in 20% of cases and were rated as favorable for "low
   expected correction effort" in 22% of cases. AI-DS lacked most in
   content specificity, ability to distill key case information, and
   coherence but performed adequately in conciseness, adherence to
   formalities, relevance of included content, and form. Conclusion:
   LLM-written DS show potential as templates for physicians to finalize,
   potentially saving time in the future.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 1
TC 5
Z9 5
DA 2024-11-07
UT WOS:001343302900001
PM 39437512
ER

EF