FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Qiu, Jianing
   Lam, Kyle
   Li, Guohao
   Acharya, Amish
   Wong, Tien Yin
   Darzi, Ara
   Yuan, Wu
   Topol, Eric J.
TI LLM-based agentic systems in medicine and healthcare
SO NATURE MACHINE INTELLIGENCE
VL 6
IS 12
BP 1418
EP 1420
DI 10.1038/s42256-024-00944-1
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB Large language model-based agentic systems can process input
   information, plan and decide, recall and reflect, interact and
   collaborate, leverage various tools and act. This opens up a wealth of
   opportunities within medicine and healthcare, ranging from clinical
   workflow automation to multi-agent-aided diagnosis.
ZS 0
Z8 0
TC 6
ZR 0
ZA 0
ZB 1
Z9 6
DA 2024-12-11
UT WOS:001370695300001
ER

PT J
AU Chen, Runsheng
TI [Prospects for the Application of Healthcare Big Data Combined With
   Large Language Models].
SO Sichuan da xue xue bao. Yi xue ban = Journal of Sichuan University.
   Medical science edition
VL 54
IS 5
BP 855
EP 856
DI 10.12182/20230960301
DT English Abstract; Journal Article; Review
PD 2023-Sep
PY 2023
AB The application of big data technology combined with large language
   models is expected to make an enormous impact in the field of medicine.
   Herein, the prospects for the application of healthcare big data
   combined with large language models were discussed in several aspects,
   including first in assisting doctors in making diagnosis and
   differential diagnosis and, then, in the field of evidence-based
   medicine. In addition, healthcare big data combined with large language
   models could also be applied in assisting doctors to conduct clinical
   and medical research. Through combining healthcare big data with large
   language models, medical diagnosis and treatment with improved
   precision, efficiency, and intelligence will be realized and greater
   contributions will be made to the field of human health.
ZB 0
Z8 0
ZA 0
ZR 0
ZS 0
TC 1
Z9 1
DA 2023-10-26
UT MEDLINE:37866938
PM 37866938
ER

PT J
AU Guo, Yan
   Wang, Heyuan
   Ren, Xue
   Wang, Tengjiao
   Chen, Wei
   Xu, Ziming
   Ge, Hui
TI Can GPTs Accelerate the Development of Intelligent Diagnosis and
   Treatment in Traditional Chinese Medicine? A Survey and Empirical
   Analysis
SO JOURNAL OF EVIDENCE BASED MEDICINE
VL 18
IS 1
AR e70004
DI 10.1111/jebm.70004
DT Article
PD MAR 2025
PY 2025
AB Intelligent traditional Chinese medicine (TCM) is a key pathway toward
   the modernization and globalization of TCM in the era of artificial
   intelligence. Due to its unique terminology and diagnostic framework,
   TCM's intelligentization process has long faced a range of challenges,
   from the digitization and formalization of knowledge bases to the
   differentiation of syndromes and personalized treatment. Recently, the
   advent of large language models (LLMs) like GPTs has marked a
   transformative milestone in semantic understanding tasks, attracting
   widespread attention from the medical, academic, and industrial
   communities. Nonetheless, LLMs often suffer from accuracy and logical
   reasoning limitations within specific fields and may manifest
   hallucinations in the generative outputs. Through a comprehensive review
   of existing literature and empirical analyses, this study delves into
   the potential and challenges of adapting LLMs to TCM. Promising
   perspectives on future developments at this innovative intersection are
   discussed.
TC 1
Z8 0
ZA 0
ZS 0
ZR 0
ZB 0
Z9 1
DA 2025-03-01
UT WOS:001428957800001
PM 39989008
ER

PT J
AU Trager, Megan H.
   Gordon, Emily R.
   Breneman, Alyssa
   Kim, Esther
   Samie, Faramarz H.
TI Accuracy of ChatGPT in diagnosis and management of dermoscopic images
SO ARCHIVES OF DERMATOLOGICAL RESEARCH
VL 317
IS 1
AR 184
DI 10.1007/s00403-024-03729-z
DT Letter
PD JAN 7 2025
PY 2025
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
TC 0
Z9 0
DA 2025-01-15
UT WOS:001392999400007
PM 39774990
ER

PT J
AU Venerito, Vincenzo
   Iannone, Florenzo
TI Large Language Model-driven Sentiment Analysis for Facilitating
   Fibromyalgia Diagnosis
SO ARTHRITIS & RHEUMATOLOGY
VL 76
MA 1222
BP 2486
EP 2487
SU 9
DT Meeting Abstract
PD SEP 2024
PY 2024
TC 0
ZB 0
ZA 0
ZS 0
Z8 0
ZR 0
Z9 0
DA 2024-12-18
UT WOS:001331419103289
ER

PT J
AU Habib, Sara
   Butt, Haroon
   Goldenholz, Shira R.
   Chang, Chi Yuan
   Goldenholz, Daniel M.
TI Large Language Model Performance on Practice Epilepsy Board Examinations
SO JAMA NEUROLOGY
VL 81
IS 6
BP 660
EP 661
DI 10.1001/jamaneurol.2024.0676
EA JUN 2024
DT Letter
PD JUN 2024
PY 2024
AB This diagnostic study examines whether large language models are able to
   pass practice licensing examinations for epilepsy.
ZB 2
ZR 0
TC 4
ZS 0
Z8 0
ZA 0
Z9 4
DA 2024-04-19
UT WOS:001201427400001
PM 38587850
ER

PT J
AU Wang, Lan
   Tang, Kaiqiang
   Wang, Yan
   Zhang, Peng
   Li, Shao
TI Advancements in Artificial Intelligence-Driven Diagnostic Models for
   Traditional Chinese Medicine
SO AMERICAN JOURNAL OF CHINESE MEDICINE
VL 53
IS 03
BP 647
EP 673
DI 10.1142/S0192415X25500259
DT Article
PD 2025
PY 2025
AB Traditional Chinese medicine (TCM) is an ancient medical system with
   distinctive ethnic characteristics. TCM diagnosis, underpinned by unique
   theoretical frameworks and methodologies, continues to play a
   significant role in contemporary healthcare. The four fundamental
   diagnostic methods, inspection, auscultation-olfaction, inquiry and
   palpation, are inherently subjective, relying on practitioner
   experience. Despite its unique advantages and practical value, TCM must
   still take advantage of modern advancements to enhance its effectiveness
   and accessibility. With the rapid development of computer technology,
   intelligent TCM diagnosis has emerged as a promising frontier.
   Integrating artificial intelligence (AI), particularly through large
   language models (LLMs), offers new avenues for enhancing TCM diagnostic
   practices. However, the systematic review and analysis of these
   technologies remains limited. This paper provides a comprehensive
   overview of the development and recent advancements in TCM diagnostic
   technologies, focusing on the applications of ML across various data
   modalities, and including images, text, and waveforms. Additionally, it
   explores the latest applications of LLMs within the TCM diagnostic
   field. Furthermore, the review discusses the prospects and challenges
   associated with AI-based TCM diagnosis. By systematically summarizing
   the latest research achievements and technological advancements, this
   study aims to provide directional guidance and decision support for
   future research and practical applications in the intersection of AI and
   TCM. Ultimately, this review seeks to foster the continued development
   and integration of intelligent TCM diagnosis into modern healthcare.
ZR 0
Z8 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
DA 2025-05-20
UT WOS:001488594200010
PM 40374369
ER

PT J
AU Kainz, Jakob
   Seisl, Philipp
   Grob, Moritz
   Hauptfeld, Leonhard
   Wahringer, Jonas
   Rappelsberger, Andrea
   Adlassnig, Klaus-Peter
TI Fine-Tuning an Existing Large Language Model with Knowledge from the
   Medical Expert System Hepaxpert.
SO Studies in health technology and informatics
VL 327
BP 143
EP 147
DI 10.3233/SHTI250290
DT Journal Article
PD 2025-May-15
PY 2025
AB The analysis and individual interpretation of hepatitis serology test
   results is a complex task in laboratory medicine, requiring either
   experienced physicians or specialized expert systems. This study
   explores fine-tuning a large language model (LLM) for hepatitis serology
   interpretation using a single graphics processing unit (GPU). A custom
   dataset based on the Hepaxpert expert system was used to train the LLM.
   Fine-tuning was performed on an Nvidia RTX 6000 Ada GPU via torchtune.
   The fine-tuned LLM showed significant performance improvements over the
   base model when compared to Hepaxpert using the METEOR algorithm. The
   findings highlight the potential of LLMs in enhancing medical expert
   systems as well as the significance of domain-specific fine-tuning.
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
ZA 0
Z9 0
DA 2025-05-20
UT MEDLINE:40380402
PM 40380402
ER

PT J
AU Kim, Dong Wook
   Park, Cheol-Young
   Shin, Jeong-Hun
   Lee, Hyunjoo Jenny
TI The Role of Artificial Intelligence in Obesity Medicine
SO ENDOCRINOLOGY AND METABOLISM CLINICS OF NORTH AMERICA
VL 54
IS 1
BP 207
EP 215
DI 10.1016/j.ecl.2024.10.008
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
ZR 0
ZA 0
Z8 0
TC 2
ZB 1
ZS 0
Z9 2
DA 2025-02-23
UT WOS:001424049000001
PM 39919876
ER

PT J
AU Hirata, Kenji
   Matsui, Yusuke
   Yamada, Akira
   Fujioka, Tomoyuki
   Yanagawa, Masahiro
   Nakaura, Takeshi
   Ito, Rintaro
   Ueda, Daiju
   Fujita, Shohei
   Tatsugami, Fuminari
   Fushimi, Yasutaka
   Tsuboyama, Takahiro
   Kamagata, Koji
   Nozaki, Taiki
   Fujima, Noriyuki
   Kawamura, Mariko
   Naganawa, Shinji
TI Generative AI and large language models in nuclear medicine: current
   status and future prospects
SO ANNALS OF NUCLEAR MEDICINE
VL 38
IS 11
BP 853
EP 864
DI 10.1007/s12149-024-01981-x
EA SEP 2024
DT Review
PD NOV 2024
PY 2024
AB This review explores the potential applications of Large Language Models
   (LLMs) in nuclear medicine, especially nuclear medicine examinations
   such as PET and SPECT, reviewing recent advancements in both fields.
   Despite the rapid adoption of LLMs in various medical specialties, their
   integration into nuclear medicine has not yet been sufficiently
   explored. We first discuss the latest developments in nuclear medicine,
   including new radiopharmaceuticals, imaging techniques, and clinical
   applications. We then analyze how LLMs are being utilized in radiology,
   particularly in report generation, image interpretation, and medical
   education. We highlight the potential of LLMs to enhance nuclear
   medicine practices, such as improving report structuring, assisting in
   diagnosis, and facilitating research. However, challenges remain,
   including the need for improved reliability, explainability, and bias
   reduction in LLMs. The review also addresses the ethical considerations
   and potential limitations of AI in healthcare. In conclusion, LLMs have
   significant potential to transform existing frameworks in nuclear
   medicine, making it a critical area for future research and development.
ZR 0
ZA 0
TC 4
ZB 1
ZS 0
Z8 0
Z9 4
DA 2024-09-30
UT WOS:001319554200001
PM 39320419
ER

PT J
AU Orlhac, Fanny
   Bradshaw, Tyler
   Buvat, Irene
TI Can a large language model be an effective assistant for literature
   reviews? An example in Radiomics
SO JOURNAL OF NUCLEAR MEDICINE
VL 65
MA 241031
SU 2
DT Meeting Abstract
PD JUN 1 2024
PY 2024
CT Annual Meeting of the Society-of-Nuclear-Medicine-and-Molecular-Imaging
   (SNMMI)
CY JUN 08-11, 2024
CL Toronto, CANADA
SP Soc Nuclear Med & Mol Imaging
Z8 0
ZB 0
ZA 0
TC 0
ZS 0
ZR 0
Z9 0
DA 2024-12-16
UT WOS:001289165600066
ER

PT J
AU Valentini, Giorgio
TI Exploring the similarity between genetic diseases improves their
   differential diagnosis and the understanding of their etiology
SO EUROPEAN JOURNAL OF HUMAN GENETICS
VL 32
IS 4
BP 373
EP 374
DI 10.1038/s41431-024-01535-9
EA JAN 2024
DT Article
PD APR 2024
PY 2024
ZA 0
TC 0
Z8 0
ZB 0
ZR 0
ZS 0
Z9 0
DA 2024-02-04
UT WOS:001150340300001
PM 38273167
ER

PT J
AU Kotzur, Travis
   Singh, Aaron
   Parker, John
   Peterson, Blaire
   Sager, Brian
   Rose, Ryan
   Corley, Fred
   Brady, Christina
TI Evaluation of a Large Language Model's Ability to Assist in an
   Orthopedic Hand Clinic
SO HAND-AMERICAN ASSOCIATION FOR HAND SURGERY
DI 10.1177/15589447241257643
EA JUN 2024
DT Article; Early Access
PY 2024
AB Background: Advancements in artificial intelligence technology, such as
   OpenAI's large language model, ChatGPT, could transform medicine through
   applications in a clinical setting. This study aimed to assess the
   utility of ChatGPT as a clinical assistant in an orthopedic hand
   clinic.Methods: Nine clinical vignettes, describing various common and
   uncommon hand pathologies, were constructed and reviewed by 4
   fellowship-trained orthopedic hand surgeons and an orthopedic resident.
   ChatGPT was given these vignettes and asked to generate a differential
   diagnosis, potential workup plan, and provide treatment options for its
   top differential. Responses were graded for accuracy and the overall
   utility scored on a 5-point Likert scale.Results: The diagnostic
   accuracy of ChatGPT was 7 out of 9 cases, indicating an overall accuracy
   rate of 78%. ChatGPT was less reliable with more complex pathologies and
   failed to identify an intentionally incorrect presentation. ChatGPT
   received a score of 3.8 +/- 1.4 for correct diagnosis, 3.4 +/- 1.4 for
   helpfulness in guiding patient management, 4.1 +/- 1.0 for appropriate
   workup for the actual diagnosis, 4.3 +/- 0.8 for an appropriate
   recommended treatment plan for the diagnosis, and 4.4 +/- 0.8 for the
   helpfulness of treatment options in managing patients.Conclusion:
   ChatGPT was successful in diagnosing most of the conditions; however,
   the overall utility of its advice was variable. While it performed well
   in recommending treatments, it faced difficulties in providing
   appropriate diagnoses for uncommon pathologies. In addition, it failed
   to identify an obvious error in presenting pathology.
TC 2
ZS 0
ZB 0
ZR 0
Z8 0
ZA 0
Z9 2
DA 2024-06-29
UT WOS:001251801400001
PM 38907651
ER

PT C
AU Zhu, Jinyang
   Gong, Qingyue
   Zhou, Chunfang
   Luan, Huidan
GP Assoc Computing Machinery
TI ZhongJing: A Locally Deployed Large Language Model for Traditional
   Chinese Medicine and Corresponding Evaluation Methodology An LLM for the
   TCM Field and the Corresponding Evaluation Method
SO PROCEEDINGS OF 2023 4TH INTERNATIONAL SYMPOSIUM ON ARTIFICIAL
   INTELLIGENCE FOR MEDICINE SCIENCE, ISAIMS 2023
BP 1036
EP 1042
DI 10.1145/3644116.3644294
DT Proceedings Paper
PD 2023
PY 2023
AB The success of ChatGPT has showcased the potential applications of Large
   Language Models (LLMs) in the field of Traditional Chinese Medicine
   (TCM), encompassing areas such as medical diagnosis, adjunctive therapy,
   and TCM talent cultivation. However, the current challenges, including
   hardware constraints, insufficient model domain knowledge, and
   difficulties in domain-specific evaluation, have constrained the fusion
   of LLMs with TCM. In an attempt to address these issues, this paper
   introduces ZhongJing, a domain-specific LLM fine-tuned within the domain
   of TCM, capable of generating responses at a rate of 8 tokens per
   second, smoothly operating on local personal computers. To assess the
   model's domain expertise, this paper introduces the TCMEval evaluation
   method, designed concerning medical students' exams. Experimental
   results demonstrate that ZhongJing achieves a 6.49 TCMEval Score
   improvement over Chinese-LLaMA2 in the field of TCM, indicating the
   model's ability to generate more specialized responses compared to
   baseline models.
CT 4th International Symposium on Artificial Intelligence for Medicine
   Science (ISAIMS)
CY OCT 20-22, 2023
CL Chengdu, PEOPLES R CHINA
ZA 0
ZB 0
ZR 0
ZS 0
Z8 0
TC 2
Z9 2
DA 2024-07-18
UT WOS:001213963600173
ER

PT J
AU Mahmoudi, Elham
   Erickson, Bradley
   Vahdati, Sanaz
   Khosravi, Bardia
   Lopez-Jimenez, Francisco
   Chao, Chieh Ju
TI PROMPT OPTIMIZATION AND CHAIN OF THOUGHT REASONING FOR AUTOMATED
   CLASSIFICATION OF ECHOCARDIOGRAPHY REPORTS USING PRIVACY-PRESERVING
   OPEN-SOURCE LANGUAGE MODELS
SO JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY
VL 85
IS 12
MA 1246-68
BP 2139
EP 2139
SU S
DT Meeting Abstract
PD APR 1 2025
PY 2025
CT Annual Meeting of the American-College-of-Cardiology (ACC)
CY MAR 29-31, 2025
CL Chicago, IL
SP Amer Coll Cardiol
ZB 0
ZR 0
TC 0
ZS 0
Z8 0
ZA 0
Z9 0
DA 2025-04-18
UT WOS:001463248900038
ER

PT J
AU Ihara, Keiko
   Dumkrieger, Gina
   Zhang, Pengfei
   Takizawa, Tsubasa
   Schwedt, Todd J.
   Chiang, Chia-Chun
TI Application of Artificial Intelligence in the Headache Field
SO CURRENT PAIN AND HEADACHE REPORTS
VL 28
IS 10
BP 1049
EP 1057
DI 10.1007/s11916-024-01297-5
EA JUL 2024
DT Review
PD OCT 2024
PY 2024
AB Purpose of ReviewHeadache disorders are highly prevalent worldwide.
   Rapidly advancing capabilities in artificial intelligence (AI) have
   expanded headache-related research with the potential to solve unmet
   needs in the headache field. We provide an overview of AI in headache
   research in this article.Recent FindingsWe briefly introduce machine
   learning models and commonly used evaluation metrics. We then review
   studies that have utilized AI in the field to advance diagnostic
   accuracy and classification, predict treatment responses, gather
   insights from various data sources, and forecast migraine attacks.
   Furthermore, given the emergence of ChatGPT, a type of large language
   model (LLM), and the popularity it has gained, we also discuss how LLMs
   could be used to advance the field. Finally, we discuss the potential
   pitfalls, bias, and future directions of employing AI in headache
   medicine.SummaryMany recent studies on headache medicine incorporated
   machine learning, generative AI and LLMs. A comprehensive understanding
   of potential pitfalls and biases is crucial to using these novel
   techniques with minimum harm. When used appropriately, AI has the
   potential to revolutionize headache medicine.
ZA 0
ZR 0
TC 2
ZB 0
Z8 0
ZS 0
Z9 2
DA 2024-07-18
UT WOS:001264634300002
PM 38976174
ER

PT J
AU Dai, Yizheng
   Shao, Xin
   Zhang, Jinlu
   Chen, Yulong
   Chen, Qian
   Liao, Jie
   Chi, Fei
   Zhang, Junhua
   Fan, Xiaohui
TI TCMChat: A generative large language model for traditional Chinese
   medicine
SO PHARMACOLOGICAL RESEARCH
VL 210
AR 107530
DI 10.1016/j.phrs.2024.107530
EA DEC 2024
DT Article
PD DEC 2024
PY 2024
AB The utilization of ground-breaking large language models (LLMs)
   accompanied with dialogue system has been progressively prevalent in the
   medical domain. Nevertheless, the expertise of LLMs in Traditional
   Chinese Medicine (TCM) remains restricted despite several TCM LLMs
   proposed recently. Herein, we introduced TCMChat
   (https://xomics.com.cn/tcmchat), a generative LLM with pre-training (PT)
   and supervised fine-tuning (SFT) on large-scale curated TCM text
   knowledge and Chinese Question-Answering (QA) datasets. In detail, we
   first compiled a customized collection of six scenarios of Chinese
   medicine as the training set by text mining and manual verification,
   involving TCM knowledgebase, choice question, reading comprehension,
   entity extraction, medical case diagnosis, and herb or formula
   recommendation. Next, we subjected the model to PT and SFT, using the
   Baichuan2-7B-Chat as the foundation model. The benchmarking datasets and
   case studies further demonstrate the superior performance of TCMChat in
   comparison to existing models. Our code, data and model are publicly
   released on GitHub (https://github.com/ZJUFanLab/TCMChat) and
   HuggingFace (https://huggingface. co/ZJUFanLab), providing high-quality
   knowledgebase for the research of TCM modernization with a userfriendly
   dialogue web tool.
Z8 0
TC 0
ZR 0
ZS 0
ZB 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001374093600001
PM 39617279
ER

PT J
AU Tate, Hudson
   Hambright, Ben
   Clark, Abby
   Dixon, Cory
   Kronz, Ben
   Ricks, James
   Spaedy, Olivia
   Whalen, Sydney
   Butler, Danner
   Bicknell, Brenton
TI Quantitative Advancements in Clinical Accuracy of Successive Generative
   Pre-Trained Transformer Models
SO JOURNAL OF INVESTIGATIVE MEDICINE
VL 72
IS 6
MA 10
DT Meeting Abstract
PD AUG 2024
PY 2024
CT Southeastern Regional Meeting of the
   American-Federation-for-Medical-Research (AFMR)
CY MAY 23-24, 2024
CL Birmingham, AL
SP Amer Federat Med Res
ZB 0
ZS 0
ZR 0
ZA 0
Z8 0
TC 0
Z9 0
DA 2024-09-18
UT WOS:001290786700011
ER

PT J
AU Goodman, Katherine E.
   Yi, Paul H.
   Morgan, Daniel J.
TI AI-Generated Clinical Summaries Require More Than Accuracy
SO JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION
VL 331
IS 8
BP 637
EP 638
DI 10.1001/jama.2024.0555
EA FEB 2024
DT Editorial Material
PD FEB 27 2024
PY 2024
AB This Viewpoint discusses AI-generated clinical summaries and the
   necessity of transparent development of standards for their safe
   rollout.
ZR 0
ZB 6
Z8 0
TC 29
ZA 0
ZS 0
Z9 30
DA 2024-02-10
UT WOS:001156388800001
PM 38285439
ER

PT J
AU McCrary, Myles R.
   Galambus, Justine
   Chen, Wei-Shen
TI Evaluating the diagnostic performance of a large language model-powered
   chatbot for providing immunohistochemistry recommendations in
   dermatopathology
SO JOURNAL OF CUTANEOUS PATHOLOGY
VL 51
IS 9
BP 689
EP 695
DI 10.1111/cup.14631
EA MAY 2024
DT Article
PD SEP 2024
PY 2024
AB BackgroundLarge language model (LLM)-powered chatbots such as ChatGPT
   have numerous applications. However, their effectiveness in
   dermatopathology has not been formally evaluated. Dermatopathological
   cases often require immunohistochemical workup. Here, we evaluate the
   performance of a chatbot in providing diagnostically useful information
   on immunohistochemistry relating to dermatological diseases.MethodsWe
   queried a commonly used chatbot for the immunophenotypes of 51 cutaneous
   diseases, including a diverse variety of epidermal, adnexal,
   hematolymphoid, and soft tissue entities. We requested it to provide
   references for each diagnosis. All tests were repeated, compiled,
   quantified, and then compared with established literature
   standards.ResultsClustering analysis demonstrated that recommendations
   correlated with tumor type, suggesting chatbots can supply appropriate
   panels. However, a significant portion of recommendations were factually
   incorrect (13.9%). Citations were rarely clinically useful (24.5%). Many
   were confabulated (27.2%). Prompt responses for cutaneous adnexal
   lesions tended to be less accurate while literature references were less
   useful. Reference retrieval performance was associated with the number
   of PubMed entries per entity.ConclusionsThis foundational study suggests
   that LLM-powered chatbots may be useful for generating
   immunohistochemical panels for dermatologic diagnoses. However, specific
   performance capabilities and biases must be considered. In addition,
   extreme caution is advised regarding the tendencies to fabricate
   material. Future models intentionally fine-tuned to augment diagnostic
   medicine may prove to be valuable.
Z8 1
ZB 2
ZS 0
ZR 0
TC 4
ZA 0
Z9 5
DA 2024-05-23
UT WOS:001221968800001
PM 38744501
ER

PT J
AU Li, Shusheng
   Tan, Wenjun
   Zhang, Changshuai
   Li, Jiale
   Ren, Haiyan
   Guo, Yanliang
   Jia, Jing
   Liu, Yangyang
   Pan, Xingfang
   Guo, Jing
   Meng, Wei
   He, Zhaoshui
TI Taming large language models to implement diagnosis and evaluating the
   generation of LLMs at the semantic similarity level in acupuncture and
   moxibustion
SO EXPERT SYSTEMS WITH APPLICATIONS
VL 264
AR 125920
DI 10.1016/j.eswa.2024.125920
EA DEC 2024
DT Article
PD MAR 10 2025
PY 2025
AB With the rapid advancement of artificial intelligence and deep learning
   technologies, large language models (LLMs) such as ChatGPT and GPT-4
   have made significant progress in comprehending and responding to human
   instructions. Acupuncture and moxibustion, therapeutic modalities in
   Traditional Chinese Medicine (TCM), possess extensive knowledge
   beneficial for patient treatment. Currently, acupuncture diagnosis
   relies on the experience and skills of individual acupuncturists,
   emphasizing the need for research to improve diagnostic accuracy through
   objective methods. Therefore, the integration of LLMs into the field of
   acupuncture can facilitate the recommendation of personalized
   acupuncture treatment programs. However, the application of general LLMs
   to the field of acupuncture diagnosis often yields suboptimal results.
   In addition, most LLM evaluation metrics depend solely on literal
   overlap and fail to capture semantic similarity. To address these
   challenges, this paper introduces AcupunctureGPT, a specialized large
   language model for acupuncture diagnosis, aimed at exploring the
   potential application of LLMs in this field. Patient Diagnostic
   Acupuncture Data is constructed to enhance the diagnostic capabilities
   of AcupunctureGPT in acupuncture. The Generated Knowledge Filter
   Prompting approach is proposed to improve the accuracy of LLMs in
   identifying similar diseases through the development and filtering of
   knowledge statements. The Sentence Similarity Evaluation Module (SSEM)
   is employed to assess the generation quality of LLMs at the semantic
   level. The Sentence Adaptive Enhancement Fusion Module (SAEFM), proposed
   within SSEM, enhances the adaptive fusion of output features at various
   levels. Experimental results demonstrate that AcupunctureGPT outperforms
   other large language models in diagnosing diseases and devising
   reasonable treatment plans. Furthermore, the evaluation metrics proposed
   in this paper have been validated for effectiveness.
TC 0
Z8 0
ZA 0
ZR 0
ZB 0
ZS 0
Z9 0
DA 2024-12-13
UT WOS:001372992400001
ER

PT J
AU Galatzer-Levy, Isaac
TI Capability of Large Language Models to Measure Psychiatric Functioning
SO NEUROPSYCHOPHARMACOLOGY
VL 49
MA 22.2
BP 27
EP 28
SU 1
DT Meeting Abstract
PD DEC 2024
PY 2024
CT 63rd Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP)
CY DEC 08-11, 2023
CL Phoenix, AZ
SP Amer Coll Neuropsychopharmacol
ZB 0
Z8 0
TC 0
ZA 0
ZR 0
ZS 0
Z9 0
DA 2025-02-23
UT WOS:001421429700068
ER

PT J
AU Giuffre, Mauro
TI Letter to the Editor: Refining retrieval and chunking strategies for
   enhanced clinical reliability of large language models in liver disease
SO HEPATOLOGY
VL 80
IS 5
BP E67
EP E68
DI 10.1097/HEP.0000000000000992
EA JUN 2024
DT Letter
PD NOV 2024
PY 2024
ZA 0
TC 0
ZB 0
Z8 0
ZS 0
ZR 0
Z9 0
DA 2024-07-26
UT WOS:001272318500001
PM 38935919
ER

PT J
AU Savage, Thomas
   Nayak, Ashwin
   Gallo, Robert
   Rangan, Ekanath
   Chen, Jonathan H.
TI Diagnostic reasoning prompts reveal the potential for large language
   model interpretability in medicine
SO NPJ DIGITAL MEDICINE
VL 7
IS 1
AR 20
DI 10.1038/s41746-024-01010-1
DT Article
PD JAN 24 2024
PY 2024
AB One of the major barriers to using large language models (LLMs) in
   medicine is the perception they use uninterpretable methods to make
   clinical decisions that are inherently different from the cognitive
   processes of clinicians. In this manuscript we develop diagnostic
   reasoning prompts to study whether LLMs can imitate clinical reasoning
   while accurately forming a diagnosis. We find that GPT-4 can be prompted
   to mimic the common clinical reasoning processes of clinicians without
   sacrificing diagnostic accuracy. This is significant because an LLM that
   can imitate clinical reasoning to provide an interpretable rationale
   offers physicians a means to evaluate whether an LLMs response is likely
   correct and can be trusted for patient care. Prompting methods that use
   diagnostic reasoning have the potential to mitigate the "black box"
   limitations of LLMs, bringing them one step closer to safe and effective
   use in medicine.
TC 65
ZS 0
Z8 2
ZB 13
ZA 0
ZR 0
Z9 66
DA 2024-02-04
UT WOS:001148298600001
PM 38267608
ER

PT J
AU Koga, Shunsuke
   Du, Wei
TI From text to image: challenges in integrating vision into ChatGPT for
   medical image interpretation
SO NEURAL REGENERATION RESEARCH
VL 20
IS 2
BP 487
EP 488
DI 10.4103/NRR.NRR-D-24-00165
DT Review
PD FEB 2025
PY 2025
ZS 0
TC 6
ZR 0
ZA 0
Z8 0
ZB 1
Z9 6
DA 2024-07-18
UT WOS:001236392200024
PM 38819060
ER

PT J
AU Jaskari, Joel
   Sahlsten, Jaakko
   Summanen, Paula
   Moilanen, Jukka
   Lehtola, Erika
   Aho, Marjo
   Sapyska, Elina
   Hietala, Kustaa
   Kaski, Kimmo
TI DR-GPT: A large language model for medical report analysis of diabetic
   retinopathy patients
SO PLOS ONE
VL 19
IS 10
AR e0297706
DI 10.1371/journal.pone.0297706
DT Article
PD OCT 11 2024
PY 2024
AB Diabetic retinopathy (DR) is a sight-threatening condition caused by
   diabetes. Screening programmes for DR include eye examinations, where
   the patient's fundi are photographed, and the findings, including DR
   severity, are recorded in the medical report. However, statistical
   analyses based on DR severity require structured labels that calls for
   laborious manual annotation process if the report format is
   unstructured. In this work, we propose a large language model DR-GPT for
   classification of the DR severity from unstructured medical reports. On
   a clinical set of medical reports, DR-GPT reaches 0.975 quadratic
   weighted Cohen's kappa using truncated Early Treatment Diabetic
   Retinopathy Study scale. When DR-GPT annotations for unlabeled data are
   paired with corresponding fundus images, the additional data improves
   image classifier performance with statistical significance. Our analysis
   shows that large language models can be applied for unstructured medical
   report databases to classify diabetic retinopathy with a variety of
   applications.
ZR 0
Z8 0
ZA 0
ZS 0
TC 1
ZB 0
Z9 1
DA 2024-10-30
UT WOS:001336670500022
PM 39392790
ER

PT J
AU Gil, Morayma Reyes
   Pantanowitz, Joshua
   Rashidi, Hooman H.
TI Venous thromboembolism in the era of machine learning and artificial
   intelligence in medicine
SO THROMBOSIS RESEARCH
VL 242
AR 109121
DI 10.1016/j.thromres.2024.109121
EA AUG 2024
DT Article
PD OCT 2024
PY 2024
AB In this review, we embark on a comprehensive exploration of venous
   thromboembolism (VTE) in the context of medical history and its current
   practice within medicine. We delve into the landscape of artificial
   intelligence (AI), exploring its present utility and envisioning its
   transformative roles within VTE management, from prevention to screening
   and beyond. Central to our discourse is a forward-looking perspective on
   the integration of AI within VTE in medicine, advocating for rigorous
   study design, robust validation processes, and meticulous statistical
   analysis to gauge the efficacy of AI applications. We further illuminate
   the potential of large language models and generative AI in
   revolutionizing VTE care, while acknowledging their inherent limitations
   and proposing innovative solutions to overcome challenges related to
   data availability and integrity, including the strategic use of
   synthetic data. The critical importance of navigating ethical, legal,
   and privacy concerns associated with AI is underscored, alongside the
   imperative for comprehensive governance and policy frameworks to
   regulate its deployment in VTE treatment. We conclude on a note of
   cautious optimism, where we highlight the significance of proactively
   addressing the myriad challenges that accompany the advent of AI in
   healthcare. Through diligent design, stringent validation, extensive
   education, and prudent regulation, we can harness AI's potential to
   significantly enhance our understanding and management of VTE. As we
   stand on the cusp of a new era, our commitment to these principles will
   be instrumental in ensuring that the promise of AI is fully realized
   within the realm of VTE care.
ZB 0
ZS 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-09-08
UT WOS:001304249800001
PM 39213896
ER

PT J
AU Nguyen, Danh Q.
   Owens, Dylan
   Gupta, Mohit
   Peterson, Eric D.
   Navar, Ann Marie
TI USING ARTIFICIAL INTELLIGENCE TO MEASURE AND UNDERSTAND STATIN
   UTILIZATION IN ASCVD: A TOOL FOR FUTURE QUALITY ASSESSMENT AND
   IMPROVEMENT
SO JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY
VL 85
IS 12
MA 909-17
BP 2471
EP 2471
SU S
DT Meeting Abstract
PD APR 1 2025
PY 2025
CT Annual Meeting of the American-College-of-Cardiology (ACC)
CY MAR 29-31, 2025
CL Chicago, IL
SP Amer Coll Cardiol
TC 0
ZS 0
ZA 0
ZB 0
ZR 0
Z8 0
Z9 0
DA 2025-04-23
UT WOS:001463119900020
ER

PT J
AU Cohen, Fred
   Vallimont, Jenn
   Gelfand, Amy A.
TI Caution regarding fabricated citations from artificial intelligence
SO HEADACHE
VL 64
IS 1
BP 3
EP 4
DI 10.1111/head.14649
EA OCT 2023
DT Editorial Material
PD JAN 2024
PY 2024
ZA 0
Z8 0
ZB 2
TC 2
ZR 0
ZS 0
Z9 2
DA 2023-11-10
UT WOS:001090780800001
PM 37873980
ER

PT J
AU Liang, Shufan
   Zhang, Jiangjiang
   Liu, Xingting
   Huang, Yinkui
   Shao, Jun
   Liu, Xiaohong
   Li, Weimin
   Wang, Guangyu
   Wang, Chengdi
TI The potential of large language models to advance precision oncology
SO EBIOMEDICINE
VL 115
AR 105695
DI 10.1016/j.ebiom.2025.105695
EA APR 2025
DT Review
PD MAY 2025
PY 2025
AB With the rapid development of artificial intelligence (AI) within
   medicine, the emergence of large language models (LLMs) has gradually
   reached the forefront of clinical research. In oncology, by mining the
   underlying connection between a text or image input and the desired
   output, LLMs demonstrate great potential for managing tumours. In this
   review, we provide a brief description of the development of LLMs,
   followed by model construction strategies and general medical functions.
   We then elaborate on the role of LLMs in cancer screening and diagnosis,
   metastasis identification, tumour staging, treatment recommendation, and
   documentation processing tasks by decoding various types of clinical
   data. Moreover, the current barriers faced by LLMs, such as
   hallucinations, ethical problems, limited application, and so on, are
   outlined along with corresponding solutions, where the further purpose
   is to inspire improvement and innovation in this field with respect to
   harnessing LLMs for advancing precision oncology. Copyright (c) 2025 The
   Author(s). Published by Elsevier B.V. This is an open access article
   under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).
TC 0
Z8 0
ZR 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-05-15
UT WOS:001485098500001
PM 40305985
ER

PT J
AU Ge, Jin
   Sun, Steve
   Owens, Joseph
   Galvez, Victor
   Gologorskaya, Oksana
   Lai, Jennifer C.
   Pletcher, Mark J.
   Lai, Ki
TI Reply: Refining retrieval and chunking strategies for enhanced clinical
   reliability of large language models in liver disease
SO HEPATOLOGY
VL 80
IS 5
BP E69
EP E70
DI 10.1097/HEP.0000000000000995
EA JUN 2024
DT Letter
PD NOV 2024
PY 2024
Z8 0
TC 0
ZA 0
ZR 0
ZS 0
ZB 0
Z9 0
DA 2024-07-20
UT WOS:001267558300001
PM 38935858
ER

PT J
AU Gerstung, Moritz
   Liu, David
   Ghassemi, Marzyeh
   Zou, James
   Chowell, Diego
   Teuwen, Jonas
   Mahmood, Faisal
   Kather, Jakob Nikolas
TI Artificial intelligence
SO CANCER CELL
VL 42
IS 6
BP 915
EP 918
DT Editorial Material
PD JUN 10 2024
PY 2024
ZS 0
ZR 0
ZA 0
Z8 0
TC 2
ZB 1
Z9 2
DA 2025-02-12
UT WOS:001412853800001
PM 38861926
ER

PT J
AU Zhuang, Yi
   Yu, Lingkai
   Jiang, Nan
   Ge, Yujia
TI TCM-KLLaMA: Intelligent generation model for Traditional Chinese
   Medicine Prescriptions based on knowledge graph and large language
   model.
SO Computers in biology and medicine
VL 189
BP 109887
EP 109887
DI 10.1016/j.compbiomed.2025.109887
DT Journal Article
PD 2025-May
PY 2025
AB Traditional Chinese medicine (TCM) prescriptions are a basic component
   of TCM treatment, developed by assessing patient symptoms and
   prescribing a mix of herbs. Accurate prescription generation is critical
   for enhancing treatment outcomes and maintaining patient safety.
   However, conventional methods based on Large Language Models (LLMs)
   focus mainly on symptom information, neglecting other TCM diagnostic
   expertise, such as tongue and pulse diagnosis, and are prone to
   hallucination, which is unacceptable in medical applications. To address
   these challenges, the paper proposes an effective prescription
   generation model enriched by a TCM knowledge graph (KG) called the
   TCM-KLLaMA model. In this model, the Chinese-LLaMA2-7B model is provided
   with a new output layer and loss function to suppress hallucinations and
   increase recommendation accuracy. A TCM KG including symptoms, tongue
   diagnosis, and pulse diagnosis was developed, and the model was
   fine-tuned utilizing the suggested synonym and matching knowledge
   injection (SMKI) mechanism. Extensive experiments demonstrate that the
   TCM- KLLaMA outperforms baseline models in both Precision and F1 Score,
   proving its superior performance in prescription generation tasks.
ZR 0
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-03-11
UT MEDLINE:40056842
PM 40056842
ER

PT J
AU Lee, Won-Yung
   Han, Sang-Yun
   Kim, Ji-Hwan
   Lee, Byung-Wook
   Han, Yejin
   Lee, Seungho
TI Gen-SynDi: Leveraging Knowledge-Guided Generative AI for Dual Education
   of Syndrome Differentiation and Disease Diagnosis
SO APPLIED SCIENCES-BASEL
VL 15
IS 9
AR 4862
DI 10.3390/app15094862
DT Article
PD APR 27 2025
PY 2025
AB Syndrome differentiation and disease diagnosis are central to
   Traditional Asian Medicine (TAM) because they guide personalized
   treatment. Yet, most TAM courses give students few structured
   opportunities to practise these paired skills. We developed Gen-SynDi, a
   knowledge-guided generative-AI framework that links syndrome
   differentiation with disease diagnosis to improve training. Using
   standardized patient files from the National Institute for Korean
   Medicine Development, we built a fatigue-focused dataset covering five
   Western-defined diseases and seven TAM syndromes. Carefully designed
   prompts and a large language model produced 28 virtual patient cases by
   joining compatible disease-syndrome pairs while preserving clinical
   realism. Inside an interactive web simulation, students conduct
   history-taking, receive free-text answers, and propose both syndrome and
   disease diagnoses; immediate feedback highlights missing questions,
   reasoning gaps, and overall accuracy. A built-in scoring module supplies
   quantitative measures of inquiry coverage and diagnostic precision, plus
   brief explanations of overlooked clues. A prompt-component role analysis
   confirmed that our prompt design improves response fidelity, and
   external experts endorsed the scenarios' realism and educational value.
   Gen-SynDi therefore offers a scalable bridge between textbook knowledge
   and clinical practice, strengthening learners' skills in differential
   diagnosis and syndrome differentiation.
Z8 0
ZR 0
ZS 0
TC 0
ZB 0
ZA 0
Z9 0
DA 2025-05-16
UT WOS:001485983700001
ER

PT J
AU Guastafierro, Vincenzo
   Corbitt, Devin N.
   Bressan, Alessandra
   Fernandes, Bethania
   Mintemur, Omer
   Magnoli, Francesca
   Ronchi, Susanna
   La Rosa, Stefano
   Uccella, Silvia
   Renne, Salvatore Lorenzo
TI Unveiling the risks of ChatGPT in diagnostic surgical pathologyChatGPT
SO VIRCHOWS ARCHIV
VL 486
IS 4
BP 663
EP 673
DI 10.1007/s00428-024-03918-1
EA SEP 2024
DT Article
PD APR 2025
PY 2025
AB ChatGPT, an AI capable of processing and generating human-like language,
   has been studied in medical education and care, yet its potential in
   histopathological diagnosis remains unexplored. This study evaluates
   ChatGPT's reliability in addressing pathology-related diagnostic
   questions across ten subspecialties and its ability to provide
   scientific references. We crafted five clinico-pathological scenarios
   per subspecialty, simulating a pathologist using ChatGPT to refine
   differential diagnoses. Each scenario, aligned with current diagnostic
   guidelines and validated by expert pathologists, was posed as open-ended
   or multiple-choice questions, either requesting scientific references or
   not. Outputs were assessed by six pathologists according to. (1)
   usefulness in supporting the diagnosis and (2) absolute number of
   errors. We used directed acyclic graphs and structural causal models to
   determine the effect of each scenario type, field, question modality,
   and pathologist evaluation. We yielded 894 evaluations. ChatGPT provided
   useful answers in 62.2% of cases, and 32.1% of outputs contained no
   errors, while the remaining had at least one error. ChatGPT provided 214
   bibliographic references: 70.1% correct, 12.1% inaccurate, and 17.8%
   non-existing. Scenario variability had the greatest impact on ratings,
   and latent knowledge across fields showed minimal variation. Although
   ChatGPT provided useful responses in one-third of cases, the frequency
   of errors and variability underscores its inadequacy for routine
   diagnostic use and highlights the need for discretion as a support tool.
   Imprecise referencing also suggests caution as a self-learning tool. It
   is essential to recognize the irreplaceable role of human experts in
   synthesizing images, clinical data, and experience for the intricate
   task of histopathological diagnosis.
ZA 0
ZR 0
ZB 4
ZS 0
Z8 0
TC 5
Z9 5
DA 2024-09-21
UT WOS:001311981900002
PM 39269615
ER

PT J
AU Reinen, Jenna
   Agurto, Carla
   Larrauri, Carlos
   Mohandass, Dheshan
   Corcoran, Cheryl
   Kambeitz-Ilankovic, Lana
   Reichenberg, Avi
   Lewandowski, Kathryn E.
   Yassin, Walid
   Wolff, Phillip
   Kapur, Tina
   Bouix, Sylvain
   Kahn, Rene
   McGorry, Patrick D.
   Kane, John M.
   Bearden, Carrie
   Nelson, Barnaby
   Woods, Scott W.
   Shenton, Martha E.
   Pasternak, Ofer
   Penzel, Nora
   Castro, Eduardo
   Polosecki, Pablo
   Cecchi, Guillermo
TI COMBINING LARGE LANGUAGE MODELS AND FEEDBACK FROM CLINICAL HIGH RISK
   INDIVIDUALS TO IDENTIFY FEATURES OF LIVED EXPERIENCE NARRATIVES
SO NEUROPSYCHOPHARMACOLOGY
VL 49
MA P801
BP 531
EP 532
SU 1
DT Meeting Abstract
PD DEC 2024
PY 2024
CT 63rd Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP)
CY DEC 08-11, 2024
CL Phoenix, AZ
SP Amer Coll Neuropsychopharmacol
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
TC 1
Z9 1
DA 2025-03-03
UT WOS:001421429900194
ER

PT J
AU Young, Cameron C.
   Enichen, Ellie
   Rivera, Christian
   Auger, Corinne A.
   Grant, Nathan
   Rao, Arya
   Succi, Marc D.
TI Diagnostic Accuracy of a Custom Large Language Model on Rare Pediatric
   Disease Case Reports
SO AMERICAN JOURNAL OF MEDICAL GENETICS PART A
VL 197
IS 2
DI 10.1002/ajmg.a.63878
EA SEP 2024
DT Article
PD FEB 2025
PY 2025
AB Accurately diagnosing rare pediatric diseases frequently represent a
   clinical challenge due to their complex and unusual clinical
   presentations. Here, we explore the capabilities of three large language
   models (LLMs), GPT-4, Gemini Pro, and a custom-built LLM (GPT-4
   integrated with the Human Phenotype Ontology [GPT-4 HPO]), by evaluating
   their diagnostic performance on 61 rare pediatric disease case reports.
   The performance of the LLMs were assessed for accuracy in identifying
   specific diagnoses, listing the correct diagnosis among a differential
   list, and broad disease categories. In addition, GPT-4 HPO was tested on
   100 general pediatrics case reports previously assessed on other LLMs to
   further validate its performance. The results indicated that GPT-4 was
   able to predict the correct diagnosis with a diagnostic accuracy of
   13.1%, whereas both GPT-4 HPO and Gemini Pro had diagnostic accuracies
   of 8.2%. Further, GPT-4 HPO showed an improved performance compared with
   the other two LLMs in identifying the correct diagnosis among its
   differential list and the broad disease category. Although these
   findings underscore the potential of LLMs for diagnostic support,
   particularly when enhanced with domain-specific ontologies, they also
   stress the need for further improvement prior to integration into
   clinical practice.
Z8 0
ZR 0
ZS 0
TC 3
ZA 0
ZB 0
Z9 3
DA 2024-09-18
UT WOS:001310786300001
PM 39268988
ER

PT J
AU Su, L X
   Weng, L
   Li, W X
   Long, Y
TI [Applications and challenges of large language models in critical care
   medicine].
SO Zhonghua yi xue za zhi
VL 103
IS 31
BP 2361
EP 2364
DI 10.3760/cma.j.cn112137-20230524-00847
DT English Abstract; Journal Article
PD 2023-Aug-22
PY 2023
AB The rapid development of big data methods and technologies has provided
   more and more new ideas and methods for clinical diagnosis and
   treatment. The emergence of large language models (LLM) has made it
   possible for human-computer interactive dialogues and applications in
   complex medical scenarios. Critical care medicine is a process of
   continuous dynamic targeted treatment. The huge data generated in this
   process needs to be integrated and optimized through models for clinical
   application, interaction in teaching simulation, and assistance in
   scientific research. Using the LLM represented by generative pre-trained
   transformer ChatGPT can initially realize the application in the
   diagnosis of severe diseases, the prediction of death risk and the
   management of medical records. At the same time, the time and space
   limitations, illusions and ethical and moral issues of ChatGPT emerged
   as the times require. In the future, it is undeniable that it may play a
   huge role in the diagnosis and treatment of critical care medicine, but
   the current application should be combined with more clinical knowledge
   reserves of critical care medicine to carefully judge its conclusions.
AB 大数据方法和技术发展日新月异，给临床诊疗提供了越来越多的新的思路和方法。大语言模型的出现使得人机交互式的对话和复杂的医疗场景下的应用成为了可能。
   重症医学是一个连续动态目标性治疗的过程，这个过程中产生的庞大数据需要通过模型进行整合与优化并在临床应用，在教学模拟中互动，在科学研究中助力。使用
   以生成式预训练转换模型（ChatGPT）为代表的大语言模型可初步实现在重症疾病的诊断、死亡风险预测和病案管理方面的应用。同时ChatGPT的时空
   局限性、幻象和伦理道德问题应运而生。ChatGPT在未来的重症医学诊疗中可能会发挥巨大作用，但目前需要结合更多的重症医学临床知识储备并谨慎对待其
   作出的结论进行判断。.
ZR 0
TC 1
ZB 0
Z8 3
ZS 0
ZA 0
Z9 4
DA 2023-08-23
UT MEDLINE:37599212
PM 37599212
ER

PT J
AU Yu, Yunguo
   Gomez-Cabello, Cesar A.
   Makarova, Svetlana
   Parte, Yogesh
   Borna, Sahar
   Haider, Syed Ali
   Genovese, Ariana
   Prabha, Srinivasagam
   Forte, Antonio J.
TI Using Large Language Models to Retrieve Critical Data from Clinical
   Processes and Business Rules
SO BIOENGINEERING-BASEL
VL 12
IS 1
AR 17
DI 10.3390/bioengineering12010017
DT Article
PD JAN 2025
PY 2025
AB Current clinical care relies heavily on complex, rule-based systems for
   tasks like diagnosis and treatment. However, these systems can be
   cumbersome and require constant updates. This study explores the
   potential of the large language model (LLM), LLaMA 2, to address these
   limitations. We tested LLaMA 2 ' s performance in interpreting complex
   clinical process models, such as Mayo Clinic Care Pathway Models (CPMs),
   and providing accurate clinical recommendations. LLM was trained on
   encoded pathways versions using DOT language, embedding them with
   SentenceTransformer, and then presented with hypothetical patient cases.
   We compared the token-level accuracy between LLM output and the ground
   truth by measuring both node and edge accuracy. LLaMA 2 accurately
   retrieved the diagnosis, suggested further evaluation, and delivered
   appropriate management steps, all based on the pathways. The average
   node accuracy across the different pathways was 0.91 (SD +/- 0.045),
   while the average edge accuracy was 0.92 (SD +/- 0.122). This study
   highlights the potential of LLMs for healthcare information retrieval,
   especially when relevant data are provided. Future research should focus
   on improving these models' interpretability and their integration into
   existing clinical workflows.
ZS 0
ZB 0
Z8 0
ZA 0
TC 1
ZR 0
Z9 1
DA 2025-02-01
UT WOS:001404597900001
PM 39851291
ER

PT J
AU Zhou, Jin
   Li, Xiaoqin
   Xia, Qianjun
   Yu, Liangcai
TI Innovations in otolaryngology using LLM for early detection of
   sleep-disordered breathing
SO SLAS TECHNOLOGY
VL 32
AR 100278
DI 10.1016/j.slast.2025.100278
EA MAR 2025
DT Article
PD JUN 2025
PY 2025
AB Sleep Disordered Breathing (SDB), including conditions like Obstructive
   Sleep Apnea (OSA), represents a major health concern, characterized by
   irregular airflow during sleep due to airway obstruction. SDB can result
   in serious health problems. Implementation of early intervention is
   vital whenever patient outcomes are to be considered. This research aims
   to advance research on otolaryngology using Machine Learning (ML)
   models, and Large Language Models (LLM) for identification of SDB using
   Electronic Health Record (HER). The approach proposes a hybrid ML
   framework combining the Dynamic Seagull Search algorithm-driven Large
   Language model (DSS-LLM). The extensive clinical dataset is used to
   train the model. It includes patient demographics, medical history,
   sleep habits, comorbidities, and physical measurements. Data
   pre-processing involves handling missing values, applying NLP
   techniques, and normalization. Feature extraction is done using
   Principal Component Analysis (PCA) to reduce the dimensionality of the
   hyperparameters and finally for selecting the best set of predictors.
   The extracted features are then used to train the proposed DSS-LLM
   model, which incorporates the DSS algorithm to optimize the LLM
   classifier, improving classification accuracy and model robustness.
   Subsequently, the idea of LLM is introduced for its application on
   textual clinical records comprising physicians' reports and patients'
   symptoms. The findings from an experiment suggest that the proposed
   model enhances the classification accuracy achieved to 98.91 %,
   precision attained by 98.9 %, recall achieved to 98.92 % and F-1 score
   attained by 98.58 % as compared to the models developed earlier. This
   research provides a novel solution to the screening of OSA at the
   pre-clinical level which involves hybrid machine learning models
   integrated with LLMs. This proposed framework is expected to boost
   clinical judgment and thereby increase better ophthalmology outcomes for
   patients.
ZS 0
TC 0
ZA 0
ZB 0
Z8 0
ZR 0
Z9 0
DA 2025-04-06
UT WOS:001457142200001
PM 40122382
ER

PT J
AU Kral, Jan
   Hradis, Michal
   Buzga, Marek
   Kunovsky, Lumir
TI Exploring the benefits and challenges of AI-driven large language models
   in gastroenterology: Think out of the box
SO BIOMEDICAL PAPERS-OLOMOUC
VL 168
IS 4
BP 277
EP 283
DI 10.5507/bp.2024.027
EA SEP 2024
DT Review
PD DEC 2024
PY 2024
AB Artificial Intelligence (AI) has evolved significantly over the past
   decades, from its early concepts in the 1950s to the present era of deep
   learning and natural language processing. Advanced large language models
   (LLMs), such as Chatbot Generative Pre-Trained Transformer (ChatGPT) is
   trained to generate human-like text responses. This technology has the
   potential to revolutionize various aspects of gastroenterology,
   including diagnosis, treatment, education, and The benefits of using
   LLMs in gastroenterology could include accelerating diagnosis and
   treatment, providing personalized care, enhancing education and
   training, assisting in decision-making, and improving communication with
   patients. However, drawbacks and challenges such as limited AI
   capability, training on possibly biased data, data errors, security and
   privacy concerns, and implementation costs must be addressed to ensure
   the responsible and effective use of this technology. The future of LLMs
   in gastroenterology relies on the ability to process and analyse large
   amounts of data, identify patterns, and summarize information and thus
   assist physicians in creating personalized treatment plans. As AI
   advances, LLMs will become more accurate and efficient, allowing for
   faster diagnosis and treatment of gastroenterological conditions.
   Ensuring effective collaboration between AI developers, healthcare
   professionals, and regulatory bodies is essential for the responsible
   and effective use of this technology. By finding the right balance
   between AI and human expertise and addressing the limitations and risks
   associated with its use, LLMs can play an increasingly significant role
   in gastroenterology, contributing to better patient care and supporting
   doctors in their work.
ZR 0
ZS 0
Z8 0
ZA 0
TC 2
ZB 0
Z9 2
DA 2024-09-12
UT WOS:001306654600001
PM 39234774
ER

PT J
AU Franc, Jeffrey Michael
   Hertelendy, Atilla
   Cheng, Lenard
   Hata, Ryan
   Verde, Manuela
TI Repeatability, Reproducibility, and Diagnostic Accuracy of a Commercial
   Large Language Model (ChatGPT) to Perform Disaster Triage Using the
   Simple Triage and Rapid Treatment (START) Protocol
SO DISASTER MEDICINE AND PUBLIC HEALTH PREPAREDNESS
VL 18
AR e183
DI 10.1017/dmp.2024.194
DT Article
PD OCT 31 2024
PY 2024
AB Objective: The release of ChatGPT in November 2022 drastically lowered
   the barrier to artificial intelligence with an intuitive web-based
   interface to a large language model. This study addressed the research
   problem: " Can ChatGPT adequately triage simulated disaster patients
   using the Simple Triage and Rapid Treatment (START) tool?" Methods: Five
   trained disaster medicine physicians developed nine prompts. A Python
   script queried ChatGPT Version 4 with each prompt combined with 391
   validated patient vignettes. Ten repetitions of each combination were
   performed: 35190 simulated triages. Results: A valid START score was
   returned In 35102 queries (99.7%). There was considerable variability in
   the results. Repeatability (use of the same prompt repeatedly) was
   responsible for 14.0% of overall variation. Reproducibility (use of
   different prompts) was responsible for 4.1% of overall variation.
   Accuracy of ChatGPT for START was 61.4% with a 5.0% under-triage rate
   and a 33.6% over-triage rate. Accuracy varied by prompt between 45.8%
   and 68.6%. Conclusions: This study suggests that the current ChatGPT
   large language model is not sufficient for triage of simulated patients
   using START due to poor repeatability and accuracy. Medical
   practitioners should be aware that while ChatGPT can be a valuable tool,
   it may lack consistency and may provide false information.
ZS 0
TC 0
ZB 0
ZR 0
Z8 0
ZA 0
Z9 0
DA 2024-11-11
UT WOS:001346192900001
ER

PT J
AU Schultebraucks, Katharina
TI Scalable Digital Innovations in Real-World Settings: Recent Advances in
   Digital Biomarkers and Large Language Models
SO NEUROPSYCHOPHARMACOLOGY
VL 49
MA 7.1
BP 8
EP 8
SU 1
DT Meeting Abstract
PD DEC 2024
PY 2024
CT 63rd Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP)
CY DEC 08-11, 2023
CL Phoenix, AZ
SP Amer Coll Neuropsychopharmacol
ZR 0
ZB 0
ZS 0
TC 0
ZA 0
Z8 0
Z9 0
DA 2025-02-23
UT WOS:001421429700019
ER

PT J
AU Abdelgadir, Yasir
   Thongprayoon, Charat
   Miao, Jing
   Pham, Justin
   Suppadungsuk, Supawadee
   Craici, Iasmina
   Cheungpasitporn, Wisit
TI Enhancing Nephrology with Artificial Intelligence (AI)-Assisted ICD-10
   Coding: Improving Health Care Reimbursement, Patient Care, Research, and
   Previsit Test Workflow Efficiency through Case Scenarios
SO JOURNAL OF THE AMERICAN SOCIETY OF NEPHROLOGY
VL 35
IS 10
MA TH-OR25
DI 10.1681/ASN.2024eajj80ee
SU S
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Kidney Week
CY OCT 24-27, 2024
CL San Diego, CA
ZS 0
ZR 0
ZA 0
TC 0
ZB 0
Z8 0
Z9 0
DA 2025-03-21
UT WOS:001405917806204
ER

PT J
AU Greb, Alexandra C.
   Hong, Soonwook
   Zheng, Henry
   Sharma, Vikram
   Limketkai, Berkeley
TI Summation and Interpretation of Endoscopy Reports of Patients with
   Inflammatory Bowel Disease Using Large Language Models
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
VL 119
IS 10S
MA S1418
BP S1016
EP S1016
DI 10.14309/01.ajg.0001035040.66571.c2
SU 10
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Annual Meeting of the American-College-of-Gastroenterology (ACG)
CY OCT 25-30, 2024
CL Pennsylvania Convention Cent, Philadelphia, PA
HO Pennsylvania Convention Cent
SP Amer Coll Gastroenterol
ZR 0
TC 0
Z8 0
ZS 0
ZB 0
ZA 0
Z9 0
DA 2024-12-01
UT WOS:001359341300029
ER

PT J
AU Mykhalko, Yaroslav
   Kish, Pavlo
   Rubtsova, Yelyzaveta
   Kutsyn, Oleksandr
   Koval, Valentyna
TI FROM TEXT TO DIAGNOSE: CHATGPT'S EFFICACY IN MEDICAL DECISION-MAKING.
SO Wiadomosci lekarskie (Warsaw, Poland : 1960)
VL 76
IS 11
BP 2345
EP 2350
DI 10.36740/WLek202311101
DT Journal Article
PD 2023
PY 2023
AB OBJECTIVE: The aim: Evaluate the diagnostic capabilities of the ChatGPT
   in the field of medical diagnosis.
   PATIENTS AND METHODS: Materials and methods: We utilized 50 clinical
   cases, employing Large Language Model ChatGPT-3.5. The experiment had
   three phases, each with a new chat setup. In the initial phase, ChatGPT
   received detailed clinical case descriptions, guided by a "Persona
   Pattern" prompt. In the second phase, cases with diagnostic errors were
   addressed by providing potential diagnoses for ChatGPT to choose from.
   The final phase assessed artificial intelligence's ability to mimic a
   medical practitioner's diagnostic process, with prompts limiting initial
   information to symptoms and history.
   RESULTS: Results: In the initial phase, ChatGPT showed a 66.00%
   diagnostic accuracy, surpassing physicians by nearly 50%. Notably, in 11
   cases requiring image interpretation, ChatGPT struggled initially but
   achieved a correct diagnosis for four without added interpretations. In
   the second phase, ChatGPT demonstrated a remarkable 70.59% diagnostic
   accuracy, while physicians averaged 41.47%. Furthermore, the overall
   accuracy of Large Language Model in first and second phases together was
   90.00%. In the third phase emulating real doctor decision-making,
   ChatGPT achieved a 46.00% success rate.
   CONCLUSION: Conclusions: Our research underscores ChatGPT's strong
   potential in clinical medicine as a diagnostic tool, especially in
   structured scenarios. It emphasizes the need for supplementary data and
   the complexity of medical diagnosis. This contributes valuable insights
   to AI-driven clinical diagnostics, with a nod to the importance of
   prompt engineering techniques in ChatGPT's interaction with doctors.
TC 6
ZR 0
ZB 1
Z8 0
ZS 0
ZA 0
Z9 6
DA 2023-12-21
UT MEDLINE:38112347
PM 38112347
ER

PT J
AU Liu, Jilei
   Shen, Hongru
   Chen, Kexin
   Li, Xiangchun
TI Large language model produces high accurate diagnosis of cancer from
   end-motif profiles of cell-free DNA
SO BRIEFINGS IN BIOINFORMATICS
VL 25
IS 5
AR bbae430
DI 10.1093/bib/bbae430
DT Article
PD SEP 2 2024
PY 2024
AB Instruction-tuned large language models (LLMs) demonstrate exceptional
   ability to align with human intentions. We present an LLM-based
   model-instruction-tuned LLM for assessment of cancer (iLLMAC)-that can
   detect cancer using cell-free deoxyribonucleic acid (cfDNA) end-motif
   profiles. Developed on plasma cfDNA sequencing data from 1135 cancer
   patients and 1106 controls across three datasets, iLLMAC achieved area
   under the receiver operating curve (AUROC) of 0.866 [95% confidence
   interval (CI), 0.773-0.959] for cancer diagnosis and 0.924 (95% CI,
   0.841-1.0) for hepatocellular carcinoma (HCC) detection using 16
   end-motifs. Performance increased with more motifs, reaching 0.886 (95%
   CI, 0.794-0.977) and 0.956 (95% CI, 0.89-1.0) for cancer diagnosis and
   HCC detection, respectively, with 64 end-motifs. On an external-testing
   set, iLLMAC achieved AUROC of 0.912 (95% CI, 0.849-0.976) for cancer
   diagnosis and 0.938 (95% CI, 0.885-0.992) for HCC detection with 64
   end-motifs, significantly outperforming benchmarked methods.
   Furthermore, iLLMAC achieved high classification performance on datasets
   with bisulfite and 5-hydroxymethylcytosine sequencing. Our study
   highlights the effectiveness of LLM-based instruction-tuning for
   cfDNA-based cancer detection.
ZA 0
ZR 0
Z8 0
ZB 1
TC 4
ZS 0
Z9 4
DA 2024-09-08
UT WOS:001304494500001
PM 39222060
ER

PT J
AU Ren, Yaxuan
   Luo, Xufei
   Wang, Ye
   Li, Haodong
   Zhang, Hairong
   Li, Zeming
   Lai, Honghao
   Li, Xuanlin
   Ge, Long
   Estill, Janne
   Zhang, Lu
   Yang, Shu
   Chen, Yaolong
   Wen, Chengping
   Bian, Zhaoxiang
   ADVANCED Working Group
TI Large Language Models in Traditional Chinese Medicine: A Scoping Review
SO JOURNAL OF EVIDENCE BASED MEDICINE
VL 18
IS 1
DI 10.1111/jebm.12658
EA DEC 2024
DT Review
PD MAR 2025
PY 2025
AB BackgroundThe application of large language models (LLMs) in medicine
   has received increasing attention, showing significant potential in
   teaching, research, and clinical practice, especially in knowledge
   extraction, management, and understanding. However, the use of LLMs in
   Traditional Chinese Medicine (TCM) has not been thoroughly studied. This
   study aims to provide a comprehensive overview of the status and
   challenges of LLM applications in TCM.MethodsA systematic search of five
   electronic databases and Google Scholar was conducted between November
   2022 and April 2024, using the Arksey and O'Malley five-stage framework
   to identify relevant studies. Data from eligible studies were
   comprehensively extracted and organized to describe LLM applications in
   TCM and assess their performance accuracy.ResultsA total of 29 studies
   were identified: 24 peer-reviewed articles, 1 review, and 4 preprints.
   Two core application areas were found: the extraction, management, and
   understanding of TCM knowledge, and assisted diagnosis and treatment.
   LLMs developed specifically for TCM achieved 70% accuracy in the TCM
   Practitioner Exam, while general-purpose Chinese LLMs achieved 60%
   accuracy. Common international LLMs did not pass the exam. Models like
   EpidemicCHAT and MedChatZH, trained on customized TCM corpora,
   outperformed general LLMs in TCM consultation.ConclusionDespite their
   potential, LLMs in TCM face challenges such as data quality and security
   issues, the specificity and complexity of TCM data, and the
   nonquantitative nature of TCM diagnosis and treatment. Future efforts
   should focus on interdisciplinary talent cultivation, enhanced data
   standardization and protection, and exploring LLM potential in
   multimodal interaction and intelligent diagnosis and treatment.
ZR 0
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001373936900001
PM 39651543
ER

PT J
AU Niu, Hao
   Alvarez-Alvarez, Ismael
   Chen, Minjun
TI Artificial Intelligence: An Emerging Tool for Studying Drug-Induced
   Liver Injury
SO LIVER INTERNATIONAL
VL 45
IS 3
AR e70038
DI 10.1111/liv.70038
DT Review
PD MAR 2025
PY 2025
AB Drug-induced liver injury (DILI) is a complex and potentially severe
   adverse reaction to drugs, herbal products or dietary supplements. DILI
   can mimic other liver diseases clinical presentation, and currently
   lacks specific diagnostic biomarkers, which hinders its diagnosis. In
   some cases, DILI may progress to acute liver failure. Given its public
   health risk, novel methodologies to enhance the understanding of DILI
   are crucial. Recently, the increasing availability of larger datasets
   has highlighted artificial intelligence (AI) as a powerful tool to
   construct complex models. In this review, we summarise the evidence
   about the use of AI in DILI research, explaining fundamental AI concepts
   and its subfields. We present findings from AI-based approaches in DILI
   investigations for risk stratification, prognostic evaluation and
   causality assessment and discuss the adoption of natural language
   processing (NLP) and large language models (LLM) in the clinical
   setting. Finally, we explore future perspectives and challenges in
   utilising AI for DILI research.
ZR 0
ZS 0
ZA 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-03-12
UT WOS:001427185500001
PM 39982029
ER

PT J
AU Liu, Jialin
   Wang, Changyu
   Liu, Siru
TI Utility of ChatGPT in Clinical Practice
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 25
AR e48568
DI 10.2196/48568
DT Article
PD JUN 28 2023
PY 2023
AB ChatGPT is receiving increasing attention and has a variety of
   application scenarios in clinical practice. In clinical decision
   support, ChatGPT has been used to generate accurate differential
   diagnosis lists, support clinical decision-making, optimize clinical
   decision support, and provide insights for cancer screening decisions.
   In addition, ChatGPT has been used for intelligent question-answering to
   provide reliable information about diseases and medical queries. In
   terms of medical documentation, ChatGPT has proven effective in
   generating patient clinical letters, radiology reports, medical notes,
   and discharge summaries, improving efficiency and accuracy for health
   care providers. Future research directions include real-time monitoring
   and predictive analytics, precision medicine and personalized treatment,
   the role of ChatGPT in telemedicine and remote health care, and
   integration with existing health care systems. Overall, ChatGPT is a
   valuable tool that complements the expertise of health care providers
   and improves clinical decision-making and patient care. However, ChatGPT
   is a double-edged sword. We need to carefully consider and study the
   benefits and potential dangers of ChatGPT. In this viewpoint, we discuss
   recent advances in ChatGPT research in clinical practice and suggest
   possible risks and challenges of using ChatGPT in clinical practice. It
   will help guide and support future artificial intelligence research
   similar to ChatGPT in health.
ZS 1
ZR 0
Z8 5
TC 230
ZB 25
ZA 0
Z9 234
DA 2023-08-24
UT WOS:001045687800005
PM 37379067
ER

PT J
AU Cui, Miao
   Sauter, Jennifer
   Chang, Jason
   Yang, Soo-Ryum
   Baine, Marina
   Rekhtman, Natasha
   Travis, William
TI Harnessing GPT-Driven AI for Enhanced Pathology: Development and
   Applications of the 'Pathology 2nd Brain'
SO LABORATORY INVESTIGATION
VL 105
IS 3
MA 1346
AR 103584
DI 10.1016/j.labinv.2024.103584
EA MAR 2025
SU S
DT Meeting Abstract
PD MAR 2025
PY 2025
CT Annual Meeting of the United-States-and-Canadian-Academy-of-Pathology
   (USCAP)
CY MAR 22-27, 2025
CL Boston, MA
SP United States & Canadian Acad Pathol
ZA 0
ZS 0
ZR 0
TC 0
ZB 0
Z8 0
Z9 0
DA 2025-04-19
UT WOS:001464120600020
ER

PT J
AU Kaster, L. P.
   Oh, I
   Vickstrom, C.
   Lanzotti, V
   Payne, P.
   Gurnett, C. A.
   Gupta, A.
TI Utilizing Large-Language Models to Extract Patient Verbal and Ambulatory
   Status from Multi-Institutional and Multi-Specialty Clinical Notes
SO ANNALS OF NEUROLOGY
VL 96
MA GAT1-4
BP S27
EP S27
SU 33
DT Meeting Abstract
PD NOV 2025
PY 2025
CT 53rd Annual Meeting of the Child-Neurology-Society (CNS)
CY NOV 11-14, 2024
CL San Diego, CA
SP Child Neurol Soc
ZA 0
TC 0
ZS 0
Z8 0
ZB 0
ZR 0
Z9 0
DA 2025-02-03
UT WOS:001389178600026
ER

PT J
AU Sarma, Karthik
   Hanss, Kaitlin
   Glowinski, Anne
   Halls, Andrew
   Krystal, Andrew
   Butte, Atul
TI Can Large Language Model-Based AI Reason About Behavioral Health?
   Preliminary Evaluation of a Decision Tree-Based LLM Algorithm for
   Psychiatric Case Diagnosis
SO NEUROPSYCHOPHARMACOLOGY
VL 49
MA P44
BP 90
EP 91
SU 1
DT Meeting Abstract
PD DEC 2024
PY 2024
CT 63rd Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP)
CY DEC 08-11, 2023
CL Phoenix, AZ
SP Amer Coll Neuropsychopharmacol
ZS 0
ZR 0
Z8 0
TC 0
ZB 0
ZA 0
Z9 0
DA 2025-02-23
UT WOS:001421429700202
ER

PT J
AU Song, Haifeng
   Xia, Yi
   Song, Yan
   Li, Jianxing
   Zhang, Guangyuan
   Xiao, Bo
TI EVALUATING THE PERFORMANCE OF DIFFERENT LARGE LANGUAGE MODELS ON HEALTH
   CONSULTATION AND PATIENT EDUCATION IN UROLITHIASIS
SO JOURNAL OF UROLOGY
VL 211
IS 5
MA MP24-02
BP E391
EP E392
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Annual Meeting of the American-Urological-Association (AUA)
CY MAY 03-06, 2024
CL San Antonio, TX
SP Amer Urolog Assoc
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 1
Z9 1
DA 2024-08-04
UT WOS:001263885301240
ER

PT J
AU Sakurada, Kazuhiro
   Ishikawa, Tetsuo
   Oba, Junna
   Kuno, Masahiro
   Okano, Yuji
   Sakamaki, Tomomi
   Tamura, Tomohiro
TI Medical AI and AI for Medical Sciences
SO JMA JOURNAL
VL 8
IS 1
BP 26
EP 37
DI 10.31662/jmaj.2024-0185
EA NOV 2024
DT Review
PD JAN 15 2025
PY 2025
AB Digital transformation of healthcare is rapidly progressing. Digital
   transformation improves the quality of services and access to health
   information for users, reduces the workload and associated costs for
   healthcare providers, and supports clinical decision-making. Data and
   artificial intelligence (AI) play a key role in this process. The AI
   used for this purpose is called medical AI. Medical AI is currently
   undergoing a shift from task-specific to general-purpose models. Large
   language models have the potential to systematize existing medical
   knowledge in a standardized way.
   The usage of AI in medicine is not limited to digital transformation; it
   plays a pivotal role in fundamentally changing the state of medical
   science. This approach, known as "AI for Medical Science," focuses on
   pioneering a form of medical science that predicts the onset and
   progression of disease based on the underlying causes of disease. The
   key to such predictive medicine is the concept of "states," which can be
   sought through machine learning. Using states instead of symptoms not
   only dramatically improves the accuracy of identification (diagnosis)
   and prediction (prognosis) but also potentially pioneers P4 medicine by
   integrating it with empirical knowledge and theories based on natural
   principles.
ZA 0
ZR 0
ZS 0
Z8 0
TC 2
ZB 0
Z9 1
DA 2024-12-01
UT WOS:001364088600001
PM 39926067
ER

PT J
AU Seifen, Christopher
   Huppertz, Tilman
   Gouveris, Haralampos
   Bahr-Hamm, Katharina
   Pordzik, Johannes
   Eckrich, Jonas
   Smith, Harry
   Kelsey, Tom
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Chasing sleep physicians: ChatGPT-4o on the interpretation of
   polysomnographic results
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 282
IS 3
BP 1631
EP 1639
DI 10.1007/s00405-024-08985-3
EA OCT 2024
DT Article
PD MAR 2025
PY 2025
AB BackgroundFrom a healthcare professional's perspective, the use of
   ChatGPT (Open AI), a large language model (LLM), offers huge potential
   as a practical and economic digital assistant. However, ChatGPT has not
   yet been evaluated for the interpretation of polysomnographic results in
   patients with suspected obstructive sleep apnea (OSA).Aims/objectivesTo
   evaluate the agreement of polysomnographic result interpretation between
   ChatGPT-4o and a board-certified sleep physician and to shed light into
   the role of ChatGPT-4o in the field of medical decision-making in sleep
   medicine.Material and methodsFor this proof-of-concept study, 40
   comprehensive patient profiles were designed, which represent a broad
   and typical spectrum of cases, ensuring a balanced distribution of
   demographics and clinical characteristics. After various prompts were
   tested, one prompt was used for initial diagnosis of OSA and a further
   for patients with positive airway pressure (PAP) therapy intolerance.
   Each polysomnographic result was independently evaluated by ChatGPT-4o
   and a board-certified sleep physician. Diagnosis and therapy suggestions
   were analyzed for agreement.ResultsChatGPT-4o and the sleep physician
   showed 97% (29/30) concordance in the diagnosis of the simple cases. For
   the same cases the two assessment instances unveiled 100% (30/30)
   concordance regarding therapy suggestions. For cases with intolerance of
   treatment with positive airway pressure (PAP) ChatGPT-4o and the sleep
   physician revealed 70% (7/10) concordance in the diagnosis and 44%
   (22/50) concordance for therapy suggestions.Conclusion and
   significancePrecise prompting improves the output of ChatGPT-4o and
   provides sleep physician-like polysomnographic result interpretation.
   Although ChatGPT shows some shortcomings in offering treatment advice,
   our results provide evidence for AI assisted automation and
   economization of polysomnographic interpretation by LLMs. Further
   research should explore data protection issues and demonstrate
   reproducibility with real patient data on a larger scale.
ZR 0
TC 2
ZB 0
ZA 0
ZS 0
Z8 0
Z9 2
DA 2024-10-27
UT WOS:001337955400003
PM 39427271
ER

PT J
AU Zhang, Sainan
   Song, Jisung
TI A chatbot based question and answer system for the auxiliary diagnosis
   of chronic diseases based on large language model
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 17118
DI 10.1038/s41598-024-67429-4
DT Article
PD JUL 25 2024
PY 2024
AB In recent years, artificial intelligence has made remarkable strides,
   improving various aspects of our daily lives. One notable application is
   in intelligent chatbots that use deep learning models. These systems
   have shown tremendous promise in the medical sector, enhancing
   healthcare quality, treatment efficiency, and cost-effectiveness.
   However, their role in aiding disease diagnosis, particularly chronic
   conditions, remains underexplored. Addressing this issue, this study
   employs large language models from the GPT series, in conjunction with
   deep learning techniques, to design and develop a diagnostic system
   targeted at chronic diseases. Specifically, performed transfer learning
   and fine-tuning on the GPT-2 model, enabling it to assist in accurately
   diagnosing 24 common chronic diseases. To provide a user-friendly
   interface and seamless interactive experience, we further developed a
   dialog-based interface, naming it Chat Ella. This system can make
   precise predictions for chronic diseases based on the symptoms described
   by users. Experimental results indicate that our model achieved an
   accuracy rate of 97.50% on the validation set, and an area under the
   curve (AUC) value reaching 99.91%. Moreover, conducted user satisfaction
   tests, which revealed that 68.7% of participants approved of Chat Ella,
   while 45.3% of participants found the system made daily medical
   consultations more convenient. It can rapidly and accurately assess a
   patient's condition based on the symptoms described and provide timely
   feedback, making it of significant value in the design of medical
   auxiliary products for household use.
ZB 0
ZR 0
ZA 0
TC 6
ZS 0
Z8 0
Z9 6
DA 2024-08-03
UT WOS:001278002800002
PM 39054346
ER

PT J
AU Wang, Xu
   Mao, April W.
   Pan, Sirui
   Wang, Dawei
   He, Lili
   Vogel, Hannes
   Mao, Jian-Hua
   Weiss, William
   Li, Tao
   Chang, Hang
TI Cellular morphometric biomarkers and large language model predict
   prognosis and treatment response in neuroblastoma patients: A
   retrospective and double-blind prospective single arm clinical study
SO EUROPEAN JOURNAL OF CANCER
VL 218
AR 115273
DI 10.1016/j.ejca.2025.115273
EA FEB 2025
DT Article
PD MAR 11 2025
PY 2025
AB Background: The heterogeneity of Neuroblastoma (NB) leads to variation
   in response to treatment , outcomes. The aim of the current study is to
   discover AI-empowered cellular morphometric biomarkers (CMBs), to
   establish the corresponding CMB risk score (CMBRS), CMB risk group
   (CMBRG), large language model driven CMB risk score (CMB-LLM-RS) , large
   language model driven CMB risk group (CMB-LLM-RG), and to investigate
   and validate their prognostic and predictive power in NB. Methods: In
   this study, the retrospective cohort enrolled 84 primary NBs between
   1/2020 and 12/2021, followed up through 11/22/2024; the prospective
   cohort enrolled 67 primary NBs between 1/2022 and 7/2023, followed up
   through 11/22/2024. Results: We identified 9 CMBs from a retrospective
   NB cohort, enabling the CMBRS, CMBRG, CMB-LLM-RS, and CMB-LLM-RG. Both
   CMBRG and CMB-LLM-RG are significantly associated with prognosis (p <
   0.0001) and treatment response (p < 0.0001). Furthermore, we
   double-blindly validated the predictive power of CMBRG and CMB-LLM-RG in
   a prospective NB cohort, which confirms their potential value in real
   clinical settings. Impor- tantly, CMBRG provides clinical value
   independent of the International Neuroblastoma Risk Group (INRG)
   classification system in both retrospective and prospective NB cohorts
   (p < 0.05); and the combination of CMBRG and INRG significantly
   increases prognostic and predictive performance for NB patients.
   Conclusions: These findings suggest that CMBRG and CMB-LLM-RG have
   prognostic and predictive value for NB and warrants evaluation in larger
   multicenter cohorts.
ZA 0
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-02-23
UT WOS:001423930700001
PM 39908653
ER

PT J
AU Koga, Shunsuke
   Du, Wei
TI Challenges of Integrating Chatbot Use in Ophthalmology Diagnostics
SO JAMA OPHTHALMOLOGY
VL 142
IS 9
BP 883
EP 884
DI 10.1001/jamaophthalmol.2024.2303
EA JUL 2024
DT Letter
PD SEP 2024
PY 2024
TC 0
Z8 0
ZS 0
ZA 0
ZR 0
ZB 0
Z9 0
DA 2024-07-14
UT WOS:001263237700003
PM 38958958
ER

PT J
AU Souaid, Tarek
   Kerbage, Anthony
   Macaron, Carole
   Burke, Carol A.
   Rouphael, Carol
TI Visual Accuracy of Gemini Pro 1.5 and GPT-4o in Determining Ulcerative
   Colitis Severity Based on Endoscopic Images Using the Modified Mayo
   Endoscopic Score
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
VL 119
IS 10S
MA S1213
BP S863
EP S863
DI 10.14309/01.ajg.0001034220.50852.04
SU 10
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Annual Meeting of the American-College-of-Gastroenterology (ACG)
CY OCT 25-30, 2024
CL Pennsylvania Convention Cent, Philadelphia, PA
HO Pennsylvania Convention Cent
SP Amer Coll Gastroenterol
ZB 0
ZR 0
Z8 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2024-11-30
UT WOS:001359891400007
ER

PT J
AU Johnston, Edward W.
   Goldberg, S. Nahum
TI Photodynamic Therapy for Abdominopelvic Abscesses
SO RADIOLOGY
VL 310
IS 3
AR e240408
DI 10.1148/radiol.240408
DT Editorial Material
PD MAR 2024
PY 2024
ZA 0
ZB 0
TC 0
ZR 0
ZS 0
Z8 0
Z9 0
DA 2024-06-21
UT WOS:001208969200019
PM 38501955
ER

PT J
AU Wang, P.
   Liu, Z.
   Li, Y.
   Holmes, J.
   Shu, P.
   Zhang, L.
   Li, X.
   Li, Q.
   Vora, S. A.
   Patel, S. H.
   Sio, T. T. W.
   Liu, T.
   Liu, W.
TI Fine-Tuning Large Language Models for Radiation Oncology, A Specialized
   Health Care Domain
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3452
BP E664
EP E664
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
Z8 0
ZB 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2024-12-16
UT WOS:001325892302131
ER

PT J
AU Erdogan, Esra Kayacan
   Babaoglu, Hakan
TI Clinical Reasoning and Knowledge Assessment of Rheumatology Residents
   Compared to AI Models: A Pilot Study
SO JOURNAL OF CLINICAL MEDICINE
VL 13
IS 23
AR 7405
DI 10.3390/jcm13237405
DT Article
PD DEC 2024
PY 2024
AB Background: The integration of artificial intelligence (AI) in medicine
   has progressed from rule-based systems to advanced models and is showing
   potential in clinical decision-making. In this study, the psychological
   impact of AI collaboration in clinical practice is assessed,
   highlighting its role as a support tool for medical residents. This
   study aimed to compare clinical decision-making approaches of junior
   rheumatology residents with both trained and untrained AI models in
   clinical reasoning, pre-diagnosis, first-line, and second-line
   management stages. Methods: Ten junior rheumatology residents and two
   GPT-4 models (trained and untrained) responded to 10 clinical cases,
   encompassing diagnostic and treatment challenges in inflammatory
   arthritis. The cases were evaluated using the Revised-IDEA (R-IDEA)
   scoring system and additional case management metrics. In addition to
   scoring clinical case performance, residents' attitudes toward AI
   integration in clinical practice were assessed through a structured
   questionnaire, focusing on perceptions of AI's potential after reviewing
   the trained GPT-4's answers. Results: Trained GPT-4 outperformed
   residents across all stages, achieving significantly higher median
   R-IDEA scores and superior performance in pre-diagnosis, first-line, and
   second-line management phases. Residents expressed a positive attitude
   toward AI integration, with 60% favoring AI as a supportive tool in
   clinical practice, anticipating benefits in competence, fatigue, and
   burnout. Conclusions: Trained GPT-4 models outperform junior residents
   in clinical reasoning and management of rheumatology cases. Residents'
   positive attitudes toward AI suggest its potential as a supportive tool
   to enhance confidence and reduce uncertainty in clinical practice.
   Trained GPT-4 may be used as a supplementary tool during the early years
   of residency.
ZR 0
ZB 0
ZS 0
ZA 0
TC 0
Z8 0
Z9 0
DA 2024-12-21
UT WOS:001376610600001
PM 39685863
ER

PT J
AU Ali, Sarah Al Farabi
   Al Dehlawi, Hebah
   Jazzar, Ahoud
   Ashi, Heba
   Abuzinadah, Nihal Esam
   Al Otaibi, Mohammad
   Algarni, Abdulrahman
   Alqahtani, Hazzaa
   Akeel, Sara
   Almazrooa, Soulafa
TI The Diagnostic Performance of Large Language Models and Oral Medicine
   Consultants for Identifying Oral Lesions in Text-Based Clinical
   Scenarios: Prospective Comparative Study
SO JMIR AI
VL 4
AR e70566
DI 10.2196/70566
DT Article
PD 2025
PY 2025
AB Background: The use of artificial intelligence (AI), especially large
   language models (LLMs), is increasing in health care, including in
   dentistry. There has yet to be an assessment of the diagnostic
   performance of LLMs in oral medicine. Objective: We aimed to compare the
   effectiveness of ChatGPT (OpenAI) and Microsoft Copilot (integrated
   within the Microsoft 365 suite) with oral medicine consultants in
   formulating accurate differential and final diagnoses for oral lesions
   from written clinical scenarios. Methods: Fifty comprehensive clinical
   case scenarios including patient age, presenting complaint, history of
   the presenting complaint, medical history, allergies, intra- and
   extraoral findings, lesion description, and any additional information
   including laboratory investigations and specific clinical features were
   given to three oral medicine consultants, who were asked to formulate a
   differential diagnosis and a final diagnosis. Specific prompts for the
   same 50 cases were designed and input into ChatGPT and Copilot to
   formulate both differential and final diagnoses. The diagnostic accuracy
   was compared between the LLMs and oral medicine consultants. Results:
   ChatGPT exhibited the highest accuracy, providing the correct
   differential diagnoses in 37 of 50 cases (74%). There were no
   significant differences in the accuracy of providing the correct
   differential diagnoses between AI models and oral medicine consultants.
   ChatGPT was as accurate as consultants in making the final diagnoses,
   but Copilot was significantly less accurate than ChatGPT (P=.015) and
   one of the oral medicine consultants (P<.001) in providing the correct
   final diagnosis. Conclusions: ChatGPT and Copilot show promising
   performance for diagnosing oral medicine pathology in clinical case
   scenarios to assist dental practitioners. ChatGPT-4 and Copilot are
   still evolving, but even now, they might provide a significant advantage
   in the clinical setting as tools to help dental practitioners in their
   daily practice.
Z8 0
ZA 0
TC 0
ZS 0
ZR 0
ZB 0
Z9 0
DA 2025-05-11
UT WOS:001481394700001
ER

PT J
AU Wada, Akihiko
   Akashi, Toshiaki
   Shih, George
   Hagiwara, Akifumi
   Nishizawa, Mitsuo
   Hayakawa, Yayoi
   Kikuta, Junko
   Shimoji, Keigo
   Sano, Katsuhiro
   Kamagata, Koji
   Nakanishi, Atsushi
   Aoki, Shigeki
TI Optimizing GPT-4 Turbo Diagnostic Accuracy in Neuroradiology through
   Prompt Engineering and Confidence Thresholds
SO DIAGNOSTICS
VL 14
IS 14
AR 1541
DI 10.3390/diagnostics14141541
DT Article
PD JUL 2024
PY 2024
AB Background and Objectives: Integrating large language models (LLMs) such
   as GPT-4 Turbo into diagnostic imaging faces a significant challenge,
   with current misdiagnosis rates ranging from 30-50%. This study
   evaluates how prompt engineering and confidence thresholds can improve
   diagnostic accuracy in neuroradiology. Methods: We analyze 751
   neuroradiology cases from the American Journal of Neuroradiology using
   GPT-4 Turbo with customized prompts to improve diagnostic precision.
   Results: Initially, GPT-4 Turbo achieved a baseline diagnostic accuracy
   of 55.1%. By reformatting responses to list five diagnostic candidates
   and applying a 90% confidence threshold, the highest precision of the
   diagnosis increased to 72.9%, with the candidate list providing the
   correct diagnosis at 85.9%, reducing the misdiagnosis rate to 14.1%.
   However, this threshold reduced the number of cases that responded.
   Conclusions: Strategic prompt engineering and high confidence thresholds
   significantly reduce misdiagnoses and improve the precision of the LLM
   diagnostic in neuroradiology. More research is needed to optimize these
   approaches for broader clinical implementation, balancing accuracy and
   utility.
Z8 0
ZS 0
ZR 0
ZA 0
TC 5
ZB 0
Z9 5
DA 2024-08-01
UT WOS:001276606000001
PM 39061677
ER

PT C
AU Jiang, Yixing
   Irvin, Jeremy A.
   Ng, Andrew Y.
   Zou, James
BE Hunter, L
   Altman, RB
   Ritchie, MD
   Murray, T
   Klein, TE
TI VetLLM: Large Language Model for Predicting Diagnosis from Veterinary
   Notes
SO BIOCOMPUTING 2024, PSB 2024
SE Biocomputing-Pacific Symposium on Biocomputing
BP 120
EP 133
DT Proceedings Paper
PD 2024
PY 2024
AB Lack of diagnosis coding is a barrier to leveraging veterinary notes for
   medical and public health research. Previous work is limited to develop
   specialized rule-based or customized supervised learning models to
   predict diagnosis coding, which is tedious and not easily transferable.
   In this work, we show that open-source large language models (LLMs)
   pretrained on general corpus can achieve reasonable performance in a
   zero-shot setting. Alpaca-7B can achieve a zero-shot F1 of 0.538 on CSU
   test data and 0.389 on PP test data, two standard benchmarks for coding
   from veterinary notes. Furthermore, with appropriate fine-tuning, the
   performance of LLMs can be substantially boosted, exceeding those of
   strong state-of-the-art supervised models. VetLLM, which is fine-tuned
   on Alpaca-7B using just 5000 veterinary notes, can achieve a F1 of 0.747
   on CSU test data and 0.637 on PP test data. It is of note that our
   fine-tuning is data-efficient: using 200 notes can outperform supervised
   models trained with more than 100,000 notes. The findings demonstrate
   the great potential of leveraging LLMs for language processing tasks in
   medicine, and we advocate this new paradigm for processing clinical
   text.
CT 29th Pacific Symposium on Biocomputing (PSB)
CY JAN 03-07, 2024
CL Kohala Coast, HI
ZS 0
ZR 0
Z8 0
ZB 0
TC 1
ZA 0
Z9 1
DA 2024-08-02
UT WOS:001258333100010
PM 38160274
ER

PT J
AU Farhat, Faiza
TI ChatGPT as a Complementary Mental Health Resource: A Boon or a Bane
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 5
BP 1111
EP 1114
DI 10.1007/s10439-023-03326-7
EA JUL 2023
DT Article
PD MAY 2024
PY 2024
AB The launch of Open AI's chatbot, ChatGPT, has generated a lot of
   attention and discussion among professionals in several fields. Many
   concerns and challenges have been brought up by researchers from various
   fields, particularly in relation to the harm that using these tools for
   medical diagnosis and treatment recommendations can cause. In addition,
   it has been debated if ChatGPT is dependable, efficient, and helpful for
   clinicians and medical professionals. Therefore, in this study, we
   assess ChatGPT's effectiveness in providing mental health support,
   particularly for issues related to anxiety and depression, based on the
   chatbot's responses and cross-questioning. The findings indicate that
   there are significant inconsistencies and that ChatGPT's reliability is
   low in this specific domain. As a result, care must be used when using
   ChatGPT as a complementary mental health resource.
Z8 0
ZS 0
ZR 0
ZB 4
ZA 0
TC 33
Z9 33
DA 2023-08-10
UT WOS:001035550600001
PM 37477707
ER

PT J
AU Pillai, Joshua
   Pillai, Kathryn
TI Accuracy of generative artificial intelligence models in differential
   diagnoses of familial Mediterranean fever and deficiency of
   Interleukin-1 receptor antagonist
SO JOURNAL OF TRANSLATIONAL AUTOIMMUNITY
VL 7
AR 100213
DI 10.1016/j.jtauto.2023.100213
EA OCT 2023
DT Article
PD DEC 2023
PY 2023
AB With the increasing development of artificial intelligence, large
   language models (LLMs) have been utilized to solve problems in natural
   language processing tasks. More recently, LLMs have shown unique
   potential in numerous applications within medicine but have been
   particularly investigated for their ability in clinical reasoning.
   Although the diagnostic accuracy of LLMs in forming differential
   diagnoses has been reviewed in general internal medicine applications,
   much is unknown in autoinflammatory disorders. From the nature of
   autoinflammatory diseases, forming a differential diagnosis is
   challenging due to the overlapping symptoms between disorders and even
   more difficult without genetic screening. In this work, the diagnostic
   accuracy of the Generative Pre-Trained Transformer Model-4 (GPT-4),
   GPT-3.5, and Large Language Model Meta AI (LLaMa) were evaluated in
   clinical vignettes of Deficiency of Interleukin-1 Receptor Antagonist
   (DIRA) and Familial Mediterranean Fever (FMF). We then compared these
   models to a control group including one internal medicine physician. It
   was found that GPT-4 did not significantly differ in correctly
   identifying DIRA and FMF patients compared to the internist. However,
   the physician maintained a significantly higher accuracy than GPT-3.5
   and LLaMa 2 for either disease. Overall, we explore and discuss the
   unique potential of LLMs in diagnostics for autoimmune diseases.
ZA 0
ZB 0
Z8 0
ZR 0
ZS 0
TC 6
Z9 6
DA 2023-12-04
UT WOS:001103664200001
PM 37927888
ER

PT J
AU Hirosawa, Takanobu
   Shimizu, Taro
TI The potential, limitations, and future of diagnostics enhanced by
   generative artificial intelligence
SO DIAGNOSIS
VL 11
IS 4
BP 446
EP 449
DI 10.1515/dx-2024-0095
EA JUL 2024
DT Article
PD NOV 6 2024
PY 2024
AB Objectives This short communication explores the potential, limitations,
   and future directions of generative artificial intelligence (GAI) in
   enhancing diagnostics.Methods This commentary reviews current
   applications and advancements in GAI, particularly focusing on its
   integration into medical diagnostics. It examines the role of GAI in
   supporting medical interviews, assisting in differential diagnosis, and
   aiding clinical reasoning through the lens of dual-process theory. The
   discussion is supported by recent examples and theoretical frameworks to
   illustrate the practical and potential uses of GAI in medicine.Results
   GAI shows significant promise in enhancing diagnostic processes by
   supporting the translation of patient descriptions into visual formats,
   providing differential diagnoses, and facilitating complex clinical
   reasoning. However, limitations such as the potential for generating
   medical misinformation, known as hallucinations, exist. Furthermore, the
   commentary highlights the integration of GAI with both intuitive and
   analytical decision-making processes in clinical diagnostics,
   demonstrating potential improvements in both the speed and accuracy of
   diagnoses.Conclusions While GAI presents transformative potential for
   medical diagnostics, it also introduces risks that must be carefully
   managed. Future advancements should focus on refining GAI technologies
   to better align with human diagnostic reasoning, ensuring GAI enhances
   rather than replaces the medical professionals' expertise.
ZS 0
Z8 0
ZB 0
TC 0
ZA 0
ZR 0
Z9 0
DA 2024-07-22
UT WOS:001268771800001
PM 38987215
ER

PT J
AU Shah, Krish
   Xu, Andrew Y.
   Sharma, Yatharth
   Daher, Mohammed
   Mcdonald, Christopher
   Diebo, Bassel G.
   Daniels, Alan H.
TI Large Language Model Prompting Techniques for Advancement in Clinical
   Medicine
SO JOURNAL OF CLINICAL MEDICINE
VL 13
IS 17
AR 5101
DI 10.3390/jcm13175101
DT Review
PD SEP 2024
PY 2024
AB Large Language Models (LLMs have the potential to revolutionize clinical
   medicine by enhancing healthcare access, diagnosis, surgical planning,
   and education. However, their utilization requires careful, prompt
   engineering to mitigate challenges like hallucinations and biases.
   Proper utilization of LLMs involves understanding foundational concepts
   such as tokenization, embeddings, and attention mechanisms, alongside
   strategic prompting techniques to ensure accurate outputs. For
   innovative healthcare solutions, it is essential to maintain ongoing
   collaboration between AI technology and medical professionals. Ethical
   considerations, including data security and bias mitigation, are
   critical to their application. By leveraging LLMs as supplementary
   resources in research and education, we can enhance learning and support
   knowledge-based inquiries, ultimately advancing the quality and
   accessibility of medical care. Continued research and development are
   necessary to fully realize the potential of LLMs in transforming
   healthcare.
ZB 1
ZS 0
Z8 0
TC 9
ZA 0
ZR 0
Z9 9
DA 2024-09-21
UT WOS:001311343800001
PM 39274316
ER

PT J
AU Obradovich, Nick
   Johnson, Tim
   Paulus, Martin P.
TI Managerial and Organizational Challenges in the Age of AI
SO JAMA PSYCHIATRY
VL 81
IS 3
BP 219
EP 220
DI 10.1001/jamapsychiatry.2023.5247
EA MAR 2024
DT Editorial Material
PD MAR 2024
PY 2024
AB This Viewpoint discusses the managerial and organizational challenges
   that could result from the use of artificial intelligence systems in
   psychiatric research and care.
TC 2
ZA 0
ZB 0
ZS 0
ZR 0
Z8 0
Z9 2
DA 2024-02-05
UT WOS:001151728400004
PM 38265819
ER

PT J
AU Liu, Wei
   Liu, Jun
   Tang, Yitao
   Liu, Chaozhong
   Song, Meiyi
   Ju, Zhenlin
   Kumar, Shweth V.
   Lu, Yiling
   Akbani, Rehan
   Mills, Gordon
   Liang, Han
TI TCPAplus: An LLM-empowered chatbot for analyzing a large protein
   expression atlas of human cancers
SO CANCER RESEARCH
VL 84
IS 7
MA LB247
DI 10.1158/1538-7445.AM2024-LB247
SU S
DT Meeting Abstract
PD APR 1 2024
PY 2024
CT Annual Meeting of the American-Association-for-Cancer-Research (AACR)
CY APR 05-10, 2024
CL San Diego, CA
SP Amer Assoc Cancer Res
ZA 0
ZB 0
Z8 0
ZR 0
ZS 0
TC 0
Z9 0
DA 2024-05-19
UT WOS:001203184200459
ER

PT J
AU Wang, Jinge
   Shue, Kenneth
   Liu, Li
   Hu, Gangqing
TI Preliminary evaluation of ChatGPT model iterations in emergency
   department diagnostics
SO SCIENTIFIC REPORTS
VL 15
IS 1
AR 10426
DI 10.1038/s41598-025-95233-1
DT Article
PD MAR 26 2025
PY 2025
AB Large language model chatbots such as ChatGPT have shown the potential
   in assisting health professionals in emergency departments (EDs).
   However, the diagnostic accuracy of newer ChatGPT models remains
   unclear. This retrospective study evaluated the diagnostic performance
   of various ChatGPT models-including GPT-3.5, GPT-4, GPT-4o, and o1
   series-in predicting diagnoses for ED patients (n = 30) and examined the
   impact of explicitly invoking reasoning (thoughts). Earlier models, such
   as GPT-3.5, demonstrated high accuracy for top-three differential
   diagnoses (80.0% in accuracy) but underperformed in identifying leading
   diagnoses (47.8%) compared to newer models such as chatgpt-4o-latest
   (60%, p < 0.01) and o1-preview (60%, p < 0.01). Asking for thoughts to
   be provided significantly enhanced the performance on predicting leading
   diagnosis for 4o models such as 4o-2024-0513 (from 45.6 to 56.7%; p =
   0.03) and 4o-mini-2024-07-18 (from 54.4 to 60.0%; p = 0.04) but had
   minimal impact on o1-mini and o1-preview. In challenging cases, such as
   pneumonia without fever, all models generally failed to predict the
   correct diagnosis, indicating atypical presentations as a major
   limitation for ED application of current ChatGPT models.
TC 0
ZA 0
Z8 0
ZB 0
ZR 0
ZS 0
Z9 0
DA 2025-04-05
UT WOS:001454462300041
PM 40140500
ER

PT J
AU Diaz-Gonzalez, Alvaro
   Forner, Alejandro
   Turnes, Juan
TI Advancing radiology reporting with large language models: Is GPT-4 the
   LI-RADS game changer or just a wild card?
SO LIVER INTERNATIONAL
VL 44
IS 7
BP 1575
EP 1577
DI 10.1111/liv.15952
DT Editorial Material
PD JUL 2024
PY 2024
ZB 1
ZS 0
TC 1
ZA 0
ZR 0
Z8 0
Z9 1
DA 2024-08-09
UT WOS:001281745200003
PM 38886910
ER

PT J
AU Li, David
   Gupta, Kartik
   Bhaduri, Mousumi
   Sathiadoss, Paul
   Bhatnagar, Sahir
   Chong, Jaron
TI Comparing GPT-3.5 and GPT-4 Accuracy and Drift in Radiology
   Diagnosis Please Cases
SO RADIOLOGY
VL 310
IS 1
AR e232411
DI 10.1148/radiol.232411
DT Article
PD JAN 2024
PY 2024
ZR 0
ZB 8
TC 25
ZS 0
ZA 0
Z8 1
Z9 25
DA 2024-04-10
UT WOS:001186842800027
PM 38226874
ER

PT J
AU Kozaily, Elie
   Geagea, Mabelissa
   Akdogan, Ecem R.
   Atkins, Jessica
   Elshazly, Mohamed B.
   Guglin, Maya
   Tedford, Ryan J.
   Wehbe, Ramsey M.
TI Accuracy and consistency of online large language model-based artificial
   intelligence chat platforms in answering patients' questions about heart
   failure
SO INTERNATIONAL JOURNAL OF CARDIOLOGY
VL 408
AR 132115
DI 10.1016/j.ijcard.2024.132115
EA MAY 2024
DT Article
PD AUG 1 2024
PY 2024
AB Background: Heart failure (HF) is a prevalent condition associated with
   significant morbidity. Patients may have questions that they feel
   embarrassed to ask or will face delays awaiting responses from their
   healthcare providers which may impact their health behavior. We aimed to
   investigate the potential of large language model (LLM) based artificial
   intelligence (AI) chat platforms in complementing the delivery of
   patient -centered care. Methods: Using online patient forums and
   physician experience, we created 30 questions related to diagnosis,
   management and prognosis of HF. The questions were posed to two
   LLM-based AI chat platforms (OpenAI's ChatGPT-3.5 and Google's Bard).
   Each set of answers was evaluated by two HF experts, independently and
   blinded to each other, for accuracy (adequacy of content) and
   consistency of content. Results: ChatGPT provided mostly appropriate
   answers (27/30, 90%) and showed a high degree of consistency (93%). Bard
   provided a similar content in its answers and thus was evaluated only
   for adequacy (23/30, 77%). The two HF experts' grades were concordant in
   83% and 67% of the questions for ChatGPT and Bard, respectively.
   Conclusion: LLM-based AI chat platforms demonstrate potential in
   improving HF education and empowering patients, however, these platforms
   currently suffer from issues related to factual errors and difficulty
   with more contemporary recommendations. This inaccurate information may
   pose serious and life -threatening implications for patients that should
   be considered and addressed in future research.
TC 13
ZB 0
ZS 0
ZR 0
ZA 0
Z8 0
Z9 13
DA 2024-06-15
UT WOS:001240180400001
PM 38697402
ER

PT J
AU Passby, Lauren
   Jenko, Nathan
   Wernham, Aaron
TI Performance of ChatGPT on Specialty Certificate Examination in
   Dermatology multiple-choice questions
SO CLINICAL AND EXPERIMENTAL DERMATOLOGY
VL 49
IS 7
BP 722
EP 727
DI 10.1093/ced/llad197
EA SEP 2023
DT Article
PD SEP 6 2023
PY 2023
AB ChatGPT is a large language model trained on increasingly large datasets
   by OpenAI to perform language-based tasks. It is capable of answering
   multiple-choice questions, such as those posed by the Specialty
   Certificate Examination (SCE) in Dermatology. We asked two iterations of
   ChatGPT: ChatGPT-3.5 and ChatGPT-4 84 multiple-choice sample questions
   from the sample SCE in Dermatology question bank. ChatGPT-3.5 achieved
   an overall score of 63%, and ChatGPT-4 scored 90% (a significant
   improvement in performance; P < 0.001). The typical pass mark for the
   SCE in Dermatology is 70-72%. ChatGPT-4 is therefore capable of
   answering clinical questions and achieving a passing grade in these
   sample questions. There are many possible educational and clinical
   implications for increasingly advanced artificial intelligence (AI) and
   its use in medicine, including in the diagnosis of dermatological
   conditions. Such advances should be embraced provided that patient
   safety is a core tenet, and the limitations of AI in the nuances of
   complex clinical cases are recognized.
TC 61
Z8 0
ZA 0
ZS 1
ZR 0
ZB 9
Z9 61
DA 2023-09-25
UT WOS:001062527800001
PM 37264670
ER

PT J
AU Qu, Roy W. W.
   Qureshi, Uneeb
   Petersen, Garrett
   Lee, Steve C. C.
TI Diagnostic and Management Applications of ChatGPT in Structured
   Otolaryngology Clinical Scenarios
SO OTO OPEN
VL 7
IS 3
AR e67
DI 10.1002/oto2.67
DT Article
PD JUL 2023
PY 2023
AB ObjectiveTo evaluate the clinical applications and limitations of chat
   generative pretrained transformer (ChatGPT) in otolaryngology. Study
   DesignCross-sectional survey. SettingTertiary academic center.
   MethodsChatGPT 4.0 was queried for diagnoses and management plans for 20
   physician-written clinical vignettes in otolaryngology. Attending
   physicians were then asked to rate the difficulty of the clinical
   vignettes and agreement with the differential diagnoses and management
   plans of ChatGPT responses on a 5-point Likert scale. Summary statistics
   were calculated. Univariate ordinal regression was then performed
   between vignette difficulty and quality of the diagnoses and management
   plans. ResultsEleven attending physicians completed the survey (61%
   response rate). Overall, vignettes were rated as very easy to neutral
   difficulty (range of median score: 1.00-4.00; overall median 2.00).
   There was a high agreement with the differential diagnosis provided by
   ChatGPT (range of median score: 3.00-5.00; overall median: 5.00). There
   was also high agreement with treatment plans (range of median score:
   3.00-5.00; overall median: 5.00). There was no association between
   vignette difficulty and agreement with differential diagnosis or
   treatment. Lower diagnosis scores had greater odds of having lower
   treatment scores. ConclusionGenerative artificial intelligence models
   like ChatGPT are being rapidly adopted in medicine. Performance with
   curated, easy-to-moderate difficulty otolaryngology scenarios indicate
   high agreement with physicians for diagnosis and management. However, a
   decreased quality in diagnosis is associated with decreased quality in
   management. Further research is necessary on ChatGPT's ability to handle
   unstructured clinical information.
ZB 8
ZS 0
Z8 0
ZR 0
ZA 0
TC 42
Z9 42
DA 2023-08-31
UT WOS:001051927400001
PM 37614494
ER

PT J
AU Robitschek, Emily
   Bastani, Asal
   Sordean, Savyon
   Horwath, Kathryn
   Lai, Jennifer
   Pletcher, Mark
   Chen, Irene
   Ge, Jin
TI Applying Large Language Models to Better Understand Psychosocial Factors
   Influencing Successful Liver Transplant Completion
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
VL 119
IS 10S
MA S2058
BP S1470
EP S1471
DI 10.14309/01.ajg.0001037600.86263.10
SU 10
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Annual Meeting of the American-College-of-Gastroenterology (ACG)
CY OCT 25-30, 2024
CL Pennsylvania Convention Cent, Philadelphia, PA
HO Pennsylvania Convention Cent
SP Amer Coll Gastroenterol
ZS 0
ZR 0
ZB 0
Z8 0
TC 0
ZA 0
Z9 0
DA 2024-11-30
UT WOS:001360386500002
ER

PT J
AU Souaid, Tarek
   Kerbage, Anthony
   Macaron, Carole
   Burke, Carol A.
   Rouphael, Carol
TI Optical Accuracy of Artificial Intelligence Large Language Models in
   Classifying Colorectal Polyps Based on Shape, Size, and Histology, Using
   Endoscopic Images
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
VL 119
IS 10S
MA S276
BP S198
EP S199
DI 10.14309/01.ajg.0001030472.25160.1f
SU 10
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Annual Meeting of the American-College-of-Gastroenterology (ACG)
CY OCT 25-30, 2024
CL Pennsylvania Convention Cent, Philadelphia, PA
HO Pennsylvania Convention Cent
SP Amer Coll Gastroenterol
Z8 0
ZS 0
ZB 0
TC 0
ZA 0
ZR 0
Z9 0
DA 2024-11-30
UT WOS:001359422900043
ER

PT J
AU Odisho, Anobel Y.
   Liu, Andrew W.
   Pace, William A.
   Krumm, Robert
   Cowan, Janet E.
   Carroll, Peter R.
   Cooperberg, Matthew R.
TI DEVELOPMENT OF A GENERATIVE ARTIFICIAL INTELLIGENCE DATA PIPELINE TO
   AUTOMATE THE CAPTURE OF UNSTRUCTURED MRI DATA FOR PROSTATE CANCER CARE
SO JOURNAL OF UROLOGY
VL 211
IS 5
MA MP07-14
BP E110
EP E110
DI 10.1097/01.JU.0001008728.41882.d7.14
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Annual Meeting of the American-Urological-Association (AUA)
CY MAY 03-06, 2024
CL San Antonio, TX
SP Amer Urolog Assoc
TC 0
ZB 0
ZS 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2024-08-04
UT WOS:001263885300214
ER

PT J
AU Chen, Hui
   Xu, Zanmei
   Chen, Lijuan
   Wang, Mingmin
   Zhang, Peng
   Pang, Fei
   Wang, Kai
TI AI-enabled precision oncology era: Advanced and interactive
   interpretation of next-gneneration sequencing (NGS) reports
SO CANCER RESEARCH
VL 84
IS 6
MA 2315
DI 10.1158/1538-7445.AM2024-2315
SU S
DT Meeting Abstract
PD MAR 15 2024
PY 2024
CT Annual Meeting of the American-Association-for-Cancer-Research (AACR)
CY APR 05-10, 2024
CL San Diego, CA
SP Amer Assoc Cancer Res
Z8 0
ZB 0
ZR 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2024-07-31
UT WOS:001252656304116
ER

PT J
AU Chong, Yosep
   Nguyen, Anh
   Song, Jin Sol
   Yim, Kwangil
   Park, Jumi
   Kwak, Jin Tae
TI A Generative Artificial Intelligence Framework for Automated Pathologic
   Diagnosis of Gastric Endoscopic Biopsy Samples
SO LABORATORY INVESTIGATION
VL 105
IS 3
MA 1345
AR 103583
DI 10.1016/j.labinv.2024.103583
EA MAR 2025
SU S
DT Meeting Abstract
PD MAR 2025
PY 2025
CT Annual Meeting of the United-States-and-Canadian-Academy-of-Pathology
   (USCAP)
CY MAR 22-27, 2025
CL Boston, MA
SP United States & Canadian Acad Pathol
ZA 0
ZR 0
ZS 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-04-19
UT WOS:001464120600032
ER

PT J
AU Park, SaYoon
   Chang-EopKim
TI Enhancing Korean Medicine Education with Large Language Models: Focusing
   on the Development of Educational Artificial Intelligence
Z1 거대언어모델을 활용한 한의학 교육 강화: 교육용 인공지능 개발을 중심으로
SO Journal of Physiology & Pathology in Korean Medicine
S1 동의생리병리학회지
VL 37
IS 5
BP 134
EP 138
DT research-article
PD 2023
PY 2023
AB Large language models (LLMs) have introduced groundbreaking innovations
   in various fields, including healthcare, where they augment medical
   diagnosis, decision-making, and facilitate patient-doctor communication
   through their exceptional contextual understanding and inferential
   abilities. In the realm of Korean medicine (KM), the utilization of LLMs
   is highly anticipated. However, it demands additional training with
   domain-specific KM data for seamless integration of KM knowledge. There
   are two predominant strategies for training domain-specific LLMs in the
   KM domain. The first approach entails direct manipulation of the LLM's
   internals by either pretraining a base model on an extensive corpus of
   KM data or fine-tuning a pretrained model's parameters using KM-related
   question-answering datasets. The second approach avoids internal model
   manipulation and leverages techniques like prompt engineering, retrieval
   augmented generation, and cognitive augmentation. Domain-specific LLMs
   specialized for KM hold the potential for diverse applications, ranging
   from personalized medical education plans and content generation to
   knowledge integration, curriculum development, automated student
   assessment, virtual patient simulations, and advanced research and
   scholarly activities. These advancements are poised to significantly
   impact the field of KM and medical education at large.
ZB 0
Z8 0
TC 0
ZA 0
ZS 0
ZR 0
Z9 0
DA 2023-01-01
UT KJD:ART003011785
ER

PT J
AU Sinha, Rooma
   Raina, Rohit
   Bag, Moumita
   Rupa, Bana
TI Empowering gynaecologists with Artificial Intelligence: Tailoring
   surgical solutions for fibroids
SO EUROPEAN JOURNAL OF OBSTETRICS & GYNECOLOGY AND REPRODUCTIVE BIOLOGY
VL 299
BP 72
EP 77
DI 10.1016/j.ejogrb.2024.06.001
EA JUN 2024
DT Article
PD AUG 2024
PY 2024
AB Background: In recent years, the integration of Artificial intelligence
   (AI) into various fields of medicine including Gynaecology, has shown
   promising potential. Surgical treatment of fibroid is myomectomy if
   uterine preservation and fertility are the primary aims. AI usage begins
   with the involvement of LLM (Large Language Model) from the point when a
   patient visits a gynecologist, from identifying signs and symptoms to
   reaching a diagnosis, providing treatment plans, and patient counseling.
   Objective: Use of AI (ChatGPT versus Google Bard) in the surgical
   management of fibroid. Study design: Identifying the patient's problems
   using LLMs like ChatGPT and Google Bard and giving a treatment option in
   8 clinical scenarios of fibroid. Data entry was done using M.S. Excel
   and was statistically analyzed using Statistical Package for Social
   Sciences (SPSS Version 26) for M.S. Windows 2010. All results were
   presented in tabular form. Data were analyzed using nonparametric tests
   Chi-square tests or Fisher exact test. p values < 0.05 were considered
   statistically significant. The sensitivity of both techniques was
   calculated. We have used Cohen's Kappa to know the degree of agreement.
   Results: We found that on the first attempt, ChatGPT gave general
   answers in 62.5 % of cases and specific answers in 37.5 % of cases.
   ChatGPT showed improved sensitivity on successive prompts 37.5 % to 62.5
   % on the third prompt. Google Bard could not identify the clinical
   question in 50 % of cases and gave incorrect answers in 12.5 % of cases
   (p = 0.04). Google Bard showed the same sensitivity of 25 % on all
   prompts. Conclusion: AI helps to reduce the time to diagnose and plan a
   treatment strategy for fibroid and acts as a powerful tool in the hands
   of a gynecologist. However, the usage of AI by patients for
   self-treatment is to be avoided and should be used only for education
   and counseling about fibroids.
ZS 0
ZR 0
ZB 0
ZA 0
Z8 0
TC 2
Z9 2
DA 2024-06-29
UT WOS:001251789000001
PM 38838389
ER

PT J
AU Hua, Rui
   Dong, Xin
   Wei, Yu
   Shu, Zixin
   Yang, Pengcheng
   Hu, Yunhui
   Zhou, Shuiping
   Sun, He
   Yan, Kaijing
   Yan, Xijun
   Chang, Kai
   Li, Xiaodong
   Bai, Yuning
   Zhang, Runshun
   Wang, Wenjia
   Zhou, Xuezhong
TI Lingdan: enhancing encoding of traditional Chinese medicine knowledge
   for clinical reasoning tasks with large language models
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
DI 10.1093/jamia/ocae087
EA JUL 2024
DT Article; Early Access
PY 2024
AB Objective The recent surge in large language models (LLMs) across
   various fields has yet to be fully realized in traditional Chinese
   medicine (TCM). This study aims to bridge this gap by developing a large
   language model tailored to TCM knowledge, enhancing its performance and
   accuracy in clinical reasoning tasks such as diagnosis, treatment, and
   prescription recommendations.Materials and Methods This study harnessed
   a wide array of TCM data resources, including TCM ancient books,
   textbooks, and clinical data, to create 3 key datasets: the TCM
   Pre-trained Dataset, the Traditional Chinese Patent Medicine (TCPM)
   Question Answering Dataset, and the Spleen and Stomach Herbal
   Prescription Recommendation Dataset. These datasets underpinned the
   development of the Lingdan Pre-trained LLM and 2 specialized models: the
   Lingdan-TCPM-Chat Model, which uses a Chain-of-Thought process for
   symptom analysis and TCPM recommendation, and a Lingdan Prescription
   Recommendation model (Lingdan-PR) that proposes herbal prescriptions
   based on electronic medical records.Results The Lingdan-TCPM-Chat and
   the Lingdan-PR Model, fine-tuned on the Lingdan Pre-trained LLM,
   demonstrated state-of-the art performances for the tasks of TCM clinical
   knowledge answering and herbal prescription recommendation. Notably,
   Lingdan-PR outperformed all state-of-the-art baseline models, achieving
   an improvement of 18.39% in the Top@20 F1-score compared with the best
   baseline.Conclusion This study marks a pivotal step in merging advanced
   LLMs with TCM, showcasing the potential of artificial intelligence to
   help improve clinical decision-making of medical diagnostics and
   treatment strategies. The success of the Lingdan Pre-trained LLM and its
   derivative models, Lingdan-TCPM-Chat and Lingdan-PR, not only
   revolutionizes TCM practices but also opens new avenues for the
   application of artificial intelligence in other specialized medical
   fields. Our project is available at
   https://github.com/TCMAI-BJTU/LingdanLLM.
Z8 4
ZR 0
ZA 0
ZS 0
TC 7
ZB 0
Z9 11
DA 2024-07-28
UT WOS:001273695100001
PM 39038795
ER

PT J
AU Liu, Yuxiao
   Liu, Mianxin
   Zhang, Yuanwang
   Guan, Yihui
   Guo, Qihao
   Xie, Fang
   Shen, Dinggang
TI Amyloid-β Deposition Prediction With Large Language Model Driven and
   Task-Oriented Learning of Brain Functional Networks
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
VL 44
IS 4
BP 1809
EP 1820
DI 10.1109/TMI.2024.3525022
DT Article
PD APR 2025
PY 2025
AB Amyloid-beta positron emission tomography can reflect the Amyloid-beta
   protein deposition in the brain and thus serves as one of the golden
   standards for Alzheimer's disease (AD) diagnosis. However, its practical
   cost and high radioactivity hinder its application in large-scale early
   AD screening. Recent neuroscience studies suggest a strong association
   between changes in functional connectivity network (FCN) derived from
   functional MRI (fMRI), and deposition patterns of Amyloid-beta protein
   in the brain. This enables an FCN-based approach to assess the
   Amyloid-beta protein deposition with less expense and radioactivity.
   However, an effective FCN-based Amyloid-beta assessment remains lacking
   for practice. In this paper, we introduce a novel deep learning
   framework tailored for this task. Our framework comprises three
   innovative components: 1) a pre-trained Large Language Model Nodal
   Embedding Encoder, designed to extract task-related features from fMRI
   signals; 2) a task-oriented Hierarchical-order FCN Learning module, used
   to enhance the representation of complex correlations among different
   brain regions for improved prediction of Amyloid-beta deposition; and 3)
   task-feature consistency losses for promoting similarity between
   predicted and real Amyloid-beta values and ensuring effectiveness of
   predicted Amyloid-beta in downstream classification task. Experimental
   results show superiority of our method over several state-of-the-art
   FCN-based methods. Additionally, we identify crucial functional
   sub-networks for predicting Amyloid-beta depositions. The proposed
   method is anticipated to contribute valuable insights into the
   understanding of mechanisms of AD and its prevention.
ZR 0
ZA 0
ZB 0
Z8 0
TC 0
ZS 0
Z9 0
DA 2025-04-13
UT WOS:001459777800001
PM 40030867
ER

PT J
AU Meyer, Nathaniel S
   Meyer, John W
TI A Practical Guide to the Utilization of ChatGPT in the Emergency
   Department: A Systematic Review of Current Applications, Future
   Directions, and Limitations.
SO Cureus
VL 17
IS 4
BP e81802
EP e81802
DI 10.7759/cureus.81802
DT Journal Article; Review
PD 2025-Apr
PY 2025
AB The rapid development of artificial intelligence (AI) tools across
   various medical specialties highlights the potential for AI to transform
   medicine over the next 20 years. Despite this potential, the adoption of
   AI can feel incremental and disconnected from the daily practice of
   individual clinicians. For emergency department (ED) physicians
   practicing in 2025, recognizing and evaluating AI tools available for
   immediate integration into practice is essential. One such tool is
   ChatGPT (OpenAI, San Francisco, California, United States), a large
   language model (LLM) that is free, easily accessible via smartphones or
   computers, and widely used across industries. However, its usability in
   the ED setting remains poorly characterized. This review explores the
   current evidence surrounding ChatGPT 4's applications in various ED
   physician tasks, documenting its strengths and limitations. While
   ChatGPT demonstrates significant utility in language generation and
   administrative tasks, its potential for supporting more complex tasks in
   medical decision-making is emerging but not yet robust. The available
   evidence is limited and variable and lacks standardization, reflecting a
   field still in its early stages of development. Notably, the performance
   improvements observed between ChatGPT 3.5 and ChatGPT 4 suggest that
   future iterations, such as the anticipated release of ChatGPT 5, could
   significantly impact these findings. This review provides a
   comprehensive snapshot of the current state of evidence regarding
   ChatGPT's use in the ED, offering both an evaluation of its capabilities
   and a practical guide for its appropriate use by ED clinicians today.
ZB 0
TC 0
ZS 0
Z8 0
ZA 0
ZR 0
Z9 0
DA 2025-05-09
UT MEDLINE:40330395
PM 40330395
ER

PT J
AU Nielsen, Jacob P. S.
   Gronhoj, Christian
   Skov, Lone
   Gyldenlove, Mette
TI Usefulness of the large language model ChatGPT (GPT-4) as a diagnostic
   tool and information source in dermatology
SO JEADV CLINICAL PRACTICE
VL 3
IS 5
BP 1570
EP 1575
DI 10.1002/jvc2.459
EA JUN 2024
DT Article
PD DEC 2024
PY 2024
AB BackgroundThe field of artificial intelligence is rapidly evolving. As
   an easily accessible platform with vast user engagement, the Chat
   Generative Pre-Trained Transformer (ChatGPT) holds great promise in
   medicine, with the latest version, GPT-4, capable of analyzing clinical
   images.ObjectivesTo evaluate ChatGPT as a diagnostic tool and
   information source in clinical dermatology.MethodsA total of 15 clinical
   images were selected from the Danish web atlas, Danderm, depicting
   various common and rare skin conditions. The images were uploaded to
   ChatGPT version GPT-4, which was prompted with 'Please provide a
   description, a potential diagnosis, and treatment options for the
   following dermatological condition'. The generated responses were
   assessed by senior registrars in dermatology and consultant
   dermatologists in terms of accuracy, relevance, and depth (scale 1-5),
   and in addition, the image quality was rated (scale 0-10). Demographic
   and professional information about the respondents was
   registered.ResultsA total of 23 physicians participated in the study.
   The majority of the respondents were consultant dermatologists (83%),
   and 48% had more than 10 years of training. The overall image quality
   had a median rating of 10 out of 10 [interquartile range (IQR): 9-10].
   The overall median rating of the ChatGPT generated responses was 2 (IQR:
   1-4), while overall median ratings in terms of relevance, accuracy, and
   depth were 2 (IQR: 1-4), 3 (IQR: 2-4) and 2 (IQR: 1-3),
   respectively.ConclusionsDespite the advancements in ChatGPT, including
   newly added image processing capabilities, the chatbot demonstrated
   significant limitations in providing reliable and clinically useful
   responses to illustrative images of various dermatological conditions.
ZA 0
TC 1
ZR 0
ZB 0
Z8 0
ZS 0
Z9 1
DA 2024-06-08
UT WOS:001237597700001
ER

PT J
AU Zada, Zaid
   Goldstein, Ariel
   Michelmann, Sebastian
   Simony, Erez
   Price, Amy
   Hasenfratz, Liat
   Barham, Emily
   Zadbood, Asieh
   Doyle, Werner
   Friedman, Daniel
   Dugan, Patricia
   Melloni, Lucia
   Devore, Sasha
   Flinker, Adeen
   Devinsky, Orrin
   Nastase, Samuel A.
   Hasson, Uri
TI A shared model-based linguistic space for transmitting our thoughts from
   brain to brain in natural conversations
SO NEURON
VL 112
IS 18
DI 10.1016/j.neuron.2024.06.025
EA SEP 2024
DT Article
PD SEP 25 2024
PY 2024
AB Effective communication hinges on a mutual understanding of word meaning
   in different contexts. We recorded brain activity using
   electrocorticography during spontaneous, face-to-face conversations in
   five pairs of epilepsy patients. We developed a model-based coupling
   framework that aligns brain activity in both speaker and listener to a
   shared embedding space from a large language model (LLM). The
   context-sensitive LLM embeddings allow us to track the exchange of
   linguistic information, word by word, from one brain to another in
   natural conversations. Linguistic content emerges in the speaker's brain
   before word articulation and rapidly re-emerges in the listener's brain
   after word articulation. The contextual embeddings better capture
   word-by-word neural alignment between speaker and listener than
   syntactic and articulatory models. Our findings indicate that the
   contextual embeddings learned by LLMs can serve as an explicit numerical
   model of the shared, context-rich meaning space humans use to
   communicate their thoughts to one another.
ZB 3
ZA 0
TC 10
Z8 0
ZR 0
ZS 0
Z9 10
DA 2024-10-09
UT WOS:001324629500001
PM 39096896
ER

PT J
AU Lefkes, Judith
   D'Amato, Marina
   Sun, Susu
   Litjens, Geert
   Ciompi, Francesco
TI Large Language Models Automate Diagnostic Conclusions Generation from
   Microscopic Descriptions in Multiple Cancer Types
SO LABORATORY INVESTIGATION
VL 105
IS 3
MA 1370
AR 103608
DI 10.1016/j.labinv.2024.103608
EA MAR 2025
SU S
DT Meeting Abstract
PD MAR 2025
PY 2025
CT Annual Meeting of the United-States-and-Canadian-Academy-of-Pathology
   (USCAP)
CY MAR 22-27, 2025
CL Boston, MA
SP United States & Canadian Acad Pathol
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
TC 0
Z9 0
DA 2025-04-19
UT WOS:001464120600063
ER

PT J
AU Shah, Kevin P.
   Dey, Shirin A.
   Pothula, Shravya
   Abud, Arnold
   Jain, Sukrit
   Srivastava, Aniruddha
   Dommaraju, Sagar
   Komanduri, Srinadh
TI Artificial Intelligence Showdown in Gastroenterology: A Comparative
   Analysis of Large Language Models (LLMs) in Tackling Board-Style Review
   Questions
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
VL 119
IS 10S
MA S2194
BP S1567
EP S1568
DI 10.14309/01.ajg.0001038144.51724.aa
SU 10
DT Meeting Abstract
PD OCT 2024
PY 2024
CT Annual Meeting of the American-College-of-Gastroenterology (ACG)
CY OCT 25-30, 2024
CL Pennsylvania Convention Cent, Philadelphia, PA
HO Pennsylvania Convention Cent
SP Amer Coll Gastroenterol
ZS 0
TC 0
ZA 0
Z8 0
ZR 0
ZB 0
Z9 0
DA 2024-11-30
UT WOS:001359889800005
ER

PT J
AU Hong, Huixiao
   Slikker, William
TI Integrating artificial intelligence with bioinformatics promotes public
   health
SO EXPERIMENTAL BIOLOGY AND MEDICINE
VL 248
IS 21
BP 1905
EP 1907
DI 10.1177/15353702231223575
EA JAN 2024
DT Editorial Material
PD NOV 2023
PY 2023
Z8 0
ZA 0
TC 1
ZS 0
ZR 0
ZB 0
Z9 1
DA 2024-01-12
UT WOS:001137033900001
PM 38179798
ER

PT J
AU Shieh, Allen
   Tran, Brandon
   He, Gene
   Kumar, Mudit
   Freed, Jason A.
   Majety, Priyanka
TI Assessing ChatGPT 4.0's test performance and clinical diagnostic
   accuracy on USMLE STEP 2 CK and clinical case reports
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 9330
DI 10.1038/s41598-024-58760-x
DT Article
PD APR 23 2024
PY 2024
AB While there is data assessing the test performance of artificial
   intelligence (AI) chatbots, including the Generative Pre-trained
   Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on
   its diagnostic accuracy of clinical cases. We assessed the large
   language model (LLM), ChatGPT 4.0, on its ability to answer questions
   from the United States Medical Licensing Exam (USMLE) Step 2, as well as
   its ability to generate a differential diagnosis based on corresponding
   clinical vignettes from published case reports. A total of 109 Step 2
   Clinical Knowledge (CK) practice questions were inputted into both
   ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer.
   Compared to its previous version, ChatGPT 3.5, we found improved
   accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to
   87.2% (p = 0.035) respectively. Utilizing the topics tested on Step 2 CK
   questions, we additionally found 63 corresponding published case report
   vignettes and asked ChatGPT 4.0 to come up with its top three
   differential diagnosis. ChatGPT 4.0 accurately created a shortlist of
   differential diagnoses in 74.6% of the 63 case reports (74.6%). We
   analyzed ChatGPT 4.0's confidence in its diagnosis by asking it to rank
   its top three differentials from most to least likely. Out of the 47
   correct diagnoses, 33 were the first (70.2%) on the differential
   diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our
   study shows the continued iterative improvement in ChatGPT's ability to
   answer standardized USMLE questions accurately and provides insights
   into ChatGPT's clinical diagnostic accuracy.
ZA 0
TC 32
ZS 0
Z8 0
ZB 3
ZR 0
Z9 32
DA 2024-06-29
UT WOS:001207399200004
PM 38654011
ER

PT J
AU West, Matthew
   Cheng, You
   He, Yingnan
   Leng, Yu
   Magdamo, Colin
   Hyman, Bradley
   Dickson, John R.
   Serrano-Pozo, Alberto
   Blacker, Deborah
   Das, Sudeshna
TI Unsupervised Deep Learning of Electronic Health Records to Characterize
   Heterogeneity Across Alzheimer Disease and Related Dementias:
   Cross-Sectional Study
SO JMIR AGING
VL 8
AR e65178
DI 10.2196/65178
DT Article
PD 2025
PY 2025
AB Background: Alzheimer disease and related dementias (ADRD) exhibit
   prominent heterogeneity. Identifying clinically meaningful ADRD subtypes
   is essential for tailoring treatments to specific patient phenotypes.
   Objective: We aimed to use unsupervised learning techniques on
   electronic health records (EHRs) from memory clinic patients to identify
   ADRD subtypes. Methods: We used pretrained embeddings of non-ADRD
   diagnosis codes (International Classification ofDiseases,Ninth Revision)
   and large language model (LLM)-derived embeddings of clinical notes from
   patient EHRs. Hierarchical clustering of these embeddings was used to
   identify ADRD subtypes. Clusters were characterized regarding their
   demographic and clinical features. Results: We analyzed a cohort of 3454
   patients with ADRD from a memory clinic at Massachusetts General
   Hospital, each with a specialist diagnosis. Clustering pretrained
   embeddings of the non-ADRD diagnosis codes in patient EHRs revealed the
   following 3 patient subtypes: one with skin conditions, another with
   psychiatric disorders and an earlier age of onset, and a third with
   diabetes complications. Similarly, using LLM-derived embeddings of
   clinical notes, we identified 3 subtypes of patients as follows: one
   with psychiatric manifestations and higher prevalence of female
   participants (prevalence ratio: 1.59), another with cardiovascular and
   motor problems and higher prevalence of male participants (prevalence
   ratio: 1.75), and a third one with geriatric health disorders. Notably,
   we observed significant overlap between clusters from both data
   modalities (chi 24=89.4; P<.001). Conclusions: By integrating
   International Classification ofDiseases,Ninth Revision codes and
   LLM-derived embeddings, our analysis delineated 2 distinctADRD subtypes
   with sex-specific comorbid and clinical presentations, offering insights
   for potential precision medicine approaches.
ZB 0
Z8 0
ZR 0
TC 0
ZS 0
ZA 0
Z9 0
DA 2025-04-13
UT WOS:001461835800001
PM 40163031
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on a Large Language Model Chatbot
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1636
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
TC 0
ZB 0
Z8 0
ZA 0
ZS 0
Z9 0
DA 2024-12-01
UT WOS:001312227704264
ER

PT J
AU Park, Hyung Jun
   Huh, Jin-Young
   Chae, Ganghee
   Choi, Myeong Geun
TI Extraction of clinical data on major pulmonary diseases from
   unstructured radiologic reports using a large language model
SO PLOS ONE
VL 19
IS 11
AR e0314136
DI 10.1371/journal.pone.0314136
DT Article
PD NOV 25 2024
PY 2024
AB Despite significant strides in big data technology, extracting
   information from unstructured clinical data remains a formidable
   challenge. This study investigated the utility of large language models
   (LLMs) for extracting clinical data from unstructured radiological
   reports without additional training. In this retrospective study, 1800
   radiologic reports, 600 from each of the three university hospitals,
   were collected, with seven pulmonary outcomes defined. Three
   pulmonology-trained specialists discerned the presence or absence of
   diseases. Data extraction from the reports was executed using Google
   Gemini Pro 1.0, OpenAI's GPT-3.5, and GPT-4. The gold standard was
   predicated on agreement between at least two pulmonologists. This study
   evaluated the performance of the three LLMs in diagnosing seven
   pulmonary diseases (active tuberculosis, emphysema, interstitial lung
   disease, lung cancer, pleural effusion, pneumonia, and pulmonary edema)
   utilizing chest radiography and computed tomography scans. All models
   exhibited high accuracy (0.85-1.00) for most conditions. GPT-4
   consistently outperformed its counterparts, demonstrating a sensitivity
   of 0.71-1.00; specificity of 0.89-1.00; and accuracy of 0.89 and 0.99
   across both modalities, thus underscoring its superior capability in
   interpreting radiological reports. Notably, the accuracy of pleural
   effusion and emphysema on chest radiographs and pulmonary edema on chest
   computed tomography scans reached 0.99. The proficiency of LLMs,
   particularly GPT-4, in accurately classifying unstructured radiological
   data hints at their potential as alternatives to the traditional manual
   chart reviews conducted by clinicians.
TC 1
Z8 0
ZA 0
ZS 0
ZR 0
ZB 0
Z9 1
DA 2024-12-13
UT WOS:001363435700050
PM 39585830
ER

PT J
AU Kjell, Oscar N. E.
   Kjell, Katarina
   Schwartz, H. Andrew
TI Beyond rating scales: With targeted evaluation, large language models
   are poised for psychological assessment
SO PSYCHIATRY RESEARCH
VL 333
AR 115667
DI 10.1016/j.psychres.2023.115667
EA JAN 2024
DT Review
PD MAR 2024
PY 2024
AB In this narrative review, we survey recent empirical evaluations of
   AI-based language assessments and present a case for the technology of
   large language models to be poised for changing standardized
   psychological assessment. Artificial intelligence has been undergoing a
   purported "paradigm shift" initiated by new machine learning models,
   large language models (e.g., BERT, LAMMA, and that behind ChatGPT).
   These models have led to unprecedented accuracy over most computerized
   language processing tasks, from web searches to automatic machine
   translation and question answering, while their dialogue-based forms,
   like ChatGPT have captured the interest of over a million users. The
   success of the large language model is mostly attributed to its
   capability to numerically represent words in their context, long a
   weakness of previous attempts to automate psychological assessment from
   language. While potential applications for automated therapy are
   beginning to be studied on the heels of chatGPT's success, here we
   present evidence that suggests, with thorough validation of targeted
   deployment scenarios, that AI's newest technology can move mental health
   assessment away from rating scales and to instead use how people
   naturally communicate, in language.
TC 16
ZA 0
ZB 2
Z8 1
ZR 0
ZS 0
Z9 17
DA 2024-03-08
UT WOS:001168160200001
PM 38290286
ER

PT J
AU Xia, Shujun
   Hua, Qing
   Mei, Zihan
   Xu, Wenwen
   Lai, Limei
   Wei, Minyan
   Qin, Yu
   Luo, Lin
   Wang, Changhua
   Huo, ShengNan
   Fu, Lijun
   Zhou, Feidu
   Wu, Jiang
   Zhang, Li
   Lv, De
   Li, Jianxin
   Wang, Xin
   Li, Ning
   Song, Yanyan
   Zhou, Jianqiao
TI Clinical application potential of large language model: a study based on
   thyroid nodules
SO ENDOCRINE
VL 87
IS 1
BP 206
EP 213
DI 10.1007/s12020-024-03981-3
EA JUL 2024
DT Article
PD JAN 2025
PY 2025
AB Background Limited data indicated the performance of large language
   model (LLM) taking on the role of doctors. We aimed to investigate the
   potential for ChatGPT-3.5 and New Bing Chat acting as doctors using
   thyroid nodules as an example. Methods A total of 145 patients with
   thyroid nodules were included for generating questions. Each question
   was entered into chatbot of ChatGPT-3.5 and New Bing Chat five times and
   five responses were acquired respectively. These responses were compared
   with answers given by five junior doctors. Responses from five senior
   doctors were regarded as gold standard. Accuracy and reproducibility of
   responses from ChatGPT-3.5 and New Bing Chat were evaluated. Results The
   accuracy of ChatGPT-3.5 and New Bing Chat in answering Q2, Q3, Q5 were
   lower than that of junior doctors (all P < 0.05), while both LLMs were
   comparable to junior doctors when answering Q4 and Q6. In terms of "high
   reproducibility and accuracy", ChatGPT-3.5 outperformed New Bing Chat in
   Q1 and Q5 (P < 0.001 and P = 0.008, respectively), but showed no
   significant difference in Q2, Q3, Q4, and Q6 (P > 0.05 for all). New
   Bing Chat generated higher accuracy than ChatGPT-3.5 (72.41% vs 58.62%)
   (P = 0.003) in decision making of thyroid nodules, and both were less
   accurate than junior doctors (89.66%, P < 0.001 for both). Conclusions
   The exploration of ChatGPT-3.5 and New Bing Chat in the diagnosis and
   management of thyroid nodules illustrates that LLMs currently
   demonstrate the potential for medical applications, but do not yet reach
   the clinical decision-making capacity of doctors.
Z8 0
TC 3
ZA 0
ZS 0
ZR 0
ZB 0
Z9 3
DA 2024-08-06
UT WOS:001281038100001
PM 39080210
ER

PT J
AU Seifen, Christopher
   Bahr-Hamm, Katharina
   Gouveris, Haralampos
   Pordzik, Johannes
   Blaikie, Andrew
   Matthias, Christoph
   Kuhn, Sebastian
   Buhr, Christoph Raphael
TI Simulation-Based Evaluation of Large Language Models for Comorbidity
   Detection in Sleep Medicine - a Pilot Study on ChatGPT o1 Preview
SO NATURE AND SCIENCE OF SLEEP
VL 17
BP 677
EP 688
DI 10.2147/NSS.S510254
DT Article
PD 2025
PY 2025
AB Purpose: Timely identification of comorbidities is critical in sleep
   medicine, where large language models (LLMs) like ChatGPT are currently
   emerging as transformative tools. Here, we investigate whether the novel
   LLM ChatGPT o1 preview can identify individual health risks or
   potentially existing comorbidities from the medical data of fictitious
   sleep medicine patients. Methods: We conducted a simulation-based study
   using 30 fictitious patients, designed to represent realistic variations
   in demographic and clinical parameters commonly seen in sleep medicine.
   Each profile included personal data (eg, body mass index, smoking
   status, drinking habits), blood pressure, and routine blood test
   results, along with a predefined sleep medicine diagnosis. Each patient
   profile was evaluated independently by the LLM and a sleep medicine
   specialist (SMS) for identification of potential comorbidities or
   individual health risks. Their recommendations were compared for
   concordance across lifestyle changes and further medical measures.
   Results: The LLM achieved high concordance with the SMS for lifestyle
   modification recommendations, including 100% concordance on smoking
   cessation (kappa = 1; p < 0.001), 97% on alcohol reduction (kappa =
   0.92; p < 0.001) and endocrinological examination (kappa = 0.92; p <
   0.001) or 93% on weight loss (kappa = 0.86; p < 0.001). However, it
   exhibited a tendency to over-recommend further medical measures
   (particularly 57% concordance for cardiological examination (kappa =
   0.08; p = 0.28) and 33% for gastrointestinal examination (kappa = 0.1; p
   = 0.22)) compared to the SMS. Conclusion: Despite the obvious limitation
   of using fictitious data, the findings suggest that LLMs like ChatGPT
   have the potential to complement clinical workflows in sleep medicine by
   identifying individual health risks and comorbidities. As LLMs continue
   to evolve, their integration into healthcare could redefine the approach
   to patient evaluation and risk stratification. Future research should
   contextualize the findings within broader clinical applications ideally
   testing locally run LLMs meeting data protection requirements.
ZA 0
ZS 0
ZR 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2025-05-10
UT WOS:001480706400001
PM 40321662
ER

PT J
AU Hu, Mingzhe
   Qian, Joshua
   Pan, Shaoyan
   Li, Yuheng
   Qiu, Richard L. J.
   Yang, Xiaofeng
TI Advancing medical imaging with language models: featuring a spotlight on
   ChatGPT
SO PHYSICS IN MEDICINE AND BIOLOGY
VL 69
IS 10
AR 10TR01
DI 10.1088/1361-6560/ad387d
DT Review
PD MAY 21 2024
PY 2024
AB This review paper aims to serve as a comprehensive guide and
   instructional resource for researchers seeking to effectively implement
   language models in medical imaging research. First, we presented the
   fundamental principles and evolution of language models, dedicating
   particular attention to large language models. We then reviewed the
   current literature on how language models are being used to improve
   medical imaging, emphasizing a range of applications such as image
   captioning, report generation, report classification, findings
   extraction, visual question response systems, interpretable diagnosis
   and so on. Notably, the capabilities of ChatGPT were spotlighted for
   researchers to explore its further applications. Furthermore, we covered
   the advantageous impacts of accurate and efficient language models in
   medical imaging analysis, such as the enhancement of clinical workflow
   efficiency, reduction of diagnostic errors, and assistance of clinicians
   in providing timely and accurate diagnoses. Overall, our goal is to have
   better integration of language models with medical imaging, thereby
   inspiring new ideas and innovations. It is our aspiration that this
   review can serve as a useful resource for researchers in this field,
   stimulating continued investigative and innovative pursuits of the
   application of language models in medical imaging.
ZB 2
ZS 0
Z8 0
ZR 0
ZA 0
TC 8
Z9 8
DA 2024-06-25
UT WOS:001251008700001
PM 38537293
ER

PT J
AU Yeo, Yee Hui
   Samaan, Jamil S.
   Ng, Wee Han
   Ting, Peng-Sheng
   Trivedi, Hirsh
   Vipani, Aarshi
   Ayoub, Walid
   Yang, Ju Dong
   Liran, Omer
   Spiegel, Brennan
   Kuo, Alexander
TI Assessing the performance of ChatGPT in answer- ing questions regarding
   cirrhosis and hepatocellu- lar carcinoma
SO CLINICAL AND MOLECULAR HEPATOLOGY
VL 29
IS 3
BP 721
EP 732
DI 10.3350/cmh.2023.0089
DT Article
PD JUL 2023
PY 2023
AB Background/Aims: Patients with cirrhosis and hepatocellular carcinoma
   (HCC) require extensive and personalized care to improve outcomes.
   ChatGPT (Generative Pre-trained Transformer), a large language model,
   holds the potential to provide professional yet patient-friendly
   support. We aimed to examine the accuracy and reproducibility of ChatGPT
   in answering questions regarding knowledge, management, and emotional
   support for cirrhosis and HCC. Methods: ChatGPT's responses to 164
   questions were independently graded by two transplant hepatologists and
   resolved by a third reviewer. The performance of ChatGPT was also
   assessed using two published questionnaires and 26 questions formulated
   from the quality measures of cirrhosis management. Finally, its
   emotional support capacity was tested. Results: We showed that ChatGPT
   regurgitated extensive knowledge of cirrhosis (79.1% correct) and HCC
   (74.0% cor-rect), but only small proportions (47.3% in cirrhosis, 41.1%
   in HCC) were labeled as comprehensive. The performance was better in
   basic knowledge, lifestyle, and treatment than in the domains of
   diagnosis and preventive medicine. For the quality measures, the model
   answered 76.9% of questions correctly but failed to specify
   decision-making cut-off s and treatment durations. ChatGPT lacked
   knowledge of regional guidelines variations, such as HCC screening
   criteria. How-ever, it provided practical and multifaceted advice to
   patients and caregivers regarding the next steps and adjusting to a new
   diagnosis. Conclusions: We analyzed the areas of robustness and
   limitations of ChatGPT's responses on the management of cirrhosis and
   HCC and relevant emotional support. ChatGPT may have a role as an
   adjunct informational tool for patients and physicians to improve
   outcomes. (Clin Mol Hepatol 2023;29:721-732)
ZS 1
Z8 6
ZR 0
ZA 0
ZB 60
TC 343
Z9 346
DA 2023-08-26
UT WOS:001042245200002
PM 36946005
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Mizuta, Kazuya
   Sakamoto, Tetsu
   Tokumasu, Kazuki
   Shimizu, Taro
TI Evaluating ChatGPT-4's Accuracy in Identifying Final Diagnoses Within
   Differential Diagnoses Compared With Those of Physicians: Experimental
   Study for Diagnostic Cases
SO JMIR FORMATIVE RESEARCH
VL 8
AR e59267
DI 10.2196/59267
DT Article
PD 2024
PY 2024
AB Background: The potential of artificial intelligence (AI) chatbots,
   particularly ChatGPT with GPT-4 (OpenAI), in assistingwith medical
   diagnosis is an emerging research area. However, it is not yet clear how
   well AI chatbots can evaluate whether thefinal diagnosis is included in
   differential diagnosis lists. Objective: This study aims to assess the
   capability of GPT-4 in identifying the final diagnosis from
   differential-diagnosis listsand to compare its performance with that of
   physicians for case report series. Methods: We used a database of
   differential-diagnosis lists from case reports in the American Journal
   of Case Reports,corresponding to final diagnoses. These lists were
   generated by 3 AI systems: GPT-4, Google Bard (currently Google
   Gemini),and Large Language Models by Meta AI 2 (LLaMA2). The primary
   outcome was focused on whether GPT-4's evaluationsidentified the final
   diagnosis within these lists. None of these AIs received additional
   medical training or reinforcement. Forcomparison, 2 independent
   physicians also evaluated the lists, with any inconsistencies resolved
   by another physician. Results: The 3 AIs generated a total of 1176
   differential diagnosis lists from 392 case descriptions. GPT-4's
   evaluations concurredwith those of the physicians in 966 out of 1176
   lists (82.1%). The Cohen kappa coefficient was 0.63 (95% CI 0.56-0.69),
   indicatinga fair to good agreement between GPT-4 and the physicians'
   evaluations. Conclusions: GPT-4 demonstrated a fair to good agreement in
   identifying the final diagnosis from differential-diagnosis
   lists,comparable to physicians for case report series. Its ability to
   compare differential diagnosis lists with final diagnoses suggests
   itspotential to aid clinical decision-making support through diagnostic
   feedback. While GPT-4 showed a fair to good agreement forevaluation, its
   application in real-world scenarios and further validation in diverse
   clinical environments are essential to fullyunderstand its utility in
   the diagnostic process.
ZS 0
ZB 0
TC 5
ZA 0
ZR 0
Z8 0
Z9 5
DA 2024-09-21
UT WOS:001303612400011
PM 38924784
ER

PT J
AU van Diessen, Eric
   van Amerongen, Ramon A.
   Zijlmans, Maeike
   Otte, Willem M.
TI Potential merits and flaws of large language models in epilepsy care: A
   critical review
SO EPILEPSIA
VL 65
IS 4
BP 873
EP 886
DI 10.1111/epi.17907
EA FEB 2024
DT Review
PD APR 2024
PY 2024
AB The current pace of development and applications of large language
   models (LLMs) is unprecedented and will impact future medical care
   significantly. In this critical review, we provide the background to
   better understand these novel artificial intelligence (AI) models and
   how LLMs can be of future use in the daily care of people with epilepsy.
   Considering the importance of clinical history taking in diagnosing and
   monitoring epilepsy-combined with the established use of electronic
   health records-a great potential exists to integrate LLMs in epilepsy
   care. We present the current available LLM studies in epilepsy.
   Furthermore, we highlight and compare the most commonly used LLMs and
   elaborate on how these models can be applied in epilepsy. We further
   discuss important drawbacks and risks of LLMs, and we provide
   recommendations for overcoming these limitations.
ZA 0
TC 5
ZS 0
ZR 0
Z8 0
ZB 0
Z9 5
DA 2024-02-10
UT WOS:001155360500001
PM 38305763
ER

PT J
AU Al-Maadid, Fatima
   Hadid, Faisal
   Mohamedzain, Ali
   Ali, Farhan
   Thabet, Farouq
TI Teaching Video NeuroImage: Rectus Femoris Muscle Fibrosis Presenting as
   Abnormal Gait in Childhood With a Positive Ely Maneuver
SO NEUROLOGY
VL 101
IS 23
BP E2456
EP E2457
DI 10.1212/WNL.0000000000207970
DT Editorial Material
PD DEC 5 2023
PY 2023
AB A 7-year-old boy presented with abnormal gait since age 3 years.
   Examination showed left-sided limping with external rotation. On passive
   flexion of the knees while the patient lied prone, the left heel could
   not reach the buttock and the left hip rose up (Video 1). This indicated
   a positive Ely test indicating limited flexibility of the rectus femoris
   muscle.1 Neurological examination was otherwise unremarkable. He had
   normal skeletal x-rays of both legs. MRI showed fibrosis of the rectus
   femoris muscle (Figure), which may be idiopathic or related to trauma.
   The patient had no history of muscle injury thus distant intramuscular
   injection was suspected to be the cause. Early diagnosis helps improve
   mobility through early surgical intervention.2 Ely test, which is not
   routinely performed during neurological examination, might be helpful in
   evaluating children with abnormal gait.
ZB 0
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
Z9 0
DA 2024-01-14
UT WOS:001110273400003
PM 37816650
ER

PT J
AU Ghorbian, Mohsen
   Ghobaei-Arani, Mostafa
   Ghorbian, Saied
TI Transforming breast cancer diagnosis and treatment with large language
   Models: A comprehensive survey
SO METHODS
VL 239
BP 85
EP 110
DI 10.1016/j.ymeth.2025.04.001
EA APR 2025
DT Article
PD JUL 2025
PY 2025
AB Breast cancer (BrCa), being one of the most prevalent forms of cancer in
   women, poses many challenges in the field of treatment and diagnosis due
   to its complex biological mechanisms. Early and accurate diagnosis plays
   a fundamental role in improving survival rates, but the limitations of
   existing imaging methods and clinical data interpretation often prevent
   optimal results. Large Language Models (LLMs), which are developed based
   on advanced architectures such as transformers, have brought about a
   significant revolution in data processing and medical decision-making.
   By analyzing a large volume of medical and clinical data, these models
   enable early diagnosis by identifying patterns in images and medical
   records and provide personalized treatment strategies by integrating
   genetic markers and clinical guidelines. Despite the transformative
   potential of these models, their use in BrCa management faces challenges
   such as data sensitivity, algorithm transparency, ethical
   considerations, and model compatibility with the details of medical
   applications that need to be addressed to achieve reliable results. This
   review systematically reviews the impact of LLMs on BrCa treatment and
   diagnosis. This study's objectives include analyzing the role of LLM
   technology in diagnosing and treating this disease. The findings
   indicate that the application of LLMs has resulted in significant
   improvements in various aspects of BrCa management, such as a 35%
   increase in the Efficiency of Diagnosis and BrCa Treatment (EDBC), a 30%
   enhancement in the System's Clinical Trust and Reliability (SCTR), and a
   20% improvement in the quality of patient education and information
   (IPEI). Ultimately, this study demonstrates the importance of LLMs in
   advancing precision medicine for BrCa and paves the way for effective
   patient-centered care solutions.
ZS 0
ZR 0
TC 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2025-04-20
UT WOS:001466448900001
PM 40199412
ER

PT J
AU Chang, Ying
   Yin, Jian-ming
   Li, Jian-min
   Liu, Chang
   Cao, Ling-yong
   Lin, Shu-yuan
TI Applications and Future Prospects of Medical LLMs: A Survey Based on the
   M-KAT Conceptual Framework
SO JOURNAL OF MEDICAL SYSTEMS
VL 48
IS 1
AR 112
DI 10.1007/s10916-024-02132-5
DT Review
PD DEC 27 2024
PY 2024
AB The success of large language models (LLMs) in general areas have
   sparked a wave of research into their applications in the medical field.
   However, enhancing the medical professionalism of these models remains a
   major challenge. This study proposed a novel model training theoretical
   framework, the M-KAT framework, which integrated domain-specific
   training methods for LLMs with the unique characteristics of the medical
   discipline. This framework aimed to improve the medical professionalism
   of the models from three perspectives: general knowledge acquisition,
   specialized skill development, and alignment with clinical thinking.
   This study summarized the outcomes of medical LLMs across four tasks:
   clinical diagnosis and treatment, medical question answering, medical
   research, and health management. Using the M-KAT framework, we analyzed
   the contribution to enhancement of professionalism of models through
   different training stages. At the same time, for some of the potential
   risks associated with medical LLMs, targeted solutions can be achieved
   through pre-training, SFT, and model alignment based on cultivated
   professional capabilities. Additionally, this study identified main
   directions for future research on medical LLMs: advancing professional
   evaluation datasets and metrics tailored to the needs of medical tasks,
   conducting in-depth studies on medical multimodal large language models
   (MLLMs) capable of integrating diverse data types, and exploring the
   forms of medical agents and multi-agent frameworks that can interact
   with real healthcare environments and support clinical decision-making.
   It is hoped that predictions of work can provide a reference for
   subsequent research.
ZS 0
Z8 0
TC 1
ZB 0
ZR 0
ZA 0
Z9 1
DA 2024-12-30
UT WOS:001383525300001
PM 39725770
ER

PT J
AU Sun, Virginia
   Heemelaar, Julius
   Hadzic, Ibrahim
   Raghu, Vineet
   Wu, Chia-Yun
   Zubiri, Leyre
   Ghamari, Azin
   Suero-Abreu, Giselle
   Wu, Jessica
   Hathaway, Nora
   Gilman, Hannah
   Villani, Alexandra-Chloe
   Ho, Sam
   Zlotoff, Daniel
   Blum, Steven
   Sullivan, Ryan
   Reynolds, Kerry
   Neilan, Tomas
TI Enhancing early detection of ICI myocarditis cases during
   hospitalization: A role for large language models
SO CIRCULATION
VL 150
MA 4119426
DI 10.1161/circ.150.suppl_1.4119426
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
TC 0
ZA 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
DA 2025-02-10
UT WOS:001398742700200
ER

PT J
AU Romano, Michael F.
   Shih, Ludy C.
   Paschalidis, Ioannis C.
   Au, Rhoda
   Kolachalama, Vijaya B.
TI Large Language Models in Neurology Research and Future Practice
SO NEUROLOGY
VL 101
IS 23
BP 1058
EP 1067
DI 10.1212/WNL.0000000000207967
DT Article
PD DEC 5 2023
PY 2023
AB Recent advancements in generative artificial intelligence, particularly
   using large language models (LLMs), are gaining increased public
   attention. We provide a perspective on the potential of LLMs to analyze
   enormous amounts of data from medical records and gain insights on
   specific topics in neurology. In addition, we explore use cases for
   LLMs, such as early diagnosis, supporting patient and caregivers, and
   acting as an assistant for clinicians. We point to the potential ethical
   and technical challenges raised by LLMs, such as concerns about privacy
   and data security, potential biases in the data for model training, and
   the need for careful validation of results. Researchers must consider
   these challenges and take steps to address them to ensure that their
   work is conducted in a safe and responsible manner. Despite these
   challenges, LLMs offer promising opportunities for improving care and
   treatment of various neurologic disorders.
TC 22
ZR 0
ZB 4
ZA 0
ZS 0
Z8 0
Z9 22
DA 2024-01-14
UT WOS:001110273400014
PM 37816646
ER

PT J
AU Hirosawa, Takanobu
   Mizuta, Kazuya
   Harada, Yukinori
   Shimizu, Taro
TI Comparative Evaluation of Diagnostic Accuracy Between Google Bard and
   Physicians
SO AMERICAN JOURNAL OF MEDICINE
VL 136
IS 11
BP 1119
EP +
DI 10.1016/j.amjmed.2023.08.003
EA OCT 2023
DT Article
PD NOV 2023
PY 2023
AB BACKGROUND: In this study, we evaluated the diagnostic accuracy of
   Google Bard, a generative artificial intelligence (AI) platform.
   METHODS: We searched published case reports from our department for
   difficult or uncommon case descriptions and mock cases created by
   physicians for common case descriptions. We entered the case
   descriptions into the prompt of Google Bard to generate the top 10
   differential-diagnosis lists. As in previous studies, other physicians
   created differential-diagnosis lists by reading the same clinical
   descriptions.RESULTS: A total of 82 clinical descriptions (52 case
   reports and 30 mock cases) were used. The accuracy rates of physicians
   were still higher than Google Bard in the top 10 (56.1% vs 82.9%, P <
   .001), the top 5 (53.7% vs 78.0%, P = .002), and the top differential
   diagnosis (40.2% vs 64.6%, P = .003). Even within the specific context
   of case reports, physicians consistently outperformed Google Bard. When
   it came to mock cases, the performances of the differential-diagnosis
   lists by Google Bard were no different from those of the physicians in
   the top 10 (80.0% vs 96.6%, P = .11) and the top 5 (76.7% vs 96.6%, P =
   .06), except for those in the top diagnoses (60.0% vs 90.0%, P =
   .02).CONCLUSION: While physicians excelled overall, and particularly
   with case reports, Google Bard dis -played comparable diagnostic
   performance in common cases. This suggested that Google Bard possesses
   room for further improvement and refinement in its diagnostic
   capabilities. Generative AIs, including Google Bard, are anticipated to
   become increasingly beneficial in augmenting diagnostic accuracy.
ZR 0
ZA 0
Z8 1
TC 22
ZB 1
ZS 0
Z9 23
DA 2023-11-24
UT WOS:001095121700001
PM 37643659
ER

PT J
AU Bannett, Yair
   Gunturkun, Fatma
   Pillai, Malvika
   Herrmann, Jessica E.
   Luo, Ingrid
   Huffman, Lynne C.
   Feldman, Heidi M.
TI Applying Large Language Models to Assess Quality of Care: Monitoring
   ADHD Medication Side Effects
SO PEDIATRICS
VL 155
IS 1
AR e2024067223
DI 10.1542/peds.2024-067223
DT Article
PD JAN 1 2024
PY 2024
AB OBJECTIVE: To assess the accuracy of a large language model (LLM) in
   measuring clinician adherence to practice guidelines for monitoring side
   effects after prescribing medications for children with
   attention-deficit/hyperactivity disorder (ADHD). METHODS: Retrospective
   population-based cohort study of electronic health records. Cohort
   included children aged 6 to 11 years with ADHD diagnosis and 2 or more
   ADHD medication encounters (stimulants or nonstimulants prescribed)
   between 2015 and 2022 in a community-based primary health care network
   (n = 1201). To identify documentation of side effects inquiry, we
   trained, tested, and deployed an open-source LLM (LLaMA) on all clinical
   notes from ADHD-related encounters (ADHD diagnosis or ADHD medication
   prescription), including in-clinic/telehealth and telephone encounters
   (n = 15 628 notes). Model performance was assessed using holdout and
   deployment test sets, compared with manual medical record review.
   RESULTS: The LLaMA model accurately classified notes that contained side
   effects inquiry (sensitivity = 87.2, specificity = 86.3, area under
   curve = 0.93 on holdout test set). Analyses revealed no model bias in
   relation to patient sex or insurance. Mean age (SD) at first
   prescription was 8.8 (1.6) years; characteristics were mostly similar
   across patients with and without documented side effects inquiry. Rates
   of documented side effects inquiry were lower for telephone encounters
   than for in-clinic/telehealth encounters (51.9% vs 73.0%, P < .001).
   Side effects inquiry was documented in 61.4% of encounters after
   stimulant prescriptions and 48.5% of encounters after nonstimulant
   prescriptions (P = .041). CONCLUSIONS: Deploying an LLM on a variable
   set of clinical notes, including telephone notes, offered scalable
   measurement of quality of care and uncovered opportunities to improve
   psychopharmacological medication management in primary care.
ZR 0
TC 1
Z8 0
ZS 0
ZA 0
ZB 0
Z9 1
DA 2025-03-23
UT WOS:001445125700006
PM 39701141
ER

PT J
AU Zhu, L.
   Anand, A.
   Gevorkyan, G.
   Mcgee, L. A.
   Rwigema, J. C.
   Rong, Y.
   Patel, S. H.
TI Testing and Validation of a Custom Trained Large Language Model for HN
   Patients with Guardrails
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 118
IS 5
MA 182
BP E52
EP E53
DT Meeting Abstract
PD APR 1 2024
PY 2024
CT Multidisciplinary Head and Neck Cancers Symposium
CY FEB 29-MAR 02, 2024
CL Phoenix, AZ
TC 1
ZS 0
Z8 0
ZA 0
ZR 0
ZB 0
Z9 1
DA 2024-10-18
UT WOS:001300212900102
ER

PT J
AU Nascimento, Jose Jerovane da Costa
   Marques, Adriell Gomes
   Souza, Lucas do Nascimento
   Dourado, Carlos Mauricio Jaborandy de Mattos
   Barros, Antonio Carlos da Silva
   de Albuquerque, Victor Hugo C.
   Sousa, Luis Fabricio de Freitas
TI A novel generative model for brain tumor detection using magnetic
   resonance imaging
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
VL 121
AR 102498
DI 10.1016/j.compmedimag.2025.102498
EA FEB 2025
DT Article
PD APR 2025
PY 2025
AB Brain tumors area disease that kills thousands of people worldwide each
   year. Early identification through diagnosis is essential for monitoring
   and treating patients. The proposed study brings anew method through
   intelligent computational cells that are capable of segmenting the tumor
   region with high precision. The method uses deep learning to detect
   brain tumors with the "You only look once"(Yolov8) framework, and a
   fine-tuning process at the end of the network layer using intelligent
   computational cells capable of traversing the detected region,
   segmenting the edges of the brain tumor. In addition, the method uses a
   classification pipeline that combines a set of classifiers and
   extractors combined with grid search, to find the best combination and
   the best parameters for the dataset. The method obtained satisfactory
   results above 98% accuracy for region detection, and above 99% for brain
   tumor segmentation and accuracies above 98% for binary classification of
   brain tumor, and segmentation time obtaining less than 1 s, surpassing
   the state of the art compared to the same database, demonstrating the
   effectiveness of the proposed method. The new approach proposes the
   classification of different databases through data fusion to classify
   the presence of tumor in MRI images, as well as the patient's life span.
   The segmentation and classification steps are validated by comparing
   them with the literature, with comparisons between works that used the
   same dataset. The method addresses anew generative AI for brain tumor
   capable of generating a pre-diagnosis through input data through Large
   Language Model (LLM), and can be used in systems to aid medical imaging
   diagnosis. As a contribution, this study employs new detection models
   combined with innovative methods based on digital image processing to
   improve segmentation metrics, as well as the use of Data Fusion,
   combining two tumor datasets to enhance classification performance. The
   study also utilizes LLM models to refine the pre-diagnosis obtained
   post-classification. Thus, this study proposes a Computer-Aided
   Diagnosis (CAD) method through AI with PDI, CNN, and LLM.
TC 0
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
Z9 0
DA 2025-03-03
UT WOS:001431977700001
PM 39985841
ER

PT J
AU Zhang, Min
   Cheng, Qi
   Wei, Zhenyu
   Xu, Jiayu
   Wu, Shiwei
   Xu, Nan
   Zhao, Chengkui
   Yu, Lei
   Feng, Weixing
TI BertTCR: a Bert-based deep learning framework for predicting
   cancer-related immune status based on T cell receptor repertoire
SO BRIEFINGS IN BIOINFORMATICS
VL 25
IS 5
AR bbae420
DI 10.1093/bib/bbae420
DT Article
PD AUG 23 2024
PY 2024
AB The T cell receptor (TCR) repertoire is pivotal to the human immune
   system, and understanding its nuances can significantly enhance our
   ability to forecast cancer-related immune responses. However, existing
   methods often overlook the intra- and inter-sequence interactions of T
   cell receptors (TCRs), limiting the development of sequence-based
   cancer-related immune status predictions. To address this challenge, we
   propose BertTCR, an innovative deep learning framework designed to
   predict cancer-related immune status using TCRs. BertTCR combines a
   pre-trained protein large language model with deep learning
   architectures, enabling it to extract deeper contextual information from
   TCRs. Compared to three state-of-the-art sequence-based methods, BertTCR
   improves the AUC on an external validation set for thyroid cancer
   detection by 21 percentage points. Additionally, this model was trained
   on over 2000 publicly available TCR libraries covering 17 types of
   cancer and healthy samples, and it has been validated on multiple public
   external datasets for its ability to distinguish cancer patients from
   healthy individuals. Furthermore, BertTCR can accurately classify
   various cancer types and healthy individuals. Overall, BertTCR is the
   advancing method for cancer-related immune status forecasting based on
   TCRs, offering promising potential for a wide range of immune status
   prediction tasks.
ZB 1
TC 5
Z8 0
ZA 0
ZR 0
ZS 0
Z9 5
DA 2024-09-10
UT WOS:001296768600001
PM 39177262
ER

PT J
AU Madadi, Yeganeh
   Delsoz, Mohammad
   Khouri, Albert S.
   Boland, Michael
   Grzybowski, Andrzej
   Yousefi, Siamak
TI Applications of artificial intelligence-enabled robots and chatbots in
   ophthalmology: recent advances and future trends
SO CURRENT OPINION IN OPHTHALMOLOGY
VL 35
IS 3
BP 238
EP 243
DI 10.1097/ICU.0000000000001035
DT Article
PD MAY 2024
PY 2024
AB Purpose of reviewRecent advances in artificial intelligence (AI),
   robotics, and chatbots have brought these technologies to the forefront
   of medicine, particularly ophthalmology. These technologies have been
   applied in diagnosis, prognosis, surgical operations, and
   patient-specific care in ophthalmology. It is thus both timely and
   pertinent to assess the existing landscape, recent advances, and
   trajectory of trends of AI, AI-enabled robots, and chatbots in
   ophthalmology.Recent findingsSome recent developments have integrated AI
   enabled robotics with diagnosis, and surgical procedures in
   ophthalmology. More recently, large language models (LLMs) like ChatGPT
   have shown promise in augmenting research capabilities and diagnosing
   ophthalmic diseases. These developments may portend a new era of
   doctor-patient-machine collaboration.SummaryOphthalmology is undergoing
   a revolutionary change in research, clinical practice, and surgical
   interventions. Ophthalmic AI-enabled robotics and chatbot technologies
   based on LLMs are converging to create a new era of digital
   ophthalmology. Collectively, these developments portend a future in
   which conventional ophthalmic knowledge will be seamlessly integrated
   with AI to improve the patient experience and enhance therapeutic
   outcomes.
ZA 0
TC 9
Z8 0
ZR 0
ZS 0
ZB 3
Z9 9
DA 2024-06-09
UT WOS:001233646400015
PM 38277274
ER

PT J
AU Schaye, Verity
   Ditullio, David
   Guzman, Benedict Vincent
   Vennemeyer, Scott
   Shih, Hanniel
   Reinstein, Ilan
   Weber, Danielle E.
   Goodman, Abbie
   Wu, Danny T. Y.
   Sartori, Daniel J.
   Santen, Sally A.
   Gruppen, Larry
   Aphinyanaphongs, Yindalon
   Burk-Rafel, Jesse
TI Large Language Model-Based Assessment of Clinical Reasoning
   Documentation in the Electronic Health Record Across Two Institutions:
   Development and Validation Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e67967
DI 10.2196/67967
DT Article
PD MAR 21 2025
PY 2025
AB Background: Clinical reasoning (CR) is an essential skill; yet,
   physicians often receive limited feedback. Artificial intelligence holds
   promise to fill this gap. Objective: We report the development of named
   entity recognition (NER), logic-based and large language model
   (LLM)-based assessments of CR documentation in the electronic health
   record across 2 institutions (New York University Grossman School of
   Medicine[NYU] and University of Cincinnati Collegeof Medicine[UC]).
   Methods: The note corpus consisted of internal medicine resident
   admission notes (retrospective set: July 2020-December 2021, n=700 NYU
   and 450 UC notes and prospective validation set: July 2023-December
   2023, n=155 NYU and 92 UC notes). Clinicians rated CR documentation
   quality in each note using a previously validated tool (Revised-IDEA),
   on 3-point scales across 2 domains: differential diagnosis (D0, D1, and
   D2) and explanation of reasoning, (EA0, EA1, and EA2). At NYU, the
   retrospective set was annotated for NER for 5 entities (diagnosis,
   diagnostic category, prioritization of diagnosis language, data, and
   linkage terms). Models were developed using different artificial
   intelligence approaches, including NER, logic-based model: a large word
   vector model (scispaCy en_core_sci_lg) with model weights adjusted with
   backpropagation from annotations, developed at NYU with external
   validation at UC, NYUTron LLM: an NYU internal 110 million parameter LLM
   pretrained on 7.25 million clinical notes, only validated at NYU, and
   GatorTron LLM: an open source 345 million parameter LLM pretrained on 82
   billion words of clinical text, fined tuned on NYU retrospective sets,
   then externally validated and further fine-tuned at UC. Model
   performance was assessed in the prospective sets with F1-scores for the
   NER, logic-based model and area under the receiver operating
   characteristic curve (AUROC) and area under the precision-recall curve
   (AUPRC) for the LLMs. Results: At NYU, the NYUTron LLM performed best:
   the D0 and D2 models had AUROC/AUPRC 0.87/0.79 and 0.89/0.86,
   respectively. The D1, EA0, and EA1 models had insufficient performance
   for implementation (AUROC range 0.57-0.80, AUPRC range 0.33-0.63). For
   the D1 classification, the approach pivoted to a stepwise approach
   taking advantage of the more performant D0 and D2 models. For the EA
   model, the approach pivoted to a binary EA2 model (ie, EA2 vs not EA2)
   with excellent performance, AUROC/AUPRC 0.85/ 0.80. At UC, the NER,
   D-logic-based model was the best performing D model (F1-scores 0.80,
   0.74, and 0.80 for D0, D1, D2, respectively. The GatorTron LLM performed
   best for EA2 scores AUROC/AUPRC 0.75/ 0.69. Conclusions:This is the
   first multi-institutional study to apply LLMs for assessing CR
   documentation in the electronic health record. Such tools can enhance
   feedback on CR. Lessons learned by implementing these models at distinct
   institutions support the generalizability of this approach.
ZR 0
TC 0
Z8 0
ZA 0
ZB 0
ZS 0
Z9 0
DA 2025-04-27
UT WOS:001469544100003
PM 40117575
ER

PT J
AU Yoo, Richard M.
   Viggiano, Ben T.
   Pundi, Krishna N.
   Fries, Jason A.
   Zahedivash, Aydin
   Podchiyska, Tanya
   Din, Natasha
   Shah, Nigam H.
TI Weak Supervision Enables Scalable Post-Market Surveillance on Medical
   Wearables
SO CIRCULATION
VL 148
MA A12454
DI 10.1161/circ.148.suppl_1.12454
SU 1
DT Meeting Abstract
PD NOV 7 2023
PY 2023
CT American-Heart-Association's Epidemiology and Prevention/Lifestyle and
   Cardiometabolic Health Scientific Sessions
CY NOV 11-13, 2023
CL Philadelphia, PA
SP Amer Heart Assoc
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-03-04
UT WOS:001157891301161
ER

PT J
AU Zeinali, Nahid
   Albashayreh, Alaa
   Fan, Weiguo
   White, Stephanie Gilbertson
TI Symptom-BERT: Enhancing Cancer Symptom Detection in EHR Clinical Notes
SO JOURNAL OF PAIN AND SYMPTOM MANAGEMENT
VL 68
IS 2
DI 10.1016/j.jpainsymman.2024.05.015
EA JUL 2024
DT Article
PD AUG 2024
PY 2024
AB Context. Extracting cancer symptom documentation allows clinicians to
   develop highly individualized symptom prediction algorithms to deliver
   symptom management care. Leveraging advanced language models to detect
   symptom data in clinical narratives can significantly fi cantly enhance
   this process. Objective. This study uses a pretrained large
   language model to detect and extract cancer symptoms in clinical
   notes. Methods. We developed a pretrained language model to
   identify cancer symptoms in clinical notes based on a clinical corpus
   from the Enterprise Data Warehouse for Research at a healthcare system
   in the Midwestern United States. This study was conducted in 4 phases:1
   1 pretraining a Bio-Clinical BERT model on one million unlabeled
   clinical documents,2 2 fi ne-tuning Symptom-BERT for detecting 13 cancer
   symptom groups within 1112 annotated clinical notes,3 3 generating 180
   synthetic clinical notes using ChatGPT-4 for external validation, and4 4
   comparing the internal and external performance of Symptom-BERT against
   a non-pretrained version and six other BERT implementations.
   Results. The Symptom-BERT model effectively detected cancer symptoms in
   clinical notes. It achieved results with a micro- averaged F1-score of
   0.933, an AUC of 0.929 internally, and 0.831 and 0.834 externally. Our
   analysis shows that physical symptoms, like Pruritus, are typically
   identified fi ed with higher performance than psychological symptoms,
   such as anxiety. Conclusion. This study underscores the
   transformative potential of specialized pretraining on domain-specific
   fi c data in boosting the performance of language models for medical
   applications. The Symptom-BERT model's ' s exceptional efficacy fi cacy
   in detecting cancer symptoms heralds a groundbreaking stride in
   patient-centered AI technologies, offering a promising path to elevate
   symptom management and cultivate superior patient self-care outcomes. J
   Pain Symptom Manage 2024;68:190-198. - 198. (c) 2024 American Academy of
   Hospice and Palliative Medicine. Published by Elsevier Inc. All rights
   are reserved, including those for text and data mining, AI training, and
   similar technologies.
ZR 0
ZB 0
Z8 0
ZA 0
TC 6
ZS 0
Z9 6
DA 2024-10-11
UT WOS:001326766200001
PM 38789092
ER

PT J
AU Cunningham, Jonathan W.
   Abraham, William T.
   Bhatt, Ankeet S.
   Dunn, Jessilyn
   Felker, G. Michael
   Jain, Sneha S.
   Lindsell, Christopher J.
   Mace, Matthew
   Martyn, Trejeeve
   Shah, Rashmee U.
   Tison, Geoffrey H.
   Fakhouri, Tala
   Psotka, Mitchell A.
   Krumholz, Harlan
   Fiuzat, Mona
   O'Connor, Christopher M.
   Solomon, Scott D.
CA Heart Failure Collaboratory
TI Artificial Intelligence in Cardiovascular Clinical Trials
SO JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY
VL 84
IS 20
BP 2051
EP 2062
DI 10.1016/j.jacc.2024.08.069
EA NOV 2024
DT Review
PD NOV 12 2024
PY 2024
AB Randomized clinical trials are the gold standard for establishing the
   efficacy and safety of cardiovascular therapies. However, current
   pivotal trials are expensive, lengthy, and insufficiently diverse.
   Emerging artificial intelligence (AI) technologies can potentially
   automate and streamline clinical trial operations. This review describes
   opportunities to integrate AI throughout a trial's life cycle, including
   designing the trial, identifying eligible patients, obtaining informed
   consent, ascertaining physiological and clinical event outcomes,
   interpreting imaging, and analyzing or disseminating the results.
   Nevertheless, AI poses risks, including generating inaccurate results,
   amplifying biases against underrepresented groups, and violating patient
   privacy. Medical journals and regulators are developing new frameworks
   to evaluate AI research tools and the data they generate. Given the
   high-stakes role of randomized trials in medical decision making, AI
   must be integrated carefully and transparently to protect the validity
   of trial results. (JACC. 2024;84:2051-2062) (c) 2024 The Authors.
   Published by Elsevier on behalf of the American College of Cardiology
   Foundation. This is an open access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZA 0
Z8 0
ZB 1
ZR 0
TC 5
ZS 0
Z9 5
DA 2024-11-16
UT WOS:001351382100001
PM 39505413
ER

PT J
AU Raja, Hina
   Huang, Xiaoqin
   Delsoz, Mohammad
   Madadi, Yeganeh
   Poursoroush, Asma
   Munawar, Asim
   Kahook, Malik Y.
   Yousefi, Siamak
TI Diagnosing Glaucoma Based on the Ocular Hypertension Treatment Study
   Dataset Using Chat Generative Pre-Trained Transformer as a Large
   Language Model
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100599
DI 10.1016/j.xops.2024.100599
EA SEP 2024
DT Article
PD JAN-FEB 2025
PY 2025
AB Purpose: To evaluate the capabilities of Chat Generative Pre-Trained
   Transformer (ChatGPT), as a large language model (LLM), for diagnosing
   glaucoma using the Ocular Hypertension Treatment Study (OHTS) dataset,
   and comparing the diagnostic capability of ChatGPT 3.5 and ChatGPT 4.0.
   Design: Prospective data collection study. Participants: A total of 3170
   eyes of 1585 subjects from the OHTS were included in this study.
   Methods: We selected demographic, clinical, ocular, visual field, optic
   nerve head photo, and history of disease parameters of each participant
   and developed case reports by converting tabular data into textual
   format based on information from both eyes of all subjects. We then
   developed a procedure using the application programming interface of
   ChatGPT, a LLM-based chatbot, to automatically input prompts into a chat
   box. This was followed by querying 2 different generations of ChatGPT
   (versions 3.5 and 4.0) regarding the underlying diagnosis of each
   subject. We then evaluated the output responses based on several
   objective metrics. Main Outcome Measures: Area under the receiver
   operating characteristic curve (AUC), accuracy, specificity,
   sensitivity, and F1 score. Results: Chat Generative Pre-Trained
   Transformer 3.5 achieved AUC of 0.74, accuracy of 66%, specificity of
   64%, sensitivity of 85%, and F1 score of 0.72. Chat Generative
   Pre-Trained Transformer 4.0 obtained AUC of 0.76, accuracy of 87%,
   specificity of 90%, sensitivity of 61%, and F1 score of 0.92.
   Conclusions: The accuracy of ChatGPT 4.0 in diagnosing glaucoma based on
   input data from OHTS was promising. The overall accuracy of ChatGPT 4.0
   was higher than ChatGPT 3.5. However, ChatGPT 3.5 was found to be more
   sensitive than ChatGPT 4.0. In its current forms, ChatGPT may serve as a
   useful tool in exploring disease status of ocular hypertensive eyes when
   specific data are available for analysis. In the future, leveraging LLMs
   with multimodal capabilities, allowing for integration of imaging and
   diagnostic testing as part of the analyses, could further enhance
   diagnostic capabilities and enhance diagnostic accuracy. Financial
   Disclosures: Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100599 (c) 2024 by the American Academy of Ophthalmology.
   This is an open access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-ncnd/4.0/).
ZR 0
ZB 0
ZA 0
Z8 0
TC 3
ZS 0
Z9 3
DA 2024-10-16
UT WOS:001330416200001
PM 39346574
ER

PT J
AU El Hajjar, Abdel Hadi
   Motairek, Issam
   Rosenzveig, Akiva
   Syed, Alveena
   Kassab, Joseph
   Al-Dalakta, Astefanos
   Klein, Allan
TI Innovative Use of Large Language Models to Diagnose Pericarditis in
   Patients Referred to a Tertiary Center for Uncertain Diagnosis
SO CIRCULATION
VL 150
MA 4147030
DI 10.1161/circ.150.suppl_1.4147030
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
CT American-Heart-Association Resuscitation Science Symposium
CY NOV 16-18, 2024
CL Chicago, IL
SP Amer Heart Assoc
Z8 0
ZS 0
ZA 0
ZR 0
ZB 0
TC 0
Z9 0
DA 2025-02-13
UT WOS:001400066403364
ER

PT J
AU Ueda, Daiju
   Walston, Shannon L.
   Matsumoto, Toshimasa
   Deguchi, Ryo
   Tatekawa, Hiroyuki
   Miki, Yukio
TI Evaluating GPT-4-based ChatGPT's clinical potential on the NEJM quiz
SO BMC DIGITAL HEALTH
VL 2
IS 1
AR 4
DI 10.1186/s44247-023-00058-5
DT Article
PD JAN 11 2024
PY 2024
AB BackgroundGPT-4-based ChatGPT demonstrates significant potential in
   various industries; however, its potential clinical applications remain
   largely unexplored.MethodsWe employed the New England Journal of
   Medicine (NEJM) quiz "Image Challenge" from October 2021 to March 2023
   to assess ChatGPT's clinical capabilities. The quiz, designed for
   healthcare professionals, tests the ability to analyze clinical
   scenarios and make appropriate decisions. We evaluated ChatGPT's
   performance on the NEJM quiz, analyzing its accuracy rate by questioning
   type and specialty after excluding quizzes which were impossible to
   answer without images. ChatGPT was first asked to answer without the
   five multiple-choice options, and then after being given the
   options.ResultsChatGPT achieved an 87% (54/62) accuracy without choices
   and a 97% (60/62) accuracy with choices, after excluding 16 image-based
   quizzes. Upon analyzing performance by quiz type, ChatGPT excelled in
   the Diagnosis category, attaining 89% (49/55) accuracy without choices
   and 98% (54/55) with choices. Although other categories featured fewer
   cases, ChatGPT's performance remained consistent. It demonstrated strong
   performance across the majority of medical specialties; however,
   Genetics had the lowest accuracy at 67% (2/3).ConclusionChatGPT
   demonstrates potential for diagnostic applications, suggesting its
   usefulness in supporting healthcare professionals in making differential
   diagnoses and enhancing AI-driven healthcare.
Z8 0
ZB 3
TC 13
ZS 0
ZA 0
ZR 0
Z9 13
DA 2024-01-11
UT WOS:001461607300001
ER

PT J
AU Zhang, Pengfei
   Wang, Hui
   Li, Pengfei
   Fu, Xianchun
   Yuan, Hang
   Ji, Hongwei
   Niu, Haitao
TI Assessing state-of-the-art online large language models for patient
   education regarding prostatitis
SO PROSTATE
VL 84
IS 12
BP 1173
EP 1175
DI 10.1002/pros.24746
EA MAY 2024
DT Letter
PD SEP 2024
PY 2024
ZA 0
TC 0
ZS 0
Z8 0
ZR 0
ZB 0
Z9 0
DA 2024-05-23
UT WOS:001223758400001
PM 38751201
ER

PT J
AU Liu, Jonathan
   Segal, Kathryn
   Daher, Mohammad
   Ozolin, Jordan
   Binder, William
   Bergen, Michael
   McDonald, Christopher L.
   Owens, Brett
   Antoci, Valentin
TI Artificial intelligence versus orthopedic surgeons as an orthopedic
   consultant in the emergency department
SO INJURY-INTERNATIONAL JOURNAL OF THE CARE OF THE INJURED
VL 56
IS 4
AR 112297
DI 10.1016/j.injury.2025.112297
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB Introduction: ChatGPT, a widely accessible AI program, has demonstrated
   potential in various healthcare applications, including emergency
   department (ED) triage, differential diagnosis, and patient education.
   However, its potential in providing recommendations to emergency
   department providers with orthopedic consultations has not been
   evaluated yet. Methods: This study compared the performance of four
   board certified orthopedic surgeons, two attendings and two trauma
   fellows who take independent call at the same institution and ChatGPT-4
   in responding to clinical scenarios commonly encountered in emergency
   departments. Five common orthopedic ED scenarios were developed (lateral
   malleolar ankle fractures, distal radius fractures, septic arthritis of
   the knee, shoulder dislocations, and Achilles tendon ruptures), each
   with four questions related to diagnosis, management, surgical
   indication, and patient counseling, totaling 20 questions. Responses
   were anonymized, coded, and evaluated by independent reviewers including
   emergency medicine physicians using a five-point Likert scale across
   five criteria: accuracy, completeness, helpfulness, specificity, and
   overall quality. Results: When comparing the ratings of AI answers to
   non-AI responders, the AI answers were shown to be superior in
   completeness, helpfulness, specificity, and overall quality with no
   difference in regards to accuracy (p < 0.05). When considering question
   subtypes including diagnosis, management, treatment, and patient
   counseling, AI was shown to have superior scores in helpfulness, and
   specificity in diagnostic questions(p < 0.05). In addition, AI responses
   were superior in all the assessed categories when looking at the patient
   counseling questions (p < 0.05). When considering different clinical
   scenarios, AI outperformed non-AI groups in completeness in the distal
   radius fracture scenario. Furthermore, AI outperformed non-AI groups in
   helpfulness in the lateral malleolus fracture scenario. In the shoulder
   dislocation scenario, AI responses were more complete, helpful, and had
   a better overall quality. AI responses were non-inferior in the
   remaining categories of the different scenarios. Conclusion: Artificial
   intelligence exhibited non-inferior and often superior performance in
   common orthopedic-ED consultations compared to board certified
   orthopedic surgeons While current AI models are limited in their ability
   to integrate specific images and patient scenarios, our findings suggest
   AI can provide high quality recommendations for generic orthopedic
   consultations and with further development, will likely have an
   increasing role in the future.
ZA 0
TC 0
ZS 0
ZB 0
ZR 0
Z8 0
Z9 0
DA 2025-05-21
UT WOS:001489449700001
PM 40147063
ER

PT J
AU Mira, Felipe Ahumada
   Favier, Valentin
   Nunes, Heloisa dos Santos Sobreira
   de Castro, Joana Vaz
   Carsuzaa, Florent
   Meccariello, Giuseppe
   Vicini, Claudio
   De Vito, Andrea
   Lechien, Jerome R.
   Estomba, Carlos Chiesa
   Maniaci, Antonino
   Iannella, Giannicola
   Rojas, Eduardo Pena
   Cornejo, Jenifer Barros
   Cammaroto, Giovanni
TI Chat GPT for the management of obstructive sleep apnea: do we have a
   polar star?
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 2087
EP 2093
DI 10.1007/s00405-023-08270-9
EA NOV 2023
DT Article
PD APR 2024
PY 2024
AB PurposeThis study explores the potential of the Chat-Generative
   Pre-Trained Transformer (Chat-GPT), a Large Language Model (LLM), in
   assisting healthcare professionals in the diagnosis of obstructive sleep
   apnea (OSA). It aims to assess the agreement between Chat-GPT's
   responses and those of expert otolaryngologists, shedding light on the
   role of AI-generated content in medical decision-making.MethodsA
   prospective, cross-sectional study was conducted, involving 350
   otolaryngologists from 25 countries who responded to a specialized OSA
   survey. Chat-GPT was tasked with providing answers to the same survey
   questions. Responses were assessed by both super-experts and
   statistically analyzed for agreement.ResultsThe study revealed that
   Chat-GPT and expert responses shared a common answer in over 75% of
   cases for individual questions. However, the overall consensus was
   achieved in only four questions. Super-expert assessments showed a
   moderate agreement level, with Chat-GPT scoring slightly lower than
   experts. Statistically, Chat-GPT's responses differed significantly from
   experts' opinions (p = 0.0009). Sub-analysis revealed areas of
   improvement for Chat-GPT, particularly in questions where super-experts
   rated its responses lower than expert consensus.ConclusionsChat-GPT
   demonstrates potential as a valuable resource for OSA diagnosis,
   especially where access to specialists is limited. The study emphasizes
   the importance of AI-human collaboration, with Chat-GPT serving as a
   complementary tool rather than a replacement for medical professionals.
   This research contributes to the discourse in otolaryngology and
   encourages further exploration of AI-driven healthcare applications.
   While Chat-GPT exhibits a commendable level of consensus with expert
   responses, ongoing refinements in AI-based healthcare tools hold
   significant promise for the future of medicine, addressing the
   underdiagnosis and undertreatment of OSA and improving patient outcomes.
ZS 0
ZB 5
Z8 0
TC 23
ZR 0
ZA 0
Z9 23
DA 2023-12-07
UT WOS:001103635400001
PM 37980605
ER

PT J
AU Li, Haotian
   Xia, Congmin
   Hou, Youjuan
   Hu, Sile
   Liu, Yanjun
   Jiang, Quan
TI TCMRD - KG: innovative design and development of rheumatology knowledge
   graph in ancient Chinese literature assisted by large language models
SO FRONTIERS IN PHARMACOLOGY
VL 16
AR 1535596
DI 10.3389/fphar.2025.1535596
DT Article
PD FEB 19 2025
PY 2025
AB Introduction Rheumatic immune diseases are a type of immune-inflammatory
   disease that affects muscles, bones, joints, and surrounding soft
   tissues. They have a long course and a high disability rate, seriously
   affecting the quality of life of patients. Traditional Chinese medicine
   plays an important role in the diagnosis and treatment of rheumatic
   immune diseases. The unique theoretical system and rich treatment
   methods of traditional Chinese medicine are preserved in ancient Chinese
   medical books.Methods This study takes the content related to rheumatism
   in ancient traditional Chinese medicine books as the research object,
   integrates ontology theory and technology into the knowledge graph, and
   realizes the reconstruction of traditional Chinese medicine information
   knowledge. It provides a basic data structure for data mining and
   knowledge discovery.Results This study is the first rheumatism-specific
   knowledge graph constructed based on ancient traditional Chinese
   medicine books. It has explored the construction method of a knowledge
   graph from ancient books by combining automatic labeling of mainstream
   large language models with manual review. Considering the knowledge
   characteristics of ancient traditional Chinese medicine books, where
   existing word segmentation technology struggles to accurately reproduce
   the original meaning, a new type of entity extraction method is
   proposed.Discussion This provides an important foundation for improving
   the clinical diagnosis and treatment level of traditional Chinese
   medicine in treating rheumatism, further exploring the knowledge
   representation and application of traditional Chinese medicine in
   rheumatism treatment, and it has potential for future expansion and
   improvement.
ZS 0
TC 1
ZA 0
Z8 0
ZR 0
ZB 0
Z9 1
DA 2025-03-09
UT WOS:001436847300001
PM 40046747
ER

PT J
AU Bhasuran, Balu
   Jin, Qiao
   Xie, Yuzhang
   Yang, Carl
   Hanna, Karim
   Costa, Jennifer
   Shavor, Cindy
   Han, Wenshan
   Lu, Zhiyong
   He, Zhe
TI Preliminary analysis of the impact of lab results on large language
   model generated differential diagnoses
SO NPJ DIGITAL MEDICINE
VL 8
IS 1
AR 166
DI 10.1038/s41746-025-01556-8
DT Article
PD MAR 18 2025
PY 2025
AB Differential diagnosis (DDx) is crucial for medicine as it helps
   healthcare providers systematically distinguish between conditions that
   share similar symptoms. This study evaluates the influence of lab test
   results on DDx accuracy generated by large language models (LLMs).
   Clinical vignettes from 50 randomly selected case reports from
   PMC-Patients were created, incorporating demographics, symptoms, and lab
   data. Five LLMs-GPT-4, GPT-3.5, Llama-2-70b, Claude-2, and
   Mixtral-8x7B-were tested to generate Top 10, Top 5, and Top 1 DDx with
   and without lab data. Results show that incorporating lab data enhances
   accuracy by up to 30% across models. GPT-4 achieved the highest
   performance, with Top 1 accuracy of 55% (0.41-0.69) and lenient accuracy
   reaching 79% (0.68-0.90). Statistically significant improvements
   (Holm-adjusted p values < 0.05) were observed, with GPT-4 and Mixtral
   excelling. Lab tests, including liver function, metabolic/toxicology
   panels, and serology, were generally interpreted correctly by LLMs for
   DDx.
Z8 0
TC 1
ZS 0
ZR 0
ZB 0
ZA 0
Z9 1
DA 2025-03-27
UT WOS:001449534900001
PM 40102561
ER

PT J
AU Bartal, Alon
   Jagodnik, Kathleen M.
   Chan, Sabrina J.
   Dekel, Sharon
TI AI and narrative embeddings detect PTSD following childbirth via birth
   stories
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 8336
DI 10.1038/s41598-024-54242-2
DT Article
PD APR 11 2024
PY 2024
AB Free-text analysis using machine learning (ML)-based natural language
   processing (NLP) shows promise for diagnosing psychiatric conditions.
   Chat Generative Pre-trained Transformer (ChatGPT) has demonstrated
   preliminary initial feasibility for this purpose; however, whether it
   can accurately assess mental illness remains to be determined. This
   study evaluates the effectiveness of ChatGPT and the
   text-embedding-ada-002 (ADA) model in detecting post-traumatic stress
   disorder following childbirth (CB-PTSD), a maternal postpartum mental
   illness affecting millions of women annually, with no standard screening
   protocol. Using a sample of 1295 women who gave birth in the last six
   months and were 18+ years old, recruited through hospital announcements,
   social media, and professional organizations, we explore ChatGPT's and
   ADA's potential to screen for CB-PTSD by analyzing maternal childbirth
   narratives. The PTSD Checklist for DSM-5 (PCL-5; cutoff 31) was used to
   assess CB-PTSD. By developing an ML model that utilizes numerical vector
   representation of the ADA model, we identify CB-PTSD via narrative
   classification. Our model outperformed (F1 score: 0.81) ChatGPT and six
   previously published large text-embedding models trained on mental
   health or clinical domains data, suggesting that the ADA model can be
   harnessed to identify CB-PTSD. Our modeling approach could be
   generalized to assess other mental health disorders.
ZB 0
ZA 0
TC 7
Z8 0
ZS 0
ZR 0
Z9 7
DA 2024-05-01
UT WOS:001201413300029
PM 38605073
ER

PT J
AU Hermann, Catherine E.
   Patel, Jharna M.
   Boyd, Leslie
   Aviki, Emeline
   Stasenko, Marina
TI Let's chat about cervical cancer: Assessing the accuracy of ChatGPT
   responses to cervical cancer questions
SO GYNECOLOGIC ONCOLOGY
VL 179
BP 164
EP 168
DI 10.1016/j.ygyno.2023.11.008
EA NOV 2023
DT Article
PD DEC 2023
PY 2023
AB Objective. To quantify the accuracy of ChatGPT in answering commonly
   asked questions pertaining to cervical cancer prevention, diagnosis,
   treatment, and survivorship/quality-of-life (QOL). Methods. ChatGPT was
   queried with 64 questions adapted from professional society websites and
   the au-thors' clinical experiences. The answers were scored by two
   attending Gynecologic Oncologists according to the following scale: 1)
   correct and comprehensive, 2) correct but not comprehensive, 3) some
   correct, some in-correct, and 4) completely incorrect. Scoring
   discrepancies were resolved by additional reviewers as needed. The
   proportion of responses earning each score were calculated overall and
   within each question category.Results. ChatGPT provided correct and
   comprehensive answers to 34 (53.1%) questions, correct but not
   com-prehensive answers to 19 (29.7%) questions, partially incorrect
   answers to 10 (15.6%) questions, and completely incorrect answers to 1
   (1.6%) question. Prevention and survivorship/QOL had the highest
   proportion of "correct" scores (scores of 1 or 2) at 22/24 (91.7%) and
   15/16 (93.8%), respectively. ChatGPT performed less well in the
   treatment category, with 15/21 (71.4%) correct scores. It performed the
   worst in the diagnosis category with only 1/3 (33.3%) correct
   scores.Conclusion. ChatGPT accurately answers questions about cervical
   cancer prevention, survivorship, and QOL. It performs less accurately
   for cervical cancer diagnosis and treatment. Further development of this
   immensely popular large language model should include physician input
   before it can be utilized as a tool for Gynecologists or recommended as
   a patient resource for information on cervical cancer diagnosis and
   treatment.(c) 2023 Elsevier Inc. All rights reserved.
TC 21
ZR 0
ZA 0
Z8 0
ZB 6
ZS 0
Z9 21
DA 2023-12-23
UT WOS:001122497400001
PM 37988948
ER

PT J
AU Seth, Ishith
   Xie, Yi
   Rodwell, Aaron
   Gracias, Dylan
   Bulloch, Gabriella
   Hunter-Smith, David J.
   Rozen, Warren M.
TI Exploring the Role of a Large Language Model on Carpal Tunnel Syndrome
   Management: An Observation Study of ChatGPT
SO JOURNAL OF HAND SURGERY-AMERICAN VOLUME
VL 48
IS 10
BP 1025
EP 1033
DI 10.1016/j.jhsa.2023.07.003
EA OCT 2023
DT Article
PD OCT 2023
PY 2023
AB Purpose Recently, large language models, such as ChatGPT, have emerged
   as promising tools to facilitate scientific research and health care
   management. The present study aimed to explore the extent of knowledge
   possessed by ChatGPT concerning carpal tunnel syndrome (CTS), a
   compressive neuropathy that may lead to impaired hand function and that
   is frequently encountered in the field of hand surgery.Methods Six
   questions pertaining to diagnosis and management of CTS were posed to
   ChatGPT. The responses were subsequently analyzed and evaluated based on
   their accuracy, coherence, and comprehensiveness. In addition, ChatGPT
   was requested to provide five high-level evidence references in support
   of its answers. A simulated doctor-patient consultation was also
   conducted to assess whether ChatGPT could offer safe medical
   advice.Results ChatGPT supplied clinically relevant information
   regarding CTS, although at a rela-tively superficial level. In the
   context of doctor-patient interaction, ChatGPT suggested a diagnostic
   pathway that deviated from the widely accepted clinical consensus on CTS
   diagnosis. Nevertheless, it incorporated differential diagnoses and
   valuable management options for CTS. Although ChatGPT demonstrated the
   ability to retain and recall information from previous patient
   conversations, it infrequently produced pertinent references, many of
   which were either nonexistent or incorrect. Conclusions ChatGPT
   displayed the capability to deliver validated medical information on CTS
   to nonmedical individuals. However, the generation of nonexistent and
   inaccurate references by ChatGPT presents a challenge to academic
   integrity.Clinical relevance To increase their utility in medicine and
   academia, large language models must go through specialized reputable
   data set training and validation from experts. It is essential to note
   that at present, large language models cannot replace the expertise of
   health care professionals and may act as a supportive tool.(c) 2023 by
   the American Society for Surgery of the Hand. All rights reserved.)
ZS 0
TC 39
ZB 2
ZA 0
Z8 0
ZR 0
Z9 39
DA 2023-11-05
UT WOS:001086963800001
PM 37530687
ER

PT J
AU Saibene, Alberto Maria
   Allevi, Fabiana
   Calvo-Henriquez, Christian
   Maniaci, Antonino
   Mayo-Yanez, Miguel
   Paderno, Alberto
   Vaira, Luigi Angelo
   Felisati, Giovanni
   Craig, John R.
TI Reliability of large language models in managing odontogenic sinusitis
   clinical scenarios: a preliminary multidisciplinary evaluation
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 4
BP 1835
EP 1841
DI 10.1007/s00405-023-08372-4
EA JAN 2024
DT Article
PD APR 2024
PY 2024
AB PurposeThis study aimed to evaluate the utility of large language model
   (LLM) artificial intelligence tools, Chat Generative Pre-Trained
   Transformer (ChatGPT) versions 3.5 and 4, in managing complex
   otolaryngological clinical scenarios, specifically for the
   multidisciplinary management of odontogenic sinusitis (ODS).MethodsA
   prospective, structured multidisciplinary specialist evaluation was
   conducted using five ad hoc designed ODS-related clinical scenarios. LLM
   responses to these scenarios were critically reviewed by a
   multidisciplinary panel of eight specialist evaluators (2 ODS experts, 2
   rhinologists, 2 general otolaryngologists, and 2 maxillofacial
   surgeons). Based on the level of disagreement from panel members, a
   Total Disagreement Score (TDS) was calculated for each LLM response, and
   TDS comparisons were made between ChatGPT3.5 and ChatGPT4, as well as
   between different evaluators.ResultsWhile disagreement to some degree
   was demonstrated in 73/80 evaluator reviews of LLMs' responses, TDSs
   were significantly lower for ChatGPT4 compared to ChatGPT3.5. Highest
   TDSs were found in the case of complicated ODS with orbital abscess,
   presumably due to increased case complexity with dental, rhinologic, and
   orbital factors affecting diagnostic and therapeutic options. There were
   no statistically significant differences in TDSs between evaluators'
   specialties, though ODS experts and maxillofacial surgeons tended to
   assign higher TDSs.ConclusionsLLMs like ChatGPT, especially newer
   versions, showed potential for complimenting evidence-based clinical
   decision-making, but substantial disagreement was still demonstrated
   between LLMs and clinical specialists across most case examples,
   suggesting they are not yet optimal in aiding clinical management
   decisions. Future studies will be important to analyze LLMs' performance
   as they evolve over time.
ZB 3
TC 17
ZA 0
Z8 1
ZR 0
ZS 0
Z9 18
DA 2024-01-19
UT WOS:001137890900006
PM 38189967
ER

PT J
AU Gabriel, Rodney A.
   Litake, Onkar
   Simpson, Sierra
   Burton, Brittany N.
   Waterman, Ruth S.
   Macias, Alvaro A.
TI On the development and validation of large language model- based
   classifiers for identifying social determinants of health
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
VL 121
IS 39
AR e2320716121
DI 10.1073/pnas.2320716121
DT Article
PD SEP 24 2024
PY 2024
AB The assessment of social determinants of health (SDoH) within healthcare
   systems is crucial for comprehensive patient care and addressing health
   disparities. Current challenges arise from the limited inclusion of
   structured SDoH information within electronic health record (EHR)
   systems, often due to the lack of standardized diagnosis codes. This
   study delves into the transformative potential of large language models
   (LLM) to overcome these challenges. LLM-based classifiers-using
   Bidirectional Encoder Representations from Transformers (BERT) and A
   Robustly Optimized BERT Pretraining Approach (RoBERTa)-were developed
   for SDoH concepts, including homelessness, food insecurity, and domestic
   violence, using synthetic training datasets generated by generative pre-
   trained transformers combined with authentic clinical notes. Models were
   then validated on separate datasets: Medical Information Mart for
   Intensive Care- III and our institutional EHR data. When training the
   model with a combination of synthetic and authentic notes, validation on
   our institutional dataset yielded an area under the receiver operating
   characteristics curve of 0.78 for detecting homelessness, 0.72 for
   detecting food insecurity, and 0.83 for detecting domestic violence.
   This study underscores the potential of LLMs in extracting SDoH
   information from clinical text. Automated detection of SDoH may be
   instrumental for healthcare providers in identifying at- risk patients,
   guiding targeted interventions, and contributing to population health
   initiatives aimed at mitigating disparities.
TC 5
ZA 0
ZS 0
ZR 0
ZB 2
Z8 0
Z9 5
DA 2024-12-11
UT WOS:001369554000005
PM 39284061
ER

PT J
AU Kunze, Kyle N.
TI Editorial Commentary: The Scope of Medical Research Concerning ChatGPT
   Remains Limited by Lack of Originality
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 6
BP 1828
EP 1830
DI 10.1016/j.arthro.2024.09.013
DT Article
PD JUN 2025
PY 2025
AB There is no shortage of literature surrounding ChatGPT and whether this
   large language model can provide accurate and clinically relevant
   information in response to simulated patient queries. Unfortunately,
   there is a shortage of literature addressing important considerations
   beyond these experimental and entertaining uses. Indeed, a trend for
   redundancy has emerged where most of the literature has applied ChatGPT
   to the same tasks while simply swapping the subject matter, resulting in
   a failure to expand the impact and reach of this potentially
   transformational artificial intelligence (AI) solution. Instead,
   research addressing pressing health care challenges and a renewed focus
   on novel use cases will allow for more meaningful research initiatives,
   product development, and tangible changes at both the system and
   point-of-care levels. Current target areas of interest in medicine that
   remain obstacles to patient care include prior authorization,
   administrative burden, documentation generation, medical triage and
   diagnosis, and patient communication efficiency. To advance this area of
   research toward such meaningful applications, a structured framework is
   necessary. Such frameworks should include problem identification;
   definition of key performance indicators; multidisciplinary and
   multi-institutional collaboration of those with domain expertise,
   including AI engineers and information technology specialists; policy
   and strategy development driven by executive-level personnel;
   institutional financial support and investment from key stakeholders for
   AI infrastructure and maintenance; and critical assessment of AI
   performance, bias, and equity.
Z8 0
TC 1
ZB 0
ZS 0
ZA 0
ZR 0
Z9 1
DA 2025-06-13
UT WOS:001505151400011
PM 39278424
ER

PT J
AU Stanley, Jack
   Rabot, Emmett
   Reddy, Siva
   Belilovsky, Eugene
   Mottron, Laurent
   Bzdok, Danilo
TI Large language models deconstruct the clinical intuition behind
   diagnosing autism
SO CELL
VL 188
IS 8
DI 10.1016/j.cell.2025.02.025
EA APR 2025
DT Article
PD APR 17 2025
PY 2025
AB Efforts to use genome-wide assays or brain scans to diagnose autism have
   seen diminishing returns. Yet the clinical intuition of healthcare
   professionals, based on longstanding first-hand experience, remains the
   gold standard for diagnosis of autism. We leveraged deep learning to
   deconstruct and interrogate the logic of expert clinician intuition from
   clinical reports to inform our understanding of autism. After
   pre-training on hundreds of millions of general sentences, we finessed
   large language models (LLMs) on >4,000 free-form health records from
   healthcare professionals to distinguish confirmed versus suspected
   autism cases. By introducing an explainability strategy, our extended
   language model architecture could pin down the most salient single
   sentences in what drives clinical thinking toward correct diagnoses. Our
   framework flagged the most autism-critical DSM-5 criteria to be
   stereotyped repetitive behaviors, special interests, and
   perception-based behaviors, which challenges today's focus on deficits
   in social interplay, suggesting necessary revision of long-trusted
   diagnostic criteria in gold-standard instruments.
ZS 0
ZB 0
ZA 0
ZR 0
Z8 0
TC 0
Z9 0
DA 2025-05-06
UT WOS:001476532200001
PM 40147442
ER

PT J
AU Tu, Tao
   Schaekermann, Mike
   Palepu, Anil
   Saab, Khaled
   Freyberg, Jan
   Tanno, Ryutaro
   Wang, Amy
   Li, Brenna
   Amin, Mohamed
   Cheng, Yong
   Vedadi, Elahe
   Tomasev, Nenad
   Azizi, Shekoofeh
   Singhal, Karan
   Hou, Le
   Webson, Albert
   Kulkarni, Kavita
   Mahdavi, S. Sara
   Semturs, Christopher
   Gottweis, Juraj
   Barral, Joelle
   Chou, Katherine
   Corrado, Greg S.
   Matias, Yossi
   Karthikesalingam, Alan
   Natarajan, Vivek
TI Towards conversational diagnostic artificial intelligence
SO NATURE
DI 10.1038/s41586-025-08866-7
EA APR 2025
DT Article; Early Access
PY 2025
AB At the heart of medicine lies physician-patient dialogue, where skillful
   history-taking enables effective diagnosis, management and enduring
   trust1,2. Artificial intelligence (AI) systems capable of diagnostic
   dialogue could increase accessibility and quality of care. However,
   approximating clinicians' expertise is an outstanding challenge. Here we
   introduce AMIE (Articulate Medical Intelligence Explorer), a large
   language model (LLM)-based AI system optimized for diagnostic dialogue.
   AMIE uses a self-play-based3 simulated environment with automated
   feedback for scaling learning across disease conditions, specialties and
   contexts. We designed a framework for evaluating clinically meaningful
   axes of performance, including history-taking, diagnostic accuracy,
   management, communication skills and empathy. We compared AMIE's
   performance to that of primary care physicians in a randomized,
   double-blind crossover study of text-based consultations with validated
   patient-actors similar to objective structured clinical examination4,5.
   The study included 159 case scenarios from providers in Canada, the
   United Kingdom and India, 20 primary care physicians compared to AMIE,
   and evaluations by specialist physicians and patient-actors. AMIE
   demonstrated greater diagnostic accuracy and superior performance on 30
   out of 32 axes according to the specialist physicians and 25 out of 26
   axes according to the patient-actors. Our research has several
   limitations and should be interpreted with caution. Clinicians used
   synchronous text chat, which permits large-scale LLM-patient
   interactions, but this is unfamiliar in clinical practice. While further
   research is required before AMIE could be translated to real-world
   settings, the results represent a milestone towards conversational
   diagnostic AI.
ZS 0
ZA 0
ZB 0
ZR 0
TC 5
Z8 0
Z9 5
DA 2025-04-15
UT WOS:001462553800001
PM 40205050
ER

PT J
AU Halawani, Abdulghafour
   Mitchell, Alec
   Saffarzadeh, Mohammadali
   Wong, Victor
   Chew, Ben H.
   Forbes, Connor M.
TI Accuracy and Readability of Kidney Stone Patient Information Materials
   Generated by a Large Language Model Compared to Official Urologic
   Organizations
SO UROLOGY
VL 186
BP 107
EP 113
DI 10.1016/j.urology.2023.11.042
EA APR 2024
DT Article
PD APR 2024
PY 2024
AB OBJECTIVE To compare the readability and accuracy of large language
   model generated patient information materials (PIMs) to those supplied
   by the American Urological Association (AUA), Canadian Urological
   Association (CUA), and European Association of Urology (EAU) for kidney
   stones. METHODS PIMs from AUA, CUA, and EAU related to nephrolithiasis
   were obtained and categorized. The most frequent patient questions
   related to kidney stones were identified from an internet query and
   input into GPT-3.5 and GPT-4. PIMs and ChatGPT outputs were assessed for
   accuracy and readability using previously published indexes. We also
   assessed changes in ChatGPT outputs when a reading level was specified
   (grade 6). RESULTS Readability scores were better for PIMs from the CUA
   (grade level 10-12), AUA (8-10), or EAU (9-11) compared to the chatbot.
   GPT-3.5 had the worst readability scores at grade 13-14 and GPT-4 was
   likewise less readable than urologic organization PIMs with scores of
   11-13. While organizational PIMs were deemed to be accurate, the chatbot
   had high accuracy with minor details omitted. GPT-4 was more accurate in
   general stone information, dietary and medical management of kidney
   stones topics in comparison to GPT-3.5, while both models had the same
   accuracy in the surgical management of nephrolithiasis topics.
   CONCLUSION Current PIMs from major urologic organizations for kidney
   stones remain more readable than publicly available GPT outputs, but
   they are still higher than the reading ability of the general
   population. Of the available PIMs for kidney stones, those from the AUA
   are the most readable. Although Chatbot outputs for common kidney stone
   patient queries have a high degree of accuracy with minor omitted
   details, it is important for clinicians to understand their strengths
   and limitations. UROLOGY 186: 107-113, 2024. (c) 2024 Elsevier Inc. All
   rights reserved.
ZR 0
ZS 0
TC 6
ZB 0
Z8 1
ZA 0
Z9 7
DA 2024-06-07
UT WOS:001232043700001
PM 38395071
ER

PT J
AU Ozkan, Ecem
   Tekin, Aysun
   Ozkan, Mahmut Can
   Cabrera, Daniel
   Niven, Alexander
   Dong, Yue
TI Global Health care Professionals' Perceptions of Large Language Model
   Use In Practice: Cross-Sectional Survey Study
SO JMIR MEDICAL EDUCATION
VL 11
AR e58801
DI 10.2196/58801
DT Article
PD 2025
PY 2025
AB Background: ChatGPT is a large language model-based chatbot developed by
   OpenAI. ChatGPT has many potential applications to health care,
   including enhanced diagnostic accuracy and efficiency, improved
   treatment planning, and better patient outcomes. However, health care
   professionals' perceptions of ChatGPT and similar artificial
   intelligence tools are not well known. Understanding these attitudes is
   important to inform the best approaches to exploring their use in
   medicine. Objective: Our aim was to evaluate the health care
   professionals' awareness and perceptions regarding potential
   applications of ChatGPT in the medical field, including potential
   benefits and challenges of adoption. Methods: We designed a 33-question
   online survey that was distributed among health care professionals via
   targeted emails and professional Twitter and LinkedIn accounts. The
   survey included a range of questions to define respondents' demographic
   characteristics, familiarity with ChatGPT, perceptions of this tool's
   usefulness and reliability, and opinions on its potential to improve
   patient care, research, and education efforts. Results: One hundred and
   fifteen health care professionals from 21 countries responded to the
   survey, including physicians, nurses, researchers, and educators. Of
   these, 101 (87.8%) had heard of ChatGPT, mainly from peers, social
   media, and news, and 77 (76.2%) had used ChatGPT at least once.
   Participants found ChatGPT to be helpful for writing manuscripts (n=31,
   45.6%), emails (n=25, 36.8%), and grants (n=12, 17.6%); accessing the
   latest research and evidence-based guidelines (n=21, 30.9%); providing
   suggestions on diagnosis or treatment (n=15, 22.1%); and improving
   patient communication (n=12, 17.6%). Respondents also felt that the
   ability of ChatGPT to access and summarize research articles (n=22,
   46.8%), provide quick answers to clinical questions (n=15, 31.9%), and
   generate patient education materials (n=10, 21.3%) was helpful. However,
   there are concerns regarding the use of ChatGPT, for example, the
   accuracy of responses (n=14, 29.8%), limited applicability in specific
   practices (n=18, 38.3%), and legal and ethical considerations (n=6,
   12.8%), mainly related to plagiarism or copyright violations.
   Participants stated that safety protocols such as data encryption (n=63,
   62.4%) and access control (n=52, 51.5%) could assist in ensuring patient
   privacy and data security. Conclusions: Our findings show that ChatGPT
   use is widespread among health care professionals in daily clinical,
   research, and educational activities. The majority of our participants
   found ChatGPT to be useful; however, there are concerns about patient
   privacy, data security, and its legal and ethical issues as well as the
   accuracy of its information. Further studies are required to understand
   the impact of ChatGPT and other large language models on clinical,
   educational, and research outcomes, and the concerns regarding its use
   must be addressed systematically and through appropriate methods.
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-23
UT WOS:001490640700001
PM 40354644
ER

PT J
AU Xiong, Yichun
   Li, Jiaqi
   Jin, Wang
   Sheng, Xiaoran
   Peng, Hui
   Wang, Zhiyi
   Jia, Caifeng
   Zhuo, Lili
   Zhang, Yibo
   Huang, Jingzhe
   Zhai, Modi
   Lyu, Beibei
   Sun, Jie
   Zhou, Meng
TI PCMR: a comprehensive precancerous molecular resource
SO SCIENTIFIC DATA
VL 12
IS 1
AR 551
DI 10.1038/s41597-025-04899-9
DT Article
PD APR 1 2025
PY 2025
AB Early detection and intervention of precancerous lesions are crucial in
   reducing cancer morbidity and mortality. Comprehensive analysis of
   genomic, transcriptomic, proteomic and epigenomic alterations can
   provide insights into the early stages of carcinogenesis. However, the
   lacke of an integrated, well-curated data resource of molecular
   signatures limits our understanding of precancerous processes. Here, we
   introduce a comprehensive PreCancerous Molecular Resource (PCMR), which
   compiles 25,828 molecular profiles of precancerous samples paired with
   normal or malignant counterparts. These profiles cover precancerous
   lesions of 35 cancer types across 20 organs and tissues, derived from
   tissue samples, liquid biopsies, cell lines and organoids, with data
   from transcriptomics, proteomics and epigenomics. PCMR includes 62,566
   precancer-gene associations derived from differential analysis and
   text-mining using the ChatGPT large language model. We examined PCMR
   dataset reliability and significance by the authoritative precancerous
   molecular signature, along with its biological and clinical relevance.
   Overall, PCMR will serve as a valuable resource for advancing precancer
   research and ultimately improving patient outcomes.
ZR 0
ZB 0
ZS 0
ZA 0
Z8 0
TC 0
Z9 0
DA 2025-04-11
UT WOS:001459759400009
PM 40169679
ER

PT J
AU Kim, Hanjae
   Jin, Hee Min
   Bin Jung, Yoon
   You, Seng Chan
TI Patient-Friendly Discharge Summaries in Korea Based on ChatGPT: Software
   Development and Validation
SO JOURNAL OF KOREAN MEDICAL SCIENCE
VL 39
IS 16
AR e148
DI 10.3346/jkms.2024.39.e148
DT Article
PD APR 29 2024
PY 2024
AB Background: Although discharge summaries in patient -friendly language
   can enhance patient comprehension and satisfaction, they can also
   increase medical staff workload. Using a large language model, we
   developed and validated software that generates a patient -friendly
   discharge summary. Methods: We developed and tested the software using
   100 discharge summary documents, 50 for patients with myocardial
   infarction and 50 for patients treated in the Department of General
   Surgery. For each document, three new summaries were generated using
   three different prompting methods (Zero -shot, One-shot, and Few -shot)
   and graded using a 5 -point Likert Scale regarding factuality,
   comprehensiveness, usability, ease, and fluency. We compared the effects
   of different prompting methods and assessed the relationship between
   input length and output quality. Results: The mean overall scores
   differed across prompting methods (4.19 +/- 0.36 in Few -shot, 4.11 +/-
   0.36 in One-shot, and 3.73 +/- 0.44 in Zero -shot; P < 0.001). Post -hoc
   analysis indicated that the scores were higher with Few -shot and
   One-shot prompts than in zero -shot prompts, whereas there was no
   significant difference between Few -shot and One-shot prompts. The
   overall proportion of outputs that scored >= 4 was 77.0% (95% confidence
   interval: 68.8-85.3%), 70.0% (95% confidence interval [CI], 61.0-79.0%),
   and 32.0% (95% CI, 22.9-41.1%) with Few -shot, One-shot, and Zero -shot
   prompts, respectively. The mean factuality score was 4.19 +/- 0.60 with
   Few -shot, 4.20 +/- 0.55 with One-shot, and 3.82 +/- 0.57 with Zero
   -shot prompts. Input length and the overall score showed negative
   correlations in the Zero -shot ( r = -0.437, P < 0.001) and One-shot ( r
   = -0.327, P < 0.001) tests but not in the Few -shot ( r = -0.050, P =
   0.625) tests. Conclusion: Large -language models utilizing Few -shot
   prompts generally produce acceptable discharge summaries without
   significant misinformation. Our research highlights the potential of
   such models in creating patient -friendly discharge summaries for Korean
   patients to support patient -centered care.
TC 5
ZA 0
ZB 1
Z8 0
ZR 0
ZS 0
Z9 5
DA 2024-07-26
UT WOS:001233720700006
PM 38685890
ER

PT J
AU Goh, Ethan
   Gallo, Robert
   Hom, Jason
   Strong, Eric
   Weng, Yingjie
   Kerman, Hannah
   Cool, Josephine
   Kanjee, Zahir
   Parsons, Andrew S
   Ahuja, Neera
   Horvitz, Eric
   Yang, Daniel
   Milstein, Arnold
   Olson, Andrew P J
   Rodman, Adam
   Chen, Jonathan H
TI Influence of a Large Language Model on Diagnostic Reasoning: A
   Randomized Clinical Vignette Study.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2024.03.12.24303785
DT Preprint
PD 2024 Mar 14
PY 2024
AB Importance: Diagnostic errors are common and cause significant
   morbidity. Large language models (LLMs) have shown promise in their
   performance on both multiple-choice and open-ended medical reasoning
   examinations, but it remains unknown whether the use of such tools
   improves diagnostic reasoning.
   Objective: To assess the impact of the GPT-4 LLM on physicians'
   diagnostic reasoning compared to conventional resources.
   Design: Multi-center, randomized clinical vignette study.
   Setting: The study was conducted using remote video conferencing with
   physicians across the country and in-person participation across
   multiple academic medical institutions.
   Participants: Resident and attending physicians with training in family
   medicine, internal medicine, or emergency medicine.
   Interventions: Participants were randomized to access GPT-4 in addition
   to conventional diagnostic resources or to just conventional resources.
   They were allocated 60 minutes to review up to six clinical vignettes
   adapted from established diagnostic reasoning exams.
   Main Outcomes and Measures: The primary outcome was diagnostic
   performance based on differential diagnosis accuracy, appropriateness of
   supporting and opposing factors, and next diagnostic evaluation steps.
   Secondary outcomes included time spent per case and final diagnosis.
   Results: 50 physicians (26 attendings, 24 residents) participated, with
   an average of 5.2 cases completed per participant. The median diagnostic
   reasoning score per case was 76.3 percent (IQR 65.8 to 86.8) for the
   GPT-4 group and 73.7 percent (IQR 63.2 to 84.2) for the conventional
   resources group, with an adjusted difference of 1.6 percentage points
   (95% CI -4.4 to 7.6; p=0.60). The median time spent on cases for the
   GPT-4 group was 519 seconds (IQR 371 to 668 seconds), compared to 565
   seconds (IQR 456 to 788 seconds) for the conventional resources group,
   with a time difference of -82 seconds (95% CI -195 to 31; p=0.20). GPT-4
   alone scored 15.5 percentage points (95% CI 1.5 to 29, p=0.03) higher
   than the conventional resources group.
   Conclusions and Relevance: In a clinical vignette-based study, the
   availability of GPT-4 to physicians as a diagnostic aid did not
   significantly improve clinical reasoning compared to conventional
   resources, although it may improve components of clinical reasoning such
   as efficiency. GPT-4 alone demonstrated higher performance than both
   physician groups, suggesting opportunities for further improvement in
   physician-AI collaboration in clinical practice.
ZR 0
Z8 0
ZS 0
ZB 0
ZA 0
TC 2
Z9 2
DA 2024-04-03
UT MEDLINE:38559045
PM 38559045
ER

PT J
AU Li, Cheng-Peng
   Jia, Wei-Wei
   Chu, Yuan
   Menge, Franka
   Speer, Tobias
   ReiSSfelder, Christoph
   Hohenberger, Peter
   Jakob, Jens
   Yang, Cui
TI Improving Accuracy and Source Transparency in Responses to Soft Tissue
   Sarcoma Queries Using GPT-4o Enhanced with German Evidence-Based
   Guidelines.
SO Oncology research and treatment
VL 48
IS 6
BP 351
EP 359
DI 10.1159/000544978
DT Journal Article
PD 2025
PY 2025
AB INTRODUCTION: This study aimed to evaluate the effectiveness of GPT-4o,
   with and without retrieval-augmented generation (RAG), in responding to
   soft tissue sarcoma (STS)-related queries.
   METHODS: The study used a 20-question dataset derived from clinical
   scenarios related to adult STS. The responses were generated by GPT-4o
   with and without the RAG approach. The RAG system incorporated the
   English version of German evidence-based S3 guidelines through an
   embedding-based retrieval system. Two sarcoma experts evaluated the
   responses for accuracy, comprehensiveness, and safety using a Likert
   scale. Statistical analyses were conducted to compare the performances.
   RESULTS: GPT-4o with RAG outperformed the model without RAG across all
   evaluated areas (p < 0.05). GPT-4o without RAG had a 40% error rate,
   which was reduced to 10% by the RAG approach. In 90% of the questions,
   the pages with the relevant information that addressed the questions
   were correctly cited using the retrieval system.
   CONCLUSION: The RAG approach significantly enhanced the performance of
   GPT-4o in answering STS-related questions. However, the model still
   produced incorrect responses in certain complex scenarios. GPT-4o, even
   with RAG, should be used cautiously in clinical settings, particularly
   for rare diseases like sarcoma. Human expertise remains irreplaceable in
   medical decision-making.
ZS 0
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
Z9 0
DA 2025-03-05
UT MEDLINE:40024240
PM 40024240
ER

PT J
AU Heston, Thomas F.
   Lewis, Lawrence M.
TI ChatGPT provides inconsistent risk-stratification of patients with
   atraumatic chest pain
SO PLOS ONE
VL 19
IS 4
AR e0301854
DI 10.1371/journal.pone.0301854
DT Article
PD APR 16 2024
PY 2024
AB Background ChatGPT-4 is a large language model with promising healthcare
   applications. However, its ability to analyze complex clinical data and
   provide consistent results is poorly known. Compared to validated tools,
   this study evaluated ChatGPT-4's risk stratification of simulated
   patients with acute nontraumatic chest pain.Methods Three datasets of
   simulated case studies were created: one based on the TIMI score
   variables, another on HEART score variables, and a third comprising 44
   randomized variables related to non-traumatic chest pain presentations.
   ChatGPT-4 independently scored each dataset five times. Its risk scores
   were compared to calculated TIMI and HEART scores. A model trained on 44
   clinical variables was evaluated for consistency.Results ChatGPT-4
   showed a high correlation with TIMI and HEART scores (r = 0.898 and
   0.928, respectively), but the distribution of individual risk
   assessments was broad. ChatGPT-4 gave a different risk 45-48% of the
   time for a fixed TIMI or HEART score. On the 44-variable model, a
   majority of the five ChatGPT-4 models agreed on a diagnosis category
   only 56% of the time, and risk scores were poorly correlated (r =
   0.605).Conclusion While ChatGPT-4 correlates closely with established
   risk stratification tools regarding mean scores, its inconsistency when
   presented with identical patient data on separate occasions raises
   concerns about its reliability. The findings suggest that while large
   language models like ChatGPT-4 hold promise for healthcare applications,
   further refinement and customization are necessary, particularly in the
   clinical risk assessment of atraumatic chest pain patients.
ZS 0
ZA 0
TC 7
ZR 0
Z8 1
ZB 2
Z9 7
DA 2024-06-15
UT WOS:001205750000117
PM 38626142
ER

PT J
AU Cao, Jennie J.
   Kwon, Daniel H.
   Ghaziani, Tara T.
   Kwo, Paul
   Tse, Gary
   Kesselman, Andrew
   Kamaya, Aya
   Tse, Justin R.
TI Large language models' responses to liver cancer surveillance,
   diagnosis, and management questions: accuracy, reliability, readability
SO ABDOMINAL RADIOLOGY
VL 49
IS 12
BP 4286
EP 4294
DI 10.1007/s00261-024-04501-7
EA AUG 2024
DT Article
PD DEC 2024
PY 2024
AB Purpose To assess the accuracy, reliability, and readability of publicly
   available large language models in answering fundamental questions on
   hepatocellular carcinoma diagnosis and management. Methods Twenty
   questions on liver cancer diagnosis and management were asked in
   triplicate to ChatGPT-3.5 (OpenAI), Gemini (Google), and Bing
   (Microsoft). Responses were assessed by six fellowship-trained
   physicians from three academic liver transplant centers who actively
   diagnose and/or treat liver cancer. Responses were categorized as
   accurate (score 1; all information is true and relevant), inadequate
   (score 0; all information is true, but does not fully answer the
   question or provides irrelevant information), or inaccurate (score - 1;
   any information is false). Means with standard deviations were recorded.
   Responses were considered as a whole accurate if mean score was > 0 and
   reliable if mean score was > 0 across all responses for the single
   question. Responses were also quantified for readability using the
   Flesch Reading Ease Score and Flesch-Kincaid Grade Level. Readability
   and accuracy across 60 responses were compared using one-way ANOVAs with
   Tukey's multiple comparison tests. Results Of the twenty questions,
   ChatGPT answered nine (45%), Gemini answered 12 (60%), and Bing answered
   six (30%) questions accurately; however, only six (30%), eight (40%),
   and three (15%), respectively, were both accurate and reliable. There
   were no significant differences in accuracy between any chatbot. ChatGPT
   responses were the least readable (mean Flesch Reading Ease Score 29;
   college graduate), followed by Gemini (30; college) and Bing (40;
   college; p < 0.001). Conclusion Large language models provide complex
   responses to basic questions on hepatocellular carcinoma diagnosis and
   management that are seldomly accurate, reliable, or readable.
TC 8
ZB 1
ZA 0
ZR 0
Z8 1
ZS 0
Z9 8
DA 2024-08-11
UT WOS:001285078800003
PM 39088019
ER

PT J
AU Attai, Kingsley
   Ekpenyong, Moses
   Amannah, Constance
   Asuquo, Daniel
   Ajuga, Peterben
   Obot, Okure
   Johnson, Ekemini
   John, Anietie
   Maduka, Omosivie
   Akwaowo, Christie
   Uzoka, Faith-Michael
TI Enhancing the Interpretability of Malaria and Typhoid Diagnosis with
   Explainable AI and Large Language Models
SO TROPICAL MEDICINE AND INFECTIOUS DISEASE
VL 9
IS 9
AR 216
DI 10.3390/tropicalmed9090216
DT Article
PD SEP 2024
PY 2024
AB Malaria and Typhoid fever are prevalent diseases in tropical regions,
   and both are exacerbated by unclear protocols, drug resistance, and
   environmental factors. Prompt and accurate diagnosis is crucial to
   improve accessibility and reduce mortality rates. Traditional diagnosis
   methods cannot effectively capture the complexities of these diseases
   due to the presence of similar symptoms. Although machine learning (ML)
   models offer accurate predictions, they operate as "black boxes" with
   non-interpretable decision-making processes, making it challenging for
   healthcare providers to comprehend how the conclusions are reached. This
   study employs explainable AI (XAI) models such as Local Interpretable
   Model-agnostic Explanations (LIME), and Large Language Models (LLMs)
   like GPT to clarify diagnostic results for healthcare workers, building
   trust and transparency in medical diagnostics by describing which
   symptoms had the greatest impact on the model's decisions and providing
   clear, understandable explanations. The models were implemented on
   Google Colab and Visual Studio Code because of their rich libraries and
   extensions. Results showed that the Random Forest model outperformed the
   other tested models; in addition, important features were identified
   with the LIME plots while ChatGPT 3.5 had a comparative advantage over
   other LLMs. The study integrates RF, LIME, and GPT in building a mobile
   app to enhance the interpretability and transparency in malaria and
   typhoid diagnosis system. Despite its promising results, the system's
   performance is constrained by the quality of the dataset. Additionally,
   while LIME and GPT improve transparency, they may introduce complexities
   in real-time deployment due to computational demands and the need for
   internet service to maintain relevance and accuracy. The findings
   suggest that AI-driven diagnostic systems can significantly enhance
   healthcare delivery in environments with limited resources, and future
   works can explore the applicability of this framework to other medical
   conditions and datasets.
ZA 0
ZR 0
ZB 0
TC 1
ZS 0
Z8 0
Z9 1
DA 2024-10-07
UT WOS:001322854400001
PM 39330905
ER

PT J
AU Wu, Wanying
   Guo, Yuhu
   Li, Qi
   Jia, Congzhuo
TI Exploring the potential of large language models in identifying
   metabolic dysfunction-associated steatotic liver disease: A comparative
   study of non-invasive tests and artificial intelligence-generated
   responses
SO LIVER INTERNATIONAL
VL 45
IS 4
DI 10.1111/liv.16112
EA NOV 2024
DT Article
PD APR 2025
PY 2025
AB Background and AimsThis study sought to assess the capabilities of large
   language models (LLMs) in identifying clinically significant metabolic
   dysfunction-associated steatotic liver disease (MASLD).MethodsWe
   included individuals from NHANES 2017-2018. The validity and reliability
   of MASLD diagnosis by GPT-3.5 and GPT-4 were quantitatively examined and
   compared with those of the Fatty Liver Index (FLI) and United States FLI
   (USFLI). A receiver operating characteristic curve was conducted to
   assess the accuracy of MASLD diagnosis via different scoring systems.
   Additionally, GPT-4V's potential in clinical diagnosis using ultrasound
   images from MASLD patients was evaluated to provide assessments of LLM
   capabilities in both textual and visual data interpretation.ResultsGPT-4
   demonstrated comparable performance in MASLD diagnosis to FLI and USFLI
   with the AUROC values of .831 (95% CI .796-.867), .817 (95% CI
   .797-.837) and .827 (95% CI .807-.848), respectively. GPT-4 exhibited a
   trend of enhanced accuracy, clinical relevance and efficiency compared
   to GPT-3.5 based on clinician evaluation. Additionally, Pearson's r
   values between GPT-4 and FLI, as well as USFLI, were .718 and .695,
   respectively, indicating robust and moderate correlations. Moreover,
   GPT-4V showed potential in understanding characteristics from hepatic
   ultrasound imaging but exhibited limited interpretive accuracy in
   diagnosing MASLD compared to skilled radiologists.ConclusionsGPT-4
   achieved performance comparable to traditional risk scores in diagnosing
   MASLD and exhibited improved convenience, versatility and the capacity
   to offer user-friendly outputs. The integration of GPT-4V highlights the
   capacities of LLMs in handling both textual and visual medical data,
   reinforcing their expansive utility in healthcare practice.
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
DA 2024-11-23
UT WOS:001354198800001
PM 39526465
ER

PT J
AU Kedia, Nikita
   Sanjeev, Suvansh
   Ong, Joshua
   Chhablani, Jay
TI ChatGPT and Beyond: An overview of the growing field of large language
   models and their use in ophthalmology
SO EYE
VL 38
IS 7
BP 1252
EP 1261
DI 10.1038/s41433-023-02915-z
EA JAN 2024
DT Review
PD MAY 2024
PY 2024
AB ChatGPT, an artificial intelligence (AI) chatbot built on large language
   models (LLMs), has rapidly gained popularity. The benefits and
   limitations of this transformative technology have been discussed across
   various fields, including medicine. The widespread availability of
   ChatGPT has enabled clinicians to study how these tools could be used
   for a variety of tasks such as generating differential diagnosis lists,
   organizing patient notes, and synthesizing literature for scientific
   research. LLMs have shown promising capabilities in ophthalmology by
   performing well on the Ophthalmic Knowledge Assessment Program,
   providing fairly accurate responses to questions about retinal diseases,
   and in generating differential diagnoses list. There are current
   limitations to this technology, including the propensity of LLMs to
   "hallucinate", or confidently generate false information; their
   potential role in perpetuating biases in medicine; and the challenges in
   incorporating LLMs into research without allowing "AI-plagiarism" or
   publication of false information. In this paper, we provide a balanced
   overview of what LLMs are and introduce some of the LLMs that have been
   generated in the past few years. We discuss recent literature evaluating
   the role of these language models in medicine with a focus on ChatGPT.
   The field of AI is fast-paced, and new applications based on LLMs are
   being generated rapidly; therefore, it is important for ophthalmologists
   to be aware of how this technology works and how it may impact patient
   care. Here, we discuss the benefits, limitations, and future
   advancements of LLMs in patient care and research.
ZR 0
TC 13
Z8 0
ZS 0
ZA 0
ZB 4
Z9 13
DA 2024-01-22
UT WOS:001135855200003
PM 38172581
ER

PT J
AU Chervenak, Joseph
   Lieman, Harry
   Blanco-Breindel, Miranda
   Jindal, Sangita
TI The promise and peril of using a large language model to obtain clinical
   information: ChatGPT performs strongly as a fertility counseling tool
   with limitations
SO FERTILITY AND STERILITY
VL 120
IS 3
BP 575
EP 583
DI 10.1016/j.fertnstert.2023.05.151
EA AUG 2023
PN 2
DT Article
PD SEP 2023
PY 2023
AB Objective: To compare the responses of the large language model-based
   "ChatGPT"to reputable sources when given fertility-related clinical
   prompts. Design: The "Feb 13"version of ChatGPT by OpenAI was tested
   against established sources relating to patient-oriented clinical
   information: 17 "frequently asked questions (FAQs)"about infertility on
   the Centers for Disease Control (CDC) Website, 2 validated fertility
   knowledge surveys, the Cardiff Fertility Knowledge Scale and the
   Fertility and Infertility Treatment Knowledge Score, as well as the
   American Society for Reproductive Medicine committee opinion "optimizing
   natural fertility."Setting: Academic medical center. Patient(s): Online
   AI Chatbot. Intervention(s): Frequently asked questions, survey
   questions and rephrased summary statements were entered as prompts in
   the chatbot over a 1-week period in February 2023. Main Outcome
   Measure(s): For FAQs from CDC: words/response, sentiment analysis
   polarity and objectivity, total factual statements, rate of statements
   that were incorrect, referenced a source, or noted the value of
   consulting providers. For fertility knowledge surveys: Percentile
   according to published population data. For Committee Opinion: Whether
   response to conclusions rephrased as questions identified missing facts.
   Result(s): When administered the CDC's 17 infertility FAQ's, ChatGPT
   produced responses of similar length (207.8 ChatGPT vs. 181.0 CDC
   words/response), factual content (8.65 factual statements/response vs.
   10.41), sentiment polarity (mean 0.11 vs. 0.11 on a scale of-1
   (negative) to 1 (positive)), and subjectivity (mean 0.42 vs. 0.35 on a
   scale of 0 (objective) to 1 (subjective)). In total, 9 (6.12%) of 147
   ChatGPT factual statements were categorized as incorrect, and only 1
   (0.68%) statement cited a reference. ChatGPT would have been at the 87th
   percentile of Bunting's 2013 international cohort for the Cardiff
   Fertility Knowledge Scale and at the 95th percentile on the basis of
   Kudesia's 2017 cohort for the Fertility and Infertility Treatment
   Knowledge Score. ChatGPT reproduced the missing facts for all 7 summary
   statements from "optimizing natural fertility."Conclusion(s): A February
   2023 version of "ChatGPT"demonstrates the ability of generative
   artificial intelligence to produce relevant, meaningful responses to
   fertility-related clinical queries comparable to established sources.
   Although performance may improve with medical domain-specific training,
   limitations such as the inability to reliably cite sources and the
   unpredictable possibility of fabricated information may limit its
   clinical use. (Fertil Sterile 2023;120:575-83. (c) 2023 by American
   Society for Reproductive Medicine.)
ZR 0
ZB 7
ZS 0
ZA 0
TC 47
Z8 1
Z9 48
DA 2023-11-11
UT WOS:001093006600001
PM 37217092
ER

PT J
AU Kunze, Kyle N.
   Varady, Nathan H.
   Mazzucco, Michael
   Lu, Amy Z.
   Chahla, Jorge
   Martin, R. Kyle
   Ranawat, Anil S.
   Pearle, Andrew D.
   Williams Iii, Riley J.
TI The Large Language Model ChatGPT-4 Exhibits Excellent Triage
   Capabilities and Diagnostic Performance for Patients Presenting With
   Various Causes of Knee Pain
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 5
DI 10.1016/j.arthro.2024.06.021
DT Article
PD MAY 2025
PY 2025
AB Purpose: To provide a proof-of-concept analysis of the appropriateness
   and performance of ChatGPT-4 to triage, synthesize differential
   diagnoses, and generate treatment plans concerning common presentations
   of knee pain. Methods: Twenty knee complaints warranting triage and
   expanded scenarios were input into ChatGPT-4, with memory cleared prior
   to each new input to mitigate bias. For the 10 triage complaints,
   ChatGPT-4 was asked to generate a differential diagnosis that was graded
   for accuracy and suitability in comparison to a differential created by
   2 orthopaedic sports medicine physicians. For the 10 clinical scenarios,
   ChatGPT-4 was prompted to provide treatment guidance for the patient,
   which was again graded. To test the higher-order capabilities of
   ChatGPT-4, further inquiry into these specific management
   recommendations was performed and graded. Results: All ChatGPT-4
   diagnoses were deemed appropriate within the spectrum of potential
   pathologies on a differential. The top diagnosis on the differential was
   identical between surgeons and ChatGPT-4 for 70% of scenarios, and the
   top diagnosis provided by the surgeon appeared as either the first or
   second diagnosis in 90% of scenarios. Overall, 16 of 30 diagnoses
   (53.3%) in the differential were identical. When provided with 10
   expanded vignettes with a single diagnosis, the accuracy of ChatGPT-4
   increased to 100%, with the suitability of management graded as
   appropriate in 90% of cases. Specific information pertaining to
   conservative management, surgical approaches, and related treatments was
   appropriate and accurate in 100% of cases. Conclusions: ChatGPT-4
   provided clinically reasonable diagnoses to triage patient complaints of
   knee pain due to various underlying conditions that were generally
   consistent with differentials provided by sports medicine physicians.
   Diagnostic performance was enhanced when providing additional
   information, allowing ChatGPT-4 to reach high predictive accuracy for
   recommendations concerning management and treatment options. However,
   ChatGPT-4 may show clinically important error rates for diagnosis
   depending on prompting strategy and information provided; therefore,
   further refinements are necessary prior to implementation into clinical
   workflows. Clinical Relevance: Although ChatGPT-4 is increasingly being
   used by patients for health information, the potential for ChatGPT-4 to
   serve as a clinical support tool is unclear. In this study, we found
   that ChatGPT-4 was frequently able to diagnose and triage knee
   complaints appropriately as rated by sports medicine surgeons,
   suggesting that it may eventually be a useful clinical support tool.
ZB 0
Z8 0
ZR 0
ZA 0
ZS 0
TC 6
Z9 6
DA 2025-05-28
UT WOS:001493899100001
PM 38925234
ER

PT J
AU Young, Cameron C.
   Enichen, Elizabeth
   Rao, Arya
   Succi, Marc D.
TI Racial, ethnic, and sex bias in large language model opioid
   recommendations for pain management
SO PAIN
VL 166
IS 3
BP 511
EP 517
DI 10.1097/j.pain.0000000000003388
DT Article
PD MAR 2025
PY 2025
AB Understanding how large language model (LLM) recommendations vary with
   patient race/ethnicity provides insight into how LLMs may counter or
   compound bias in opioid prescription. Forty real-world patient cases
   were sourced from the MIMIC-IV Note dataset with chief complaints of
   abdominal pain, back pain, headache, or musculoskeletal pain and amended
   to include all combinations of race/ethnicity and sex. Large language
   models were instructed to provide a subjective pain rating and
   comprehensive pain management recommendation. Univariate analyses were
   performed to evaluate the association between racial/ethnic group or sex
   and the specified outcome measures-subjective pain rating, opioid name,
   order, and dosage recommendations-suggested by 2 LLMs (GPT-4 and
   Gemini). Four hundred eighty real-world patient cases were provided to
   each LLM, and responses included pharmacologic and nonpharmacologic
   interventions. Tramadol was the most recommended weak opioid in 55.4% of
   cases, while oxycodone was the most frequently recommended strong opioid
   in 33.2% of cases. Relative to GPT-4, Gemini was more likely to rate a
   patient's pain as "severe" (OR: 0.57 95% CI: [0.54, 0.60]; P < 0.001),
   recommend strong opioids (OR: 2.05 95% CI: [1.59, 2.66]; P < 0.001), and
   recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P < 0.001).
   Race/ethnicity and sex did not influence LLM recommendations. This study
   suggests that LLMs do not preferentially recommend opioid treatment for
   one group over another. Given that prior research shows race-based
   disparities in pain perception and treatment by healthcare providers,
   LLMs may offer physicians a helpful tool to guide their pain management
   and ensure equitable treatment across patient groups.
ZR 0
ZS 0
ZA 0
ZB 1
TC 3
Z8 0
Z9 3
DA 2025-02-18
UT WOS:001417334300001
PM 39283333
ER

PT J
AU Gilbert, M.
   Crutchfield, A.
   Luo, B.
   Thind, K.
   Ghanem, A. I.
   Siddiqui, F.
TI Using a Large Language Model (LLM) for Automated Extraction of Discrete
   Elements from Clinical Notes for Creation of Cancer Databases
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3371
BP E625
EP E625
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
ZA 0
ZS 0
ZB 0
ZR 0
TC 1
Z9 1
DA 2024-12-16
UT WOS:001325892302054
ER

PT B
AU Shubbar, Safa
Z2  
TI Advancing Autism Spectrum Disorder Diagnosis: A Phenotype-Genotype
   Co-Analysis and Retrieval-Augmented LLM Framework for Clinical Decision
   Support
DT Dissertation/Thesis
PD Jan 01 2025
PY 2025
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
ZS 0
Z9 0
UT PQDT:123210398
ER

PT J
AU Farrell, Sean
   Appleton, Charlotte
   Noble, Peter-John Maentylae
   Al Moubayed, Noura
TI PetBERT: automated ICD-11 syndromic disease coding for outbreak
   detection in first opinion veterinary electronic health records
SO SCIENTIFIC REPORTS
VL 13
IS 1
AR 18015
DI 10.1038/s41598-023-45155-7
DT Article
PD OCT 21 2023
PY 2023
AB Effective public health surveillance requires consistent monitoring of
   disease signals such that researchers and decision-makers can react
   dynamically to changes in disease occurrence. However, whilst
   surveillance initiatives exist in production animal veterinary medicine,
   comparable frameworks for companion animals are lacking. First-opinion
   veterinary electronic health records (EHRs) have the potential to reveal
   disease signals and often represent the initial reporting of clinical
   syndromes in animals presenting for medical attention, highlighting
   their possible significance in early disease detection. Yet despite
   their availability, there are limitations surrounding their free
   text-based nature, inhibiting the ability for national-level mortality
   and morbidity statistics to occur. This paper presents PetBERT, a large
   language model trained on over 500 million words from 5.1 million EHRs
   across the UK. PetBERT-ICD is the additional training of PetBERT as a
   multi-label classifier for the automated coding of veterinary clinical
   EHRs with the International Classification of Disease 11 framework,
   achieving F1 scores exceeding 83% across 20 disease codings with minimal
   annotations. PetBERT-ICD effectively identifies disease outbreaks,
   outperforming current clinician-assigned point-of-care labelling
   strategies up to 3 weeks earlier. The potential for PetBERT-ICD to
   enhance disease surveillance in veterinary medicine represents a
   promising avenue for advancing animal health and improving public health
   outcomes.
ZA 0
ZB 3
ZR 0
TC 6
Z8 0
ZS 0
Z9 6
DA 2023-12-01
UT WOS:001094273200034
PM 37865683
ER

PT J
AU Wu, Xuzhou
   Li, Guangxin
   Wang, Xing
   Xu, Zeyu
   Wang, Yingni
   Lei, Shuge
   Xian, Jianming
   Wang, Xueyu
   Zhang, Yibao
   Li, Gong
   Yuan, Kehong
TI Diagnosis assistant for liver cancer utilizing a large language model
   with three types of knowledge
SO PHYSICS IN MEDICINE AND BIOLOGY
VL 70
IS 9
AR 095009
DI 10.1088/1361-6560/adcb17
DT Article
PD MAY 4 2025
PY 2025
AB Objective. Liver cancer has a high incidence rate, but experienced
   doctors are lacking in primary healthcare settings. The development of
   large models offers new possibilities for diagnosis. However, in liver
   cancer diagnosis, large models face certain limitations, such as
   insufficient understanding of specific medical images, inadequate
   consideration of liver vessel factors, and inaccuracies in reasoning
   logic. Therefore, this study proposes a diagnostic assistance tool
   specific to liver cancer to enhance the diagnostic capabilities of
   primary care doctors. Approach. A liver cancer diagnosis framework
   combining large and small models is proposed. A more accurate model for
   liver tumor segmentation and a more precise model for liver vessel
   segmentation are developed. The features extracted from the segmentation
   results of the small models are combined with the patient's medical
   records and then provided to the large model. The large model employs
   chain of thought prompts to simulate expert diagnostic reasoning and
   uses Retrieval-Augmented Generation to provide reliable answers based on
   trusted medical knowledge and cases. Main results. In the small model
   part, the proposed liver tumor and liver vessel segmentation methods
   achieve improved performance. In the large model part, this approach
   receives higher evaluation scores from doctors when analyzing patient
   imaging and medical records. Significance. First, a diagnostic framework
   combining small models and large models is proposed to optimize the
   liver cancer diagnosis process. Second, two segmentation models are
   introduced to compensate for the large model's shortcomings in
   extracting semantic information from images. Third, by simulating
   doctors' reasoning and integrating trusted knowledge, the framework
   enhances the reliability and interpretability of the large model's
   responses while reducing hallucination phenomena.
Z8 0
ZS 0
ZA 0
ZR 0
TC 0
ZB 0
Z9 0
DA 2025-05-08
UT WOS:001480266600001
PM 40203862
ER

PT J
AU Yang, Xintian
   Li, Tongxin
   Su, Qin
   Liu, Yaling
   Kang, Chenxi
   Lyu, Yong
   Zhao, Lina
   Nie, Yongzhan
   Pan, Yanglin
TI Application of large language models in disease diagnosis and treatment
SO CHINESE MEDICAL JOURNAL
VL 138
IS 2
BP 130
EP 142
DI 10.1097/CM9.0000000000003456
DT Review
PD JAN 20 2025
PY 2025
AB Large language models (LLMs) such as ChatGPT, Claude, Llama, and Qwen
   are emerging as transformative technologies for the diagnosis and
   treatment of various diseases. With their exceptional long-context
   reasoning capabilities, LLMs are proficient in clinically relevant
   tasks, particularly in medical text analysis and interactive dialogue.
   They can enhance diagnostic accuracy by processing vast amounts of
   patient data and medical literature and have demonstrated their utility
   in diagnosing common diseases and facilitating the identification of
   rare diseases by recognizing subtle patterns in symptoms and test
   results. Building on their image-recognition abilities, multimodal LLMs
   (MLLMs) show promising potential for diagnosis based on radiography,
   chest computed tomography (CT), electrocardiography (ECG), and common
   pathological images. These models can also assist in treatment planning
   by suggesting evidence-based interventions and improving clinical
   decision support systems through integrated analysis of patient records.
   Despite these promising developments, significant challenges persist
   regarding the use of LLMs in medicine, including concerns regarding
   algorithmic bias, the potential for hallucinations, and the need for
   rigorous clinical validation. Ethical considerations also underscore the
   importance of maintaining the function of supervision in clinical
   practice. This paper highlights the rapid advancements in research on
   the diagnostic and therapeutic applications of LLMs across different
   medical disciplines and emphasizes the importance of policymaking,
   ethical supervision, and multidisciplinary collaboration in promoting
   more effective and safer clinical applications of LLMs. Future
   directions include the integration of proprietary clinical knowledge,
   the investigation of open-source and customized models, and the
   evaluation of real-time effects in clinical diagnosis and treatment
   practices.
TC 2
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
Z9 2
DA 2025-01-25
UT WOS:001400214400011
PM 39722188
ER

PT J
AU Choi, Hongyoon
   Lee, Dongjoo
   Kang, Yeon-koo
   Suh, Minseok
TI Empowering PET imaging reporting with retrieval-augmented large language
   models and reading reports database: a pilot single center study
SO EUROPEAN JOURNAL OF NUCLEAR MEDICINE AND MOLECULAR IMAGING
VL 52
IS 7
BP 2452
EP 2462
DI 10.1007/s00259-025-07101-9
EA JAN 2025
DT Article
PD JUN 2025
PY 2025
AB PurposeThe potential of Large Language Models (LLMs) in enhancing a
   variety of natural language tasks in clinical fields includes medical
   imaging reporting. This pilot study examines the efficacy of a
   retrieval-augmented generation (RAG) LLM system considering zero-shot
   learning capability of LLMs, integrated with a comprehensive database of
   PET reading reports, in improving reference to prior reports and
   decision making.MethodsWe developed a custom LLM framework with
   retrieval capabilities, leveraging a database of over 10 years of PET
   imaging reports from a single center. The system uses vector space
   embedding to facilitate similarity-based retrieval. Queries prompt the
   system to generate context-based answers and identify similar cases or
   differential diagnoses. From routine clinical PET readings, experienced
   nuclear medicine physicians evaluated the performance of system in terms
   of the relevance of queried similar cases and the appropriateness score
   of suggested potential diagnoses.ResultsThe system efficiently organized
   embedded vectors from PET reports, showing that imaging reports were
   accurately clustered within the embedded vector space according to the
   diagnosis or PET study type. Based on this system, a proof-of-concept
   chatbot was developed and showed the framework's potential in
   referencing reports of previous similar cases and identifying exemplary
   cases for various purposes. From routine clinical PET readings, 84.1% of
   the cases retrieved relevant similar cases, as agreed upon by all three
   readers. Using the RAG system, the appropriateness score of the
   suggested potential diagnoses was significantly better than that of the
   LLM without RAG. Additionally, it demonstrated the capability to offer
   differential diagnoses, leveraging the vast database to enhance the
   completeness and precision of generated reports.ConclusionThe
   integration of RAG LLM with a large database of PET imaging reports
   suggests the potential to support clinical practice of nuclear medicine
   imaging reading by various tasks of AI including finding similar cases
   and deriving potential diagnoses from them. This study underscores the
   potential of advanced AI tools in transforming medical imaging reporting
   practices.
ZR 0
Z8 0
TC 1
ZS 0
ZB 0
ZA 0
Z9 1
DA 2025-01-25
UT WOS:001401835700001
PM 39843863
ER

PT J
AU Shi, Michael
   Hanna, Jovana
   Clavell, Christine
   Eid, Kevin
   Eid, Alen
   Ghorayeb, Ghassan
   John Nguyen
TI Assessing Readability of Patient Education Materials: A Comparative
   Study of ASRS Resources and AI-Generated Content by Popular Large
   Language Models (ChatGPT 4.0 and Google Bard)
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 5646
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZS 0
ZR 0
ZB 0
Z8 0
TC 3
ZA 0
Z9 3
DA 2024-11-30
UT WOS:001313316206217
ER

PT J
AU Dai, Jiayi
   Kim, Mi-Young
   Sutton, Reed T.
   Mitchell, Joseph R.
   Goebel, Randolph G.
   Baumgart, Daniel C.
TI DEVELOPMENT OF IBDBERT - NATURAL LANGUAGE PROCESSING ANALYSIS OF CROHN'S
   DISEASE COMPUTED TOMOGRAPHY ENTEROGRAPHY (CTE) REPORTS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Sa2032
BP S612
EP S612
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZR 0
TC 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837702379
ER

PT J
AU Boonstra, Machteld
   Weissenbacher, Davy
   Moore, Jason
   Gonzalez-Hernandez, Graciela
   Asselbergs, Folkert
TI Artificial intelligence: revolutionizing cardiology with large language
   models
SO EUROPEAN HEART JOURNAL
VL 45
IS 5
SI SI
BP 332
EP 345
DI 10.1093/eurheartj/ehad838
EA JAN 2024
DT Review
PD FEB 1 2024
PY 2024
AB Graphical Abstract Overview of input sources (top) to train or fine-tune
   cardio large language models and different applications (bottom). ECG,
   electrocardiogram; Q&A, questions and answers.
   Natural language processing techniques are having an increasing impact
   on clinical care from patient, clinician, administrator, and research
   perspective. Among others are automated generation of clinical notes and
   discharge letters, medical term coding for billing, medical chatbots
   both for patients and clinicians, data enrichment in the identification
   of disease symptoms or diagnosis, cohort selection for clinical trial,
   and auditing purposes. In the review, an overview of the history in
   natural language processing techniques developed with brief technical
   background is presented. Subsequently, the review will discuss
   implementation strategies of natural language processing tools, thereby
   specifically focusing on large language models, and conclude with future
   opportunities in the application of such techniques in the field of
   cardiology.
ZB 9
TC 39
ZS 0
ZA 0
Z8 1
ZR 0
Z9 39
DA 2024-01-13
UT WOS:001135440400001
PM 38170821
ER

PT J
AU Sorin, Vera
   Kapelushnik, Noa
   Hecht, Idan
   Zloto, Ofira
   Glicksberg, Benjamin S.
   Bufman, Hila
   Livne, Adva
   Barash, Yiftach
   Nadkarni, Girish N.
   Klang, Eyal
TI Integrated visual and text-based analysis of ophthalmology clinical
   cases using a large language model
SO SCIENTIFIC REPORTS
VL 15
IS 1
AR 4999
DI 10.1038/s41598-025-88948-8
DT Article
PD FEB 10 2025
PY 2025
AB Recent advancements in generative artificial intelligence have enabled
   analysis of text with visual data, which could have important
   implications in healthcare. Diagnosis in ophthalmology is often based on
   a combination of ocular examination, and clinical context. The aim of
   this study was to evaluate the performance of multimodal GPT-4 (GPT-4 V)
   in an integrated analysis of ocular images and clinical text. This
   retrospective study included 40 patients seen in our institution with
   images of their ocular examinations. Cases were selected by a
   board-certified ophthalmologist, to represent various pathologies. We
   provided the model with each patient image, without and then with the
   clinical context. We also asked two non-ophthalmology physicians to
   write diagnoses for each image, without and then with the clinical
   context. Answers for both GPT-4 V and the non-ophthalmologists were
   evaluated by two board-certified ophthalmologists. Performance
   accuracies were calculated and compared. GPT-4 V provided the correct
   diagnosis in 19/40 (47.5%) cases based on images without clinical
   context, and in 27/40 (67.5%) cases when clinical context was provided.
   Non-ophthalmologist physicians provided the correct diagnoses in 24/40
   (60.0%), and 23/40 (57.5%) of cases without clinical context, and in
   29/40 (72.5%) and 27/40 (67.5%) with clinical context. For all study
   participants adding context improved accuracy (p = 0.033). GPT-4 V is
   currently able to simultaneously analyze and integrate visual and
   textual data, and arrive at accurate clinical diagnoses in the majority
   of cases. Multimodal large language models like GPT-4 V have significant
   potential to advance both patient care and research in ophthalmology.
TC 2
ZA 0
ZR 0
Z8 0
ZS 0
ZB 0
Z9 2
DA 2025-02-17
UT WOS:001418722300017
PM 39930078
ER

PT J
AU Solomon, Benjamin D.
   Khatri, Purvesh
TI Clustering of clinical symptoms using large language models reveals low
   diagnostic specificity of proposed alternatives to consensus mast cell
   activation syndrome criteria
SO JOURNAL OF ALLERGY AND CLINICAL IMMUNOLOGY
VL 155
IS 1
DI 10.1016/j.jaci.2024.09.006
EA JAN 2025
DT Article
PD JAN 2025
PY 2025
AB Background: The rate of diagnosis of mast cell activation syndrome
   (MCAS) has increased since the disorder's original description as a
   mastocytosis-like phenotype. While a set of consortium MCAS criteria is
   well described and widely accepted, this increase occurs in the setting
   of a broader set of proposed alternative MCAS criteria. Objective:
   Effective diagnostic criteria must minimize the range of unrelated
   diagnoses that can be erroneously classified as the condition of
   interest. We sought to determine if the symptoms associated with
   alternative MCAS criteria result in less concise or consistent
   diagnostic alternatives, reducing diagnostic specificity. Methods: We
   used multiple large language models, including ChatGPT, Claude, and
   Gemini, to bootstrap the probabilities of diagnoses that are compatible
   with consortium or alternative MCAS criteria. We utilized diversity and
   network analyses to quantify diagnostic precision and specificity
   compared to control diagnostic criteria including systemic lupus
   erythematosus, Kawasaki disease, and migraines. Results: Compared to
   consortium MCAS criteria, alternative MCAS criteria are associated with
   more variable (Shannon diversity 5.8 vs 4.6, respectively; P = .004) and
   less precise (mean Bray-Curtis similarity 0.07 vs 0.19, respectively; P
   = .004) diagnoses. The diagnosis networks derived from consortium and
   alternative MCAS criteria had lower between- network similarity compared
   to the similarity between diagnosis networks derived from 2 distinct
   systemic lupus erythematosus criteria (cosine similarity 0.55 vs 0.86,
   respectively; P = .0022). Conclusion: Alternative MCAS criteria are
   associated with a distinct set of diagnoses compared to consortium MCAS
   criteria and have lower diagnostic consistency. This lack of specificity
   is pronounced in relation to multiple control criteria, raising the
   concern that alternative criteria could disproportionately contribute to
   MCAS overdiagnosis, to the exclusion of more appropriate diagnoses. (J
   Allergy Clin Immunol 2025;155:213-8.)
ZS 0
ZB 0
Z8 0
TC 1
ZR 0
ZA 0
Z9 1
DA 2025-01-29
UT WOS:001403121900001
PM 39278360
ER

PT J
AU Zhu, Zirui
   Zeng, Zhuo
   Zeng, Huiqing
   Luo, Xiongbiao
TI Research progress on artificial intelligence driving precision diagnosis
   and treatment of chronic obstructive pulmonary disease
SO Xiamen Daxue Xuebao (Ziran Kexue Ban)
VL 63
IS 5
BP 894
EP 905
DI 10.6043/j.issn.0438-0479.202402019
DT Article
PD SEP 2024
PY 2024
AB [Background] Chronic obstructive pulmonary disease (COPD) is a complex
   and prevalent respiratory disorder with irreversible airflow limitation
   worldwide, Precision diagnosis and treatment at its early stage
   significantly improve the quality of life of patients, COPD symptoms are
   diverse and progressive, e. g. chronic cough, sputum production, dyspnea
   and chest tightness. indicating advances in COPD, While the
   pathophysiology of COPD is multifaceted with persistent airway
   inflammation, airway remodeling, and alveolar destruction, the etiology
   of COPD is multifactorial, including prolonged smoking, environmental
   pollutants. occupational hazards, and genetic predispositions. These
   factors collectively result in airflow obstruction and pathological
   changes in the respiratory tract, Specifically, the progression of COPD
   is often accompanied with persistent inflammatory responses, oxidative
   stress and intensive pulmonary damage, [Progress] Pulmonary function
   tests (PFTs) are routinely performed to examine COPD. providing
   physicians with a ratio of the forced expiratory volume in one second by
   the forced vital capacity to evaluate COPD, Unfortunately, the results
   of PFTs critically affected by the effort of patients, and the
   interpretation of PFTs also depends on experience and skills of
   physicians. While PFTs allow physicians to quantify the severity of
   COPD, they do not reach a specific diagnosis and are commonly associated
   with medical history, physical examination such as CT imaging,
   functional MR imaging and respiratory sound, and laboratory data to
   determine a diagnosis. Therefore, physicians expect more precise COPD
   diagnosis and treatment methods than conventional ones to improve
   patient's quality of life. Nowadays artificial intelligence (AI) is
   widely discussed in precision medicine. Specifically, Al techniques or
   mathematical models also increasingly used in COPD diagnosis, treatment,
   monitoring, and management, These models are generally categorized into
   unimodal and multimodal Al models in accordance with clinical COPD data.
   While the unimodal model uses only a single one modality such as PFTs or
   CT images, the multimodal model fuses a diversity of data ineluding
   imaging, biomedical information, and clinical records, All these models
   generally provide physicians with a holistic assessment of COPD,
   patient-specific treatment for precision medicine, [Perspective] In
   general, Al techniques provide a promising way to precisely diagnose and
   treat COPD in its early stage, as well as COPD management and
   monitoring. Specifically, artificial general intelligence, generative
   artificial intelligence, multimodal large language models are innovating
   clinical methods in diagnosis, treatment, monitoring, and management of
   pulmonary diseases, although they still suffer from medical data privacy
   and security, model generalizability, interpretability and complexity,
   legal and ethical issues. Future research should address these issues in
   various angles, It is essential to strengthen privacy protection and
   security measures, Moreover, it is vital to improve the
   generalizability, transparency and interpretability and reduce the
   complexity of various Al models in clinical applications, Additionally,
   medical ethics are important when applying Al techniques to precision
   pulmonary medicine.
TC 0
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
Z9 0
DA 2025-03-21
UT BCI:BCI202500316530
ER

PT J
AU Hu, Danqing
   Liu, Bing
   Zhu, Xiaofeng
   Lu, Xudong
   Wu, Nan
TI Zero-shot information extraction from radiological reports using ChatGPT
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 183
AR 105321
DI 10.1016/j.ijmedinf.2023.105321
EA DEC 2023
DT Article
PD MAR 2024
PY 2024
AB Introduction: Electronic health records contain an enormous amount of
   valuable information recorded in free text. Information extraction is
   the strategy to transform free text into structured data, but some of
   its components require annotated data to tune, which has become a
   bottleneck. Large language models achieve good performances on various
   downstream NLP tasks without parameter tuning, becoming a possible way
   to extract information in a zero-shot manner. Methods: In this study, we
   aim to explore whether the most popular large language model, ChatGPT,
   can extract information from the radiological reports. We first design
   the prompt template for the interested information in the CT reports.
   Then, we generate the prompts by combining the prompt template with the
   CT reports as the inputs of ChatGPT to obtain the responses. A
   post-processing module is developed to transform the responses into
   structured extraction results. Besides, we add prior medical knowledge
   to the prompt template to reduce wrong extraction results. We also
   explore the consistency of the extraction results. Results: We conducted
   the experiments with 847 real CT reports. The experimental results
   indicate that ChatGPT can achieve competitive performances for some
   extraction tasks like tumor location, tumor long and short diameters
   compared with the baseline information extraction system. By adding some
   prior medical knowledge to the prompt template, extraction tasks about
   tumor spiculations and lobulations obtain significant improvements but
   tasks about tumor density and lymph node status do not achieve better
   performances. Conclusion: ChatGPT can achieve competitive information
   extraction for radiological reports in a zero-shot manner. Adding prior
   medical knowledge as instructions can further improve performances for
   some extraction tasks but may lead to worse performances for some
   complex extraction tasks.
ZA 0
TC 29
ZR 0
ZB 4
Z8 1
ZS 0
Z9 30
DA 2024-03-04
UT WOS:001165970200001
PM 38157785
ER

PT J
AU Ying, Lingwen
   Li, Sichen
   Chen, Chunyang
   Yang, Fan
   Li, Xin
   Chen, Yao
   Ding, Yu
   Chang, Guoying
   Li, Juan
   Wang, Xiumin
TI Screening/diagnosis of pediatric endocrine disorders through the
   artificial intelligence model in different language settings
SO EUROPEAN JOURNAL OF PEDIATRICS
VL 183
IS 6
BP 2655
EP 2661
DI 10.1007/s00431-024-05527-1
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB This study is aimed at examining the impact of ChatGPT on pediatric
   endocrine and metabolic conditions, particularly in the areas of
   screening and diagnosis, in both Chinese and English modes. A
   40-question questionnaire covering the four most common pediatric
   endocrine and metabolic conditions was posed to ChatGPT in both Chinese
   and English three times each. Six pediatric endocrinologists evaluated
   the responses. ChatGPT performed better when responding to questions in
   English, with an unreliable rate of 7.5% compared to 27.5% for Chinese
   questions, indicating a more consistent response pattern in English.
   Among the reliable questions, the answers were more comprehensive and
   satisfactory in the English mode. We also found disparities in ChatGPT's
   performance when interacting with different target groups and diseases,
   with improved performance for questions posed by clinicians in English
   and better performance for questions related to diabetes and
   overweight/obesity in Chinese for both clinicians and patients. Language
   comprehension, providing incomprehensive answers, and errors in key data
   were the main contributors to the low scores, according to reviewer
   feedback.Conclusion: Despite these limitations, as ChatGPT continues to
   evolve and expand its network, it has significant potential as a
   practical and effective tool for clinical diagnosis and treatment. What
   is Known:center dot The deep learning-based large-language model ChatGPT
   holds great promise for improving clinical practice for both physicians
   and patients and has the potential to increase the speed and accuracy of
   disease screening and diagnosis, as well as enhance the overall
   efficiency of the medical process. However, the reliability and
   appropriateness of AI model responses in specific field remains
   unclear.center dot This study focused on the reliability and
   appropriateness of AI model responses to straightforward and fundamental
   questions related to the four most prevalent pediatric endocrine and
   metabolic disorders, for both healthcare providers and patients, in
   different language scenarios.What is New:center dot The AI model
   performed better when responding to questions in English, with more
   consistent, as well as more comprehensive and satisfactory responses. In
   addition, we also found disparities in ChatGPT's performance when
   interacting with different target groups and different diseases.center
   dot Despite these limitations, as ChatGPT continues to evolve and expand
   its network, it has significant potential as a practical and effective
   tool for clinical diagnosis and treatment.
Z8 0
ZS 0
ZB 0
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-04-01
UT WOS:001187459700002
PM 38502320
ER

PT J
AU Ra, Sinyoung
   Kim, Jonghun
   Na, Inye
   Ko, Eun Sook
   Park, Hyunjin
TI Enhancing radiomics features via a large language model for classifying
   benign and malignant breast tumors in mammography
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 265
AR 108765
DI 10.1016/j.cmpb.2025.108765
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Background and Objectives: Radiomics is widely used to assist in
   clinical decision-making, disease diagnosis, and treatment planning for
   various target organs, including the breast. Recent advances in large
   language models (LLMs) have helped enhance radiomics analysis. Materials
   and Methods: Herein, we sought to improve radiomics analysis by
   incorporating LLM-learned clinical knowledge, to classify benign and
   malignant tumors in breast mammography. We extracted radiomics features
   from the mammograms based on the region of interest and retained the
   features related to the target task. Using prompt engineering, we
   devised an input sequence that reflected the selected features and the
   target task. The input sequence was fed to the chosen LLM (LLaMA
   variant), which was fine-tuned using low-rank adaptation to enhance
   radiomics features. This was then evaluated on two mammogram datasets
   (VinDr-Mammo and INbreast) against conventional baselines. Results: The
   enhanced radiomics-based method performed better than baselines using
   conventional radiomics features tested on two mammogram datasets,
   achieving accuracies of 0.671 for the VinDr-Mammo dataset and 0.839 for
   the INbreast dataset. Conventional radiomics models require retraining
   from scratch for an unseen dataset using a new set of features. In
   contrast, the model developed in this study effectively reused the
   common features between the training and unseen datasets by explicitly
   linking feature names with feature values, leading to extensible
   learning across datasets. Our method performed better than the baseline
   method in this retraining setting using an unseen dataset. Conclusions:
   Our method, one of the first to incorporate LLM into radiomics, has the
   potential to improve radiomics analysis.
ZS 0
Z8 0
ZR 0
TC 0
ZA 0
ZB 0
Z9 0
DA 2025-04-21
UT WOS:001466026900001
PM 40203779
ER

PT J
AU Cardakli, Nur
   Kraus, Courtney L.
TI Utilization of a large language modelpowered chatbot to identify
   congenital glaucoma from other ocular etiologies
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
TC 0
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
Z9 0
DA 2024-12-01
UT WOS:001312227701034
ER

PT J
AU Ohse, Julia
   Hadzic, Bakir
   Mohammed, Parvez
   Peperkorn, Nicolina
   Fox, Janosch
   Krutzki, Joshua
   Lyko, Alexander
   Fan, Mingyu
   Zheng, Xiaohu
   Raetsch, Matthias
   Shiban, Youssef
TI GPT-4 shows potential for identifying social anxiety from clinical
   interview data
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30498
DI 10.1038/s41598-024-82192-2
DT Article
PD DEC 16 2024
PY 2024
AB While the potential of Artificial Intelligence (AI)-particularly Natural
   Language Processing (NLP) models-for detecting symptoms of depression
   from text has been vastly researched, only a few studies examine such
   potential for the detection of social anxiety symptoms. We investigated
   the ability of the large language model (LLM) GPT-4 to correctly infer
   social anxiety symptom strength from transcripts obtained from
   semi-structured interviews. N = 51 adult participants were recruited
   from a convenience sample of the German population. Participants filled
   in a self-report questionnaire on social anxiety symptoms (SPIN) prior
   to being interviewed on a secure online teleconference platform.
   Transcripts from these interviews were then evaluated by GPT-4. GPT-4
   predictions were highly correlated (r = 0.79) with scores obtained on
   the social anxiety self-report measure. Following the cut-off
   conventions for this population, an F1 accuracy score of 0.84 could be
   obtained. Future research should examine whether these findings hold
   true in larger and more diverse datasets.
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 1
Z9 1
DA 2024-12-27
UT WOS:001379708000008
PM 39681627
ER

PT J
AU Watanabe, Takashi
   Baba, Akira
   Fukuda, Takeshi
   Watanabe, Ken
   Woo, Jun
   Ojiri, Hiroya
TI Role of visual information in multimodal large language model
   performance: an evaluation using the Japanese nuclear medicine board
   examination
SO ANNALS OF NUCLEAR MEDICINE
VL 39
IS 2
BP 217
EP 224
DI 10.1007/s12149-024-01992-8
EA NOV 2024
DT Article
PD FEB 2025
PY 2025
AB ObjectivesThis study aimed to assess the performance of state-of-the-art
   multimodal large language models (LLMs), specifically GPT-4o, Claude 3
   Opus, and Gemini 1.5 Pro, on Japanese Nuclear Medicine Board Examination
   (JNMBE) questions and to evaluate the influence of visual information on
   the decision-making process.MethodsThis study utilized 92 questions with
   images from the JNMBE (2019-2023). The LLMs' responses were assessed
   under two conditions: providing both text and images and providing only
   text. Each model answered all questions thrice, and the most frequent
   answer choice was considered the final answer. The accuracy and
   agreement rates among the model answers were evaluated using statistical
   tests.ResultsGPT-4o, Claude 3 Opus, and Gemini 1.5 Pro exhibited no
   significant differences in terms of accuracy between the text-and-image
   and text-only conditions. GPT-4o and Claude 3 Opus demonstrated
   accuracies of 54.3% (95% CI: 44.2%-64.1%) each when provided with both
   text and images; however, they selected the same options as in the
   text-only condition for 71.7% of the questions. Gemini 1.5 Pro performed
   significantly worse than GPT-4o under text and image conditions. The
   agreement rates among the model answers ranged from weak to
   moderate.ConclusionThe influence of images on decision-making in nuclear
   medicine is limited to the latest multimodal LLMs, and their diagnostic
   ability in this highly specialized field remains insufficient. Improving
   the utilization of image information and enhancing the answer
   reproducibility are crucial for the effective application of LLMs in
   nuclear medicine education and practice. Further advancements in these
   areas are necessary to harness the potential of LLMs as assistants in
   nuclear medicine diagnosis.
ZR 0
Z8 0
ZS 0
ZB 0
ZA 0
TC 1
Z9 1
DA 2024-11-20
UT WOS:001353876000001
PM 39538110
ER

PT J
AU Hu, Dingyi
   Jiang, Zhiguo
   Shi, Jun
   Xie, Fengying
   Wu, Kun
   Tang, Kunming
   Cao, Ming
   Huai, Jianguo
   Zheng, Yushan
TI Pathology report generation from whole slide images with knowledge
   retrieval and multi-level regional feature selection
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 263
AR 108677
DI 10.1016/j.cmpb.2025.108677
EA MAR 2025
DT Article
PD MAY 2025
PY 2025
AB Background and objectives: With the development of deep learning
   techniques, the computer-assisted pathology diagnosis plays a crucial
   role in clinical diagnosis. An important task within this field is
   report generation, which provides doctors with text descriptions of
   whole slide images (WSIs). Report generation from WSIs presents
   significant challenges due to the structural complexity and pathological
   diversity of tissues, as well as the large size and high information
   density of WSIs. The objective of this study is to design histopathology
   report generation method that can efficiently generate reports from WSIs
   and is suitable for clinical practice. Methods: In this paper, we
   propose a novel approach for generating pathology reports from WSIs,
   leveraging knowledge retrieval and multi-level regional feature
   selection. To deal with the uneven distribution pathological information
   in WSIs, we introduce a multi-level regional feature encoding network
   and a feature selection module that extracts multi-level region
   representations and filters out region features irrelevant the
   diagnosis, enabling more efficient report generation. Moreover, we
   design a knowledge retrieval module improve the report generation
   performance that can leverage the diagnostic information from historical
   cases. Additionally, we propose an out-of-domain application mode based
   on large language model (LLM). The use of LLM enhances the scalability
   of the generation model and improves its adaptability to data from
   different sources. Results: The proposed method is evaluated on a public
   datasets and one in-house dataset. On the public GastricADC (991 WSIs),
   our method outperforms state-of-the-art text generation methods and
   achieved 0.568 and 0.345 on metric Rouge-L and Bleu-4, respectively. On
   the in-house Gastric-3300 (3309 WSIs), our method achieved significantly
   better performance with Rouge-L of 0.690, which surpassed the
   second-best state-of-the-art method Wcap 6.3%. Conclusions: We present
   an advanced method for pathology report generation from WSIs, addressing
   the key challenges associated with the large size and complex
   pathological structures of these images. In particular, the multi-level
   regional feature selection module effectively captures diagnostically
   significant regions of varying sizes. The knowledge retrieval-based
   decoder leverages historical diagnostic data to enhance report accuracy.
   Our method not only improves the informativeness and relevance of the
   generated pathology reports but also outperforms the state-of-the-art
   techniques.
ZS 0
ZB 0
ZA 0
Z8 0
ZR 0
TC 0
Z9 0
DA 2025-03-12
UT WOS:001437933700001
PM 40023962
ER

PT J
AU Feldman, Mitchell J.
   Hoffer, Edward P.
   Conley, Jared J.
   Chang, Jaime
   Chung, Jeanhee A.
   Jernigan, Michael C.
   Lester, William T.
   Strasser, Zachary H.
   Chueh, Henry C.
TI Dedicated AI Expert System vs Generative AI With Large Language Model
   for Clinical Diagnoses
SO JAMA NETWORK OPEN
VL 8
IS 5
AR e2512994
DI 10.1001/jamanetworkopen.2025.12994
DT Article
PD MAY 29 2025
PY 2025
AB Importance Large language models (LLMs) have not yet been compared with
   traditional diagnostic decision support systems (DDSSs) on unpublished
   clinical cases. Objective To compare the performance of 2 widely used
   LLMs (ChatGPT, version 4 [hereafter, LLM1] and Gemini, version 1.5
   [hereafter, LLM2]) with a DDSS (DXplain [hereafter, DDSS]) on 36
   unpublished general medicine cases. Design, Setting, and Participants
   This diagnostic study, conducted from October 6, 2023, to November 22,
   2024, looked for the presence of the known case diagnosis in the
   differential diagnoses of the LLMs and DDSS after data from previously
   unpublished clinical cases from 3 academic medical centers were entered.
   The systems' performance was assessed both with and without laboratory
   test data. Each case was reviewed by 3 physicians blinded to the case
   diagnosis. Physicians identified all clinical findings as well as the
   subset deemed relevant to making the diagnosis for mapping to the DDSS's
   controlled vocabulary. Two other physicians, also blinded to the
   diagnoses, entered the data from these cases into the DDSS, LLM1, and
   LLM2. Exposures All cases were entered into each LLM twice, with and
   without laboratory test results. For the DDSS, each case was entered 4
   times: for all findings and for findings relevant to the diagnosis, each
   with and without laboratory test results. The top 25 diagnoses in each
   resulting differential diagnosis were reviewed. Main Outcomes and
   Measures Presence or absence of the case diagnosis in the system's
   differential diagnosis and, when present, in which quintile it appeared
   in the top 25 diagnoses. Results Among 36 patient cases of various races
   and ethnicities, genders, and ages (mean [SD] age, 51.4 [16.4] years),
   in the version with all findings but no laboratory test results, the
   DDSS listed the case diagnosis in its differential diagnosis more often
   (56% [20 of 36]) than LLM1 (42% [15 of 36]) and LLM2 (39% [14 of 36]),
   although this difference did not reach statistical significance (DDSS vs
   LLMI, P = .09; DDSS vs LLM2, P = .08). All 3 systems listed the case
   diagnosis in most cases if laboratory test results were included (all
   findings DDSS, 72% [26 of 36]; LLM1, 64% [23 of 36]; and LLM2, 58% [21
   of 36]). Conclusions and Relevance In this diagnostic study comparing
   the performance of a traditional DDSS and current LLMs on unpublished
   clinical cases, in most cases, every system listed the case diagnosis in
   their top 25 diagnoses if laboratory test results were included. A
   hybrid approach that combines the parsing and expository linguistic
   capabilities of LLMs with the deterministic and explanatory capabilities
   of traditional DDSSs may produce synergistic benefits.
ZA 0
Z8 0
TC 0
ZR 0
ZB 0
ZS 0
Z9 0
DA 2025-06-05
UT WOS:001499415200009
PM 40440012
ER

PT J
AU Feng, Ruibin
   Brennan, Kelly A.
   Azizi, Zahra
   Goyal, Jatin
   Pedron, Maxime
   Chang, Hui Ju
   Ganesan, Prasanth
   Ruiperez-Campillo, Samuel
   Deb, Brototo
   Clopton, Paul L.
   Baykaner, Tina
   Rogers, Albert J.
   Narayan, Sanjiv M.
TI Optimizing ChatGPT to Detect VT Recurrence From Complex Medical Notes
SO CIRCULATION
VL 148
MA A16401
DI 10.1161/circ.148.suppl_1.16401
SU 1
DT Meeting Abstract
PD NOV 7 2023
PY 2023
CT American-Heart-Association's Epidemiology and Prevention/Lifestyle and
   Cardiometabolic Health Scientific Sessions
CY NOV 11-13, 2023
CL Philadelphia, PA
SP Amer Heart Assoc
ZA 0
ZR 0
Z8 0
ZB 0
ZS 0
TC 2
Z9 2
DA 2024-03-04
UT WOS:001157891306175
ER

PT J
AU Bricker, Jonathan B.
   Sullivan, Brianna M.
   Mull, Kristin E.
   Lavista-Ferres, Juan
   Santiago-Torres, Margarita
TI Efficacy of a conversational chatbot for cigarette smoking cessation:
   Protocol of the QuitBot full-scale randomized controlled trial
SO CONTEMPORARY CLINICAL TRIALS
VL 147
AR 107727
DI 10.1016/j.cct.2024.107727
EA NOV 2024
DT Article
PD DEC 2024
PY 2024
AB Globally, cigarette smoking results in over 8 million premature annual
   deaths. Addressing this issue requires high-impact, cost-effective
   population-level interventions for smoking cessation. Conversational
   chatbots offer a potential solution given the recent advancements in
   machine learning and large language models. Chatbots can deliver
   supportive, empathetic behaviors, personalized responses, and timely
   advice tailored to users' needs that is engaging through therapeutic
   conversations aimed at creating lasting social-emotional connections.
   Despite their promise, little is known about the efficacy and underlying
   mechanisms of chatbots for cigarette smoking cessation. We developed
   QuitBot, a quit smoking program of two to three-minute conversations
   covering topics ranging from motivations to quit, setting a quit date,
   choosing cessation medications, coping with triggers, maintaining
   abstinence, and recovering from a relapse. QuitBot employs
   conversational interactions, powered by an expert-curated large language
   model, allowing users to ask questions and receive personalized guidance
   on quitting smoking. Here, we report the design and execution of a
   randomized clinical trial comparing QuitBot (n = 760) against Smokefree
   TXT (SFT) text messaging program (n = 760), with a 12-month follow-up
   period. Both interventions include 42-days of content on motivations to
   quit, skills to cope with triggers, and relapse prevention. The key
   distinction between QuitBot and SFT is that QuitBot has communication
   and engagement features. This study aims to determine: whether QuitBot
   yields higher quit rates than SFT; and whether therapeutic alliance
   processes and engagement are mechanisms underlying cessation outcomes.
   Additionally, we will explore whether baseline factors including trust,
   social support, and demographics, moderate the efficacy of QuitBot.
   Trial Registration number ClinicalTrials.gov NCT04308759
ZR 0
ZB 0
ZA 0
TC 0
ZS 0
Z8 0
Z9 0
DA 2024-11-18
UT WOS:001353469500001
PM 39490766
ER

PT J
AU Hwang, Eui fin
   Goo, Mo
   Park, Chang Min
TI AI Applications for Thoracic Imaging: Considerations for Best Practice
SO RADIOLOGY
VL 314
IS 2
AR e240650
DI 10.1148/radiol.240650
DT Article
PD FEB 2025
PY 2025
AB Artificial intelligence (AI) technology is rapidly being introduced into
   thoracic radiology practice. Current representative use cases for AI in
   thoracic imaging show cumulative evidence of effectiveness. These
   include AI assistance for reading chest radiographs and low-dose
   (1.5-mSv) chest CT scans for lung cancer screening and triaging
   pulmonary embolism on chest CT scans. Other potential use cases are also
   under investigation, including filtering out normal chest radiographs,
   monitoring reading errors, and automated opportunistic screening of
   nontarget diseases. However, implementing AI tools in daily practice
   requires establishing practical strategies. Practical AI implementation
   will require objective on-site performance evaluation, institutional
   information technology infrastructure integration, and postdeployment
   monitoring. Meanwhile, the remaining challenges of adopting AI
   technology need to be addressed. These challenges include educating
   radiologists and radiology trainees, alleviating liability risk, and
   addressing potential disparities due to the uneven distribution of data
   and AI technology. Finally, next-generation AI technology represented by
   large language models (LLMs), including multimodal models, which can
   interpret both text and images, is expected to innovate the current
   landscape of AI in thoracic radiology practice. These LLMs offer
   opportunities ranging from generating text reports from images to
   explaining examination results to patients. However, these models
   require more research into their feasibility and efficacy.
ZS 0
Z8 0
ZA 0
ZR 0
TC 1
ZB 0
Z9 1
DA 2025-03-09
UT WOS:001434835900015
PM 39998373
ER

PT J
AU Silva, Gisele S.
   Khera, Rohan
   Schwamm, Lee H.
TI Reviewer Experience Detecting and Judging Human Versus Artificial
   Intelligence Content: The Stroke Journal Essay Contest
SO STROKE
VL 55
IS 10
BP 2573
EP 2578
DI 10.1161/STROKEAHA.124.045012
DT Review
PD OCT 2024
PY 2024
AB Artificial intelligence (AI) large language models (LLMs) now produce
   human-like general text and images. LLMs' ability to generate persuasive
   scientific essays that undergo evaluation under traditional peer review
   has not been systematically studied. To measure perceptions of quality
   and the nature of authorship, we conducted a competitive essay contest
   in 2024 with both human and AI participants. Human authors and 4
   distinct LLMs generated essays on controversial topics in stroke care
   and outcomes research. A panel of Stroke Editorial Board members (mostly
   vascular neurologists), blinded to author identity and with varying
   levels of AI expertise, rated the essays for quality, persuasiveness,
   best in topic, and author type. Among 34 submissions (22 human and 12
   LLM) scored by 38 reviewers, human and AI essays received mostly similar
   ratings, though AI essays were rated higher for composition quality.
   Author type was accurately identified only 50% of the time, with prior
   LLM experience associated with improved accuracy. In multivariable
   analyses adjusted for author attributes and essay quality, only
   persuasiveness was independently associated with odds of a reviewer
   assigning AI as author type (adjusted odds ratio, 1.53 [95% CI,
   1.09-2.16]; P=0.01). In conclusion, a group of experienced editorial
   board members struggled to distinguish human versus AI authorship, with
   a bias against best in topic for essays judged to be AI generated.
   Scientific journals may benefit from educating reviewers on the types
   and uses of AI in scientific writing and developing thoughtful policies
   on the appropriate use of AI in authoring manuscripts.
ZA 0
Z8 0
ZR 0
ZS 0
ZB 1
TC 4
Z9 4
DA 2024-10-24
UT WOS:001337182000002
PM 39224979
ER

PT J
AU Yang, Kuo
   Dong, Xin
   Zhang, Shuhan
   Yu, Haibin
   Zhong, Liqun
   Zhang, Lei
   Zhao, He
   Hou, Yutong
   Song, Xinpeng
   Zhou, Xuezhong
TI PresRecRF: Herbal prescription recommendation via the representation
   fusion of large TCM semantics and molecular knowledge
SO PHYTOMEDICINE
VL 135
AR 156116
DI 10.1016/j.phymed.2024.156116
EA OCT 2024
DT Article
PD DEC 2024
PY 2024
AB Background: Herbal prescription recommendation (HPR) is a hotspot in the
   research of clinical intelligent decision support. Recently plentiful
   HPR models based on deep neural networks have been proposed. Owing to
   insufficient data, e.g., lack of knowledge of molecular, TCM theory, and
   herbal dosage in HPR modeling, the existing models suffer from
   challenges, e.g., plain prediction precision, and are far from
   real-world clinics. Purpose: To address these problems, we proposed a
   novel herbal prescription recommendation model with the representation
   fusion of large TCM semantics and molecular knowledge (termed
   PresRecRF). Study Design and Methods: PresRecRF comprises three key
   modules. The representation learning module consists of two key
   components: a molecular knowledge representation component, integrating
   molecular knowledge into the herbsymptom-protein knowledge graph to
   enhance representations for herbs and symptoms; and a TCM knowledge
   representation component, leveraging BERT and ChatGPT to acquire TCM
   knowledge-enriched semantic representations. We introduced a
   representation fusion module to effectively merge molecular and TCM
   semantic representations. In the herb recommendation module, a
   multi-task objective loss is implemented to predict both herbs and
   dosages simultaneously. Results: The experimental results on two
   clinical datasets show that PresRecRF can achieve the optimal
   performance. Further analysis of ablation, hyper-parameters, and case
   studies indicate the effectiveness and reliability of the proposed
   model, suggesting that it can help precision medicine and treatment
   recommendations. Conclusion: The entire process of the proposed
   PresRecRF model closely mirrors the actual diagnosis and treatment
   procedures carried out by doctors, which are better applied in real
   clinical scenarios. The source codes of PresRecRF is available at
   https://github.com/2020MEAI/PresRecRF.
ZR 0
ZS 0
ZA 0
Z8 0
ZB 0
TC 0
Z9 0
DA 2024-12-07
UT WOS:001368283600001
PM 39396402
ER

PT J
AU Lai, Yongkang
   Liao, Foqiang
   Zhao, Jiulong
   Zhu, Chunping
   Hu, Yi
   Li, Zhaoshen
TI Exploring the capacities of ChatGPT: A comprehensive evaluation of its
   accuracy and repeatability in addressing helicobacter
   pylori-related queries
SO HELICOBACTER
VL 29
IS 3
AR e13078
DI 10.1111/hel.13078
DT Article
PD MAY 2024
PY 2024
AB Background: Educational initiatives on Helicobacter pylori (H. pylori)
   constitute a highly effective approach for preventing its infection and
   establishing standardized protocols for its eradication. ChatGPT, a
   large language model, is a potentially patient-friendly online tool
   capable of providing health-related knowledge. This study aims to assess
   the accuracy and repeatability of ChatGPT in responding to questions
   related to H. pylori. Materials and Methods: Twenty-one common questions
   about H. pylori were collected and categorized into four domains: basic
   knowledge, diagnosis, treatment, and prevention. ChatGPT was utilized to
   individually answer the aforementioned 21 questions. Its responses were
   independently assessed by two experts on H. pylori. Questions with
   divergent ratings were resolved by a third reviewer. Cohen's kappa
   coefficient was calculated to assess the consistency between the scores
   of the two reviewers. Results: The responses of ChatGPT on H.
   pylori-related questions were generally satisfactory, with 61.9% marked
   as "completely correct" and 33.33% as "correct but inadequate." The
   repeatability of the responses of ChatGPT to H. pylori-related questions
   was 95.23%. Among the responses, those related to prevention
   (comprehensive: 75%) had the best response, followed by those on
   treatment (comprehensive: 66.7%), basic knowledge (comprehensive: 60%),
   and diagnosis (comprehensive: 50%). In the "treatment" domain, 16.6% of
   the ChatGPT responses were categorized as "mixed with correct or
   incorrect/outdated data." However, ChatGPT still lacks relevant
   knowledge regarding H. pylori resistance and the use of sensitive
   antibiotics. Conclusions: ChatGPT can provide correct answers to the
   majority of H. pylori-related queries. It exhibited good reproducibility
   and delivered responses that were easily comprehensible to patients.
   Further enhancement of real-time information updates and correction of
   inaccurate information will make ChatGPT an essential auxiliary tool for
   providing accurate H. pylori-related health information to patients.
ZR 0
ZB 1
ZS 0
Z8 0
TC 12
ZA 0
Z9 12
DA 2024-06-21
UT WOS:001247019800001
PM 38867649
ER

PT J
AU Krusche, Martin
   Callhoff, Johnna
   Knitza, Johannes
   Ruffer, Nikolas
TI Diagnostic accuracy of a large language model in rheumatology:
   comparison of physician and ChatGPT-4
SO RHEUMATOLOGY INTERNATIONAL
VL 44
IS 2
BP 303
EP 306
DI 10.1007/s00296-023-05464-6
EA SEP 2023
DT Article
PD FEB 2024
PY 2024
AB Pre-clinical studies suggest that large language models (i.e., ChatGPT)
   could be used in the diagnostic process to distinguish inflammatory
   rheumatic (IRD) from other diseases. We therefore aimed to assess the
   diagnostic accuracy of ChatGPT-4 in comparison to rheumatologists. For
   the analysis, the data set of Graf et al. (2022) was used. Previous
   patient assessments were analyzed using ChatGPT-4 and compared to
   rheumatologists' assessments. ChatGPT-4 listed the correct diagnosis
   comparable often to rheumatologists as the top diagnosis 35% vs 39% (p =
   0.30); as well as among the top 3 diagnoses, 60% vs 55%, (p = 0.38). In
   IRD-positive cases, ChatGPT-4 provided the top diagnosis in 71% vs 62%
   in the rheumatologists' analysis. Correct diagnosis was among the top 3
   in 86% (ChatGPT-4) vs 74% (rheumatologists). In non-IRD cases, ChatGPT-4
   provided the correct top diagnosis in 15% vs 27% in the rheumatologists'
   analysis. Correct diagnosis was among the top 3 in non-IRD cases in 46%
   of the ChatGPT-4 group vs 45% in the rheumatologists group. If only the
   first suggestion for diagnosis was considered, ChatGPT-4 correctly
   classified 58% of cases as IRD compared to 56% of the rheumatologists (p
   = 0.52). ChatGPT-4 showed a slightly higher accuracy for the top 3
   overall diagnoses compared to rheumatologist's assessment. ChatGPT-4 was
   able to provide the correct differential diagnosis in a relevant number
   of cases and achieved better sensitivity to detect IRDs than
   rheumatologist, at the cost of lower specificity. The pilot results
   highlight the potential of this new technology as a triage tool for the
   diagnosis of IRD.
ZB 11
Z8 1
ZR 0
ZA 0
ZS 0
TC 56
Z9 57
DA 2023-10-05
UT WOS:001070598100001
PM 37742280
ER

PT J
AU Verma, Anurag
   Hsu, Po Ya
   Kripke, Colleen
   Howard, William
   Sirugo, Giorgio
   Myes, Kelly
TI Advanced Machine Learning Models for Classifying Transthyretin
   Amyloidosis in Clinical Settings
SO CIRCULATION
VL 150
MA 4147767
DI 10.1161/circ.150.suppl_1.4147767
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
CT American-Heart-Association Resuscitation Science Symposium
CY NOV 16-18, 2024
CL Chicago, IL
SP Amer Heart Assoc
ZA 0
TC 0
Z8 0
ZS 0
ZR 0
ZB 0
Z9 0
DA 2025-02-13
UT WOS:001400066404173
ER

PT J
AU Baumgaertner, Kilian
   Byczkowski, Michael
   Schmid, Tamara
   Muschko, Marc
   Woessner, Philipp
   Gerlach, Axel
   Bonekamp, David
   Schlemmer, Heinz-Peter
   Hohenfellner, Markus
   Goertz, Magdalena
TI Effectiveness of the Medical Chatbot PROSCA to Inform Patients About
   Prostate Cancer: Results of a Randomized Controlled Trial
SO EUROPEAN UROLOGY OPEN SCIENCE
VL 69
BP 80
EP 88
DI 10.1016/j.euros.2024.08.022
EA SEP 2024
DT Article
PD NOV 2024
PY 2024
AB Background and objective: Artificial intelligence (AI)-powered
   conversational agents are increasingly finding application in health
   care, as these can provide patient education at any time. However, their
   effectiveness in medical settings remains largely unexplored. This study
   aimed to assess the impact of the chatbot "PROState cancer
   Conversational Agent"(PROSCA), which was trained to provide validated
   support from diagnostic tests to treatment options for men facing
   prosate cancer (PC) diagnosis. Methods: The chatbot PROSCA, developed by
   urologists at Heidelberg University Hospital and SAP SE, was evaluated
   through a randomized controlled trial (RCT). Patients were assigned to
   either the chatbot group, receiving additional access to PROSCA
   alongside standard information by urologists, or the control group
   (1:1), receiving standard information. A total of 112 men were included,
   of whom 103 gave feedback at study completion. Key findings and
   limitations: Overtime, patients' information needs decreased
   significantly more in the chatbot group than in the control group (p =
   0.035). In the chatbot group, 43/54 men (79.6%) used PROSCA, and all of
   them found it easy to use. Of the men, 71.4% agreed that the chatbot
   improved their informedness about PC and 90.7% would like to use PROSCA
   again. Limitations are study sample size, singlecenter design, and
   specific clinical application. Conclusions and clinical implications:
   With the introduction of the PROSCA chatbot, we created and evaluated an
   innovative, evidence-based AI health information tool as an additional
   source of information for PC. Our RCT results showed significant
   benefits of the chatbot in reducing patients' information needs and
   enhancing their understanding of PC. This easy-to-use AI tool provides
   accurate, timely, and accessible support, demonstrating its value in the
   PC diagnosis process. Future steps include further customization of the
   chatbot's responses and integration with the existing health care
   systems to maximize its impact on patient outcomes. Patient summary:
   This study evaluated an artificial intelligence-powered chatbot- PROSCA,
   a digital tool designed to support men facing prostate cancer diagnosis
   by providing validated information from diagnosis to treatment. Results
   showed that patients who used the chatbot as an additional tool felt
   better informed than those who received standard information from
   urologists. The majority of users appreciated the ease of use of the
   chatbot and expressed a desire to use it again; this suggests that
   PROSCA could be a valuable resource to improve patient understanding in
   prostate cancer diagnosis. (c) 2024 The Author(s). Published by Elsevier
   B.V. on behalf of European Association of Urology. This is an open
   access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZB 0
ZA 0
TC 1
ZS 0
Z8 0
ZR 0
Z9 1
DA 2024-09-29
UT WOS:001318013100001
PM 39329071
ER

PT J
AU Abi-Rafeh, Jad
   Mroueh, Vanessa J.
   Bassiri-Tehrani, Brian
   Marks, Jacob
   Kazan, Roy
   Nahai, Foad
TI Complications Following Body Contouring: Performance Validation of Bard,
   a Novel AI Large Language Model, in Triaging and Managing Postoperative
   Patient Concerns
SO AESTHETIC PLASTIC SURGERY
VL 48
IS 5
BP 953
EP 976
DI 10.1007/s00266-023-03819-9
EA JAN 2024
DT Article
PD MAR 2024
PY 2024
AB Introduction Large language models (LLM) have revolutionized the way
   humans interact with artificial intelligence (AI) technology, with
   marked potential for applications in esthetic surgery. The present study
   evaluates the performance of Bard, a novel LLM, in identifying and
   managing postoperative patient concerns for complications following body
   contouring surgery.Methods The American Society of Plastic Surgeons'
   website was queried to identify and simulate all potential postoperative
   complications following body contouring across different acuities and
   severity. Bard's accuracy was assessed in providing a differential
   diagnosis, soliciting a history, suggesting a most-likely diagnosis,
   appropriate disposition, treatments/interventions to begin from home,
   and red-flag signs/symptoms indicating deterioration, or requiring
   urgent emergency department (ED) presentation.Results Twenty-two
   simulated body contouring complications were examined. Overall, Bard
   demonstrated a 59% accuracy in listing relevant diagnoses on its
   differentials, with a 52% incidence of incorrect or misleading
   diagnoses. Following history-taking, Bard demonstrated an overall
   accuracy of 44% in identifying the most-likely diagnosis, and a 55%
   accuracy in suggesting the indicated medical dispositions. Helpful
   treatments/interventions to begin from home were suggested with a 40%
   accuracy, whereas red-flag signs/symptoms, indicating deterioration,
   were shared with a 48% accuracy. A detailed analysis of performance,
   stratified according to latency of postoperative presentation (<48hours,
   48hours-1month, or >1month postoperatively), and according to acuity and
   indicated medical disposition, is presented herein.Conclusions Despite
   promising potential of LLMs and AI in healthcare-related applications,
   Bard's performance in the present study significantly falls short of
   accepted clinical standards, thus indicating a need for further research
   and development prior to adoption.Level of Evidence IV This journal
   requires that authors assign a level of evidence to each article. For a
   full description of these Evidence-Based Medicine ratings, please refer
   to the Table of Contents or the online Instructions to Authors
   www.springer.com/00266.
ZS 0
ZB 0
ZR 0
TC 1
Z8 0
ZA 0
Z9 1
DA 2024-02-03
UT WOS:001150315000001
PM 38273152
ER

PT J
AU Huang, Yixing
   Gomaa, Ahmed
   Semrau, Sabine
   Haderlein, Marlen
   Lettmaier, Sebastian
   Weissmann, Thomas
   Grigo, Johanna
   Tkhayat, Hassen Ben
   Frey, Benjamin
   Gaipl, Udo
   Distel, Luitpold
   Maier, Andreas
   Fietkau, Rainer
   Bert, Christoph
   Putz, Florian
TI Benchmarking ChatGPT-4 on a radiation oncology in-training exam and Red
   Journal Gray Zone cases: potentials and challenges for ai-assisted
   medical education and decision making in radiation oncology
SO FRONTIERS IN ONCOLOGY
VL 13
AR 1265024
DI 10.3389/fonc.2023.1265024
DT Article
PD SEP 14 2023
PY 2023
AB PurposeThe potential of large language models in medicine for education
   and decision-making purposes has been demonstrated as they have achieved
   decent scores on medical exams such as the United States Medical
   Licensing Exam (USMLE) and the MedQA exam. This work aims to evaluate
   the performance of ChatGPT-4 in the specialized field of radiation
   oncology.MethodsThe 38th American College of Radiology (ACR) radiation
   oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone
   cases are used to benchmark the performance of ChatGPT-4. The TXIT exam
   contains 300 questions covering various topics of radiation oncology.
   The 2022 Gray Zone collection contains 15 complex clinical
   cases.ResultsFor the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved
   the scores of 62.05% and 78.77%, respectively, highlighting the
   advantage of the latest ChatGPT-4 model. Based on the TXIT exam,
   ChatGPT-4's strong and weak areas in radiation oncology are identified
   to some extent. Specifically, ChatGPT-4 demonstrates better knowledge of
   statistics, CNS & eye, pediatrics, biology, and physics than knowledge
   of bone & soft tissue and gynecology, as per the ACR knowledge domain.
   Regarding clinical care paths, ChatGPT-4 performs better in diagnosis,
   prognosis, and toxicity than brachytherapy and dosimetry. It lacks
   proficiency in in-depth details of clinical trials. For the Gray Zone
   cases, ChatGPT-4 is able to suggest a personalized treatment approach to
   each case with high correctness and comprehensiveness. Importantly, it
   provides novel treatment aspects for many cases, which are not suggested
   by any human experts.ConclusionBoth evaluations demonstrate the
   potential of ChatGPT-4 in medical education for the general public and
   cancer patients, as well as the potential to aid clinical
   decision-making, while acknowledging its limitations in certain domains.
   Owing to the risk of hallucinations, it is essential to verify the
   content generated by models such as ChatGPT for accuracy.
ZA 0
ZR 0
TC 56
ZB 10
Z8 0
ZS 1
Z9 56
DA 2023-12-23
UT WOS:001119288400001
PM 37790756
ER

PT J
AU Zheng, Ce
   Ye, Hongfei
   Guo, Jinming
   Yang, Junrui
   Fei, Ping
   Yuan, Yuanzhi
   Huang, Danqing
   Huang, Yuqiang
   Peng, Jie
   Xie, Xiaoling
   Xie, Meng
   Zhao, Peiquan
   Chen, Li
   Zhang, Mingzhi
TI Development and evaluation of a large language model of ophthalmology in
   Chinese
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1390
EP 1397
DI 10.1136/bjo-2023-324526
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background Large language models (LLMs), such as ChatGPT, have
   considerable implications for various medical applications. However,
   ChatGPT's training primarily draws from English-centric internet data
   and is not tailored explicitly to the medical domain. Thus, an
   ophthalmic LLM in Chinese is clinically essential for both healthcare
   providers and patients in mainland China.
   Methods We developed an LLM of ophthalmology (MOPH) using Chinese
   corpora and evaluated its performance in three clinical scenarios:
   ophthalmic board exams in Chinese, answering evidence-based
   medicine-oriented ophthalmic questions and diagnostic accuracy for
   clinical vignettes. Additionally, we compared MOPH's performance to that
   of human doctors.
   Results In the ophthalmic exam, MOPH's average score closely aligned
   with the mean score of trainees (64.7 (range 62-68) vs 66.2 (range
   50-92), p=0.817), but achieving a score above 60 in all seven mock
   exams. In answering ophthalmic questions, MOPH demonstrated an adherence
   of 83.3% (25/30) of responses following Chinese guidelines (Likert scale
   4-5). Only 6.7% (2/30, Likert scale 1-2) and 10% (3/30, Likert scale 3)
   of responses were rated as 'poor or very poor' or 'potentially
   misinterpretable inaccuracies' by reviewers. In diagnostic accuracy,
   although the rate of correct diagnosis by ophthalmologists was superior
   to that by MOPH (96.1% vs 81.1%, p>0.05), the difference was not
   statistically significant.
   Conclusion This study demonstrated the promising performance of MOPH, a
   Chinese-specific ophthalmic LLM, in diverse clinical scenarios. MOPH has
   potential real-world applications in Chinese-language ophthalmology
   settings.
ZS 0
ZA 0
TC 4
ZR 0
Z8 0
ZB 0
Z9 4
DA 2024-07-29
UT WOS:001274616900001
PM 39019566
ER

PT J
AU Cardamone, Nicholas C.
   Olfson, Mark
   Schmutte, Timothy
   Ungar, Lyle
   Liu, Tony
   Cullen, Sara W.
   Williams, Nathaniel J.
   Marcus, Steven C.
TI Classifying Unstructured Text in Electronic Health Records for Mental
   Health Prediction Models: Large Language Model Evaluation Study
SO JMIR MEDICAL INFORMATICS
VL 13
AR e65454
DI 10.2196/65454
DT Article
PD 2025
PY 2025
AB Background: Prediction models have demonstrated a range of applications
   across medicine, including using electronic health record (EHR) data to
   identify hospital readmission and mortality risk. Large language models
   (LLMs) can transform unstructured EHR text into structured features,
   which can then be integrated into statistical prediction models,
   ensuring that the results are both clinically meaningful and
   interpretable. Objective: This study aims to compare the classification
   decisions made by clinical experts with those generated by a
   state-of-the-art LLM, using terms extracted from a large EHR data set of
   individuals with mental health disorders seen in emergency departments
   (EDs). Methods: Using a dataset from the EHR systems of more than 50
   health care provider organizations in the United States from 2016 to
   2021, we extracted all clinical terms that appeared in at least 1000
   records of individuals admitted to the ED for a mental health-related
   problem from a source population of over 6 million ED episodes. Two
   experienced mental health clinicians (one medically trained psychiatrist
   and one clinical psychologist) reached consensus on the classification
   of EHR terms and diagnostic codes into categories. We evaluated an LLM's
   agreement with clinical judgment across three classification tasks as
   follows: (1) classify terms into "mental health" or "physical health",
   (2) classify mental health terms into 1 of 42 prespecified categories,
   and (3) classify physical health terms into 1 of 19 prespecified broad
   categories. Results: There was high agreement between the LLM and
   clinical experts when categorizing 4553 terms as "mental health" or
   "physical health" (kappa=0.77, 95% CI 0.75-0.80). However, there was
   still considerable variability in LLM-clinician agreement on the
   classification of mental health terms (kappa=0.62, 95% CI 0.59-0.66) and
   physical health terms (kappa=0.69, 95% CI 0.67-0.70). Conclusions: The
   LLM displayed high agreement with clinical experts when classifying EHR
   terms into certain mental health or physical health term categories.
   However, agreement with clinical experts varied considerably within both
   sets of mental and physical health term categories. Importantly, the use
   of LLMs presents an alternative to manual human coding, presenting great
   potential to create interpretable features for prediction models.
ZS 0
TC 2
ZR 0
ZA 0
ZB 0
Z8 0
Z9 2
DA 2025-02-14
UT WOS:001415993800001
PM 39864953
ER

PT J
AU Guo, Edward
   Gupta, Mehul
   Sinha, Sarthak
   Roessler, Karl
   Tatagiba, Marcos
   Akagami, Ryojo
   Al-Mefty, Ossama
   Sugiyama, Taku
   Stieg, Philip E.
   Pickett, Gwynedd E.
   de Lotbiniere-Bassett, Madeleine
   Singh, Rahul
   Lama, Sanju
   Sutherland, Garnette R.
TI neuroGPT-X: toward a clinic-ready large language model
SO JOURNAL OF NEUROSURGERY
VL 140
IS 4
BP 1041
EP 1053
DT Article
PD APR 2024
PY 2024
AB OBJECTIVE The objective was to assess the performance of a
   context-enriched large language model (LLM) compared with international
   neurosurgical experts on questions related to the management of
   vestibular schwannoma. Furthermore, another objective was to develop a
   chat-based platform incorporating in-text citations, references, and
   memory to enable accurate, relevant, and reliable information in real
   time. METHODS The analysis involved 1) creating a data set through web
   scraping, 2) developing a chat-based platform called neuroGPT-X, 3)
   enlisting 8 expert neurosurgeons across international centers to
   independently create questions (n = 1) and to answer (n = 4) and
   evaluate responses (n = 3) while blinded, and 4) analyzing the
   evaluation results on the management of vestibular schwannoma. In the
   blinded phase, all answers were assessed for accuracy, coherence,
   relevance, thoroughness, speed, and overall rating. All experts were
   unblinded and provided their thoughts on the utility and limitations of
   the tool. In the unblinded phase, all neurosurgeons provided answers to
   a Likert scale survey and longanswer questions regarding the clinical
   utility, likelihood of use, and limitations of the tool. The tool was
   then evaluated on the basis of a set of 103 consensus statements on
   vestibular schwannoma care from the 8th Quadrennial International
   Conference on Vestibular Schwannoma. RESULTS Responses from the naive
   and context-enriched Generative Pretrained Transformer (GPT) models were
   consistently rated not significantly different in terms of accuracy,
   coherence, relevance, thoroughness, and overall performance, and they
   were often rated significantly higher than expert responses. Both the
   naive and content-enriched GPT models provided faster responses to the
   standardized question set than expert neurosurgeon respondents (p <
   0.01). The context-enriched GPT model agreed with 98 of the 103 (95%)
   consensus statements. Of interest, all expert surgeons expressed
   concerns about the reliability of GPT in accurately addressing the
   nuances and controversies surrounding the management of vestibular
   schwannoma. Furthermore, the authors developed neuroGPT-X, a chat-based
   platform designed to provide point-of-care clinical support and mitigate
   the limitations of human memory. neuroGPT-X incorporates features such
   as in-text citations and references to enable accurate, relevant, and
   reliable information in real time. CONCLUSIONS The present study, with
   its subspecialist-level performance in generating written responses to
   complex neurosurgical problems for which evidence-based consensus for
   management is lacking, suggests that context-enriched LLMs show promise
   as a point-of-care medical resource. The authors anticipate that this
   work will be a springboard for expansion into more medical specialties,
   incorporating evidence-based clinical information and developing
   expert-level dialogue surrounding LLMs in healthcare.
ZB 2
ZS 0
Z8 1
ZR 0
TC 10
ZA 0
Z9 11
DA 2024-06-30
UT WOS:001251735100004
PM 38564804
ER

PT J
AU Veshtaj, Marinela
   Omar, Alaa
   Alam, Loba
   Kim, Ga Hee
   Pinney, Sean
   Argulian, Edgar
TI Artificial Intelligence for Clinical Risk Stratification: Expert Based
   Risk Scores versus Online Open Source Generative Pre-Trained
   Transformers
SO CIRCULATION
VL 150
MA 4142895
DI 10.1161/circ.150.suppl_1.4142895
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
CT American-Heart-Association Resuscitation Science Symposium
CY NOV 16-18, 2024
CL Chicago, IL
SP Amer Heart Assoc
ZR 0
ZA 0
TC 0
ZS 0
ZB 0
Z8 0
Z9 0
DA 2025-02-13
UT WOS:001400066400343
ER

PT J
AU Kashyap, Aditya M.
   Rao, Delip
   Boland, Mary Regina
   Shen, Li
   Callison-Burch, Chris
TI Predicting explainable dementia types with LLM-aided feature engineering
SO BIOINFORMATICS
VL 41
IS 4
AR btaf156
DI 10.1093/bioinformatics/btaf156
DT Article
PD APR 2025
PY 2025
AB Motivation The integration of Machine Learning and Artificial
   Intelligence (AI) into healthcare has immense potential due to the
   rapidly growing volume of clinical data. However, existing AI models,
   particularly Large Language Models (LLMs) like GPT-4, face significant
   challenges in terms of explainability and reliability, particularly in
   high-stakes domains like healthcare.Results This paper proposes a novel
   LLM-aided feature engineering approach that enhances interpretability by
   extracting clinically relevant features from the Oxford Textbook of
   Medicine. By converting clinical notes into concept vector
   representations and employing a linear classifier, our method achieved
   an accuracy of 0.72, outperforming a traditional n-gram Logistic
   Regression baseline (0.64) and the GPT-4 baseline (0.48), while focusing
   on high-level clinical features. We also explore using Text Embeddings
   to reduce the overall time and cost of our approach by 97%.Availability
   and implementation All code relevant to this paper is available at:
   https://github.com/AdityaKashyap423/Dementia_LLM_Feature_Engineering/tre
   e/main.
TC 0
ZR 0
ZS 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2025-05-02
UT WOS:001473768800001
PM 40199828
ER

PT J
AU Huang, Andy S.
   Hirabayashi, Kyle
   Barna, Laura
   Parikh, Deep
   Pasquale, Louis R.
TI Assessment of a Large Language Model's Responses to Questions and Cases
   About Glaucoma and Retina Management
SO JAMA OPHTHALMOLOGY
VL 142
IS 4
BP 371
EP 375
DI 10.1001/jamaophthalmol.2023.6917
EA APR 2024
DT Article
PD APR 2024
PY 2024
AB Importance: Large language models (LLMs) are revolutionizing medical
   diagnosis and treatment, offering unprecedented accuracy and ease
   surpassing conventional search engines. Their integration into medical
   assistance programs will become pivotal for ophthalmologists as an
   adjunct for practicing evidence-based medicine. Therefore, the
   diagnostic and treatment accuracy of LLM-generated responses compared
   with fellowship-trained ophthalmologists can help assess their accuracy
   and validate their potential utility in ophthalmic subspecialties.
   Objective: To compare the diagnostic accuracy and comprehensiveness of
   responses from an LLM chatbot with those of fellowship-trained glaucoma
   and retina specialists on ophthalmological questions and real patient
   case management. Design, Setting, and Participants: This comparative
   cross-sectional study recruited 15 participants aged 31 to 67 years,
   including 12 attending physicians and 3 senior trainees, from eye
   clinics affiliated with the Department of Ophthalmology at Icahn School
   of Medicine at Mount Sinai, New York, New York. Glaucoma and retina
   questions (10 of each type) were randomly selected from the American
   Academy of Ophthalmology's Commonly Asked Questions. Deidentified
   glaucoma and retinal cases (10 of each type) were randomly selected from
   ophthalmology patients seen at Icahn School of Medicine at Mount
   Sinai-affiliated clinics. The LLM used was GPT-4 (version dated May 12,
   2023). Data were collected from June to August 2023. Main Outcomes and
   Measures: Responses were assessed via a Likert scale for medical
   accuracy and completeness. Statistical analysis involved the
   Mann-Whitney U test and the Kruskal-Wallis test, followed by pairwise
   comparison. Results: The combined question-case mean rank for accuracy
   was 506.2 for the LLM chatbot and 403.4 for glaucoma specialists (n =
   831; Mann-Whitney U = 27976.5; P < .001), and the mean rank for
   completeness was 528.3 and 398.7, respectively (n = 828; Mann-Whitney U
   = 25218.5; P < .001). The mean rank for accuracy was 235.3 for the LLM
   chatbot and 216.1 for retina specialists (n = 440; Mann-Whitney U =
   15518.0; P = .17), and the mean rank for completeness was 258.3 and
   208.7, respectively (n = 439; Mann-Whitney U = 13123.5; P = .005). The
   Dunn test revealed a significant difference between all pairwise
   comparisons, except specialist vs trainee in rating chatbot
   completeness. The overall pairwise comparisons showed that both trainees
   and specialists rated the chatbot's accuracy and completeness more
   favorably than those of their specialist counterparts, with specialists
   noting a significant difference in the chatbot's accuracy (z = 3.23; P =
   .007) and completeness (z = 5.86; P < .001). Conclusions and Relevance:
   This study accentuates the comparative proficiency of LLM chatbots in
   diagnostic accuracy and completeness compared with fellowship-trained
   ophthalmologists in various clinical scenarios. The LLM chatbot
   outperformed glaucoma specialists and matched retina specialists in
   diagnostic and treatment accuracy, substantiating its role as a
   promising diagnostic adjunct in ophthalmology.
Z8 1
ZS 0
ZR 0
ZA 0
TC 53
ZB 8
Z9 53
DA 2024-03-21
UT WOS:001174564400007
PM 38386351
ER

PT J
AU Shenoy, Ujwala
   Zhang, Lu
   Jha, Mawra
   Kwong, Raymond
   Manning, Warren
   Nezafat, Reza
   Tsao, Connie
TI Development and Accuracy of Natural Language Processing-based Expression
   Matching to Identify and Classify Cardiomyopathy from Cardiovascular
   Magnetic Resonance Reports
SO CIRCULATION
VL 150
MA 4140236
DI 10.1161/circ.150.suppl_1.4140236
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
ZS 0
TC 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 0
DA 2025-02-10
UT WOS:001398742703409
ER

PT J
AU Zarfati, Mor
   Soffer, Shelly
   Nadkarni, Girish N.
   Klang, Eyal
TI Retrieval-Augmented Generation: Advancing personalized care and research
   in oncology
SO EUROPEAN JOURNAL OF CANCER
VL 220
AR 115341
DI 10.1016/j.ejca.2025.115341
EA MAR 2025
DT Article
PD MAY 2 2025
PY 2025
AB Retrieval-Augmented Generation (RAG) pairs large language models (LLMs)
   with recent data to produce more accurate, context-aware outputs. By
   converting text into numeric embeddings, RAG locates and retrieves
   relevant "chunks" of data, that along with the query, ground the model's
   responses in current, specific information. This process helps reduce
   outdated or fabricated answers. In oncology, RAG has shown particular
   promise. Studies have demonstrated its ability to improve treatment
   recommendations by integrating genetic profiles, strengthened clinical
   trial matching through biomarker analysis, and accelerated drug
   development by clarifying modeldriven insights. Despite its advantages,
   RAG depends on high-quality data. Biased or incomplete sources can lead
   to inaccurate outcomes. Careful implementation and human oversight are
   crucial for ensuring the effectiveness and reliability of RAG in
   oncology.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-03-21
UT WOS:001444559600001
PM 40068371
ER

PT J
AU Celiker, Pelin
   Naeini, Parisa Emami
TI Determining the utility of large language models in generating the ICD10
   code for uveitis and uveitis related conditions
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZB 0
ZA 0
ZR 0
ZS 0
Z8 0
TC 0
Z9 0
DA 2024-12-01
UT WOS:001312227701039
ER

PT J
AU McCoy, Thomas H.
   Castro, Victor M.
   Perlis, Roy H.
TI Estimating depression severity in narrative clinical notes using large
   language models
SO JOURNAL OF AFFECTIVE DISORDERS
VL 381
BP 270
EP 274
DI 10.1016/j.jad.2025.04.014
EA APR 2025
DT Article
PD JUL 15 2025
PY 2025
AB Background: Depression treatment guidelines emphasize measurement-based
   care using patient-reported outcome measures, yet their impact on
   narrative documentation quality remains underexplored. Methods: We
   sampled 15,000 narrative clinical outpatient notes from the electronic
   health record of a large academic medical center, reflecting visits
   between January 2, 2019 and January 30, 2024, for which a 9-item Patient
   Health Questionnaire (PHQ-9) was completed at the same time. After
   censoring PHQ-9 scores from notes, we estimated severity of depressive
   symptoms with a foundational large language model (gpt4o-08-06) in a
   HIPAA-compliant enclave. We estimated correlation between true PHQ-9 and
   model-estimated score and examined the predictive performance of the
   model for moderate or greater depressive symptoms. Results: Mean age was
   46.3 years (SD 14.9); 9083 (60.6 %) identified as female. 925 (6.2 %)
   identified as Asian, 638 (4.3 %) as Black, 853 (5.7 %) as another race,
   and 12,187 (81.2 %) as White. A total of 1044 (7.0 %) identified as
   Hispanic ethnicity, while 12,699 (84.7 %) were non-Hispanic. Mean
   measured PHQ-9 score was 1.23 (SD 3.45); 721 (4.8 %) met criteria for
   moderate or greater depressive symptoms. LLM-predicted PHQ-9 scores were
   modestly correlated with actual scores (r2 = 0.264 (95 % CI
   0.252-0.276)); PPV for moderate or greater depression was 0.309 (95 % CI
   0.302-0.317). Performance was consistent across demographic subgroups,
   with modest differences identified by race, ethnicity, and sex.
   Conclusion: A foundational LLM performed poorly but consistently across
   subgroups in imputing PHQ-9 scores from notes when actual PHQ-9
   reporting was ablated. This result suggests the extent to which
   inclusion of PROMs may impoverish documentation of psychiatric symptoms.
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2025-04-26
UT WOS:001469145100001
PM 40187432
ER

PT J
AU Moothedan, Elijah
   Jhumkhawala, Vama
   Burgoa, Sara
   Martinez, Lisa
   Sacca, Lea
TI Qualitatively Assessing ChatGPT Responses to Frequently Asked Questions
   Regarding Sexually Transmitted Diseases
SO SEXUALLY TRANSMITTED DISEASES
VL 52
IS 3
BP 188
EP 192
DI 10.1097/OLQ.0000000000002088
DT Article
PD MAR 2025
PY 2025
AB BackgroundChatGPT, a large language model artificial intelligence
   platform that uses natural language processing, has seen its
   implementation across a number of sectors, notably in health care.
   However, there remains limited understanding regarding the efficacy of
   ChatGPT in addressing commonly asked questions on public health
   subjects. This study aimed to investigate whether ChatGPT could
   appropriately answer frequently asked questions related to sexually
   transmitted diseases (STDs).MethodsTen frequently asked questions on
   STDs were gathered from 25 different government agency websites. The
   questions were inputted into ChatGPT, and subsequent responses were
   analyzed for accuracy, clarity, and appropriateness using an
   evidence-based approach on a 4-point grading scale.ResultsOf the
   responses provided by ChatGPT, 4 were determined to be excellent
   requiring no clarification and 6 requiring minimal clarification. No
   responses were graded as unsatisfactory. Additionally, the responses
   appropriately emphasized consulting a health care
   specialist.ConclusionAlthough the majority of responses required minimal
   clarification, ChatGPT has the potential to be an effective
   supplementary tool for patient education. Additional research is
   necessary to explore possible public health strategies that incorporate
   artificial intelligence to address concerns related to STDs.
ZB 1
TC 1
ZR 0
ZA 0
Z8 0
ZS 0
Z9 1
DA 2025-02-12
UT WOS:001413749900004
PM 39481015
ER

PT J
AU Hong, Soonwook
   Zheng, Henry W.
   Pace, Jordan L.
   Makar, Christian
   Eghbali, Mason
   Limketkai, Berkeley
TI RAPID AND ACCURATE EVALUATION OF DRUG-INDUCED LIVER INJURY CASES WITH A
   CONTEXT-AUGMENTED LARGE LANGUAGE MODEL
SO GASTROENTEROLOGY
VL 166
IS 5
MA Tu2018
BP S1494
EP S1495
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z8 0
Z9 0
DA 2024-10-30
UT WOS:001282837706116
ER

PT J
AU Muntean, George Adrian
   Marginean, Anca
   Groza, Adrian
   Damian, Ioana
   Roman, Sara Alexia
   Hapca, Madalina Claudia
   Sere, Anca Madalina
   Manoiu, Roxana Mihaela
   Muntean, Maximilian Vlad
   Nicoara, Simona Delia
TI A Qualitative Evaluation of ChatGPT4 and PaLM2's Response to Patient's
   Questions Regarding Age-Related Macular Degeneration
SO DIAGNOSTICS
VL 14
IS 14
AR 1468
DI 10.3390/diagnostics14141468
DT Article
PD JUL 2024
PY 2024
AB Patient compliance in chronic illnesses is essential for disease
   management. This also applies to age-related macular degeneration (AMD),
   a chronic acquired retinal degeneration that needs constant monitoring
   and patient cooperation. Therefore, patients with AMD can benefit by
   being properly informed about their disease, regardless of the
   condition's stage. Information is essential in keeping them compliant
   with lifestyle changes, regular monitoring, and treatment. Large
   language models have shown potential in numerous fields, including
   medicine, with remarkable use cases. In this paper, we wanted to assess
   the capacity of two large language models (LLMs), ChatGPT4 and PaLM2, to
   offer advice to questions frequently asked by patients with AMD. After
   searching on AMD-patient-dedicated websites for frequently asked
   questions, we curated and selected a number of 143 questions. The
   questions were then transformed into scenarios that were answered by
   ChatGPT4, PaLM2, and three ophthalmologists. Afterwards, the answers
   provided by the two LLMs to a set of 133 questions were evaluated by two
   ophthalmologists, who graded each answer on a five-point Likert scale.
   The models were evaluated based on six qualitative criteria: (C1)
   reflects clinical and scientific consensus, (C2) likelihood of possible
   harm, (C3) evidence of correct reasoning, (C4) evidence of correct
   comprehension, (C5) evidence of correct retrieval, and (C6) missing
   content. Out of 133 questions, ChatGPT4 received a score of five from
   both reviewers to 118 questions (88.72%) for C1, to 130 (97.74%) for C2,
   to 131 (98.50%) for C3, to 133 (100%) for C4, to 132 (99.25%) for C5,
   and to 122 (91.73%) for C6, while PaLM2 to 81 questions (60.90%) for C1,
   to 114 (85.71%) for C2, to 115 (86.47%) for C3, to 124 (93.23%) for C4,
   to 113 (84.97%) for C5, and to 93 (69.92%) for C6. Despite the overall
   high performance, there were answers that are incomplete or inaccurate,
   and the paper explores the type of errors produced by these LLMs. Our
   study reveals that ChatGPT4 and PaLM2 are valuable instruments for
   patient information and education; however, since there are still some
   limitations to these models, for proper information, they should be used
   in addition to the advice provided by the physicians.
ZA 0
ZR 0
TC 1
ZS 0
ZB 0
Z8 0
Z9 1
DA 2024-08-01
UT WOS:001276597300001
PM 39061606
ER

PT J
AU Savage, Thomas
   Wang, John
   Gallo, Robert
   Boukil, Abdessalem
   Patel, Vishwesh
   Safavi-Naini, Seyed Amir Ahmad
   Soroush, Ali
   Chen, Jonathan H.
TI Large language model uncertainty proxies: discrimination and calibration
   for medical diagnosis and treatment
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
VL 32
IS 1
BP 139
EP 149
DI 10.1093/jamia/ocae254
EA OCT 2024
DT Article
PD OCT 12 2024
PY 2024
AB Introduction The inability of large language models (LLMs) to
   communicate uncertainty is a significant barrier to their use in
   medicine. Before LLMs can be integrated into patient care, the field
   must assess methods to estimate uncertainty in ways that are useful to
   physician-users.Objective Evaluate the ability for uncertainty proxies
   to quantify LLM confidence when performing diagnosis and treatment
   selection tasks by assessing the properties of discrimination and
   calibration.Methods We examined confidence elicitation (CE), token-level
   probability (TLP), and sample consistency (SC) proxies across GPT3.5,
   GPT4, Llama2, and Llama3. Uncertainty proxies were evaluated against 3
   datasets of open-ended patient scenarios.Results SC discrimination
   outperformed TLP and CE methods. SC by sentence embedding achieved the
   highest discriminative performance (ROC AUC 0.68-0.79), yet with poor
   calibration. SC by GPT annotation achieved the second-best
   discrimination (ROC AUC 0.66-0.74) with accurate calibration. Verbalized
   confidence (CE) was found to consistently overestimate model
   confidence.Discussion and Conclusions SC is the most effective method
   for estimating LLM uncertainty of the proxies evaluated. SC by sentence
   embedding can effectively estimate uncertainty if the user has a set of
   reference cases with which to re-calibrate their results, while SC by
   GPT annotation is the more effective method if the user does not have
   reference cases and requires accurate raw calibration. Our results
   confirm LLMs are consistently over-confident when verbalizing their
   confidence (CE).
ZS 0
ZA 0
ZB 2
TC 6
ZR 0
Z8 0
Z9 6
DA 2024-10-17
UT WOS:001330240100001
PM 39396184
ER

PT J
AU Abi-Rafeh, Jad
   Hanna, Steven
   Bassiri-Tehrani, Brian
   Kazan, Roy
   Nahai, Foad
TI Complications Following Facelift and Neck Lift: Implementation and
   Assessment of Large Language Model and Artificial Intelligence (ChatGPT)
   Performance Across 16 Simulated Patient Presentations
SO AESTHETIC PLASTIC SURGERY
DI 10.1007/s00266-023-03538-1
EA AUG 2023
DT Article; Early Access
PY 2023
AB Introduction ChatGPT represents a potential resource for patient
   guidance and education, with the possibility for quality improvement in
   healthcare delivery. The present study evaluates the role of ChatGPT as
   an interactive patient resource, and assesses its performance in
   identifying, triaging, and guiding patients with concerns of
   postoperative complications following facelift and neck lift
   surgery.Methods Sixteen patient profiles were generated to simulate
   postoperative patient presentations, with complications of varying
   acuity and severity. ChatGPT was assessed for its accuracy in generating
   a differential diagnosis, soliciting a history, providing the
   most-likely diagnosis, the appropriate disposition,
   treatments/interventions to begin from home, and red-flag symptoms
   necessitating an urgent presentation to the emergency department.Results
   Overall accuracy in providing a complete differential diagnosis in
   response to simulated presentations was 85%, with an accuracy of 88% in
   identifying the most-likely diagnosis after history-taking. However,
   appropriate patient dispositions were suggested in only 56% of cases.
   Relevant home treatments/interventions were suggested with an 82%
   accuracy, and red-flag symptoms with a 73% accuracy. A detailed
   analysis, stratified according to latency of postoperative presentation
   (<48 h, 48 h-1 week, or >1 week), and according to acuity of
   complications, is presented herein.Conclusions ChatGPT overestimated the
   urgency of indicated patient dispositions in 44% of cases, concerning
   for potential unnecessary increase in healthcare resource utilization.
   Imperfect performance, and the tool's tendency for overinclusion in its
   responses, risk increasing patient anxiety and straining
   physician-patient relationships. While artificial intelligence has great
   potential in triaging postoperative patient concerns, and improving
   efficiency and resource utilization, ChatGPT's performance, in its
   current form, demonstrates a need for further refinement before its safe
   and effective implementation in facial aesthetic surgical practice.
ZA 0
ZS 0
TC 20
ZB 0
ZR 0
Z8 0
Z9 20
DA 2023-08-31
UT WOS:001050406400004
PM 37589944
ER

PT J
AU Alonso-Sanchez, Maria Francisca
   Hinzen, Wolfram
   He, Rui
   Gati, Joseph
   Palaniyappan, Lena
TI Perplexity of utterances in untreated first-episode psychosis: an
   ultra-high field MRI dynamic causal modelling study of the semantic
   network
SO JOURNAL OF PSYCHIATRY & NEUROSCIENCE
VL 49
IS 4
BP E252
EP E262
DI 10.1503/jpn.240031
DT Article
PD JUL-AUG 2024
PY 2024
AB Background: Psychosis involves a distortion of thought content, which is
   partly reflected in anomalous ways in which words are semantically
   connected into utterances in speech. We sought to explore how these
   linguistic anomalies are realized through putative circuit-level
   abnormalities in the brain's semantic network.Methods: Using a
   computational large-language model, Bidirectional Encoder
   Representations from Transformers (BERT), we quantified the contextual
   expectedness of a given word sequence (perplexity) across 180 samples
   obtained from descriptions of 3 pictures by patients with first-episode
   schizophrenia (FES) and controls matched for age, parental social
   status, and sex, scanned with 7 T ultra-high field functional magnetic
   resonance imaging (fMRI). Subsequently, perplexity was used to
   parametrize a spectral dynamic causal model (DCM) of the effective
   connectivity within (intrinsic) and between (extrinsic) 4 key regions of
   the semantic network at rest, namely the anterior temporal lobe, the
   inferior frontal gyrus (IFG), the posterior middle temporal gyrus (MTG),
   and the angular gyrus.Results: We included 60 participants, including 30
   patients with FES and 30 controls. We observed higher perplexity in the
   FES group, indicating that speech was less predictable by the preceding
   context among patients. Results of Bayesian model comparisons showed
   that a DCM including the group by perplexity interaction best explained
   the underlying patterns of neural activity. We observed an increase of
   self-inhibitory effective connectivity within the IFG, as well as
   reduced self-inhibitory tone within the pMTG, in the FES group. An
   increase in self-inhibitory tone in the IFG correlated strongly and
   positively with inter-regional excitation between the IFG and posterior
   MTG, while self-inhibition of the posterior MTG was negatively
   correlated with this interregional excitation.Limitation: Our design did
   not address connectivity in the semantic network during tasks that
   selectively activated the semantic network, which could corroborate
   findings from this resting-state fMRI study. Furthermore, we do not
   present a replication study, which would ideally use speech in a
   different language.Conclusion: As an explanation for peculiar speech in
   psychosis, these results index a shift in the excitatory-inhibitory
   balance regulating information flow across the semantic network,
   confined to 2 regions that were previously linked specifically to the
   executive control of meaning. Based on our approach of combining a large
   language model with causal connectivity estimates, we propose loss in
   semantic control as a potential neurocognitive mechanism contributing to
   disorganization in psychosis.
TC 3
ZR 0
Z8 0
ZB 1
ZS 0
ZA 0
Z9 3
DA 2024-08-16
UT WOS:001288854500001
PM 39122409
ER

PT J
AU Rosskopf, Steffen
   Meder, Benjamin
TI Healthcare 4.0-Medizin im Wandel
SO HERZ
VL 49
IS 5
BP 350
EP 354
DI 10.1007/s00059-024-05267-w
EA AUG 2024
DT Review
PD OCT 2024
PY 2024
AB Healthcare 4.0 describes the future transformation of the healthcare
   sector driven by the combination of digital technologies, such as
   artificial intelligence (AI), big data and the Internet of Medical
   Things, enabling the advancement of precision medicine. This overview
   article addresses various areas such as large language models (LLM),
   diagnostics and robotics, shedding light on the positive aspects of
   Healthcare 4.0 and showcasing exciting methods and application examples
   in cardiology. It delves into the broad knowledge base and enormous
   potential of LLMs, highlighting their immediate benefits as digital
   assistants or for administrative tasks. In diagnostics, the increasing
   usefulness of wearables is emphasized and an AI for predicting heart
   filling pressures based on cardiac magnetic resonance imaging (MRI) is
   introduced. Additionally, it discusses the revolutionary methodology of
   a digital simulation of the physical heart (digital twin). Finally, it
   addresses both regulatory frameworks and a brief vision of data-driven
   healthcare delivery, explaining the need for investments in technical
   personnel and infrastructure to achieve a more effective medicine.
Z8 0
ZB 0
ZS 0
ZA 0
TC 0
ZR 0
Z9 0
DA 2024-08-14
UT WOS:001287384100001
PM 39115627
ER

PT J
AU Leypold, Tim
   Lingens, Lara F.
   Beier, Justus P.
   Boos, Anja M.
TI Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4
   as a Consultation Assistant
SO LIFE-BASEL
VL 14
IS 5
AR 646
DI 10.3390/life14050646
DT Article
PD MAY 2024
PY 2024
AB The role of artificial intelligence (AI) in healthcare is evolving,
   offering promising avenues for enhancing clinical decision making and
   patient management. Limited knowledge about lipedema often leads to
   patients being frequently misdiagnosed with conditions like lymphedema
   or obesity rather than correctly identifying lipedema. Furthermore,
   patients with lipedema often present with intricate and extensive
   medical histories, resulting in significant time consumption during
   consultations. AI could, therefore, improve the management of these
   patients. This research investigates the utilization of OpenAI's
   Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large
   language model (LLM), as an assistant in consultations for lipedema
   patients. Six simulated scenarios were designed to mirror typical
   patient consultations commonly encountered in a lipedema clinic. GPT-4
   was tasked with conducting patient interviews to gather medical
   histories, presenting its findings, making preliminary diagnoses, and
   recommending further diagnostic and therapeutic actions. Advanced prompt
   engineering techniques were employed to refine the efficacy, relevance,
   and accuracy of GPT-4's responses. A panel of experts in lipedema
   treatment, using a Likert Scale, evaluated GPT-4's responses across six
   key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4
   achieving an average score of 4.24, indicating good reliability and
   applicability in a clinical setting. This study is one of the initial
   forays into applying large language models like GPT-4 in specific
   clinical scenarios, such as lipedema consultations. It demonstrates the
   potential of AI in supporting clinical practices and emphasizes the
   continuing importance of human expertise in the medical field, despite
   ongoing technological advancements.
ZA 0
ZB 0
TC 2
Z8 0
ZR 0
ZS 0
Z9 2
DA 2024-06-02
UT WOS:001232298600001
PM 38792666
ER

PT J
AU Wu, Yuqi
   Mao, Kaining
   Zhang, Yanbo
   Chen, Jie
TI CALLM: Enhancing Clinical Interview Analysis Through Data Augmentation
   With Large Language Models
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
VL 28
IS 12
BP 7531
EP 7542
DI 10.1109/JBHI.2024.3435085
DT Article
PD DEC 2024
PY 2024
AB The global prevalence of mental health disorders is increasing, leading
   to a significant economic burden estimated in trillions of dollars. In
   automated mental health diagnosis, the scarcity and imbalance of
   clinical data pose considerable challenges for researchers, limiting the
   effectiveness of machine learning algorithms. To cope with this issue,
   this paper aims to introduce a novel clinical transcript data
   augmentation framework by leveraging large language models (CALLM). The
   framework follows a "patient-doctor role-playing" intuition to generate
   realistic synthetic data. In addition, our study introduces a unique
   "Textbook-Assignment-Application" (T-A-A) partitioning approach to offer
   a systematic means of crafting synthetic clinical interview datasets.
   Concurrently, we have also developed a "Response-Reason" prompt
   engineering paradigm to generate highly authentic and diagnostically
   valuable transcripts. By leveraging a fine-tuned DistilBERT model on the
   E-DAIC PTSD dataset, we achieved a balanced accuracy of 0.77, an
   F1-score of 0.70, and an AUC of 0.78 during test set evaluations, which
   showcase robust adaptability in both Zero-Shot Learning (ZSL) and
   Few-Shot Learning (FSL) scenarios. We further compare the CALLM
   framework with other data augmentation methods and PTSD diagnostic works
   and demonstrates consistent improvements. Compared to conventional data
   collection methods, our synthetic dataset not only demonstrates superior
   performance but also incurs less than 1% of the associated costs.
Z8 0
ZS 0
ZB 0
ZR 0
TC 3
ZA 0
Z9 3
DA 2024-12-19
UT WOS:001373825400017
PM 39074002
ER

PT J
AU Riviere, Jacques G.
   Palacin, Pere Soler
   Butte, Manish J.
TI Proceedings from the inaugural Artificial Intelligence in Primary Immune
   Deficiencies (AIPID) conference
SO JOURNAL OF ALLERGY AND CLINICAL IMMUNOLOGY
VL 153
IS 3
BP 637
EP 642
DI 10.1016/j.jaci.2024.01.002
EA MAR 2024
DT Article
PD MAR 2024
PY 2024
AB Here, we summarize the proceedings of the inaugural Artificial
   Intelligence in Primary Immune Deficiencies conference, during which
   experts and advocates gathered to advance research into the applications
   of artificial intelligence (AI), machine learning, and other
   computational tools in the diagnosis and management of inborn errors of
   immunity (IEIs). The conference focused on the key themes of expediting
   IEI diagnoses, challenges in data collection, roles of natural language
   processing and large language models in interpreting electronic health
   records, and ethical considerations in implementation. Innovative AI
   -based tools trained on electronic health records and claims databases
   have discovered new patterns of warning signs for IEIs, facilitating
   faster diagnoses and enhancing patient outcomes. Challenges in training
   AIs persist on account of data limitations, especially in cases of rare
   diseases, overlapping phenotypes, and biases inherent in current data
   sets. Furthermore, experts highlighted the significance of ethical
   considerations, data protection, and the necessity for open science
   principles. The conference delved into regulatory frameworks, equity in
   access, and the imperative for collaborative efforts to overcome these
   obstacles and harness the transformative potential of AI. Concerted
   efforts to successfully integrate AI into daily clinical immunology
   practice are still needed. (J Allergy Clin Immunol 2024;153:637-42.)
ZB 0
ZA 0
ZR 0
TC 1
Z8 0
ZS 0
Z9 1
DA 2024-04-30
UT WOS:001203610200001
PM 38224784
ER

PT J
AU Ono, Daisuke
   Dickson, Dennis W.
   Koga, Shunsuke
TI Evaluating the efficacy of few-shot learning for GPT-4Vision in
   neurodegenerative disease histopathology: A comparative analysis with
   convolutional neural network model
SO NEUROPATHOLOGY AND APPLIED NEUROBIOLOGY
VL 50
IS 4
AR e12997
DI 10.1111/nan.12997
DT Article
PD AUG 2024
PY 2024
AB Aims: Recent advances in artificial intelligence, particularly with
   large language models like GPT-4Vision (GPT-4V)-a derivative feature of
   ChatGPT-have expanded the potential for medical image interpretation.
   This study evaluates the accuracy of GPT-4V in image classification
   tasks of histopathological images and compares its performance with a
   traditional convolutional neural network (CNN). Methods: We utilised
   1520 images, including haematoxylin and eosin staining and tau
   immunohistochemistry, from patients with various neurodegenerative
   diseases, such as Alzheimer's disease (AD), progressive supranuclear
   palsy (PSP) and corticobasal degeneration (CBD). We assessed GPT-4V's
   performance using multi-step prompts to determine how textual context
   influences image interpretation. We also employed few-shot learning to
   enhance improvements in GPT-4V's diagnostic performance in classifying
   three specific tau lesions-astrocytic plaques, neuritic plaques and
   tufted astrocytes-and compared the outcomes with the CNN model YOLOv8.
   Results: GPT-4V accurately recognised staining techniques and tissue
   origin but struggled with specific lesion identification. The
   interpretation of images was notably influenced by the provided textual
   context, which sometimes led to diagnostic inaccuracies. For instance,
   when presented with images of the motor cortex, the diagnosis shifted
   inappropriately from AD to CBD or PSP. However, few-shot learning
   markedly improved GPT-4V's diagnostic capabilities, enhancing accuracy
   from 40% in zero-shot learning to 90% with 20-shot learning, matching
   the performance of YOLOv8, which required 100-shot learning to achieve
   the same accuracy. Conclusions: Although GPT-4V faces challenges in
   independently interpreting histopathological images, few-shot learning
   significantly improves its performance. This approach is especially
   promising for neuropathology, where acquiring extensive labelled
   datasets is often challenging.
Z8 0
ZA 0
ZB 0
ZS 0
TC 9
ZR 0
Z9 9
DA 2024-07-27
UT WOS:001272403000001
PM 39010256
ER

PT J
AU Djulbegovic, Mak B.
   Bair, Henry
   Gonzalez, David J. Taylor
   Ishikawa, Hiroshi
   Wollstein, Gadi
   Schuman, Joel S.
TI Artificial Intelligence for Optical Coherence Tomography in Glaucoma
SO TRANSLATIONAL VISION SCIENCE & TECHNOLOGY
VL 14
IS 1
AR 27
DI 10.1167/tvst.14.1.27
DT Review
PD JAN 2025
PY 2025
AB Purpose: The integration of artificial intelligence (AI), particularly
   deep learning (DL), with optical coherence tomography (OCT) offers
   significant opportunities in the diagnosis and management of glaucoma.
   This article explores the application of various DL models in enhancing
   OCT capabilities and addresses the challenges associated with their
   clinical implementation. Methods: A review of articles utilizing DL
   models was conducted, including convolutional neural networks (CNNs),
   recurrent neural networks (RNNs), generative adversarial networks
   (GANs), autoencoders, and large language models (LLMs). Key developments
   and practical applications of these models in OCT image analysis were
   emphasized, particularly in the context of enhancing image quality,
   glaucoma diagnosis, and monitoring progression. Results: CNNs excel in
   segmenting retinal layers and detecting glaucomatous damage, whereas
   RNNs are effective in analyzing sequential OCT scans for disease
   progression. GANs enhance image quality and data augmentation, and
   autoencoders facilitate advanced feature extraction. LLMs show promise
   in integrating textual and visual data for comprehensive diagnostic
   assessments. Despite these advancements, challenges such as data
   availability, variability, potential biases, and the need for extensive
   validation persist. Conclusions: DL models are reshaping glaucoma
   management by enhancing OCT's diagnostic capabilities. However, the
   successful translation into clinical practice requires addressing major
   challenges related to data variability, biases, fairness, and model
   validation to ensure accurate and reliable patient care. Translational
   Relevance: This review bridges the gap between basic research and
   clinical care by demonstrating how AI, particularly DL models, can
   markedly enhance OCT's clinical utility in diagnosis, monitoring, and
   prediction, moving toward more individualized, personalized, and precise
   treatment strategies.
ZR 0
Z8 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
DA 2025-04-11
UT WOS:001461389800004
PM 39854198
ER

PT J
AU Mora, J.
   Chen, S.
   Mak, R. H.
   Bitterman, D. S.
TI Cancer Treatment Information Differences by Bilingual Prompting in Large
   Language Model Chatbots
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3415
BP E645
EP E646
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
ZB 0
TC 0
ZA 0
ZR 0
Z8 0
Z9 0
DA 2024-12-16
UT WOS:001325892302096
ER

PT J
AU Ghalibafan, Seyyedehfatemeh
   Gonzalez, David J. Taylor
   Cai, Louis Z.
   Chou, Brandon Graham
   Panneerselvam, Sugi
   Barrett, Spencer Conrad
   Djulbegovic, Mak B.
   Yannuzzi, Nicolas A.
TI APPLICATIONS OF MULTIMODAL GENERATIVE ARTIFICIAL INTELLIGENCE IN A
   REAL-WORLD RETINA CLINIC SETTING
SO RETINA-THE JOURNAL OF RETINAL AND VITREOUS DISEASES
VL 44
IS 10
BP 1732
EP 1740
DI 10.1097/IAE.0000000000004204
DT Article
PD OCT 2024
PY 2024
AB Supplemental Digital Content is Available in the Text.Generative
   Pre-trained Transformer 4 with vision aids clinical care and medical
   record keeping using standardized multiple-choice questions. Its
   effectiveness in complex, open-ended medical scenarios, especially in
   retina clinics, is limited, highlighting constraints in offering ocular
   health advice.
   Purpose:This study evaluates a large language model, Generative
   Pre-trained Transformer 4 with vision, for diagnosing vitreoretinal
   diseases in real-world ophthalmology settings.Methods:A retrospective
   cross-sectional study at Bascom Palmer Eye Clinic, analyzing patient
   data from January 2010 to March 2023, assesses Generative Pre-trained
   Transformer 4 with vision's performance on retinal image analysis and
   International Classification of Diseases 10th revision coding across 2
   patient groups: simpler cases (Group A) and complex cases (Group B)
   requiring more in-depth analysis. Diagnostic accuracy was assessed
   through open-ended questions and multiple-choice questions independently
   verified by three retina specialists.Results:In 256 eyes from 143
   patients, Generative Pre-trained Transformer 4-V demonstrated a 13.7%
   accuracy for open-ended questions and 31.3% for multiple-choice
   questions, with International Classification of Diseases 10th revision
   code accuracies at 5.5% and 31.3%, respectively. Accurately diagnosed
   posterior vitreous detachment, nonexudative age-related macular
   degeneration, and retinal detachment. International Classification of
   Diseases 10th revision coding was most accurate for nonexudative
   age-related macular degeneration, central retinal vein occlusion, and
   macular hole in OEQs, and for posterior vitreous detachment,
   nonexudative age-related macular degeneration, and retinal detachment in
   multiple-choice questions. No significant difference in diagnostic or
   coding accuracy was found in Groups A and B.Conclusion:Generative
   Pre-trained Transformer 4 with vision has potential in clinical care and
   record keeping, particularly with standardized questions. Its
   effectiveness in open-ended scenarios is limited, indicating a
   significant limitation in providing complex medical advice.
Z8 0
TC 3
ZR 0
ZA 0
ZB 0
ZS 0
Z9 3
DA 2024-10-23
UT WOS:001334163300013
PM 39287535
ER

PT J
AU Sezgin, Emre
   Jackson, Daniel I.
   Kocaballi, A. Baki
   Bibart, Mindy
   Zupanec, Sue
   Landier, Wendy
   Audino, Anthony
   Ranalli, Mark
   Skeens, Micah
TI Can Large Language Models Aid Caregivers of Pediatric Cancer Patients in
   Information Seeking? A Cross-Sectional Investigation
SO CANCER MEDICINE
VL 14
IS 1
AR e70554
DI 10.1002/cam4.70554
DT Article
PD JAN 2025
PY 2025
AB PurposeCaregivers in pediatric oncology need accurate and understandable
   information about their child's condition, treatment, and side effects.
   This study assesses the performance of publicly accessible large
   language model (LLM)-supported tools in providing valuable and reliable
   information to caregivers of children with cancer. MethodsIn this
   cross-sectional study, we evaluated the performance of the four
   LLM-supported tools-ChatGPT (GPT-4), Google Bard (Gemini Pro), Microsoft
   Bing Chat, and Google SGE-against a set of frequently asked questions
   (FAQs) derived from the Children's Oncology Group Family Handbook and
   expert input (In total, 26 FAQs and 104 generated responses). Five
   pediatric oncology experts assessed the generated LLM responses using
   measures including accuracy, clarity, inclusivity, completeness,
   clinical utility, and overall rating. Additionally, the content quality
   was evaluated including readability, AI disclosure, source credibility,
   resource matching, and content originality. We used descriptive analysis
   and statistical tests including Shapiro-Wilk, Levene's, Kruskal-Wallis
   H-tests, and Dunn's post hoc tests for pairwise comparisons.
   ResultsChatGPT shows high overall performance when evaluated by the
   experts. Bard also performed well, especially in accuracy and clarity of
   the responses, whereas Bing Chat and Google SGE had lower overall
   scores. Regarding the disclosure of responses being generated by AI, it
   was observed less frequently in ChatGPT responses, which may have
   affected the clarity of responses, whereas Bard maintained a balance
   between AI disclosure and response clarity. Google SGE generated the
   most readable responses whereas ChatGPT answered with the most
   complexity. LLM tools varied significantly (p < 0.001) across all expert
   evaluations except inclusivity. Through our thematic analysis of expert
   free-text comments, emotional tone and empathy emerged as a unique theme
   with mixed feedback on expectations from AI to be empathetic.
   ConclusionLLM-supported tools can enhance caregivers' knowledge of
   pediatric oncology. Each model has unique strengths and areas for
   improvement, indicating the need for careful selection based on specific
   clinical contexts. Further research is required to explore their
   application in other medical specialties and patient demographics,
   assessing broader applicability and long-term impacts.
ZA 0
TC 2
Z8 0
ZS 0
ZB 1
ZR 0
Z9 2
DA 2025-01-13
UT WOS:001391811100001
PM 39776222
ER

PT J
AU Khanmohammadi, R.
   Ghanem, A. I.
   Verdecchia, K.
   Hall, R.
   Elshaikh, M. A.
   Movsas, B.
   Bagher-Ebadian, H.
   Chetty, I. J.
   Ghassemi, M. M.
   Thind, K.
TI A Novel Localized Student-Teacher LLM for Enhanced Toxicity Extraction
   in Radiation Oncology
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3388
BP E632
EP E633
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
Z8 0
TC 0
ZB 0
ZR 0
ZA 0
ZS 0
Z9 0
DA 2024-12-16
UT WOS:001325892302069
ER

PT J
AU Goh, Ethan
   Gallo, Robert
   Hom, Jason
   Strong, Eric
   Weng, Yingjie
   Kerman, Hannah
   Cool, Josephine A.
   Kanjee, Zahir
   Parsons, Andrew S.
   Ahuja, Neera
   Horvitz, Eric
   Yang, Daniel
   Milstein, Arnold
   Olson, Andrew P. J.
   Rodman, Adam
   Chen, Jonathan H.
TI Large Language Model Influence on Diagnostic Reasoning A Randomized
   Clinical Trial
SO JAMA NETWORK OPEN
VL 7
IS 10
AR e2440969
DI 10.1001/jamanetworkopen.2024.40969
DT Article
PD OCT 28 2024
PY 2024
AB IMPORTANCE Large language models (LLMs) have shown promise in their
   performance on both multiple-choice and open-ended medical reasoning
   examinations, but it remains unknown whether the use of such tools
   improves physician diagnostic reasoning. OBJECTIVE To assess the effect
   of an LLM on physicians' diagnostic reasoning compared with conventional
   resources. DESIGN, SETTING, AND PARTICIPANTS A single-blind randomized
   clinical trial was conducted from November 29 to December 29, 2023.
   Using remote video conferencing and in-person participation across
   multiple academic medical institutions, physicians with training in
   family medicine, internal medicine, or emergency medicine were
   recruited. INTERVENTION Participants were randomized to either access
   the LLM in addition to conventional diagnostic resources or conventional
   resources only, stratified by career stage. Participants were allocated
   60 minutes to review up to 6 clinical vignettes. MAIN OUTCOMES AND
   MEASURES The primary outcome was performance on a standardized rubric of
   diagnostic performance based on differential diagnosis accuracy,
   appropriateness of supporting and opposing factors, and next diagnostic
   evaluation steps, validated and graded via blinded expert consensus.
   Secondary outcomes included time spent per case (in seconds) and final
   diagnosis accuracy. All analyses followed the intention-to-treat
   principle. A secondary exploratory analysis evaluated the standalone
   performance of the LLM by comparing the primary outcomes between the LLM
   alone group and the conventional resource group. RESULTS Fifty
   physicians (26 attendings, 24 residents; median years in practice, 3
   [IQR, 2-8]) participated virtually as well as at 1 in-person site. The
   median diagnostic reasoning score per case was 76% (IQR, 66%-87%) for
   the LLM group and 74% (IQR, 63%-84%) for the conventional resources-only
   group, with an adjusted difference of 2 percentage points (95% CI, -4 to
   8 percentage points; P = .60). The median time spent per case for the
   LLM group was 519 (IQR, 371-668) seconds, compared with 565 (IQR,
   456-788) seconds for the conventional resources group, with a time
   difference of -82 (95% CI, -195 to 31; P = .20) seconds. The LLM alone
   scored 16 percentage points (95% CI, 2-30 percentage points; P = .03)
   higher than the conventional resources group. CONCLUSIONS AND RELEVANCE
   In this trial, the availability of an LLM to physicians as a diagnostic
   aid did not significantly improve clinical reasoning compared with
   conventional resources. The LLM alone demonstrated higher performance
   than both physician groups, indicating the need for technology and
   workforce development to realize the potential of physician-artificial
   intelligence collaboration in clinical practice.
ZB 9
Z8 0
ZS 0
ZA 0
TC 81
ZR 0
Z9 81
DA 2024-11-11
UT WOS:001346416900001
PM 39466245
ER

PT J
AU Scuricini, Alessandro
   Ramoni, Davide
   Liberale, Luca
   Montecucco, Fabrizio
   Carbone, Federico
TI The role of artificial intelligence in cardiovascular research: Fear
   less and live bolder
SO EUROPEAN JOURNAL OF CLINICAL INVESTIGATION
VL 55
SI SI
AR e14364
DI 10.1111/eci.14364
SU 1
DT Review
PD APR 2025
PY 2025
AB BackgroundArtificial intelligence (AI) has captured the attention of
   everyone, including cardiovascular (CV) clinicians and scientists.
   Moving beyond philosophical debates, modern cardiology cannot overlook
   AI's growing influence but must actively explore its potential
   applications in clinical practice and research methodology.Methods and
   ResultsAI offers exciting possibilities for advancing CV medicine by
   uncovering disease heterogeneity, integrating complex multimodal data,
   and enhancing treatment strategies. In this review, we discuss the
   innovative applications of AI in cardiac electrophysiology, imaging,
   angiography, biomarkers, and genomic data, as well as emerging tools
   like face recognition and speech analysis. Furthermore, we focus on the
   expanding role of machine learning (ML) in predicting CV risk and
   outcomes, outlining a roadmap for the implementation of AI in CV care
   delivery. While the future of AI holds great promise, technical
   limitations and ethical challenges remain significant barriers to its
   widespread clinical adoption.ConclusionsAddressing these issues through
   the development of high-quality standards and involving key stakeholders
   will be essential for AI to transform cardiovascular care safely and
   effectively.
ZS 0
ZR 0
TC 1
ZB 0
Z8 0
ZA 0
Z9 1
DA 2025-04-12
UT WOS:001460920400008
PM 40191936
ER

PT J
AU Wang, Yuli
   Hsu, Wen-Chi
   Dai, Yuwei
   Shi, Victoria
   Lin, Gigin
   Bai, Harrison
   Lin, Cheng Ting
TI Automatic assignment of CAD-RADS categories in coronary CTA reports
   using large language model
SO CIRCULATION
VL 150
MA 4119869
DI 10.1161/circ.150.suppl_1.4119869
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
ZS 0
ZA 0
TC 0
ZR 0
Z8 0
ZB 0
Z9 0
DA 2025-02-10
UT WOS:001398742700217
ER

PT J
AU Casals-Farre, Octavi
   Baskaran, Ravanth
   Singh, Aditya
   Kaur, Harmeena
   Ul Hoque, Tazim
   de Almeida, Andreia
   Coffey, Marcus
   Hassoulas, Athanasios
TI Assessing ChatGPT 4.0's Capabilities in the United Kingdom Medical
   Licensing Examination (UKMLA): A Robust Categorical Analysis
SO SCIENTIFIC REPORTS
VL 15
IS 1
AR 13031
DI 10.1038/s41598-025-97327-2
DT Article
PD APR 15 2025
PY 2025
AB Advances in the various applications of artificial intelligence will
   have important implications for medical training and practice. The
   advances in ChatGPT-4 alongside the introduction of the medical
   licensing assessment (MLA) provide an opportunity to compare GPT-4's
   medical competence against the expected level of a United Kingdom junior
   doctor and discuss its potential in clinical practice. Using 191 freely
   available questions in MLA style, we assessed GPT-4's accuracy with and
   without offering multiple-choice options. We compared single and
   multi-step questions, which targeted different points in the clinical
   process, from diagnosis to management. A chi-squared test was used to
   assess statistical significance. GPT-4 scored 86.3% and 89.6% in papers
   one-and-two respectively. Without the multiple-choice options, GPT's
   performance was 61.5% and 74.7% in papers one-and-two respectively.
   There was no significant difference between single and multistep
   questions, but GPT-4 answered 'management' questions significantly worse
   than 'diagnosis' questions with no multiple-choice options (p = 0.015).
   GPT-4's accuracy across categories and question structures suggest that
   LLMs are competently able to process clinical scenarios but remain
   incapable of understanding these clinical scenarios.
   Large-Language-Models incorporated into practice alongside a trained
   practitioner may balance risk and benefit as the necessary robust
   testing on evolving tools is conducted.
ZR 0
Z8 0
TC 1
ZB 0
ZS 0
ZA 0
Z9 1
DA 2025-04-27
UT WOS:001468488100021
PM 40234701
ER

PT J
AU Putman, Tim E.
   Schaper, Kevin
   Matentzoglu, Nicolas
   Rubinetti, Vincent P.
   Alquaddoomi, Faisal S.
   Cox, Corey
   Caufield, J. Harry
   Elsarboukh, Glass
   Gehrke, Sarah
   Hegde, Harshad
   Reese, Justin T.
   Braun, Ian
   Bruskiewich, Richard M.
   Cappelletti, Luca
   Carbon, Seth
   Caron, Anita R.
   Chan, Lauren E.
   Chute, Christopher G.
   Cortes, Katherina G.
   De Souza, Vinicius
   Fontana, Tommaso
   Harris, Nomi L.
   Hartley, Emily L.
   Hurwitz, Eric
   Jacobsen, Julius O. B.
   Krishnamurthy, Madan
   Laraway, Bryan J.
   McLaughlin, James A.
   McMurry, Julie A.
   Moxon, Sierra A. T.
   Mullen, Kathleen R.
   O'Neil, Shawn T.
   Shefchek, Kent A.
   Stefancsik, Ray
   Toro, Sabrina
   Vasilevsky, Nicole A.
   Walls, Ramona L.
   Whetzel, Patricia L.
   Osumi-Sutherland, David
   Smedley, Damian
   Robinson, Peter N.
   Mungall, Christopher J.
   Haendel, Melissa A.
   Munoz-Torres, Monica C.
TI The Monarch Initiative in 2024: an analytic platform integrating
   phenotypes, genes and diseases across species
SO NUCLEIC ACIDS RESEARCH
VL 52
IS D1
BP D938
EP D949
DI 10.1093/nar/gkad1082
EA NOV 2023
DT Article
PD NOV 24 2023
PY 2023
AB Bridging the gap between genetic variations, environmental determinants,
   and phenotypic outcomes is critical for supporting clinical diagnosis
   and understanding mechanisms of diseases. It requires integrating open
   data at a global scale. The Monarch Initiative advances these goals by
   developing open ontologies, semantic data models, and knowledge graphs
   for translational research. The Monarch App is an integrated platform
   combining data about genes, phenotypes, and diseases across species.
   Monarch's APIs enable access to carefully curated datasets and advanced
   analysis tools that support the understanding and diagnosis of disease
   for diverse applications such as variant prioritization, deep
   phenotyping, and patient profile-matching. We have migrated our system
   into a scalable, cloud-based infrastructure; simplified Monarch's data
   ingestion and knowledge graph integration systems; enhanced data mapping
   and integration standards; and developed a new user interface with novel
   search and graph navigation features. Furthermore, we advanced Monarch's
   analytic tools by developing a customized plugin for OpenAI's ChatGPT to
   increase the reliability of its responses about phenotypic data,
   allowing us to interrogate the knowledge in the Monarch graph using
   state-of-the-art Large Language Models. The resources of the Monarch
   Initiative can be found at monarchinitiative.org and its corresponding
   code repository at github.com/monarch-initiative/monarch-app.
   Graphical Abstract
ZA 0
ZR 0
ZS 0
TC 20
Z8 0
ZB 9
Z9 20
DA 2023-12-06
UT WOS:001107819200001
PM 38000386
ER

PT J
AU Zhang, Junxiu
   Ma, Yao
   Zhang, Rong
   Chen, Yanhua
   Xu, Mengyao
   Su, Rina
   Ma, Ke
TI A comparative study of GPT-4o and human ophthalmologists in glaucoma
   diagnosis
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 30385
DI 10.1038/s41598-024-80917-x
DT Article
PD DEC 5 2024
PY 2024
AB Artificial intelligence (AI), particularly large language models like
   GPT-4o, holds promise for enhancing diagnostic accuracy in healthcare.
   This study evaluates the diagnostic performance of GPT-4o compared to
   human ophthalmologists in glaucoma cases. A prospective, observational
   study was conducted at a tertiary care ophthalmology center. Twenty-six
   glaucoma cases, including both primary and secondary types, were
   selected from publicly available databases and institutional records.
   The cases were analyzed by GPT-4o and three ophthalmologists with
   varying levels of experience. The accuracy and completeness of primary
   and differential diagnoses were assessed using 10-point and 6-point
   Likert scales, respectively. Statistical analyses were performed using
   nonparametric methods, including the Kruskal-Wallis and Mann-Whitney U
   tests. GPT-4o was significantly less accurate in primary diagnosis
   compared to human ophthalmologists. Specifically, GPT-4o achieved a mean
   score of 5.500 (p < 0.001) compared to Doctor C, who had the highest
   score of 8.038 (p < 0.001). Completeness scores for GPT-4o 3.077 (p <
   0.001) were also lower than Doctor B, who had the lowest score of 3.615
   (p < 0.001) among human ophthalmologists. However, for differential
   diagnosis, GPT-4o (7.577) showed comparable accuracy to Doctor A (7.615)
   and Doctor C (7.673) (p < 0.0001) while achieving the highest
   completeness score (4.096), outperforming Doctor C (3.846), Doctor A
   (2.923), and Doctor B (2.808) (p < 0.0001). AI, including GPT-4o, is
   currently not an acceptable standalone method for diagnosing glaucoma
   due to its lower accuracy compared to human clinicians. These findings
   suggest that GPT-4o could serve as a valuable adjunct in clinical
   practice, particularly in complex cases, but should not replace human
   expertise, especially for initial diagnoses. Future improvements in AI
   models could enhance their utility in ophthalmology.
Z8 0
ZS 0
TC 1
ZA 0
ZR 0
ZB 0
Z9 1
DA 2024-12-21
UT WOS:001373816800044
PM 39639068
ER

PT J
AU Garcia-Mendez, Silvia
   de Arriba-Perez, Francisco
TI Large Language Models and Healthcare Alliance: Potential and Challenges
   of Two Representative Use Cases
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 52
IS 8
BP 1928
EP 1931
DI 10.1007/s10439-024-03454-8
EA FEB 2024
DT Article
PD AUG 2024
PY 2024
AB Large language models (LLMS) emerge as the most promising Natural
   Language Processing approach for clinical practice acceleration (i.e.,
   diagnosis, prevention and treatment procedures). Similarly, intelligent
   conversational systems that leverage LLMS have disruptively become the
   future of therapy in the era of Chatgpt. Accordingly, this research
   addresses the application of LLMS in healthcare, paying particular
   attention to two relevant use cases: cognitive decline and depression,
   more specifically, postpartum depression. In the end, the most promising
   opportunities they represent (e.g., clinical tasks augmentation,
   personalized healthcare, etc.) and related concerns (e.g., data privacy
   and quality, fairness, etc.) are discussed to contribute to the global
   debate on their integration in the sanitary system.
ZR 0
TC 5
ZB 1
ZA 0
ZS 0
Z8 0
Z9 5
DA 2024-02-11
UT WOS:001156157700001
PM 38310159
ER

PT J
AU Chen, Xiaolan
   Zhang, Weiyi
   Zhao, Ziwei
   Xu, Pusheng
   Zheng, Yingfeng
   Shi, Danli
   He, Mingguang
TI ICGA-GPT: report generation and question answering for indocyanine green
   angiography images
SO BRITISH JOURNAL OF OPHTHALMOLOGY
VL 108
IS 10
BP 1450
EP 1456
DI 10.1136/bjo-2023-324446
EA MAR 2024
DT Article
PD OCT 2024
PY 2024
AB Background Indocyanine green angiography (ICGA) is vital for diagnosing
   chorioretinal diseases, but its interpretation and patient communication
   require extensive expertise and time-consuming efforts. We aim to
   develop a bilingual ICGA report generation and question-answering (QA)
   system.
   Methods Our dataset comprised 213 129 ICGA images from 2919
   participants. The system comprised two stages: image-text alignment for
   report generation by a multimodal transformer architecture, and large
   language model (LLM)-based QA with ICGA text reports and human-input
   questions. Performance was assessed using both qualitative metrics
   (including Bilingual Evaluation Understudy (BLEU), Consensus-based Image
   Description Evaluation (CIDEr), Recall-Oriented Understudy for Gisting
   Evaluation-Longest Common Subsequence (ROUGE-L), Semantic Propositional
   Image Caption Evaluation (SPICE), accuracy, sensitivity, specificity,
   precision and F1 score) and subjective evaluation by three experienced
   ophthalmologists using 5-point scales (5 refers to high quality).
   Results We produced 8757 ICGA reports covering 39 disease-related
   conditions after bilingual translation (66.7% English, 33.3% Chinese).
   The ICGA-GPT model's report generation performance was evaluated with
   BLEU scores (1-4) of 0.48, 0.44, 0.40 and 0.37; CIDEr of 0.82; ROUGE of
   0.41 and SPICE of 0.18. For disease-based metrics, the average
   specificity, accuracy, precision, sensitivity and F1 score were 0.98,
   0.94, 0.70, 0.68 and 0.64, respectively. Assessing the quality of 50
   images (100 reports), three ophthalmologists achieved substantial
   agreement (kappa=0.723 for completeness, kappa=0.738 for accuracy),
   yielding scores from 3.20 to 3.55. In an interactive QA scenario
   involving 100 generated answers, the ophthalmologists provided scores of
   4.24, 4.22 and 4.10, displaying good consistency (kappa=0.779).
   Conclusion This pioneering study introduces the ICGA-GPT model for
   report generation and interactive QA for the first time, underscoring
   the potential of LLMs in assisting with automated ICGA image
   interpretation.
ZS 0
TC 10
ZB 3
ZR 0
Z8 0
ZA 0
Z9 10
DA 2024-03-30
UT WOS:001189002900001
PM 38508675
ER

PT J
AU Tustumi, Francisco
   Andreollo, Nelson Adami
   de Aguilar-Nascimento, Jose Eduardo
TI FUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT
SO ABCD-ARQUIVOS BRASILEIROS DE CIRURGIA DIGESTIVA-BRAZILIAN ARCHIVES OF
   DIGESTIVE SURGERY
VL 36
IS 1
AR e1727
DI 10.1590/0102-672020230002e1727
DT Review
PD 2023
PY 2023
AB The field of medicine has always been at the forefront of technological
   innovation, Fabricio Ferreira COELHO3 , Paulo HERMAN3 constantly seeking
   new strategies to diagnose, treat, and prevent diseases. Guidelines for
   clinical practice to orientate medical teams regarding diagnosis,
   treatment, and prevention measures have increased over the years. The
   purpose is to gather the most medical knowledge to construct an
   orientation for practice. Evidence-based guidelines follow several main
   characteristics of a systematic RESUMO -Racmonal: O tratamento de
   escolha para pacientes com ipertensao portal review, including
   systematic and unbiased search, selection, and extraction of the source
   of evidence. esquistossomotica com sangramento de varizes e a desconexao
   azigo-portal mais In recent years, the rapid advancement of artificial
   intelligence has provided clinicians and patients esplenetomia (DAPE)
   associad a terapa endoscoica. Porem, estuds mostram aumento with access
   to personalized, data-driven insights, suport and new opportunities for
   healthcare do calibre das varizes em alguns pacientes durante o
   seguimento em longo prazo. Objetmvo: professionals to improve patient
   outcomes, increase efficiency, and reduce costs. One of the most Avaliar
   o impacto da DAPE e tratamento endoscopico pos-operatorio no
   comportamento exciting developments in Artificial Intelligence has been
   the emergence of chatbots. A chatbot is a computer program used to
   simulate conversations with human users. Recently, OpenAI, a research
   das varizes esofagicas e recidiva hemorragica, de pacientes
   esquistossomoticos. Metodos: organization focused on machine learning,
   developed ChatGPT, a large language model that Foram estudados 36
   pacientes com eguimento superior a cinco anos, distribuidos em generates
   human-like text. ChatGPT uses a type of AI known as a deep learning
   model. ChatGPT dois grupos: qued a prssao portal abaixo de 30% e acima
   de 30% compaados com o can quickly search a nd select pieces of evidence
   through numerous databases to provide answers calibre das varizes
   esofagicas no pos-operatorio precoce e tardio alem do indice de recidiva
   to complex questions, reducing the time and effort required to research
   a particular topic manually. hemorragica. Resultados Consequently,
   language models can accelerate the creation of clinical practice
   guidelines. While there is no doubt that ChatGPT has the potential to
   revolutionize the way healthcare is delivered, esofagicas que, durante o
   seguimento aumentaram de calibre e foram controladas com it is essential
   to note that it should not be used as a substitute for human healthcare
   professionals. Instead, ChatGPT should be considered a tool that can be
   used to augment and support the work of o comportamento do calibre das
   varizes no pos-opeatorio precoce nem tardio nem os healthcare
   professionals, helping them to provide better care to their patients.
ZB 6
TC 41
ZR 0
ZA 0
Z8 0
ZS 1
Z9 41
DA 2023-06-08
UT WOS:000993819100001
PM 37162073
ER

PT J
AU Vishwanath, Varnita
   Marchand, Greg J.
   Azadi, Ali
TI Case Report of a Large Endometrioma Precipitating a Hypertensive
   Emergency
SO OBSTETRICS AND GYNECOLOGY
VL 143
IS 5S
MA 2683395
BP 13S
EP 13S
DI 10.1097/01.AOG.0001013020.29174.7f
SU 5
DT Meeting Abstract
PD MAY 2024
PY 2024
CT 72nd Annual Clinical and Scientific Meeting of the
   American-College-of-Obstetricians-and-Gynecologists
CY MAY 17-19, 2024
CL San Francisco, CA
SP Amer Coll Obstetricians & Gynecologists
Z8 0
ZR 0
ZS 0
ZB 0
ZA 0
TC 0
Z9 0
DA 2024-07-14
UT WOS:001258908200201
ER

PT J
AU Chen, Anjun
   Liu, Lei
   Zhu, Tongyu
TI Advancing the democratization of generative artificial intelligence in
   healthcare: a narrative review
SO JOURNAL OF HOSPITAL MANAGEMENT AND HEALTH POLICY
VL 8
AR 12
DI 10.21037/jhmhp-24-54
DT Article
PD JUN 30 2024
PY 2024
AB Background and Objective: The emergence of ChatGPT-like generative
   artificial intelligence (GenAI) has dramatically transformed the
   healthcare landscape, bringing new hope for the democratization of
   artificial intelligence (AI) in healthcare-a topic that has not been
   comprehensively reviewed. This review aims to analyze the reasons
   propelling the democratization of healthcare GenAI, outline the initial
   evidence in the literature, and propose future directions to advance
   GenAI democratization. Methods: We conducted a deep literature search
   for GenAI studies using Google Scholar, PubMed, ChatGPT, Journal of the
   American Medical Association ( JAMA ), Nature, , Springer Link, and
   Journal of Medical Internet Research (JMIR). JMIR ). We performed an
   abstraction analysis on the nature of GenAI versus traditional AI and
   the applications of GenAI in medical education and clinical care. Key
   Content and Findings: (I) A detailed comparison of traditional and GenAI
   in healthcare reveals that large language model (LLM)-based GenAI's
   unprecedent general-purpose capabilities and natural language
   interaction ability, coupled with its free public availability, make
   GenAI ideal for democratization in healthcare. (II) We have identified
   plenty of initial evidence for GenAI democratization in medical
   education and clinical care, marking the start of the emerging trend of
   GenAI democratization in a host of impactful applications. Applications
   in medical education include medical exam preparation, medical teaching
   and training, and simulation. Applications in clinical care include
   diagnosis assistance, disease risk prediction, new generalist chatbots,
   treatment decision support, surgery support, medical image analysis,
   patient communication, physician communication, documentation
   automation, clinical trial automation, informatics tasks automation, and
   specialized or custom LLMs. (III) Responsible AI is essential for the
   future of healthcare GenAI. National initiatives and regulatory efforts
   are working to ensure safety, efficacy, accountability, equity, security
   and privacy are built into healthcare GenAI. Responsible GenAI requires
   a human-machine collaboration approach, where AI augments human
   expertise rather than replaces it. Conclusions: The democratization of
   GenAI in healthcare has just begun, driven by the nature of GenAI and
   guided by the principle of human-machine collaboration. To further
   advance GenAI democratization, we propose three key future directions:
   integrating GenAI in medical education curricula, democratizing GenAI
   clinical evaluation research, and building learning health systems (LHS)
   with GenAI for system- level enforcement of democratization.
   Democratizing GenAI in healthcare will revolutionize medicine and
   significantly impact care delivery and health policies.
ZR 0
TC 3
ZB 1
ZA 0
ZS 0
Z8 0
Z9 3
DA 2024-08-08
UT WOS:001281635300002
ER

PT J
AU Sheng, Bin
   Guan, Zhouyu
   Lim, Lee-Ling
   Jiang, Zehua
   Mathioudakis, Nestoras
   Li, Jiajia
   Liu, Ruhan
   Bao, Yuqian
   Bee, Yong Mong
   Wang, Ya-Xing
   Zheng, Yingfeng
   Tan, Gavin Siew Wei
   Ji, Hongwei
   Car, Josip
   Wang, Haibo
   Klonoff, David C.
   Li, Huating
   Tham, Yih-Chung
   Wong, Tien Yin
   Jia, Weiping
TI Large language models for diabetes care: Potentials and prospects
SO SCIENCE BULLETIN
VL 69
IS 5
BP 583
EP 588
DI 10.1016/j.scib.2024.01.004
EA MAR 2024
DT Editorial Material
PD MAR 15 2024
PY 2024
Z8 1
ZB 2
ZR 0
TC 27
ZS 0
ZA 0
Z9 27
DA 2024-05-25
UT WOS:001226928500001
PM 38220476
ER

PT J
AU Furukawa, Toshi A.
   Iwata, Susumu
   Horikoshi, Masaru
   Sakata, Masatsugu
   Toyomoto, Rie
   Luo, Yan
   Tajika, Aran
   Kudo, Noriko
   Aramaki, Eiji
TI Harnessing AI to Optimize Thought Records and Facilitate Cognitive
   Restructuring in Smartphone CBT: An Exploratory Study
SO COGNITIVE THERAPY AND RESEARCH
VL 47
IS 6
BP 887
EP 893
DI 10.1007/s10608-023-10411-7
EA JUL 2023
DT Article
PD DEC 2023
PY 2023
AB BackgroundEffective cognitive restructuring (CR) requires identification
   of automatic thoughts that underlie experienced emotions. However,
   accurate recording of thoughts and emotions is challenging when CR is
   provided in internet cognitive-behavior therapy (iCBT). This study
   investigated the potential use of the artificial intelligence (AI)
   including the natural language processing (NLP) to facilitate CR offered
   in iCBT.MethodsWe applied the Japanese Text-to-Text Transfer Transformer
   (T5), one of the most advanced Large Language Models for the NLP,to
   records of thought-feeling pairs provided by participants in two
   randomized controlled trials of iCBT. We conducted threefold
   cross-validated prediction of self-reported feelings based on recorded
   thoughts. We examined the validity of the predictions by checking them
   against the human expert judgments and by the efficacy when the thought
   records were subjected to CR.Results1626 participants provided 4369
   though-feeling records. The overall prediction accuracy was 73.5%. The
   self-reported feelings matched the human expert judgments more
   frequently when they were correctly predicted by the T5 than not (90% vs
   37.5%, 95%CI of difference: 34.8 to 70.2%). When subjected to CR, the
   correctly predicted thought-feeling pairs led to greater reductions in
   negative feelings than the incorrectly predicted pairs (- 1.54 vs - 1.43
   on a scale of 0 to 5, 95%CI of difference: 0.03 to 0.19).ConclusionsA
   new CR module of an iCBT application can incorporate this model and
   advise the users to revisit and revise their automatic thoughts to
   reflect their feelings more accurately. Whether such an iCBT application
   can ultimately lead to greater reductions in depression is to be
   examined in a future randomized trial.
Z8 0
ZR 0
ZS 0
TC 3
ZA 0
ZB 0
Z9 3
DA 2023-07-21
UT WOS:001023960400001
ER

PT J
AU Olszewski, Robert
   Watros, Klaudia
   Manczak, Malgorzata
   Owoc, Jakub
   Jeziorski, Krzysztof
   Brzezinski, Jakub
TI Assessing the response quality and readability of chatbots in
   cardiovascular health, oncology, and psoriasis: A comparative study
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 190
AR 105562
DI 10.1016/j.ijmedinf.2024.105562
EA JUL 2024
DT Article
PD OCT 2024
PY 2024
AB Background: Chatbots using the Large Language Model (LLM) generate human
   responses to questions from all categories. Due to staff shortages in
   healthcare systems, patients waiting for an appointment increasingly use
   chatbots to get information about their condition. Given the number of
   chatbots currently available, assessing the responses they generate is
   essential. Methods: Five chatbots with free access were selected
   (Gemini, Microsoft Copilot, PiAI, ChatGPT, ChatSpot) and blinded using
   letters (A, B, C, D, E). Each chatbot was asked questions about
   cardiology, oncology, and psoriasis. Responses were compared to
   guidelines from the European Society of Cardiology, American Academy of
   Dermatology and American Society of Clinical Oncology. All answers were
   assessed using readability scales (Flesch Reading Scale, Gunning Fog
   Scale Level, Flesch-Kincaid Grade Level and Dale-Chall Score). Using a
   3point Likert scale, two independent medical professionals assessed the
   compliance of the responses with the guidelines. Results: A total of 45
   questions were asked of all chatbots. Chatbot C gave the shortest
   answers, 7.0 (6.0 - 8.0), and Chatbot A the longest 17.5 (13.0 - 24.5).
   The Flesch Reading Ease Scale ranged from 16.3 (12.2 - 21.9) (Chatbot D)
   to 39.8 (29.0 - 50.4) (Chatbot A). Flesch-Kincaid Grade Level ranged
   from 12.5 (10.6 - 14.6) (Chatbot A) to 15.9 (15.1 - 17.1) (Chatbot D).
   Gunning Fog Scale Level ranged from 15.77 (Chatbot A) to 19.73 (Chatbot
   D). Dale-Chall Score ranged from 10.3 (9.3 - 11.3) (Chatbot A) to 11.9
   (11.5 - 12.4) (Chatbot D). Conclusion: This study indicates that
   chatbots vary in length, quality, and readability. They answer each
   question in their own way, based on the data they have pulled from the
   web. Reliability of the responses generated by chatbots is high. This
   suggests that people who want information from a chatbot need to be
   careful and verify the answers they receive, particularly when they ask
   about medical and health aspects.
ZS 0
ZR 0
TC 3
Z8 1
ZB 0
ZA 0
Z9 4
DA 2024-08-07
UT WOS:001281403200001
PM 39059084
ER

PT J
AU Rahman, Md Mushfiqur
   Irbaz, Mohammad Sabik
   North, Kai
   Williams, Michelle S.
   Zampieri, Marcos
   Lybarger, Kevin
TI Health text simplification: An annotated corpus for digestive cancer
   education and novel strategies for reinforcement learning
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 158
AR 104727
DI 10.1016/j.jbi.2024.104727
EA SEP 2024
DT Article
PD OCT 2024
PY 2024
AB Objective: The reading level of health educational materials
   significantly influences the understandability and accessibility of the
   information, particularly for minoritized populations. Many patient
   educational resources surpass widely accepted standards for reading
   level and complexity. There is a critical need for high-performing text
   simplification models for health information to enhance dissemination
   and literacy. This need is particularly acute in cancer education, where
   effective prevention and screening education can substantially reduce
   morbidity and mortality. Methods: We introduce Simplified Digestive
   Cancer (SimpleDC), a parallel corpus of cancer education materials
   tailored for health text simplification research, comprising educational
   content from the American Cancer Society, Centers for Disease Control
   and Prevention, and National Cancer Institute. The corpus includes 31
   web pages with the corresponding manually simplified versions. It
   consists of 1183 annotated sentence pairs (361 train, 294 development,
   and 528 test). Utilizing SimpleDC and the existing Med-EASi corpus, we
   explore Large Language Model (LLM)-based simplification methods,
   including fine-tuning, reinforcement learning (RL), reinforcement
   learning with human feedback (RLHF), domain adaptation, and prompt-based
   approaches. Our experimentation encompasses Llama 2, Llama 3, and GPT-4.
   We introduce a novel RLHF reward function featuring a lightweight model
   adept at distinguishing between original and simplified texts when
   enables training on unlabeled data. Results: Fine-tuned Llama models
   demonstrated high performance across various metrics. Our RLHF reward
   function outperformed existing RL text simplification reward functions.
   The results underscore that RL/RLHF can achieve performance comparable
   to fine-tuning and improve the performance of fine-tuned models.
   Additionally, these methods effectively adapt out-of-domain text
   simplification models to a target domain. The best-performing
   RL-enhanced Llama models outperformed GPT-4 in both automatic metrics
   and manual evaluation by subject matter experts. Conclusion: The newly
   developed SimpleDC corpus will serve as a valuable asset to the research
   community, particularly in patient education simplification. The RL/RLHF
   methodologies presented herein enable effective training of
   simplification models on unlabeled text and the utilization of
   out-of-domain simplification corpora.
ZR 0
Z8 0
TC 2
ZS 0
ZB 0
ZA 0
Z9 2
DA 2024-09-29
UT WOS:001318940100001
PM 39293643
ER

PT J
AU Hirosawa, Takanobu
   Harada, Yukinori
   Tokumasu, Kazuki
   Ito, Takahiro
   Suzuki, Tomoharu
   Shimizu, Taro
TI Evaluating ChatGPT-4's Diagnostic Accuracy: Impact of Visual Data
   Integration
SO JMIR MEDICAL INFORMATICS
VL 12
AR e55627
DI 10.2196/55627
DT Article
PD 2024
PY 2024
AB Background: In the evolving field of health care, multimodal generative
   artificial intelligence (AI) systems, such as ChatGPT-4 with vision
   (ChatGPT-4V), represent a significant advancement, as they integrate
   visual data with text data. This integration has the potential to
   revolutionize clinical diagnostics by offering more comprehensive
   analysis capabilities. However, the impact on diagnostic accuracy of
   using image data to augment ChatGPT-4 remains unclear. Objective: This
   study aims to assess the impact of adding image data on ChatGPT-4's
   diagnostic accuracy and provide insights into how image data integration
   can enhance the accuracy of multimodal AI in medical diagnostics.
   Specifically, this study endeavored to compare the diagnostic accuracy
   between ChatGPT-4V, which processed both text and image data, and its
   counterpart, ChatGPT-4, which only uses text data. Methods: We
   identified a total of 557 case reports published in the American Journal
   of Case Reports from January 2022 to March 2023. After excluding cases
   that were nondiagnostic, pediatric, and lacking image data, we included
   363 case descriptions with their final diagnoses and associated images.
   We compared the diagnostic accuracy of ChatGPT-4V and ChatGPT-4 without
   vision based on their ability to include the final diagnoses within
   differential diagnosis lists. Two independent physicians evaluated their
   accuracy, with a third resolving any discrepancies, ensuring a rigorous
   and objective analysis. Results: The integration of image data into
   ChatGPT-4V did not significantly enhance diagnostic accuracy, showing
   that final diagnoses were included in the top 10 differential diagnosis
   lists at a rate of 85.1% (n=309), comparable to the rate of 87.9%
   (n=319) for the text -only version ( P =.33). Notably, ChatGPT-4V's
   performance in correctly identifying the top diagnosis was inferior, at
   44.4% (n=161), compared with 55.9% (n=203) for the text -only version (
   P =.002, chi 2 test). Additionally, ChatGPT-4's self -reports showed
   that image data accounted for 30% of the weight in developing the
   differential diagnosis lists in more than half of cases. Conclusions:
   Our findings reveal that currently, ChatGPT-4V predominantly relies on
   textual data, limiting its ability to fully use the diagnostic potential
   of visual information. This study underscores the need for further
   development of multimodal generative AI systems to effectively integrate
   and use clinical image data. Enhancing the diagnostic performance of
   such AI systems through improved multimodal data integration could
   significantly benefit patient care by providing more accurate and
   comprehensive diagnostic insights. Future research should focus on
   overcoming these limitations, paving the way for the practical
   application of advanced AI in medicine.
ZB 2
Z8 1
TC 11
ZA 0
ZR 0
ZS 0
Z9 11
DA 2024-05-16
UT WOS:001217446200001
PM 38592758
ER

PT J
AU Bommakanti, Nikhil
   Rizvi, Fatima
   Rizvi, Anza
   Mansour, Hana A.
   Momenaei, Bita
   Safran, Jordan
   Yu, Michael
   Obeid, Anthony
   Yonekawa, Yoshihiro
TI Accuracy and readability of after visit summaries for retinal conditions
   generated by a large language model
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 822
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
Z8 0
ZR 0
ZS 0
TC 0
ZA 0
ZB 0
Z9 0
DA 2024-12-01
UT WOS:001312227702165
ER

PT J
AU Song, Jintao
   Huang, Junjie
   Liu, Ruili
TI Integrating NLP and LLMs to discover biomarkers and mechanisms in
   Alzheimer's disease
SO SLAS TECHNOLOGY
VL 31
AR 100257
DI 10.1016/j.slast.2025.100257
EA MAR 2025
DT Article
PD APR 2025
PY 2025
AB Alzheimer's disease (AD) is a progressive neurological condition
   characterized by cognitive decline, memory loss, and aberrant behaviour.
   It affects millions of people globally and is one of the main causes of
   dementia. The neurodegenerative condition known as AD has intricate,
   multifaceted mechanisms that make it difficult to comprehend and
   identify in its early stages. Conventional diagnostic techniques
   frequently fail to detect the disease in its early stages. By combining
   Natural Language Processing (NLP) and Large Language Models (LLMs), this
   research suggests a novel approach for identifying potential biomarkers
   and underlying mechanisms of AD. Clinical data is gathered from publicly
   accessible databases and healthcare facilities, including genetic
   information, neuroimaging scans, and medical records. The pre-processing
   of unstructured clinical notes involves tokenization and genetic
   profiles and neuroimaging data are normalized by Z-score normalization
   for consistency. Multi-Input Convolutional Neural Networks (MI-CNN) are
   employed to efficiently fuse diverse data sources, allowing for a
   thorough analysis. Key biomarkers linked to AD are identified and
   categorized using the Genetic Algorithm combined with Bidirectional
   Encoder Representations from Transformers (BERT) (GenBERT). By
   fine-tuning BERT's hyperparameters using genetic optimization
   approaches, GenBERT enables the effective analysis of large medical
   datasets, such as patient histories, genetic data, and clinical notes.
   The combination strategy increases feature selection and the model's
   capacity to identify minute genomic and linguistic patterns suggestive
   of AD. The goal of this integrated strategy is to provide early
   diagnostic tools and new insights into the pathogenesis of the disease,
   which could transform methods for detecting and treating AD. As it
   concerns early AD prediction, the GenBERT model performs better than
   current techniques, obtaining the highest accuracy (98.30%) and F1-score
   (0.97), as well as greater precision (0.95) and recall (0.92).
   Additionally, it demonstrates its capacity to reliably identify both
   positive and negative AD cases with sensitivity (98.65%) and specificity
   (99.73%). Overall, GenBERT offers a trustworthy and useful tool for AD
   early diagnosis.
ZA 0
ZS 0
Z8 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2025-03-12
UT WOS:001438158000001
PM 39988114
ER

PT J
AU Lin, Wei-Chun
   Reznick, Caleb
   Reznick, Leah
   Lucero, Abigail
   Campbell, J. Peter
   Ishikawa, Hiroshi
   Hribar, Michelle
TI Enhancing Amblyopia Identification Using NLP: A Study of BioClinical
   BERT and Flan-T5 Models
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZA 0
ZR 0
ZS 0
ZB 0
TC 0
Z8 0
Z9 0
DA 2024-12-01
UT WOS:001312227701035
ER

PT J
AU Pugh, Samuel L.
   Chandler, Chelsea
   Cohen, Alex S.
   Diaz-Asper, Catherine
   Elvevag, Brita
   Foltz, Peter W.
TI Assessing dimensions of thought disorder with large language models: The
   tradeoff of accuracy and consistency
SO PSYCHIATRY RESEARCH
VL 341
AR 116119
DI 10.1016/j.psychres.2024.116119
EA SEP 2024
DT Article
PD NOV 2024
PY 2024
AB Natural Language Processing (NLP) methods have shown promise for the
   assessment of formal thought disorder, a hallmark feature of
   schizophrenia in which disturbances to the structure, organization, or
   coherence of thought can manifest as disordered or incoherent speech. We
   investigated the suitability of modern Large Language Models (LLMs-
   e.g., GPT-3.5, GPT-4, and Llama 3) to predict expert-generated ratings
   for three dimensions of thought disorder (coherence, content, and
   tangentiality) assigned to speech samples collected from both patients
   with a diagnosis of schizophrenia (n = 26) and healthy control
   participants (n = 25). In addition to (1) evaluating the accuracy of
   LLM-generated ratings relative to human experts, we also (2)
   investigated the degree to which the LLMs produced consistent ratings
   across multiple trials, and we (3) sought to understand the factors that
   impacted the consistency of LLM-generated output. We found that
   machine-generated ratings of the level of thought disorder in speech
   matched favorably those of expert humans, and we identified a tradeoff
   between accuracy and consistency in LLM ratings. Unlike traditional NLP
   methods, LLMs were not always consistent in their predictions, but these
   inconsistencies could be mitigated with careful parameter selection and
   ensemble methods. We discuss implications for NLP-based assessment of
   thought disorder and provide recommendations of best practices for
   integrating these methods in the field of psychiatry.
TC 2
ZS 0
Z8 0
ZR 0
ZB 0
ZA 0
Z9 2
DA 2024-09-16
UT WOS:001309569000001
PM 39226873
ER

PT J
AU Bellamkonda, Nikhil
   Farlow, Janice L.
   Haring, Catherine T.
   Sim, Michael W.
   Seim, Nolan B.
   Cannon, Richard B.
   Monroe, Marcus M.
   Agrawal, Amit
   Rocco, James W.
   McCrary, Hilary C.
TI Evaluating the Accuracy of ChatGPT in Common Patient Questions Regarding
   HPV plus Oropharyngeal Carcinoma
SO ANNALS OF OTOLOGY RHINOLOGY AND LARYNGOLOGY
VL 133
IS 9
BP 814
EP 819
DI 10.1177/00034894241259137
EA JUL 2024
DT Article
PD SEP 2024
PY 2024
AB Objectives: Large language model (LLM)-based chatbots such as ChatGPT
   have been publicly available and increasingly utilized by the general
   public since late 2022. This study sought to investigate ChatGPT
   responses to common patient questions regarding Human Papilloma Virus
   (HPV) positive oropharyngeal cancer (OPC). Methods: This was a
   prospective, multi-institutional study, with data collected from high
   volume institutions that perform >50 transoral robotic surgery cases per
   year. The 100 most recent discussion threads including the term "HPV" on
   the American Cancer Society's Cancer Survivors Network's Head and Neck
   Cancer public discussion board were reviewed. The 11 most common
   questions were serially queried to ChatGPT 3.5; answers were recorded. A
   survey was distributed to fellowship trained head and neck oncologic
   surgeons at 3 institutions to evaluate the responses. Results: A total
   of 8 surgeons participated in the study. For questions regarding HPV
   contraction and transmission, ChatGPT answers were scored as clinically
   accurate and aligned with consensus in the head and neck surgical
   oncology community 84.4% and 90.6% of the time, respectively. For
   questions involving treatment of HPV+ OPC, ChatGPT was clinically
   accurate and aligned with consensus 87.5% and 91.7% of the time,
   respectively. For questions regarding the HPV vaccine, ChatGPT was
   clinically accurate and aligned with consensus 62.5% and 75% of the
   time, respectively. When asked about circulating tumor DNA testing, only
   12.5% of surgeons thought responses were accurate or consistent with
   consensus. Conclusion: ChatGPT 3.5 performed poorly with questions
   involving evolving therapies and diagnostics-thus, caution should be
   used when using a platform like ChatGPT 3.5 to assess use of advanced
   technology. Patients should be counseled on the importance of consulting
   their surgeons to receive accurate and up to date recommendations, and
   use LLM's to augment their understanding of these important
   health-related topics.
ZB 0
Z8 0
ZR 0
ZA 0
TC 1
ZS 0
Z9 1
DA 2024-08-06
UT WOS:001280661600001
PM 39075853
ER

PT J
AU Perlis, Roy H.
   Goldberg, Joseph F.
   Ostacher, Michael J.
   Schneck, Christopher D.
TI Clinical decision support for bipolar depression using large language
   models
SO NEUROPSYCHOPHARMACOLOGY
VL 49
IS 9
BP 1412
EP 1416
DI 10.1038/s41386-024-01841-2
EA MAR 2024
DT Article
PD AUG 2024
PY 2024
AB Management of depressive episodes in bipolar disorder remains
   challenging for clinicians despite the availability of treatment
   guidelines. In other contexts, large language models have yielded
   promising results for supporting clinical decisionmaking. We developed
   50 sets of clinical vignettes reflecting bipolar depression and
   presented them to experts in bipolar disorder, who were asked to
   identify 5 optimal next-step pharmacotherapies and 5 poor or
   contraindicated choices. The same vignettes were then presented to a
   large language model (GPT4-turbo; gpt-4-1106-preview), with or without
   augmentation by prompting with recent bipolar treatment guidelines, and
   asked to identify the optimal next-step pharmacotherapy. Overlap between
   model output and gold standard was estimated. The augmented model
   prioritized the expert-designated optimal choice for 508/1000 vignettes
   (50.8%, 95% CI 47.7-53.9%; Cohen's kappa = 0.31, 95% CI 0.28-0.35). For
   120 vignettes (12.0%), at least one model choice was among the poor or
   contraindicated treatments. Results were not meaningfully different when
   gender or race of the vignette was permuted to examine risk for bias. By
   comparison, an un-augmented model identified the optimal treatment for
   234 (23.0%, 95% CI 20.8-26.0%; McNemar's p < 0.001 versus augmented
   model) of the vignettes. A sample of community clinicians scoring the
   same vignettes identified the optimal choice for 23.1% (95% CI
   15.7-30.5%) of vignettes, on average; McNemar's p < 0.001 versus
   augmented model. Large language models prompted with evidence-based
   guidelines represent a promising, scalable strategy for clinical
   decision support. In addition to prospective studies of efficacy,
   strategies to avoid clinician overreliance on such models, and address
   the possibility of bias, will be needed.
TC 10
ZB 1
Z8 0
ZS 0
ZR 0
ZA 0
Z9 10
DA 2024-03-28
UT WOS:001182357900004
PM 38480911
ER

PT J
AU Guillen-Grima, Francisco
   Guillen-Aguinaga, Sara
   Guillen-Aguinaga, Laura
   Alas-Brun, Rosa
   Onambele, Luc
   Ortega, Wilfrido
   Montejo, Rocio
   Aguinaga-Ontoso, Enrique
   Barach, Paul
   Aguinaga-Ontoso, Ines
TI Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical
   Residency Entrance Examination (MIR): Promising Horizons for AI in
   Clinical Medicine
SO CLINICS AND PRACTICE
VL 13
IS 6
BP 1460
EP 1487
DI 10.3390/clinpract13060130
DT Article
PD DEC 2023
PY 2023
AB The rapid progress in artificial intelligence, machine learning, and
   natural language processing has led to increasingly sophisticated large
   language models (LLMs) for use in healthcare. This study assesses the
   performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the
   MIR medical examination for access to medical specialist training in
   Spain. Our objectives included gauging the model's overall performance,
   analyzing discrepancies across different medical specialties, discerning
   between theoretical and practical questions, estimating error
   proportions, and assessing the hypothetical severity of errors committed
   by a physician. Material and methods: We studied the 2022 Spanish MIR
   examination results after excluding those questions requiring image
   evaluations or having acknowledged errors. The remaining 182 questions
   were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English.
   Logistic regression models analyzed the relationships between question
   length, sequence, and performance. We also analyzed the 23 questions
   with images, using GPT-4's new image analysis capability. Results: GPT-4
   outperformed GPT-3.5, scoring 86.81% in Spanish (p < 0.001). English
   translations had a slightly enhanced performance. GPT-4 scored 26.1% of
   the questions with images in English. The results were worse when the
   questions were in Spanish, 13.0%, although the differences were not
   statistically significant (p = 0.250). Among medical specialties, GPT-4
   achieved a 100% correct response rate in several areas, and the
   Pharmacology, Critical Care, and Infectious Diseases specialties showed
   lower performance. The error analysis revealed that while a 13.2% error
   rate existed, the gravest categories, such as "error requiring
   intervention to sustain life" and "error resulting in death", had a 0%
   rate. Conclusions: GPT-4 performs robustly on the Spanish MIR
   examination, with varying capabilities to discriminate knowledge across
   specialties. While the model's high success rate is commendable,
   understanding the error severity is critical, especially when
   considering AI's potential role in real-world medical practice and its
   implications for patient safety.
ZA 0
TC 28
Z8 0
ZS 1
ZB 6
ZR 0
Z9 28
DA 2024-01-17
UT WOS:001132385500001
PM 37987431
ER

PT J
AU Freidel, Sebastian
   Schwarz, Emanuel
TI Knowledge graphs in psychiatric research: Potential applications and
   future perspectives
SO ACTA PSYCHIATRICA SCANDINAVICA
VL 151
IS 3
SI SI
BP 180
EP 191
DI 10.1111/acps.13717
EA JUN 2024
DT Review
PD MAR 2025
PY 2025
AB BackgroundKnowledge graphs (KGs) remain an underutilized tool in the
   field of psychiatric research. In the broader biomedical field KGs are
   already a significant tool mainly used as knowledge database or for
   novel relation detection between biomedical entities. This review aims
   to outline how KGs would further research in the field of psychiatry in
   the age of Artificial Intelligence (AI) and Large Language Models
   (LLMs).MethodsWe conducted a thorough literature review across a
   spectrum of scientific fields ranging from computer science and
   knowledge engineering to bioinformatics. The literature reviewed was
   taken from PubMed, Semantic Scholar and Google Scholar searches
   including terms such as "Psychiatric Knowledge Graphs", "Biomedical
   Knowledge Graphs", "Knowledge Graph Machine Learning Applications",
   "Knowledge Graph Applications for Biomedical Sciences". The resulting
   publications were then assessed and accumulated in this review regarding
   their possible relevance to future psychiatric applications.ResultsA
   multitude of papers and applications of KGs in associated research
   fields that are yet to be utilized in psychiatric research was found and
   outlined in this review. We create a thorough recommendation for other
   computational researchers regarding use-cases of these KG applications
   in psychiatry.ConclusionThis review illustrates use-cases of KG-based
   research applications in biomedicine and beyond that may aid in
   elucidating the complex biology of psychiatric illness and open new
   routes for developing innovative interventions. We conclude that there
   is a wealth of opportunities for KG utilization in psychiatric research
   across a variety of application areas including biomarker discovery,
   patient stratification and personalized medicine approaches.
ZR 0
ZB 0
ZA 0
Z8 0
TC 2
ZS 0
Z9 2
DA 2024-06-22
UT WOS:001249217200001
PM 38886846
ER

PT J
AU Zhang, YuNing
   Dong, Yijie
   Mei, Zihan
   Hou, Yiqing
   Wei, Minyan
   Yeung, Yat Hin
   Xu, Jiale
   Hua, Qing
   Lai, LiMei
   Li, Ning
   Xia, ShuJun
   Zhou, Chun
   Zhou, JianQiao
TI Performance of large language models on benign prostatic hyperplasia
   frequently asked questions
SO PROSTATE
VL 84
IS 9
BP 807
EP 813
DI 10.1002/pros.24699
EA APR 2024
DT Article
PD JUN 2024
PY 2024
AB Background: Benign prostatic hyperplasia (BPH) is a common condition,
   yet it is challenging for the average BPH patient to find credible and
   accurate information about BPH. Our goal is to evaluate and compare the
   accuracy and reproducibility of large language models (LLMs), including
   ChatGPT-3.5, ChatGPT-4, and the New Bing Chat in responding to a BPH
   frequently asked questions (FAQs) questionnaire. Methods: A total of 45
   questions related to BPH were categorized into basic and professional
   knowledge. Three LLM-ChatGPT-3.5, ChatGPT-4, and New Bing Chat-were
   utilized to generate responses to these questions. Responses were graded
   as comprehensive, correct but inadequate, mixed with incorrect/outdated
   data, or completely incorrect. Reproducibility was assessed by
   generating two responses for each question. All responses were reviewed
   and judged by experienced urologists. Results: All three LLMs exhibited
   high accuracy in generating responses to questions, with accuracy rates
   ranging from 86.7% to 100%. However, there was no statistically
   significant difference in response accuracy among the three (p > 0.017
   for all comparisons). Additionally, the accuracy of the LLMs' responses
   to the basic knowledge questions was roughly equivalent to that of the
   specialized knowledge questions, showing a difference of less than 3.5%
   (GPT-3.5: 90% vs. 86.7%; GPT-4: 96.7% vs. 95.6%; New Bing: 96.7% vs.
   93.3%). Furthermore, all three LLMs demonstrated high reproducibility,
   with rates ranging from 93.3% to 97.8%. Conclusions: ChatGPT-3.5,
   ChatGPT-4, and New Bing Chat offer accurate and reproducible responses
   to BPH-related questions, establishing them as valuable resources for
   enhancing health literacy and supporting BPH patients in conjunction
   with healthcare professionals.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 2
TC 8
Z9 8
DA 2024-04-04
UT WOS:001194679200001
PM 38558009
ER

PT J
AU Li, Caixia
   Zhao, Yina
   Bai, Yang
   Zhao, Baoquan
   Tola, Yetunde Oluwafunmilayo
   Chan, Carmen W. H.
   Zhang, Meifen
   Fu, Xia
TI Unveiling the Potential of Large Language Models in Transforming Chronic
   Disease Management: Mixed Methods Systematic Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e70535
DI 10.2196/70535
DT Review
PD APR 16 2025
PY 2025
AB Background: Chronic diseases are a major global health burden,
   accounting for nearly three-quarters of the deaths worldwide. Large
   language models (LLMs) are advanced artificial intelligence systems with
   transformative potentialto optimize chronic disease management; however,
   robust evidence is lacking. Objective: This review aims to synthesize
   evidence on the feasibility, opportunities, and challenges of LLMs
   across the disease management spectrum, from prevention to screening,
   diagnosis, treatment, and long-term care. Methods: Following the PRISMA
   (Preferred Reporting Items for Systematic Reviews and Meta-Analysis)
   guidelines, 11 databases (Cochrane Central Register of Controlled
   Trials, CINAHL, Embase, IEEE Xplore, MEDLINE via Ovid, ProQuest Health &
   MedicineCollection, ScienceDirect, Scopus, Web of Science Core
   Collection, China National KnowledgeInternet, and SinoMed) were searched
   on April 17, 2024. Intervention and simulation studies that examined
   LLMs in the management of chronic diseases were included. The
   methodological quality of the included studies was evaluated using a
   rating rubric designed for simulation-based research and the risk of
   bias in nonrandomized studies of interventions tool for
   quasi-experimental studies. Narrative analysis with descriptivefigures
   was used to synthesizethe study findings. Random-effects meta-analyses
   were conducted to assess the pooled effect estimates of the feasibility
   of LLMs in chronic disease management. Results: A total of 20 studies
   examined general-purpose (n=17) and retrieval-augmented
   generation-enhanced LLMs (n=3) for the management of chronic diseases,
   including cancer, cardiovascular diseases, and metabolic disorders. LLMs
   demonstrated feasibility across the chronic disease management spectrum
   by generating relevant, comprehensible, and accurate health
   recommendations (pooled accurate rate 71%, 95% CI 0.59-0.83; I2=88.32%)
   with retrieval-augmented generation-enhanced LLMs having higher accuracy
   rates compared to general-purpose LLMs (odds ratio 2.89, 95% CI
   1.83-4.58; I2=54.45%). LLMs facilitated equitable information access;
   increased patient awareness regarding ailments, preventive measures, and
   treatment options; and promoted self-management behaviors in lifestyle
   modification and symptom coping. Additionally, LLMs facilitate
   compassionate emotional support, social connections, and health care
   resources to improve the health outcomesof chronic diseases. However,
   LLMs face challenges in addressing privacy, language, and cultural
   issues; undertaking advanced tasks, including diagnosis, medication, and
   comorbidity management; and generating personalized regimens with
   real-timeadjustments and multiple modalities. Conclusions:LLMs have
   demonstrated the potentialto transform chronic disease management at the
   individual, social, and health care levels; however, their direct
   application in clinical settings is still in its infancy. A multifaceted
   approach that incorporates robust data security, domain-specific model
   fine-tuning, multimodal data integration, and wearables is crucial for
   the evolution of LLMs into invaluable adjuncts for health care
   professionals to transform chronic disease management. Trial
   Registration: PROSPERO CRD42024545412;
   https://www.crd.york.ac.uk/PROSPERO/view/CRD42024545412
ZB 0
Z8 0
ZS 0
ZR 0
ZA 0
TC 0
Z9 0
DA 2025-05-09
UT WOS:001478857800005
PM 40239198
ER

PT J
AU Fonseca, Angelo
   Ferreira, Axel
   Ribeiro, Luis
   Moreira, Sandra
   Duque, Cristina
TI Embracing the future-is artificial intelligence already better? A
   comparative study of artificial intelligence performance in diagnostic
   accuracy and decision-making
SO EUROPEAN JOURNAL OF NEUROLOGY
VL 31
IS 4
DI 10.1111/ene.16195
EA JAN 2024
DT Article
PD APR 2024
PY 2024
AB Background and purposeThe integration of artificial intelligence (AI) in
   healthcare has the potential to revolutionize patient care and clinical
   decision-making. This study aimed to explore the reliability of large
   language models in neurology by comparing the performance of an AI
   chatbot with neurologists in diagnostic accuracy and
   decision-making.MethodsA cross-sectional observational study was
   conducted. A pool of clinical cases from the American Academy of
   Neurology's Question of the Day application was used as the basis for
   the study. The AI chatbot used was ChatGPT, based on GPT-3.5. The
   results were then compared to neurology peers who also answered the
   questions-a mean of 1500 neurologists/neurology residents.ResultsThe
   study included 188 questions across 22 different categories. The AI
   chatbot demonstrated a mean success rate of 71.3% in providing correct
   answers, with varying levels of proficiency across different neurology
   categories. Compared to neurology peers, the AI chatbot performed at a
   similar level, with a mean success rate of 69.2% amongst peers.
   Additionally, the AI chatbot achieved a correct diagnosis in 85.0% of
   cases and it provided an adequate justification for its correct
   responses in 96.1%.ConclusionsThe study highlights the potential of AI,
   particularly large language models, in assisting with clinical reasoning
   and decision-making in neurology and emphasizes the importance of AI as
   a complementary tool to human expertise. Future advancements and
   refinements are needed to enhance the AI chatbot's performance and
   broaden its application across various medical specialties.
ZA 0
ZS 0
Z8 0
ZB 0
ZR 0
TC 7
Z9 7
DA 2024-01-24
UT WOS:001144093900001
PM 38235841
ER

PT J
AU Castro, Victor M
   McCoy, Thomas H
   Verhaak, Pilar
   Ramachandiran, Anudeepa K
   Perlis, Roy H
TI Changes in psychiatric documentation and treatment in primary care with
   artificial intelligence scribe use.
SO medRxiv : the preprint server for health sciences
DI 10.1101/2025.05.14.25327620
DT Journal Article; Preprint
PD 2025 May 15
PY 2025
AB Importance: Despite increasingly widespread use of artificial
   intelligence-driven ambient scribes in medicine, the extent to which
   they may impact clinician practice is not well-studied.
   Objective: To characterize differences in documentation and treatment of
   psychiatric symptoms in primary care outpatient notes generated using
   ambient scribes.
   Design: Case-control electronic health records.
   Setting: Primary care annual visit notes from the Massachusetts General
   and Brigham and Women's Hospital systems between February 2023 and
   February 2023.
   Participants: Random sample of 20,302 notes from 4 types of visits,
   matching 1:1 using sociodemographic and clinical features: those using
   an ambient scribe, those using a human scribe, those occurring during
   the same period without a scribe, and those occurring prior to scribe
   deployment.
   Exposure: Use of an artificial intelligence-driven ambient scribe.
   Main Outcome and Measures: Neuropsychiatric symptom documentation, in
   terms of estimated Research Domain Criteria, using a HIPAA-compliant
   large language model (GPT4o; gpt-4o-11-20); incident antidepressant
   prescriptions and diagnostic codes; referral for mental health
   follow-up.
   Results: In the ambient scribe group, mean age was 48 (SD 14) years; 59%
   of notes reflected individuals of female sex, and 5.0% met criteria for
   moderate or greater depressive symptoms by PHQ-9. Estimated levels of
   RDoC symptomatology in all 6 domains were significantly greater in the
   ambient-scribed notes (p <.001 for all contrasts). In a logistic
   regression model, likelihood of a psychiatric intervention (referral,
   new diagnosis, or antidepressant prescription) was significantly lower
   among ambient-scribed visits compared to unscribed (aOR 0.83, 95% CI
   0.72-0.95), but not for human-scribed compared to unscribed (aOR 1.01,
   95% CI 0.87-1.17).
   Conclusion and Relevance: In this case-control design examining
   outpatient primary care notes, we found that incorporation of artificial
   intelligence-driven ambient scribes in primary care was associated with
   greater levels of neuropsychiatric symptom documentation but lesser
   likelihood of acting on psychiatric symptoms. Further study will be
   required to determine whether these changes are associated with
   differential outcomes.
   Trial registration: n/a.
   Key Points: Question: How is documentation and treatment of psychiatric
   symptoms in primary care different for outpatient visits using
   artificial intelligence (AI)-driven ambient scribes.Findings: In more
   than 20,000 routine annual visits, ambient scribe use was associated
   with greater documentation of neuropsychiatric symptoms but less
   likelihood of a depression-related intervention or diagnostic
   code.Meaning: The extent to which use of ambient scribes may alter
   response to psychiatric symptoms by clinicians merits further
   investigation.
ZB 0
TC 0
ZA 0
ZR 0
ZS 0
Z8 0
Z9 0
DA 2025-06-06
UT MEDLINE:40463564
PM 40463564
ER

PT J
AU Sandmann, Sarah
   Riepenhausen, Sarah
   Plagwitz, Lucas
   Varghese, Julian
TI Systematic analysis of ChatGPT, Google search and Llama 2 for clinical
   decision support tasks
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 2050
DI 10.1038/s41467-024-46411-8
DT Article
PD MAR 6 2024
PY 2024
AB It is likely that individuals are turning to Large Language Models
   (LLMs) to seek health advice, much like searching for diagnoses on
   Google. We evaluate clinical accuracy of GPT-3 center dot 5 and GPT-4
   for suggesting initial diagnosis, examination steps and treatment of 110
   medical cases across diverse clinical disciplines. Moreover, two model
   configurations of the Llama 2 open source LLMs are assessed in a
   sub-study. For benchmarking the diagnostic task, we conduct a naive
   Google search for comparison. Overall, GPT-4 performed best with
   superior performances over GPT-3 center dot 5 considering diagnosis and
   examination and superior performance over Google for diagnosis. Except
   for treatment, better performance on frequent vs rare diseases is
   evident for all three approaches. The sub-study indicates slightly lower
   performances for Llama models. In conclusion, the commercial LLMs show
   growing potential for medical question answering in two successive major
   releases. However, some weaknesses underscore the need for robust and
   regulated AI models in health care. Open source LLMs can be a viable
   option to address specific needs regarding data privacy and transparency
   of training.
   People will likely use ChatGPT to seek health advice. Here, the authors
   show promising performance of ChatGPT and open source models, but a lack
   of high accuracy considering medical question answering. Improvements
   are expected over time via domain-specific finetuning and integration of
   regulations.
ZS 0
ZR 0
Z8 3
ZB 11
TC 56
ZA 0
Z9 59
DA 2024-04-03
UT WOS:001180826600013
PM 38448475
ER

PT J
AU Kunze, Kyle N.
   Nwachukwu, Benedict U.
   Cote, Mark P.
   Ramkumar, Prem N.
TI Large Language Models Applied to Health Care Tasks May Improve Clinical
   Efficiency, Value of Care Rendered, Research, and Medical Education
SO ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY
VL 41
IS 3
BP 547
EP 556
DI 10.1016/j.arthro.2024.12.010
EA FEB 2025
DT Article
PD MAR 2025
PY 2025
AB Large language models (LLMs) are generative artificial intelligence
   models that create content on the basis of the data on which it was
   trained. Processing capabilities have evolved from text only to being
   multimodal including text, images, audio, and video features. In health
   care settings, LLMs are being applied to several clinically important
   areas, including patient care and workflow efficiency, communications,
   hospital operations and data management, medical education, practice
   management, and health care research. Under the umbrella of patient
   care, several core use cases of LLMs include simplifying documentation
   tasks, enhancing patient communication (interactive language and
   written), conveying medical knowledge, and performing medical triage and
   diagnosis. However, LLMs warrant scrutiny when applied to health care
   tasks, as errors may have negative implications for health care
   outcomes, specifically in the context of perpetuating bias, ethical
   considerations, and cost-effectiveness. Customized LLMs developed for
   more narrow purposes may help overcome certain performance limitations,
   transparency challenges, and biases present in contemporary generalized
   LLMs by curating training data. Methods of customizing LLMs broadly fall
   under 4 categories: prompt engineering, retrieval augmented generation,
   fine-tuning, and agentic augmentation, with each approach conferring
   different information-retrieval properties for the LLM. Level of
   Evidence: Level V, expert opinion.
TC 1
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
Z9 1
DA 2025-02-26
UT WOS:001425552200001
PM 39694303
ER

PT J
AU Li, Hongyang
   Gerkin, Richard C.
   Bakke, Alyssa
   Norel, Raquel
   Cecchi, Guillermo
   Laudamiel, Christophe
   Niv, Masha Y.
   Ohla, Kathrin
   Hayes, John E.
   Parma, Valentina
   Meyer, Pablo
TI Text-based predictions of COVID-19 diagnosis from self-reported
   chemosensory descriptions
SO COMMUNICATIONS MEDICINE
VL 3
IS 1
AR 104
DI 10.1038/s43856-023-00334-5
DT Article
PD JUL 27 2023
PY 2023
AB Background There is a prevailing view that humans' capacity to use
   language to characterize sensations like odors or tastes is poor,
   providing an unreliable source of information.
   Methods Here, we developed a machine learning method based on Natural
   Language Processing (NLP) using Large Language Models (LLM) to predict
   COVID-19 diagnosis solely based on text descriptions of acute changes in
   chemosensation, i.e., smell, taste and chemesthesis, caused by the
   disease. The dataset of more than 1500 subjects was obtained from survey
   responses early in the COVID-19 pandemic, in Spring 2020.
   Results When predicting COVID-19 diagnosis, our NLP model performs
   comparably (AUC ROC similar to 0.65) to models based on self-reported
   changes in function collected via quantitative rating scales. Further,
   our NLP model could attribute importance of words when performing the
   prediction; sentiment and descriptive words such as "smell", "taste",
   "sense", had strong contributions to the predictions. In addition,
   adjectives describing specific tastes or smells such as "salty",
   "sweet", "spicy", and "sour" also contributed considerably to
   predictions.
   Conclusions Our results show that the description of perceptual symptoms
   caused by a viral infection can be used to fine-tune an LLM model to
   correctly predict and interpret the diagnostic status of a subject. In
   the future, similar models may have utility for patient verbatims from
   online health portals or electronic health records.
ZB 1
ZR 0
Z8 0
ZA 0
TC 3
ZS 0
Z9 3
DA 2023-08-22
UT WOS:001037431200001
PM 37500763
ER

PT J
AU Mohammadi, S. Saeed
   Nguyen, Quan Dong
TI A User-friendly Approach for the Diagnosis of Diabetic Retinopathy Using
   ChatGPT and Automated Machine Learning
SO OPHTHALMOLOGY SCIENCE
VL 4
IS 4
AR 100495
DI 10.1016/j.xops.2024.100495
EA APR 2024
DT Article
PD AUG 2024
PY 2024
AB Purpose: To assess the capabilities of Chat Generative Pre-trained
   Transformer (ChatGPT) and Vertex AI in executing code -free
   preprocessing, training machine learning (ML) models, and analyzing the
   data. Design: Evaluation of diagnostic test or technology. Participants:
   ChatGPT and Vetrex AI as publicly available large language model and ML
   platform, respectively. Methods: ChatGPT was employed to improve the
   resolution of fundus photography images from the Methods to Evaluate
   Segmentation and Indexing Techniques in the field of Retinal
   Ophthalmology (Messidor -2) open -source dataset using the Contrast
   Limited Adaptive Histogram Equalization (CLAHE) technique by Fiji
   software. Subsequently, Vertex AI, an automated ML (AutoML) platform,
   was utilized to develop 2 classification models. The first model served
   as a binary classifier for detecting the presence of diabetic
   retinopathy (DR), while the second determined its severity. Finally,
   ChatGPT was used to provide scripts for R and Python programming
   languages for data analysis and was also directly employed in analyzing
   the data in a code -free method. Main Outcome Measures: Evaluating the
   utility of ChatGPT in generating scripts for preprocessing images using
   Fiji and analyzing data across Python and R and assessing its potential
   in analyzing data through a codefree method. Investigating the
   capabilities of Vertex AI to train image classification models for
   detection of DR and its severity. Results: Two ML models were trained
   using 1740 images from the Messidor -2 database. The first model,
   designed to detect the severity of DR, achieved an area under the
   precision-recall curve (AUPRC) of 0.81, with a precision rate of 81.81%
   and recall of 72.83%. The second model, tailored for the detection of
   the presence of DR, recorded a precision and recall of 84.48% with an
   AUPRC of 0.90. Conclusions: ChatGPT and Vertex AI have the potential to
   enable physicians without coding expertise to preprocess images, analyze
   data, and train ML models. Financial Disclosure(s): Proprietary or
   commercial disclosure may be found in the Footnotes and Disclosures at
   the end of this article. Ophthalmology Science 2024;4:100495 (c) 2024 by
   the American Academy of Ophthalmology. This is an open access article
   under the CC BY-NC-ND license (http://creativecommons.org/
   licenses/by-nc-nd/4.0/).
ZA 0
ZS 0
ZR 0
Z8 0
ZB 1
TC 9
Z9 9
DA 2024-05-19
UT WOS:001218113300001
PM 38690313
ER

PT J
AU Moore, N. S.
   Laird, J. H., Jr.
   Verma, N.
   Hager, T.
   Sritharan, D.
   Lee, V.
   Maresca, R.
   Chadha, S.
   Park, H. S. M.
   Aneja, S.
TI Applying Language Models to Radiology Text for Identifying
   Oligometastatic Non-Small Cell Lung Cancer
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3413
BP E644
EP E644
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
ZS 0
TC 0
ZB 0
Z8 0
ZA 0
ZR 0
Z9 0
DA 2024-12-16
UT WOS:001325892302094
ER

PT C
AU Guo, Yuhang
   Wan, Zhiyu
GP IEEE COMPUTER SOC
TI Performance Evaluation of Multimodal Large Language Models (LLaVA and
   GPT-4-based ChatGPT) in Medical Image Classification Tasks
SO 2024 IEEE 12TH INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS, ICHI
   2024
SE IEEE International Conference on Healthcare Informatics
BP 541
EP 543
DI 10.1109/ICHI61247.2024.00080
DT Proceedings Paper
PD 2024
PY 2024
AB Large language models (LLMs) have gained significant attention due to
   their prospective applications in medicine. Utilizing multimodal LLMs
   can potentially assist clinicians in medical image classification tasks.
   It is important to evaluate the performance of LLMs in medical image
   processing to potentially improve the medical system. We evaluated two
   multimodal LLMs (LLaVA and GPT-4-based ChatGPT) against the classic VGG
   in tumor classification across brain MRI, breast ultrasound, and kidney
   CT datasets. Despite LLMs facing significant hallucination issue in
   medical imaging, prompt engineering markedly enhanced their performance.
   In comparison to the baseline method, GPT-4-based ChatGPT with prompt
   engineering achieves 98%, 112%, and 69% of the baseline's performance in
   terms of accuracy (or 99%, 107%, and 62% in terms of F1-score) in those
   three datasets, respectively. However, privacy, bias, accountability,
   and transparency concerns necessitate caution. Our study underscore
   LLMs' potential in medical imaging but emphasize the need for thorough
   performance and safety evaluations for their practical application.
CT 12th IEEE International Conference on Healthcare Informatics (IEEE-ICHI)
CY JUN 03-06, 2024
CL Orlando, FL
SP IEEE; IEEE Comp Soc Tech Community Intelligent Informat; Univ Minnesota,
   Div Computat Hlth Sci; Weill Cornell Med Inst Artificial Intelligence &
   Digital Hlth; Univ Florida Hlth; Yale Univ, Sch Med; Springer; Florida
   State Univ, Coll Commun & Informat
ZR 0
Z8 0
TC 2
ZB 0
ZA 0
ZS 0
Z9 2
DA 2024-11-02
UT WOS:001304501700073
ER

PT J
AU Somani, Sulaiman
   Kim, Dale
   Perez, Eduardo
   Ngo, Summer
   Hernandez-Boussard, Tina
   Rodriguez, Fatima
TI Large Language Models to Understand Reasons for Anticoagulation
   Nonprescription in Atrial Fibrillation
SO CIRCULATION
VL 150
MA 4144857
DI 10.1161/circ.150.suppl_1.4144857
SU 1
DT Meeting Abstract
PD NOV 12 2024
PY 2024
CT American-Heart-Association Resuscitation Science Symposium
CY NOV 16-18, 2024
CL Chicago, IL
SP Amer Heart Assoc
Z8 0
ZB 0
TC 0
ZS 0
ZA 0
ZR 0
Z9 0
DA 2025-02-13
UT WOS:001400066402089
ER

PT J
AU Zhang, Yapei
   Shi, Min
   Liebman, Daniel L.
   Barna, Laura
   Pasquale, Louis R.
   Elze, Tobias
   Friedman, David S.
   Boland, Michael V.
   Shen, Lucy Q.
   Wang, Mengyu
TI Evaluation of the accuracy of AIgenerated clinical summaries from
   Glaucoma outpatient visits.
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 1641
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
ZR 0
ZA 0
ZB 0
Z8 0
ZS 0
TC 0
Z9 0
DA 2024-12-01
UT WOS:001312227704269
ER

PT J
AU Lee, Aric
   Ong, Wilson
   Makmur, Andrew
   Ting, Yong Han
   Tan, Wei Chuan
   Lim, Shi Wei Desmond
   Low, Xi Zhen
   Tan, Jonathan Jiong Hao
   Kumar, Naresh
   Hallinan, James T. P. D.
TI Applications of Artificial Intelligence and Machine Learning in Spine
   MRI
SO BIOENGINEERING-BASEL
VL 11
IS 9
AR 894
DI 10.3390/bioengineering11090894
DT Review
PD SEP 2024
PY 2024
AB Diagnostic imaging, particularly MRI, plays a key role in the evaluation
   of many spine pathologies. Recent progress in artificial intelligence
   and its subset, machine learning, has led to many applications within
   spine MRI, which we sought to examine in this review. A literature
   search of the major databases (PubMed, MEDLINE, Web of Science,
   ClinicalTrials.gov) was conducted according to the Preferred Reporting
   Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The
   search yielded 1226 results, of which 50 studies were selected for
   inclusion. Key data from these studies were extracted. Studies were
   categorized thematically into the following: Image Acquisition and
   Processing, Segmentation, Diagnosis and Treatment Planning, and Patient
   Selection and Prognostication. Gaps in the literature and the proposed
   areas of future research are discussed. Current research demonstrates
   the ability of artificial intelligence to improve various aspects of
   this field, from image acquisition to analysis and clinical care. We
   also acknowledge the limitations of current technology. Future work will
   require collaborative efforts in order to fully exploit new technologies
   while addressing the practical challenges of generalizability and
   implementation. In particular, the use of foundation models and
   large-language models in spine MRI is a promising area, warranting
   further research. Studies assessing model performance in real-world
   clinical settings will also help uncover unintended consequences and
   maximize the benefits for patient care.
ZB 0
ZS 0
Z8 0
TC 3
ZR 0
ZA 0
Z9 3
DA 2024-10-07
UT WOS:001322923600001
PM 39329636
ER

PT J
AU Anguita, Rodrigo
   Downie, Catriona
   Desideri, Lorenzo Ferro
   Sagoo, Mandeep S.
TI Assessing large language models' accuracy in providing patient support
   for choroidal melanoma
SO EYE
VL 38
IS 16
BP 3113
EP 3117
DI 10.1038/s41433-024-03231-w
EA JUL 2024
DT Article
PD NOV 2024
PY 2024
AB PurposeThis study aimed to evaluate the accuracy of information that
   patients can obtain from large language models (LLMs) when seeking
   answers to common questions about choroidal melanoma.MethodsComparative
   study comparing frequently asked questions from choroidal melanoma
   patients and queried three major LLMs-ChatGPT 3.5, Bing AI, and DocsGPT.
   Answers were reviewed by three ocular oncology experts and scored as
   accurate, partially accurate, or inaccurate. Statistical analysis
   compared the quality of responses across models.ResultsFor medical
   advice questions, ChatGPT gave 92% accurate responses compared to 58%
   for Bing AI and DocsGPT. For pre/post-op questions, ChatGPT and Bing AI
   were 86% accurate while DocsGPT was 73% accurate. There were no
   statistically significant differences between models. ChatGPT responses
   were the longest while Bing AI responses were the shortest, but length
   did not affect accuracy. All LLMs appropriately directed patients to
   seek medical advice from professionals.ConclusionLLMs show promising
   capability to address common choroidal melanoma patient questions at
   generally acceptable accuracy levels. However, inconsistent, and
   inaccurate responses do occur, highlighting the need for improved
   fine-tuning and oversight before integration into clinical practice.
ZR 0
ZB 0
ZS 0
TC 4
ZA 0
Z8 0
Z9 4
DA 2024-07-27
UT WOS:001272234600004
PM 39003430
ER

PT J
AU Hur, Jihyun K.
   Heffner, Joseph
   Feng, Gloria W.
   Joormann, Jutta
   Rutledge, Robb B.
TI Language sentiment predicts changes in depressive symptoms
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
VL 121
IS 39
AR e2321321121
DI 10.1073/pnas.2321321121
DT Article
PD SEP 16 2024
PY 2024
AB The prevalence of depression is a major societal health concern, and
   there is an ongoing need to develop tools that predict who will become
   depressed. Past research suggests that depression changes the language
   we use, but it is unclear whether language is predictive of worsening
   symptoms. Here, we test whether the sentiment of brief written
   linguistic responses predicts changes in depression. Across two studies
   (N = 467), participants provided responses to neutral open-ended
   questions, narrating aspects of their lives relevant to depression
   (e.g., mood, motivation, sleep). Participants also completed the Patient
   Health Questionnaire (PHQ-9) to assess depressive symptoms and a risky
   decision-making task with periodic measurements of momentary happiness
   to quantify mood dynamics. The sentiment of written responses was
   evaluated by human raters (N = 470), Large Language Models (LLMs;
   ChatGPT 3.5 and 4.0), and the Linguistic Inquiry and Word Count (LIWC)
   tool. We found that language sentiment evaluated by human raters and
   LLMs, but not LIWC, predicted changes in depressive symptoms at a
   three-week follow-up. Using computational modeling, we found that
   language sentiment was associated with current mood, but language
   sentiment predicted symptom changes even after controlling for current
   mood. In summary, we demonstrate a scalable tool that combines brief
   written responses with sentiment analysis by AI tools that matches human
   performance in the prediction of future psychiatric symptoms.
ZA 0
TC 1
ZS 0
ZR 0
ZB 1
Z8 0
Z9 1
DA 2025-03-23
UT WOS:001392568800001
PM 39284070
ER

PT J
AU Kim, Junyoung
   Wang, Kai
   Weng, Chunhua
   Liu, Cong
TI Assessing the utility of large language models for phenotype-driven gene
   prioritization in the diagnosis of rare genetic disease
SO AMERICAN JOURNAL OF HUMAN GENETICS
VL 111
IS 10
BP 2189
EP 2202
DI 10.1016/j.ajhg.2024.08.010
EA OCT 2024
DT Article
PD OCT 3 2024
PY 2024
AB Phenotype-driven gene prioritization is fundamental to diagnosing rare
   genetic disorders. While traditional approaches rely on curated
   knowledge graphs with phenotype-gene relations, recent advancements in
   large language models (LLMs) promise a streamlined text-to- gene
   solution. In this study, we evaluated five LLMs, including two
   generative pre-trained transformers (GPT) series and three Llama2
   series, assessing their performance across task completeness, gene
   prediction accuracy, and adherence to required output structures. We
   conducted experiments, exploring various combinations of models,
   prompts, phenotypic input types, and task difficulty levels. Our
   findings revealed that the best-performed LLM, GPT-4, achieved an
   average accuracy of 17.0% in identifying diagnosed genes within the top
   50 predictions, which still falls behind traditional tools. However,
   accuracy increased with the model size. Consistent results were observed
   over time, as shown in the dataset curated after 2023. Advanced
   techniques such as retrieval-augmented generation (RAG) and few-shot
   learning did not improve the accuracy. Sophisticated prompts were more
   likely to enhance task completeness, especially in smaller models.
   Conversely, complicated prompts tended to decrease output structure
   compliance rate. LLMs also achieved better-than-random prediction
   accuracy with free-text input, though performance was slightly lower
   than with standardized concept input. Bias analysis showed that highly
   cited genes, such as BRCA1, , TP53, , and PTEN, , are more likely to be
   predicted. Our study provides valuable insights into integrating LLMs
   with genomic analysis, contributing to the ongoing discussion on their
   utilization in clinical workflows.
ZR 0
Z8 0
TC 1
ZS 0
ZA 0
ZB 1
Z9 1
DA 2024-10-18
UT WOS:001331490700001
PM 39255797
ER

PT J
AU Chiarelli, Giuseppe
   Stephens, Alex
   Finati, Marco
   Cirulli, Giuseppe Ottone
   Beatrici, Edoardo
   Filipas, Dejan K.
   Arora, Sohrab
   Tinsley, Shane
   Bhandari, Mahendra
   Carrieri, Giuseppe
   Trinh, Quoc-Dien
   Briganti, Alberto
   Montorsi, Francesco
   Lughezzani, Giovanni
   Buffi, Nicolo
   Rogers, Craig
   Abdollah, Firas
TI Adequacy of prostate cancer prevention and screening recommendations
   provided by an artificial intelligence-powered large language model
SO INTERNATIONAL UROLOGY AND NEPHROLOGY
VL 56
IS 8
BP 2589
EP 2595
DI 10.1007/s11255-024-04009-5
EA APR 2024
DT Article
PD AUG 2024
PY 2024
AB Purpose We aimed to assess the appropriateness of ChatGPT in providing
   answers related to prostate cancer (PCa) screening, comparing GPT-3.5
   and GPT-4. Methods A committee of five reviewers designed 30 questions
   related to PCa screening, categorized into three difficulty levels. The
   questions were formulated identically for both GPTs three times, varying
   the prompts. Each reviewer assigned a score for accuracy, clarity, and
   conciseness. The readability was assessed by the Flesch Kincaid Grade
   (FKG) and Flesch Reading Ease (FRE). The mean scores were extracted and
   compared using the Wilcoxon test. We compared the readability across the
   three different prompts by ANOVA. Results In GPT-3.5 the mean score (SD)
   for accuracy, clarity, and conciseness was 1.5 (0.59), 1.7 (0.45), 1.7
   (0.49), respectively for easy questions; 1.3 (0.67), 1.6 (0.69), 1.3
   (0.65) for medium; 1.3 (0.62), 1.6 (0.56), 1.4 (0.56) for hard. In GPT-4
   was 2.0 (0), 2.0 (0), 2.0 (0.14), respectively for easy questions; 1.7
   (0.66), 1.8 (0.61), 1.7 (0.64) for medium; 2.0 (0.24), 1.8 (0.37), 1.9
   (0.27) for hard. GPT-4 performed better for all three qualities and
   difficulty levels than GPT-3.5. The FKG mean for GPT-3.5 and GPT-4
   answers were 12.8 (1.75) and 10.8 (1.72), respectively; the FRE for
   GPT-3.5 and GPT-4 was 37.3 (9.65) and 47.6 (9.88), respectively. The 2nd
   prompt has achieved better results in terms of clarity (all p < 0.05).
   Conclusions GPT-4 displayed superior accuracy, clarity, conciseness, and
   readability than GPT-3.5. Though prompts influenced the quality response
   in both GPTs, their impact was significant only for clarity.
ZR 0
Z8 0
ZS 0
ZA 0
ZB 0
TC 5
Z9 5
DA 2024-04-12
UT WOS:001195665100004
PM 38564079
ER

PT J
AU Huang, Xiaoqin
   Raja, Hina
   Madadi, Yeganeh
   Delsoz, Mohammad
   Poursoroush, Asma
   Kahook, Malik Y.
   Yousefi, Siamak
TI Predicting Glaucoma Before Onset Using a Large Language Model Chatbot
SO AMERICAN JOURNAL OF OPHTHALMOLOGY
VL 266
BP 289
EP 299
DI 10.1016/j.ajo.2024.05.022
EA SEP 2024
DT Article
PD OCT 2024
PY 2024
AB center dot PURPOSE: To investigate the capability of ChatGPT for
   forecasting the conversion from ocular hypertension (OHT) to glaucoma
   based on the Ocular Hypertension Treatment Study (OHTS). center dot
   DESIGN: Retrospective case-control study. center dot PARTICIPANTS: A
   total of 3008 eyes of 1504 subjects from the OHTS were included in the
   study. center dot METHODS: We selected demographic, clinical, ocular,
   optic nerve head, and visual field (VF) parameters 1 year before
   glaucoma development from the OHTS participants. Subsequently, we
   developed queries by converting tabular parameters into textual format
   based on both eyes of all participants. We used the ChatGPT application
   program interface (API) to automatically perform ChatGPT prompting for
   all subjects. We then investigated whether ChatGPT can accurately
   forecast conversion from OHT to glaucoma based on various objective
   metrics. center dot MAIN OUTCOME MEASURE: Accuracy, area under the
   receiver operating characteristic curve (AUC), sensitivity, specificity,
   and weighted F1 score. center dot RESULTS: ChatGPT4.0 demonstrated an
   accuracy of 75%, AUC of 0.67, sensitivity of 56%, specificity of 78%,
   and weighted F1 score of 0.77 in predicting conversion to glaucoma 1
   year before onset. ChatGPT3.5 provided an accuracy of 61%, AUC of 0.62,
   sensitivity of 64%, specificity of 59%, and weighted F1 score of 0.63 in
   predicting conversion to glaucoma 1 year before onset. center dot
   CONCLUSIONS: The performance of ChatGPT4.0 in forecasting development of
   glaucoma 1 year before onset was reasonable. The overall performance of
   ChatGPT4.0 was consistently higher than ChatGPT3.5. Large language
   models (LLMs) hold great promise for augmenting glaucoma research
   capabilities and enhancing clinical care. Future efforts in creating
   ophthalmology-specific LLMs that leverage multimodal data in combination
   with active learning may lead to more useful integration with clinical
   practice and deserve further investigations. (Am J Ophthalmol 2024;266:
   289-299. (c) 2024 Elsevier Inc. All rights are reserved, including those
   for text and data mining, AI training, and similar technologies.)
ZS 0
ZA 0
ZR 0
Z8 0
TC 9
ZB 1
Z9 9
DA 2024-09-25
UT WOS:001316319200001
PM 38823673
ER

PT J
AU Garcia, Danilo
   Granjard, Alexandre
   Vanhee, Lois
   Berg, Matilda
   Andersson, Gerhard
   Lasota, Marta
   Sikstrom, Sverker
TI AI-driven analyzes of open-ended responses to assess outcomes of
   internet-based cognitive behavioral therapy (ICBT) in adolescents with
   anxiety and depression comorbidity
SO JOURNAL OF AFFECTIVE DISORDERS
VL 381
BP 659
EP 668
DI 10.1016/j.jad.2025.04.003
EA APR 2025
DT Article
PD JUL 15 2025
PY 2025
AB Objective: Although patients prefer describing their problems using
   words, mental health interventions are commonly evaluated using rating
   scales. Fortunately, recent advances in natural language processing
   (i.e., AI-methods) yield new opportunities to quantify people's own
   mental health descriptions. Our aim was to explore whether responses to
   open-ended questions, quantified using AI, provide additional value in
   measuring intervention outcomes compared to traditional rating scales.
   Method: Swedish adolescents (N = 44) who received Internet-based
   Cognitive Behavioral Therapy (ICBT) for eight weeks completed (pre/post)
   scales measuring anxiety and depression and three open-ended questions
   (related to depression, anxiety and general mental health). The language
   responses were quantified using a large language model and quantitative
   methods to predict mental health as measured by rating scales, valence
   (i.e., words' positive/negative affectivity), and semantic content
   (i.e., meaning). Results: Similar to the rating scales, language
   measures revealed statistically significant health improvements between
   pre and post measures such as reduced depression and anxiety symptoms
   and an increase in the use of words conveying positive emotions and
   different meanings (e.g., pre-intervention: "anxious", depressed;
   post-intervention: "happy", "the future"). Notably, the health changes
   identified through semantic content measures remained statistically
   significant even after accounting for the changes captured by the rating
   scales. Conclusion: Language responses analyzed using AI-methods
   assessed outcomes with fewer items, demonstrating effectiveness and
   accuracy comparable to traditional rating scales. Additionally, this
   approach provided valuable insights into patients' well-being beyond
   mere symptom reduction, thus highlighting areas of improvement that
   rating scales often overlook. Since patients often prefer using natural
   language to express their mental health, this method could complement,
   and address comprehension issues associated fixed-item questionnaires.
ZS 0
Z8 0
TC 0
ZA 0
ZB 0
ZR 0
Z9 0
DA 2025-05-06
UT WOS:001476641800001
PM 40187428
ER

PT J
AU Hsueh, Jessica Y.
   Nethala, Daniel
   Singh, Shiva
   Linehan, W. Marston
   Ball, Mark W.
TI Investigating the clinical reasoning abilities of large language model
   GPT-4: an analysis of postoperative complications from renal surgeries
SO UROLOGIC ONCOLOGY-SEMINARS AND ORIGINAL INVESTIGATIONS
VL 42
IS 9
BP 292e1
EP 292e7
DI 10.1016/j.urolonc.2024.04.010
EA JUN 2024
DT Article
PD SEP 2024
PY 2024
AB Purpose: Large language models, a subset of artificial intelligence,
   have immense potential to support human tasks. The role of these models
   in science and medicine is unclear, requiring strong critical thinking
   and analysis skills. The objective of our study was to evaluate GPT-4's
   abilities to assess postoperative complications after renal surgeries.
   Materials and methods: Discharge summaries were compiled, and patient
   information was deidentified in a Python-based program. Prompts were
   engineered in GPT-4 to assess for the presence of postoperative
   complications. GPT-4 was further asked to interpret each complication's
   Clavien-Dindo classification and institutional-specific category.
   GPT-4's database was compared to a human-curated database. Discrepancies
   were manually reviewed to calculate match and accuracy rates. Results:
   Approximately 944 renal surgeries were conducted from August 2005 to
   March 2022. There was a 79.6% match rate between GPT-4 and human-curated
   data in detecting postoperative complications. Accuracy rates were 86.7%
   for GPT-4 and 92.9% for humancurated. A subgroup of 139 patients had a
   complication detected by both GPT-4 and human with available
   Clavien-Dindo classification and category information. There was a 37.4%
   overall match rate for Clavien-Dindo grade and 55.4% match rate for
   category. Conclusions: GPT-4 was able to accurately detect if there were
   any postoperative complications. It struggled with the complex task of
   further analyzing complications, especially with Clavien-Dindo
   classification, which requires more critical thinking and
   interpretation. While GPT-4 is not yet ready for advanced postoperative
   complication analysis, it can still be used to support clinicians in
   this endeavor.
TC 4
ZR 0
ZB 1
Z8 0
ZA 0
ZS 0
Z9 4
DA 2024-11-09
UT WOS:001345270500001
PM 38714380
ER

PT J
AU Yun, Hye Sun
   Bickmore, Timothy
TI Online Health Information-Seeking in the Era of Large Language Models:
   Cross-Sectional Web-Based Survey Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 27
AR e68560
DI 10.2196/68560
DT Article
PD MAR 31 2025
PY 2025
AB Background: As large language model (LLM)-based chatbots such as ChatGPT
   (OpenAI) grow in popularity, it is essential to understand their role in
   delivering online health information compared to other resources. These
   chatbots often generate inaccurate content, posing potential safety
   risks. This motivates the need to examine how users perceive and act on
   health information provided by LLM-based chatbots. Objective: This study
   investigates the patterns, perceptions, and actions of users seeking
   health information online, including LLM-based chatbots. The
   relationships between online health information-seeking behaviors and
   important sociodemographic characteristics are examined as well.
   Methods: A web-based survey of crowd workers was conducted via Prolific.
   The questionnaire covered sociodemographic information, trust in health
   care providers, eHealth literacy, artificial intelligence (AI)
   attitudes, chronic health condition status, online health information
   source types, perceptions, and actions, such as cross-checking or
   adherence. Quantitative and qualitative analyses were applied. Results:
   Most participants consulted search engines (291/297, 98%) and
   health-related websites (203/297, 68.4%) for their health information,
   while21.2% (63/297) used LLM-based chatbots, with ChatGPT and Microsoft
   Copilot being the most popular. Most participants (268/297, 90.2%)
   sought information on health conditions, with fewer seeking advice on
   medication (179/297, 60.3%), treatments (137/297, 46.1%), and
   self-diagnosis (62/297, 23.2%). Perceived information quality and trust
   varied little across source types. The preferred source for validating
   information from the internet was consulting health care professionals
   (40/132, 30.3%), while only a very small percentage of participants
   (5/214, 2.3%) consulted AI tools to cross-check information from search
   engines and health-related websites. For information obtained from
   LLM-based chatbots,19.4% (12/63) of participants cross-checked the
   information, while 48.4% (30/63) of participants followed the advice.
   Both of these rates were lower than information from search engines,
   health-related websites, forums, or social media. Furthermore, use of
   LLM-based chatbots for health information was negatively correlated with
   age (rho=-0.16, P=.006). In contrast, attitudes surrounding AI for
   medicine had significant positive correlations with the number of source
   types consulted for health advice (rho=0.14, P=.01), use of LLM-based
   chatbotsfor health information (rho=0.31, P<.001), and number of health
   topics searched (rho=0.19, P<.001). Conclusions:Although traditional
   online sources remain dominant, LLM-based chatbots are emerging as a
   resource for health information for some users, specifically those who
   are younger and have a higher trust in AI. The perceived quality and
   trustworthiness of health information varied little across source types.
   However, the adherence to health information from LLM-based chatbots
   seemed more cautious compared to search engines or health-related
   websites. As LLMs continue to evolve, enhancing their accuracy and
   transparency will be essential in mitigating any potential risks by
   supporting responsible information-seeking while maximizing the
   potential of AI in health contexts.
ZR 0
Z8 0
TC 1
ZS 0
ZB 0
ZA 0
Z9 1
DA 2025-04-27
UT WOS:001470101200010
PM 40163112
ER

PT J
AU Choi, Dong Hyun
   Kim, Yoonjic
   Choi, Sae Won
   Kim, Ki Hong
   Choi, Yeongho
   Shin, Sang Do
TI Using Large Language Models to Extract Core Injury Information From
   Emergency Department Notes
SO JOURNAL OF KOREAN MEDICAL SCIENCE
VL 39
IS 46
AR e291
DI 10.3346/jkms.2024.39.e291
DT Article
PD DEC 2 2024
PY 2024
AB Background: Injuries pose a significant global health challenge due to
   their high incidence and mortality rates. Although injury surveillance
   is essential for prevention, it is resource-intensive. This study aimed
   to develop and validate locally deployable large language models (LLMs)
   to extract core injury-related information from Emergency Department
   (ED) clinical notes. Methods: We conducted a diagnostic study using
   retrospectively collected data from January 2014 to December 2020 from
   two urban academic tertiary hospitals. One served as the derivation
   cohort and the other as the external test cohort. Adult patients
   presenting to the ED with injury-related complaints were included.
   Primary outcomes included classification accuracies for information
   extraction tasks related to injury mechanism, place of occurrence,
   activity, intent, and severity. We fine-tuned a single generalizable
   Llama-2 model and five distinct Bidirectional Encoder Representations
   from Transformers (BERT) models for each task to extract information
   from initial ED physician notes. The Llama-2 model was able to perform
   different tasks by modifying the instruction prompt. Data recorded in
   injury registries provided the gold standard labels. Model performance
   was assessed using accuracy and macro-average F1 scores. Results: The
   derivation and external test cohorts comprised 36,346 and 32,232
   patients, respectively. In the derivation cohort's test set, the Llama-2
   model achieved accuracies (95% confidence intervals) of 0.899
   (0.889-0.909) for injury mechanism, 0.774 (0.760-0.789) for place of
   occurrence, 0.679 (0.665-0.694) for activity, 0.972 (0.967-0.977) for
   intent, and 0.935 (0.926-0.943) for severity. The Llama-2 model
   outperformed the BERT models in accuracy and macro-average F1 scores
   across all tasks in both cohorts. Imposing constraints on the Llama-2
   model to avoid uncertain predictions further improved its accuracy.
   Conclusion: Locally deployable LLMs, trained to extract core
   injury-related information from free-text ED clinical notes,
   demonstrated good performance. Generative LLMs can serve as versatile
   solutions for various injury-related information extraction tasks.
TC 3
Z8 0
ZA 0
ZS 0
ZB 0
ZR 0
Z9 3
DA 2024-12-11
UT WOS:001371832200003
PM 39623965
ER

PT J
AU Bushuven, Stefan
   Bentele, Michael
   Bentele, Stefanie
   Gerber, Bianka
   Bansbach, Joachim
   Ganter, Julian
   Trifunovic-Koenig, Milena
   Ranisch, Robert
TI "ChatGPT, Can You Help Me Save My Child's Life?" - Diagnostic Accuracy
   and Supportive Capabilities to Lay Rescuers by ChatGPT in Prehospital
   Basic Life Support and Paediatric Advanced Life Support Cases - An
   In-silico Analysis
SO JOURNAL OF MEDICAL SYSTEMS
VL 47
IS 1
AR 123
DI 10.1007/s10916-023-02019-x
DT Article
PD NOV 21 2023
PY 2023
AB BackgroundPaediatric emergencies are challenging for healthcare workers,
   first aiders, and parents waiting for emergency medical services to
   arrive. With the expected rise of virtual assistants, people will likely
   seek help from such digital AI tools, especially in regions lacking
   emergency medical services. Large Language Models like ChatGPT proved
   effective in providing health-related information and are competent in
   medical exams but are questioned regarding patient safety. Currently,
   there is no information on ChatGPT's performance in supporting parents
   in paediatric emergencies requiring help from emergency medical
   services. This study aimed to test 20 paediatric and two basic life
   support case vignettes for ChatGPT and GPT-4 performance and safety in
   children.MethodsWe provided the cases three times each to two models,
   ChatGPT and GPT-4, and assessed the diagnostic accuracy, emergency call
   advice, and the validity of advice given to parents.ResultsBoth models
   recognized the emergency in the cases, except for septic shock and
   pulmonary embolism, and identified the correct diagnosis in 94%.
   However, ChatGPT/GPT-4 reliably advised to call emergency services only
   in 12 of 22 cases (54%), gave correct first aid instructions in 9 cases
   (45%) and incorrectly advised advanced life support techniques to
   parents in 3 of 22 cases (13.6%).ConclusionConsidering these results of
   the recent ChatGPT versions, the validity, reliability and thus safety
   of ChatGPT/GPT-4 as an emergency support tool is questionable. However,
   whether humans would perform better in the same situation is uncertain.
   Moreover, other studies have shown that human emergency call operators
   are also inaccurate, partly with worse performance than ChatGPT/GPT-4 in
   our study. However, one of the main limitations of the study is that we
   used prototypical cases, and the management may differ from urban to
   rural areas and between different countries, indicating the need for
   further evaluation of the context sensitivity and adaptability of the
   model. Nevertheless, ChatGPT and the new versions under development may
   be promising tools for assisting lay first responders, operators, and
   professionals in diagnosing a paediatric emergency.Trial registrationNot
   applicable.
ZS 0
ZB 2
TC 16
Z8 0
ZR 0
ZA 0
Z9 16
DA 2023-12-17
UT WOS:001105533600001
PM 37987870
ER

PT J
AU D'Amico, Saverio
   Delleani, Mattia
   Sauta, Elisabetta
   Asti, Gianluca
   Zazzetti, Elena
   Campagna, Alessia
   Lanino, Luca
   Maggioni, Giulia
   Ubezio, Marta
   Todisco, Gabriele
   Russo, Antonio
   Tentori, Cristina Astrid
   Buizza, Alessandro
   Bicchieri, Marilena
   Zampini, Matteo
   Brindisi, Matteo
   Ficara, Francesca
   Riva, Elena
   Ventura, Denise
   Crisafulli, Laura
   Pinocchio, Nicole
   Jacobs, Flavia
   Zambelli, Alberto
   Savevski, Victor
   Santoro, Armando
   Sanavia, Tiziana
   Rollo, Cesare
   Sartori, Flavio
   Fariselli, Piero
   Sanz, Guillermo
   Santini, Valeria
   Sole, Francesc
   Platzbecker, Uwe
   Fenaux, Pierre
   Diez-Campelo, Maria
   Kordasti, Shahram
   Komrokji, Rami S.
   Garcia-Manero, Guillermo
   Haferlach, Torsten
   Zeidan, Amer M.
   Castellani, Gastone
   Della Porta, Matteo Giovanni
TI Generation of Multimodal Longitudinal Synthetic Data By Artificial
   Intelligence to Improve Personalized Medicine in Hematology
SO BLOOD
VL 144
BP 4981
EP 4983
DI 10.1182/blood-2024-209541
SU 1
DT Meeting Abstract
PD NOV 5 2024
PY 2024
CT 66th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 07-10, 2024
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZB 0
ZA 0
TC 0
ZS 0
Z9 0
DA 2025-03-12
UT WOS:001414500000040
ER

PT J
AU Afshar, Majid
   Gao, Yanjun
   Gupta, Deepak
   Croxford, Emma
   Demner-Fushman, Dina
TI On the role of the UMLS in supporting diagnosis generation proposed by
   Large Language Models
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 157
AR 104707
DI 10.1016/j.jbi.2024.104707
EA AUG 2024
DT Article
PD SEP 2024
PY 2024
AB Objective: Traditional knowledge-based and machine learning diagnostic
   decision support systems have benefited from integrating the medical
   domain knowledge encoded in the Unified Medical Language System (UMLS).
   The emergence of Large Language Models (LLMs) to supplant traditional
   systems poses questions of the quality and extent of the medical
   knowledge in the models' internal knowledge representations and the need
   for external knowledge sources. The objective of this study is
   three-fold: to probe the diagnosis-related medical knowledge of popular
   LLMs, to examine the benefit of providing the UMLS knowledge to LLMs
   (grounding the diagnosis predictions), and to evaluate the correlations
   between human judgments and the UMLS-based metrics for generations by
   LLMs. Methods: We evaluated diagnoses generated by LLMs from consumer
   health questions and daily care notes in the electronic health records
   using the ConsumerQA and Problem Summarization datasets. Probing LLMs
   for the UMLS knowledge was performed by prompting the LLM to complete
   the diagnosis-related UMLS knowledge paths. Grounding the predictions
   was examined in an approach that integrated the UMLS graph paths and
   clinical notes in prompting the LLMs. The results were compared to
   prompting without the UMLS paths. The final experiments examined the
   alignment of different evaluation metrics, UMLS-based and non-UMLS, with
   human expert evaluation. Results: In probing the UMLS knowledge, GPT-3.5
   significantly outperformed Llama2 and a simple baseline yielding an F1
   score of 10.9% in completing one-hop UMLS paths for a given concept.
   Grounding diagnosis predictions with the UMLS paths improved the results
   for both models on both tasks, with the highest improvement (4%) in
   SapBERT score. There was a weak correlation between the widely used
   evaluation metrics (ROUGE and SapBERT) and human judgments. Conclusion:
   We found that while popular LLMs contain some medical knowledge in their
   internal representations, augmentation with the UMLS knowledge provides
   performance gains around diagnosis generation. The UMLS needs to be
   tailored for the task to improve the LLMs predictions. Finding
   evaluation metrics that are aligned with human judgments better than the
   traditional ROUGE and BERT-based scores remains an open research
   question.
ZA 0
ZR 0
ZS 0
TC 2
ZB 0
Z8 0
Z9 2
DA 2024-09-02
UT WOS:001300508200001
PM 39142598
ER

PT J
AU Suh, Pae Sun
   Shim, Woo Hyun
   Suh, Chong Hyun
   Heo, Hwon
   Park, Chae Ri
   Eom, Hye Joung
   Park, Kye Jin
   Choe, Jooae
   Kim, Pyeong Hwa
   Park, Hyo Jung
   Ahn, Yura
   Park, Ho Young
   Choi, Yoonseok
   Woo, Chang-Yun
   Park, Hyungjun
TI Comparing Diagnostic Accuracy of Radiologists versus GPT-4V and Gemini
   Pro Vision Using Image Inputs from Diagnosis Please Cases
SO RADIOLOGY
VL 312
IS 1
AR e240273
DI 10.1148/radiol.240273
DT Article
PD JUL 2024
PY 2024
AB Background: The diagnostic abilities of multimodal large language models
   (LLMs) using direct image inputs and the impact of the temperature
   parameter of LLMs remain unexplored. Purpose: To investigate the ability
   of GPT-4V and Gemini Pro Vision in generating differential diagnoses at
   different temperatures compared with radiologists using Radiology
   Diagnosis Please cases. Materials and Methods: This retrospective study
   included Diagnosis Please cases published from January 2008 to October
   2023. Input images included original images and captures of the textual
   patient history and figure legends (without imaging findings) from PDF
   files of each case. The LLMs were tasked with providing three
   differential diagnoses, repeated five times at temperatures 0, 0.5, and
   1. Eight subspecialty-trained radiologists solved cases. An experienced
   radiologist compared generated and final diagnoses, considering the
   result correct if the generated diagnoses included the final diagnosis
   after five repetitions. Accuracy was assessed across models,
   temperatures, and radiology subspecialties, with statistical
   significance set at P < .007 after Bonferroni correction for multiple
   comparisons across the LLMs at the three temperatures and with
   radiologists. Results: A total of 190 cases were included in
   neuroradiology (n n = 53), multisystem (n n = 27), gastrointestinal (n n
   = 25), genitourinary (n n = 23), musculoskeletal (n n = 17), chest (n n
   = 16), cardiovascular (n n = 12), pediatric (n n = 12), and breast (n n
   = 5) subspecialties. Overall accuracy improved with increasing
   temperature settings (0, 0.5, 1) for both GPT-4V (41% [78 of 190 cases],
   45% [86 of 190 cases], 49% [93 of 190 cases], respectively) and Gemini
   Pro Vision (29% [55 of 190 cases], 36% [69 of 190 cases], 39% [74 of 190
   cases], respectively), although there was no evidence of a statistically
   significant difference after Bonferroni adjustment (GPT-4V, P = .12;
   Gemini Pro Vision, P = .04). The overall accuracy of radiologists (61%
   [115 of 190 cases]) was higher than that of Gemini Pro Vision at
   temperature 1 (T1) (P P < .001), while no statistically significant
   difference was observed between radiologists and GPT4V at T1 after
   Bonferroni adjustment (P P = .02). Radiologists (range, 45%-88%)
   outperformed the LLMs at T1 (range, 24%-75%) in most subspecialties.
   Conclusion: Using direct radiologic image inputs, GPT-4V and Gemini Pro
   Vision showed improved diagnostic accuracy with increasing temperature
   settings. Although GPT-4V slightly underperformed compared with
   radiologists, it nonetheless demonstrated promising potential as a
   supportive tool in diagnostic decision-making. (c) RSNA, 2024
ZA 0
TC 21
ZB 2
ZR 0
Z8 1
ZS 0
Z9 22
DA 2024-08-05
UT WOS:001279556500025
PM 38980179
ER

PT J
AU Fu, Sidney W.
   Tang, Cong
   Tan, Xiaohui
   Srivastava, Sudhir
TI Liquid biopsy for early cancer detection: technological revolutions and
   clinical dilemma
SO EXPERT REVIEW OF MOLECULAR DIAGNOSTICS
VL 24
IS 10
BP 937
EP 955
DI 10.1080/14737159.2024.2408744
EA OCT 2024
DT Review
PD OCT 2 2024
PY 2024
AB IntroductionLiquid biopsy is an innovative advancement in oncology,
   offering a noninvasive method for early cancer detection and monitoring
   by analyzing circulating tumor cells, DNA, RNA, and other biomarkers in
   bodily fluids. This technique has the potential to revolutionize
   precision oncology by providing real-time analysis of tumor dynamics,
   enabling early detection, monitoring treatment responses, and tailoring
   personalized therapies based on the molecular profiles of individual
   patients.Areas coveredIn this review, the authors discuss current
   methodologies, technological challenges, and clinical applications of
   liquid biopsy. This includes advancements in detecting minimal residual
   disease, tracking tumor evolution, and combining liquid biopsy with
   other diagnostic modalities for precision oncology. Key areas explored
   are the sensitivity, specificity, and integration of multi-omics, AI,
   ML, and LLM technologies.Expert opinionLiquid biopsy holds great
   potential to revolutionize cancer care through early detection and
   personalized treatment strategies. However, its success depends on
   overcoming technological and clinical hurdles, such as ensuring high
   sensitivity and specificity, interpreting results amidst tumor
   heterogeneity, and making tests accessible and affordable. Continued
   innovation and collaboration are crucial to fully realize the potential
   of liquid biopsy in improving early cancer detection, treatment, and
   monitoring.
ZR 0
ZA 0
Z8 0
ZB 2
TC 6
ZS 0
Z9 6
DA 2024-10-09
UT WOS:001325602700001
PM 39360748
ER

PT J
AU Cho, Hyeongmin
   Yoo, Sooyoung
   Kim, Borham
   Jang, Sowon
   Sunwoo, Leonard
   Kim, Sanghwan
   Lee, Donghyoung
   Kim, Seok
   Nam, Sejin
   Chung, Jin-Haeng
TI Extracting lung cancer staging descriptors from pathology reports: A
   generative language model approach
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 157
AR 104720
DI 10.1016/j.jbi.2024.104720
EA SEP 2024
DT Article
PD SEP 2024
PY 2024
AB Background: In oncology, electronic health records contain textual key
   information for the diagnosis, staging, and treatment planning of
   patients with cancer. However, text data processing requires a lot of
   time and effort, which limits the utilization of these data. Recent
   advances in natural language processing (NLP) technology, including
   large language models, can be applied to cancer research. Particularly,
   extracting the information required for the pathological stage from
   surgical pathology reports can be utilized to update cancer staging
   according to the latest cancer staging guidelines. Objectives: This
   study has two main objectives. The first objective is to evaluate the
   performance of extracting information from text-based surgical pathology
   reports and determining pathological stages based on the extracted
   information using fine-tuned generative language models (GLMs) for
   patients with lung cancer. The second objective is to determine the
   feasibility of utilizing relatively small GLMs for information
   extraction in a resource-constrained computing environment. Methods:
   Lung cancer surgical pathology reports were collected from the Common
   Data Model database of Seoul National University Bundang Hospital
   (SNUBH), a tertiary hospital in Korea. We selected 42 descriptors
   necessary for tumor-node (TN) classification based on these reports and
   created a gold standard with validation by two clinical experts. The
   pathology reports and gold standard were used to generate
   prompt-response pairs for training and evaluating GLMs which then were
   used to extract information required for staging from pathology reports.
   Results: We evaluated the information extraction performance of six
   trained models as well as their performance in TN classification using
   the extracted information. The Deductive Mistral-7B model, which was
   pre-trained with the deductive dataset, showed the best performance
   overall, with an exact match ratio of 92.24% in the information
   extraction problem and an accuracy of 0.9876 (predicting T and N
   classification concurrently) in classification. Conclusion: This study
   demonstrated that training GLMs with deductive datasets can improve
   information extraction performance, and GLMs with a relatively small
   number of parameters at approximately seven billion can achieve high
   performance in this problem. The proposed GLM-based information
   extraction method is expected to be useful in clinical decision-making
   support, lung cancer staging and research.
ZS 0
ZA 0
ZR 0
TC 4
ZB 1
Z8 0
Z9 4
DA 2024-09-21
UT WOS:001312772300001
PM 39233209
ER

PT J
AU Bhayana, Rajesh
   Alwahbi, Omar
   Ladak, Aly Muhammad
   Deng, Yangqing
   Dias, Adriano Basso
   Elbanna, Khaled
   Gomez, Jorge Abreu
   Jajodia, Ankush
   Jhaveri, Kartik
   Johnson, Sarah
   Kajal, Dilkash
   Wang, David
   Soong, Christine
   Kielar, Ania
   Krishna, Satheesh
TI Leveraging Large Language Models to Generate Clinical Histories for
   Oncologic Imaging Requisitions
SO RADIOLOGY
VL 314
IS 2
AR e242134
DI 10.1148/radiol.242134
DT Article
PD FEB 2025
PY 2025
AB Background: Clinical information improves imaging interpretation, but
   physician-provided histories on requisitions for oncologic imaging often
   lack key details. Purpose: To evaluate large language models (LLMs) for
   automatically generating clinical histories for oncologic imaging
   requisitions from clinical notes and compare them with original
   requisition histories. Materials and Methods: In total, 207 patients
   with CT performed at a cancer center from January to November 2023 and
   with an electronic health record clinical note coinciding with ordering
   date were randomly selected. A multidisciplinary team informed selection
   of 10 parameters important for oncologic imaging history, including
   primary oncologic diagnosis, treatment history, and acute symptoms.
   Clinical notes were independently reviewed to establish the reference
   standard regarding presence of each parameter. After prompt engineering
   with seven patients, GPT-4 (version 0613; OpenAI) was prompted on April
   9, 2024, to automatically generate structured clinical histories for the
   200 remaining patients. Using the reference standard, LLM extraction
   performance was calculated (recall, precision, F1 score). LLM-generated
   and original requisition histories were compared for completeness
   (proportion including each parameter), and 10 radiologists performed
   pairwise comparison for quality, preference, and subjective likelihood
   of harm. Results: For the 200 LLM-generated histories, GPT-4 performed
   well, extracting oncologic parameters from clinical notes (F1 = 0.983).
   Compared with original requisition histories, LLM-generated histories
   more frequently included parameters critical for radiologist
   interpretation, including primary oncologic diagnosis (99.5% vs 89% [199
   and 178 of 200 histories, respectively]; P < .001), acute or worsening
   symptoms (15% vs 4% [29 and seven of 200]; P < .001), and relevant
   surgery (61% vs 12% [122 and 23 of 200]; P < .001). Radiologists
   preferred LLM-generated histories for imaging interpretation (89% vs 5%,
   7% equal; P < .001), indicating they would enable more complete
   interpretation (86% vs 0%, 15% equal; P < .001) and have a lower
   likelihood of harm (3% vs 55%, 42% neither; P < .001). Conclusion: An
   LLM enabled accurate automated clinical histories for oncologic imaging
   from clinical notes. Compared with original requisition histories,
   LLM-generated histories were more complete and were preferred by
   radiologists for imaging interpretation and perceived safety.
ZA 0
Z8 0
ZR 0
ZB 0
ZS 0
TC 1
Z9 1
DA 2025-03-08
UT WOS:001434851700023
PM 39903072
ER

PT J
AU Ali, Mohammad Javed
TI ChatGPT and Lacrimal Drainage Disorders: Performance and Scope of
   Improvement
SO OPHTHALMIC PLASTIC AND RECONSTRUCTIVE SURGERY
VL 39
IS 3
BP 221
EP 225
DI 10.1097/IOP.0000000000002418
DT Article
PD MAY-JUN 2023
PY 2023
AB Purpose:This study aimed to report the performance of the large language
   model ChatGPT (OpenAI, San Francisco, CA, U.S.A.) in the context of
   lacrimal drainage disorders. Methods:A set of prompts was constructed
   through questions and statements spanning common and uncommon aspects of
   lacrimal drainage disorders. Care was taken to avoid constructing
   prompts that had significant or new knowledge beyond the year 2020. Each
   of the prompts was presented thrice to ChatGPT. The questions covered
   common disorders such as primary acquired nasolacrimal duct obstruction
   and congenital nasolacrimal duct obstruction and their cause and
   management. The prompts also tested ChatGPT on certain specifics, such
   as the history of dacryocystorhinostomy (DCR) surgery, lacrimal pump
   anatomy, and human canalicular surfactants. ChatGPT was also quizzed on
   controversial topics such as silicone intubation and the use of
   mitomycin C in DCR surgery. The responses of ChatGPT were carefully
   analyzed for evidence-based content, specificity of the response,
   presence of generic text, disclaimers, factual inaccuracies, and its
   abilities to admit mistakes and challenge incorrect premises. Three
   lacrimal surgeons graded the responses into three categories: correct,
   partially correct, and factually incorrect. Results:A total of 21
   prompts were presented to the ChatGPT. The responses were detailed and
   were based according to the prompt structure. In response to most
   questions, ChatGPT provided a generic disclaimer that it could not give
   medical advice or professional opinion but then provided an answer to
   the question in detail. Specific prompts such as "how can I perform an
   external DCR?" were responded by a sequential listing of all the
   surgical steps. However, several factual inaccuracies were noted across
   many ChatGPT replies. Several responses on controversial topics such as
   silicone intubation and mitomycin C were generic and not precisely
   evidence-based. ChatGPT's response to specific questions such as
   canalicular surfactants and idiopathic canalicular inflammatory disease
   was poor. The presentation of variable prompts on a single topic led to
   responses with either repetition or recycling of the phrases. Citations
   were uniformly missing across all responses. Agreement among the three
   observers was high (95%) in grading the responses. The responses of
   ChatGPT were graded as correct for only 40% of the prompts, partially
   correct in 35%, and outright factually incorrect in 25%. Hence, some
   degree of factual inaccuracy was present in 60% of the responses, if we
   consider the partially correct responses. The exciting aspect was that
   ChatGPT was able to admit mistakes and correct them when presented with
   counterarguments. It was also capable of challenging incorrect prompts
   and premises. Conclusion:The performance of ChatGPT in the context of
   lacrimal drainage disorders, at best, can be termed average. However,
   the potential of this AI chatbot to influence medicine is enormous.
   There is a need for it to be specifically trained and retrained for
   individual medical subspecialties.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 10
TC 44
Z9 44
DA 2023-06-16
UT WOS:000998726200017
PM 37166289
ER

PT J
AU Sabanayagam, Charumathi
   Banu, Riswana
   Lim, Cynthia
   Tham, Yih Chung
   Cheng, Ching-Yu
   Tan, Gavin
   Ekinci, Elif
   Sheng, Bin
   Mckay, Gareth
   Shaw, Jonathan E.
   Matsushita, Kunihiro
   Tangri, Navdeep
   Choo, Jason
   Wong, Tien Y.
TI Artificial intelligence in chronic kidney disease management: a scoping
   review
SO THERANOSTICS
VL 15
IS 10
BP 4566
EP 4578
DI 10.7150/thno.108552
DT Review
PD 2025
PY 2025
AB Rationale: Chronic kidney disease (CKD) is a major public health problem
   worldwide associated with cardiovascular disease, renal failure, and
   mortality. To effectively address this growing burden, innovative
   solutions to management are urgently required. We conducted a scoping
   review to identify key use cases in which artificial intelligence (AI)
   could be leveraged for improving management of CKD. Additionally, we
   examined the challenges faced by AI in CKD management, proposed
   potential solutions to overcome these barriers. Methods: We reviewed 41
   articles published between 2014-2024 which examined various AI
   techniques including machine learning (ML) and deep learning (DL),
   unsupervised clustering, digital twin, natural language processing (NLP)
   and large language models (LLMs) in CKD management. We focused on four
   areas: early detection, risk stratification and prediction, treatment
   recommendations and patient care and communication. Results: We
   identified 41 articles published between 2014-2024 that assessed
   image-based DL models for early detection (n = 6), ML models for risk
   stratification and prediction (n = 14) and treatment recommendations (n
   = 4), and NLP and LLMs for patient care and communication (n = 17). Key
   challenges in integrating AI models into healthcare include technical
   issues such as data quality and access, model accuracy, and
   interpretability, alongside adoption barriers like workflow integration,
   user training, and regulatory approval. Conclusions: There is tremendous
   potential of integrating AI into clinical care of CKD patients to enable
   early detection, prediction, and improved patient outcomes.
   Collaboration among healthcare providers, researchers, regulators, and
   industries is crucial to developing robust protocols that ensure
   compliance with legal standards, while minimizing risks and maintaining
   patient
Z8 0
ZA 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-05-02
UT WOS:001473295700018
PM 40225559
ER

PT J
AU Schwartz, Ilan S.
   Link, Katherine E.
   Daneshjou, Roxana
   Cortes-Penfield, Nicolas
TI Black Box Warning: Large Language Models and the Future of Infectious
   Diseases Consultation
SO CLINICAL INFECTIOUS DISEASES
VL 78
IS 4
BP 860
EP 866
DI 10.1093/cid/ciad633
EA NOV 2023
DT Article
PD APR 10 2024
PY 2024
AB Large language models (LLMs) are artificial intelligence systems trained
   by deep learning algorithms to process natural language and generate
   text responses to user prompts. Some approach physician performance on a
   range of medical challenges, leading some proponents to advocate for
   their potential use in clinical consultation and prompting some
   consternation about the future of cognitive specialties. However, LLMs
   currently have limitations that preclude safe clinical deployment in
   performing specialist consultations, including frequent confabulations,
   lack of contextual awareness crucial for nuanced diagnostic and
   treatment plans, inscrutable and unexplainable training data and
   methods, and propensity to recapitulate biases. Nonetheless, considering
   the rapid improvement in this technology, growing calls for clinical
   integration, and healthcare systems that chronically undervalue
   cognitive specialties, it is critical that infectious diseases
   clinicians engage with LLMs to enable informed advocacy for how they
   should-and shouldn't-be used to augment specialist care.
   Large language models (LLMs), advanced artificial intelligence systems
   capable of generating natural language, could revolutionize healthcare,
   including current models of specialist consultation. Infectious diseases
   clinicians must urgently engage with and understand limitations of LLMs
   to advocate for their responsible integration.
   Graphical Abstract
   https://tidbitapp.io/tidbits/black-box-warning-large-language-models-and
   -clinical-consultation-in-infectious-disease
ZB 10
ZR 0
TC 50
Z8 1
ZS 0
ZA 0
Z9 51
DA 2023-11-30
UT WOS:001102860600001
PM 37971399
ER

PT J
AU Wu, Gloria
   Del Buono, Milan
   Wong, Adrial
   Zhao, Weichen
   Nguyen, Mary
   Satheesh, Swetha
   Lee, David A.
TI Can Al Large Language Models and Al Assistants help educate our
   Retinitis Pigmentosa (RP) patients?
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
VL 65
IS 7
MA 2327
DT Meeting Abstract
PD JUN 2024
PY 2024
CT Annual Meeting of the
   Association-for-Research-in-Vision-and-Ophthalmology (ARVO)
CY MAY 05-09, 2024
CL Seattle, WA
SP Assoc Res Vision & Ophthalmol
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-12-01
UT WOS:001312227706289
ER

PT J
AU Bejan, Cosmin A.
   Reed, Amy M.
   Mikula, Matthew
   Zhang, Siwei
   Xu, Yaomin
   Fabbri, Daniel
   Embi, Peter J.
   Hsi, Ryan S.
TI Large language models improve the identification of emergency department
   visits for symptomatic kidney stones
SO SCIENTIFIC REPORTS
VL 15
IS 1
AR 3503
DI 10.1038/s41598-025-86632-5
DT Article
PD JAN 28 2025
PY 2025
AB Recent advancements of large language models (LLMs) like generative
   pre-trained transformer 4 (GPT-4) have generated significant interest
   among the scientific community. Yet, the potential of these models to be
   utilized in clinical settings remains largely unexplored. In this study,
   we investigated the abilities of multiple LLMs and traditional machine
   learning models to analyze emergency department (ED) reports and
   determine if the corresponding visits were due to symptomatic kidney
   stones. Leveraging a dataset of manually annotated ED reports, we
   developed strategies to enhance LLMs including prompt optimization,
   zero- and few-shot prompting, fine-tuning, and prompt augmentation.
   Further, we implemented fairness assessment and bias mitigation methods
   to investigate the potential disparities by LLMs with respect to race
   and gender. A clinical expert manually assessed the explanations
   generated by GPT-4 for its predictions to determine if they were sound,
   factually correct, unrelated to the input prompt, or potentially
   harmful. The best results were achieved by GPT-4 (macro-F1 = 0.833, 95%
   confidence interval [CI] 0.826-0.841) and GPT-3.5 (macro-F1 = 0.796, 95%
   CI 0.796-0.796). Ablation studies revealed that the initial pre-trained
   GPT-3.5 model benefits from fine-tuning. Adding demographic information
   and prior disease history to the prompts allows LLMs to make better
   decisions. Bias assessment found that GPT-4 exhibited no racial or
   gender disparities, in contrast to GPT-3.5, which failed to effectively
   model racial diversity.
TC 2
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
Z9 2
DA 2025-02-09
UT WOS:001409652700033
PM 39875475
ER

PT J
AU Bhayana, Rajesh
   Jajodia, Ankush
   Chawla, Tanya
   Deng, Yangqing
   Bouchard-Fortier, Genevieve
   Haider, Masoom
   Krishna, Satheesh
TI Accuracy of Large Language Model-based Automatic Calculation of
   Ovarian-Adnexal Reporting and Data System MRI Scores from Pelvic MRI
   Reports
SO RADIOLOGY
VL 315
IS 1
AR e241554
DI 10.1148/radiol.241554
DT Article
PD APR 2025
PY 2025
AB Background: Ovarian-Adnexal Reporting and Data System (O-RADS) for MRI
   helps assign malignancy risk, but radiologist adoption is inconsistent.
   Automatic assignment of O-RADS scores from reports could increase
   adoption and accuracy. Purpose: To evaluate the accuracy of large
   language models (LLMs), after strategic optimization, for automatically
   calculating O-RADS scores from reports. Materials and Methods: This
   retrospective single-center study from a large quaternary care cancer
   center included consecutive gadolinium chelate-enhanced pelvic MRI
   reports with at least one assigned O-RADS score from July 2021 to
   October 2023. Reports from January 2018 to October 2019 (before O-RADS
   MRI implementation) were randomly selected for additional testing.
   Reference standard O-RADS scores were determined by radiologists
   interpreting reports. After prompt optimization using a subset of
   reports, two LLM-based strategies were evaluated: few-shot learning with
   GPT-4 (version 0613; OpenAI) prompted with O-RADS rules ("LLM only") and
   a hybrid strategy leveraging GPT-4 to classify features fed into a
   deterministic formula ("hybrid"). Accuracy of each model and originally
   reported scores were calculated and compared using the McNemar test.
   Results: A total of 284 reports from 284 female patients (mean age, 53.2
   years +/- 16.3 [SD]) with 372 adnexal lesions were included: 10 reports
   in the training set (16 lesions), 134 reports in the internal test set 1
   (173 lesions; 158 O-RADS assigned), and 140 reports in internal test set
   2 (183 lesions). For assigning O-RADS MRI scores, the hybrid model
   accuracy (97%; 168 of 173) outperformed LLM-only model (90%; 155 of 173;
   P = .006). For lesions with an originally reported O-RADS score, hybrid
   model accuracy exceeded that of reporting radiologists (97% [153 of 158]
   vs 88% [139 of 158]; P = .004). Hybrid model also outperformed LLM-only
   model for 183 lesions from before O-RADS implementation (95% [173 of
   183] vs 87% [159 of 183], respectively; P = .01). Conclusion: A hybrid
   LLM-based application, combining LLM feature classification with
   deterministic elements, accurately assigned O-RADS MRI scores from
   report descriptions, exceeding both an LLM-only strategy and the
   original reporting radiologist. (c) RSNA, 2025
ZR 0
ZS 0
TC 1
ZA 0
ZB 0
Z8 0
Z9 1
DA 2025-04-20
UT WOS:001464808700007
PM 40167432
ER

PT J
AU Omar, Mahmud
   Brin, Dana
   Glicksberg, Benjamin
   Klang, Eyal
TI Utilizing natural language processing and large language models in the
   diagnosis and prediction of infectious diseases: A systematic review
SO AMERICAN JOURNAL OF INFECTION CONTROL
VL 52
IS 9
BP 992
EP 1001
DI 10.1016/j.ajic.2024.03.016
EA AUG 2024
DT Article
PD SEP 2024
PY 2024
AB Background: Natural Language Processing (NLP) and Large Language Models
   (LLMs) hold largely untapped potential in infectious disease management.
   This review explores their current use and uncovers areas needing more
   attention. Methods: This analysis followed systematic review procedures,
   registered with the Prospective Register of Systematic Reviews. We
   conducted a search across major databases including PubMed, Embase, Web
   of Science, and Scopus, up to December 2023, using keywords related to
   NLP, LLM, and infectious diseases. We also employed the Quality
   Assessment of Diagnostic Accuracy Studies-2 tool for evaluating the
   quality and robustness of the included studies. Results: Our review
   identified 15 studies with diverse applications of NLP in infectious
   disease management. Notable examples include GPT-4's application in
   detecting urinary tract infections and BERTweet's use in Lyme Disease
   surveillance through social media analysis. These models demonstrated
   effective disease monitoring and public health tracking capabilities.
   However, the effectiveness varied across studies. For instance, while
   some NLP tools showed high accuracy in pneumonia detection and high
   sensitivity in identifying invasive mold diseases from medical reports,
   others fell short in areas like bloodstream infection management.
   Conclusions: This review highlights the yet-to-be-fully-realized promise
   of NLP and LLMs in infectious disease management. It calls for more
   exploration to fully harness AI's capabilities, particularly in the
   areas of diagnosis, surveillance, predicting disease courses, and
   tracking epidemiological trends. (c) 2024 Association for Professionals
   in Infection Control and Epidemiology, Inc. Published by Elsevier Inc.
   All rights are reserved, including those for text and data mining, AI
   training, and similar technologies.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 2
TC 15
Z9 15
DA 2024-08-29
UT WOS:001297798000001
PM 38588980
ER

PT J
AU Dhanasekaran, Renumathy
   Daugherty, Tami
   Kwo, Paul Yien
   Ghaziani, T. Tara
   Masuoka, Howard
   Elango, Vetri Venthan
TI DEVELOPING A HIGH-PERFORMING CUSTOMIZED AI TUMOR BOARD TOOL FOR HCC
   STAGING AND MANAGEMENT
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1965
BP S884
EP S884
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
TC 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-10-30
UT WOS:001282837703466
ER

PT J
AU Denson, Nicholas K.
   Smith, Julia
   Reigle, James
   Ni, Yizhao
   Dhaliwal, Jasbir
TI AUTOMATING ENDOSCOPIC SCORING THROUGH ARTIFICIAL INTELLIGENCE
SO GASTROENTEROLOGY
VL 166
IS 5
MA Tu2008
BP S1489
EP S1490
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZR 0
ZA 0
ZB 0
ZS 0
TC 0
Z8 0
Z9 0
DA 2024-10-30
UT WOS:001282837706106
ER

PT J
AU Wiest, Isabella Catharina
   Verhees, Falk Gerrik
   Ferber, Dyke
   Zhu, Jiefu
   Bauer, Michael
   Lewitzka, Ute
   Pfennig, Andrea
   Mikolas, Pavol
   Kather, Jakob Nikolas
TI Detection of suicidality from medical text using privacy-preserving
   large language models
SO BRITISH JOURNAL OF PSYCHIATRY
VL 225
IS 6
BP 532
EP 537
DI 10.1192/bjp.2024.134
EA NOV 2024
DT Review
PD DEC 2024
PY 2024
AB Background Attempts to use artificial intelligence (AI) in
   psychiatric disorders show moderate success, highlighting the potential
   of incorporating information from clinical assessments to improve the
   models. This study focuses on using large language models (LLMs) to
   detect suicide risk from medical text in psychiatric care. Aims To
   extract information about suicidality status from the admission notes in
   electronic health records (EHRs) using privacy-sensitive, locally hosted
   LLMs, specifically evaluating the efficacy of Llama-2 models. Method We
   compared the performance of several variants of the open source LLM
   Llama-2 in extracting suicidality status from 100 psychiatric reports
   against a ground truth defined by human experts, assessing accuracy,
   sensitivity, specificity and F1 score across different prompting
   strategies. Results A German fine-tuned Llama-2 model showed the highest
   accuracy (87.5%), sensitivity (83.0%) and specificity (91.8%) in
   identifying suicidality, with significant improvements in sensitivity
   and specificity across various prompt designs. Conclusions The study
   demonstrates the capability of LLMs, particularly Llama-2, in accurately
   extracting information on suicidality from psychiatric records while
   preserving data privacy. This suggests their application in surveillance
   systems for psychiatric emergencies and improving the clinical
   management of suicidality by improving systematic quality control and
   research.
ZR 0
TC 1
ZB 0
Z8 0
ZS 0
ZA 0
Z9 1
DA 2024-11-14
UT WOS:001348165300001
PM 39497458
ER

PT J
AU Anvari, Sama
   Lee, Yung
   Jin, David S.
   Malone, Sarah
   Collins, Matthew
TI AI IN HEPATOLOGY: A COMPARATIVE ANALYSIS OF CHATGPT-4, BING, AND BARD AT
   ANSWERING CLINICAL QUESTIONS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Su1976
BP S888
EP S888
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
TC 0
ZR 0
ZS 0
ZB 0
ZA 0
Z8 0
Z9 0
DA 2024-10-30
UT WOS:001282837703477
ER

PT J
AU Dihan, Qais A.
   Brown, Andrew D.
   Chauhan, Muhammad Z.
   Alzein, Ahmad F.
   Abdelnaem, Seif E.
   Kelso, Sean D.
   Rahal, Dania A.
   Park, Royce
   Ashraf, Mohammadali
   Azzam, Amr
   Morsi, Mahmoud
   Warner, David B.
   Sallam, Ahmed B.
   Saeed, Hajirah N.
   Elhusseiny, Abdelrahman M.
TI Leveraging large language models to improve patient education on dry eye
   disease
SO EYE
VL 39
IS 6
BP 1115
EP 1122
DI 10.1038/s41433-024-03476-5
EA DEC 2024
DT Article
PD APR 2025
PY 2025
AB BACKGROUND/OBJECTIVES: Dry eye disease (DED) is an exceedingly common
   diagnosis in patients, yet recent analyses have demonstrated patient
   education materials (PEMs) on DED to be of low quality and readability.
   Our study evaluated the utility and performance of three large language
   models (LLMs) in enhancing and generating new patient education
   materials (PEMs) on dry eye disease (DED). SUBJECTS/METHODS: We
   evaluated PEMs generated by ChatGPT-3.5, ChatGPT-4, Gemini Advanced,
   using three separate prompts. Prompts A and B requested they generate
   PEMs on DED, with Prompt B specifying a 6th-grade reading level, using
   the SMOG (Simple Measure of Gobbledygook) readability formula. Prompt C
   asked for a rewrite of existing PEMs at a 6th-grade reading level. Each
   PEM was assessed on readability (SMOG, FKGL: Flesch-Kincaid Grade
   Level), quality (PEMAT: Patient Education Materials Assessment Tool,
   DISCERN), and accuracy (Likert Misinformation scale). RESULTS: All
   LLM-generated PEMs in response to Prompt A and B were of high quality
   (median DISCERN = 4), understandable (PEMAT understandability >= 70%)
   and accurate (Likert Score=1). LLM-generated PEMs were not actionable
   (PEMAT Actionability <70%). ChatGPT-4 and Gemini Advanced rewrote
   existing PEMs (Prompt C) from a baseline readability level (FKGL: 8.0
   +/- 2.4, SMOG: 7.9 +/- 1.7) to targeted 6th-grade reading level;
   rewrites contained little to no misinformation (median Likert
   misinformation=1 (range: 1-2)). However, only ChatGPT-4 rewrote PEMs
   while maintaining high quality and reliability (median DISCERN = 4).
   CONCLUSION: LLMs (notably ChatGPT-4) were able to generate and rewrite
   PEMs on DED that were readable, accurate, and high quality. Our study
   underscores the value of leveraging LLMs as supplementary tools to
   improving PEMs.
ZR 0
ZS 0
TC 5
Z8 0
ZA 0
ZB 0
Z9 5
DA 2024-12-22
UT WOS:001379292900001
PM 39681711
ER

PT J
AU Jiang, Bin
   Pham, Nancy
   Staalduinen, Eric K. van
   Liu, Yongkai
   Nazari-Farsani, Sanaz
   Sanaat, Amirhossein
   van Voorst, Henk
   Fettahoglu, Ates
   Kim, Donghoon
   Ouyang, Jiahong
   Kumar, Ashwin
   Srivatsan, Aditya
   Hussein, Ramy
   Lansberg, Maarten G.
   Boada, Fernando
   Zaharchuck, Gerg
TI Deep Learning Applications in Imaging of Acute Ischemic Stroke: A
   Systematic Review and Narrative Summary
SO RADIOLOGY
VL 315
IS 1
BP 1
EP 16
DI 10.1148/radiol.240775
DT Article
PD APR 2025
PY 2025
AB Background: Acute ischemic stroke (AIS) is a major cause of morbidity
   and mortality, requiring swift and precise clinical decisions based on
   neuroimaging. Recent advances in deep learning-based computer vision and
   language artificial intelligence (AI) models have demonstrated
   transformative performance for several stroke-related applications.
   Purpose: To evaluate deep learning applications for imaging in AIS in
   adult patients, providing a comprehensive overview of the current state
   of the technology and identifying opportunities for advancement.
   Materials and Methods: A systematic literature review was conducted
   following Preferred Reporting Items for Systematic Reviews and
   Meta-Analyses guidelines. A comprehensive search of four databases from
   January 2016 to January 2024 was performed, targeting deep learning
   applications for imaging of AIS, including automated detection of large
   vessel occlusion and measurement of Alberta Stroke Program Early CT
   Score. Articles were selected based on predefined inclusion and
   exclusion criteria, focusing on convolutional neural networks and
   transformers. The top-represented areas were addressed, and the relevant
   information was extracted and summarized. Results: Of 380 studies
   included, 171 (45.0%) focused on stroke lesion segmentation, 129 (33.9%)
   on classification and triage, 31 (8.2%) on outcome prediction, 15 (3.9%)
   on generative AI and large language models, and 11 (2.9%) on rapid or
   low-dose imaging specific to stroke applications. Detailed data
   extraction was performed for 68 studies. Public AIS datasets are also
   highlighted, for researchers developing AI models for stroke imaging.
   Conclusion: Deep learning applications have permeated AIS imaging,
   particularly for stroke lesion segmentation. However, challenges remain,
   including the need for standardized protocols and test sets, larger
   public datasets, and performance validation in real-world settings.
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
ZA 0
Z9 0
DA 2025-04-27
UT WOS:001469734000006
PM 40197098
ER

PT J
AU Shaheen, Abdulla
   Afflitto, Gabriele Gallo
   Swaminathan, Swarup S.
TI ChatGPT-Assisted Classification fi cation of Postoperative Bleeding
   Following Microinvasive Glaucoma Surgery Using Electronic Health Record
   Data
SO OPHTHALMOLOGY SCIENCE
VL 5
IS 1
AR 100602
DI 10.1016/j.xops.2024.100602
EA SEP 2024
DT Article
PD FEB 2025
PY 2025
AB Purpose: To evaluate the performance of a large language model (LLM) in
   classifying electronic health record (EHR) text, and to use this
   classification to evaluate the type and resolution of hemorrhagic events
   (HEs) after microinvasive glaucoma surgery (MIGS). Design: Retrospective
   cohort study. Participants: Eyes from the Bascom Palmer Glaucoma
   Repository. Methods: Eyes that underwent MIGS between July 1, 2014 and
   February 1, 2022 were analyzed. Chat Generative Pre-trained Transformer
   (ChatGPT) was used to classify deidentified EHR anterior chamber
   examination text into HE categories (no hyphema, microhyphema, clot, and
   hyphema). Agreement between classifications by ChatGPT and a glaucoma
   specialist was evaluated using Cohen's Kappa and precision-recall (PR)
   curve. Time to resolution of HEs was assessed using Cox
   proportional-hazards models. Goniotomy HE resolution was evaluated by
   degree of angle treatment (90 degrees-179 degrees,180 degrees-269
   degrees, 270 degrees-360 degrees). degrees-360 degrees ). Logistic
   regression was used to identify HE risk factors. Main Outcome Measures:
   Accuracy of ChatGPT HE classification and incidence and resolution of
   HEs. Results: The study included 434 goniotomy eyes (368 patients) and
   528 Schlemm's canal stent (SCS) eyes (390 patients). Chat Generative
   Pre-trained Transformer facilitated excellent HE classification (Cohen's
   kappa 0.93, area under PR curve 0.968). Using ChatGPT classifications,
   at postoperative day 1, HEs occurred in 67.8% of goniotomy and 25.2% of
   SCS eyes (P < 0.001). The 270 degrees degrees to 360 degrees degrees
   goniotomy group had the highest HE rate (84.0%, P < 0.001). At
   postoperative week 1, HEs were observed in 43.4% and 11.3% of goniotomy
   and SCS eyes, respectively (P < 0.001). By postoperative month 1, HE
   rates were 13.3% and 1.3% among goniotomy and SCS eyes, respectively (P
   < 0.001). Time to HE resolution differed between the goniotomy angle
   groups (log-rank P = 0.034); median time to resolution was 10, 10, and
   15 days for the 90 degrees degrees to 179 degrees, 180 degrees to 269
   degrees, and 270 degrees to 360 degrees groups, respectively. Risk
   factor analysis demonstrated greater goniotomy angle was the only
   significant predictor of HEs (odds ratio for 270 degrees-360 degrees:
   360 degrees : 4.08, P < 0.001). Conclusions: Large language models can
   be effectively used to classify longitudinal EHR free-text examination
   data with high accuracy, highlighting a promising direction for future
   LLM-assisted research and clinical decision support. Hemorrhagic events
   are relatively common self-resolving complications that occur more often
   in goniotomy cases and with larger goniotomy treatments. Time to HE
   resolution differs significantly between goniotomy groups. Financial
   Disclosure(s):Proprietary or commercial disclosure may be found in the
   Footnotes and Disclosures at the end of this article. Ophthalmology
   Science 2025;5:100602<feminine ordinal indicator>2024 by the American
   Academy of Ophthalmology. This is an open access article under the CC
   BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
ZA 0
ZS 0
ZB 0
TC 0
ZR 0
Z8 0
Z9 0
DA 2024-10-05
UT WOS:001321792000001
PM 39380881
ER

PT J
AU Maghsoudi, Arash
   Zhou, Emily
   Guffey, Danielle
   Ma, Shengling
   Xiao, Xiangjun
   Peng, Bo
   Amos, Christopher I.
   Ouyomi, Abiodun O.
   Razjouyan, Javad
   Li, Ang
TI A Transformer Natural Language Processing Algorithm for Cancer
   Associated Thrombosis Phenotype
SO BLOOD
VL 142
DI 10.1182/blood-2023-184756
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
ZA 0
ZB 0
Z8 0
TC 1
ZS 0
Z9 1
DA 2024-02-29
UT WOS:001159306705028
ER

PT J
AU Giske, Christian G.
   Bressan, Michelle
   Fiechter, Farah
   Hinic, Vladimira
   Mancini, Stefano
   Nolte, Oliver
   Egli, Adrian
TI GPT-4-based AI agents-the new expert system for detection of
   antimicrobial resistance mechanisms?
SO JOURNAL OF CLINICAL MICROBIOLOGY
VL 62
IS 11
DI 10.1128/jcm.00689-24
EA OCT 2024
DT Article
PD NOV 13 2024
PY 2024
AB The European Committee on Antimicrobial Susceptibility Testing (EUCAST)
   recommends two steps for detecting beta-lactamases in Gram-negative
   bacteria. Screening for potential extended-spectrum beta-lactamase
   (ESBL), plasmid-mediated AmpC beta-lactamase, or carbapenemase
   production is confirmed. We aimed to validate generative pre-trained
   transformer (GPT)-4 and GPT-agent for pre-classification of disk
   diffusion to indicate potential beta-lactamases. We assigned 225
   Gram-negative isolates based on phenotypic resistances against
   beta-lactam antibiotics and additional tests to one or more resistance
   mechanisms as follows: "none," "ESBL," "AmpC," or "carbapenemase." Next,
   we customized a GPT-agent with EUCAST guidelines and breakpoint table
   (v13.1). We compared routine diagnostics (reference) to those of (i)
   EUCAST-GPT-expert, (ii) microbiologists, and (iii) non-customized GPT-4.
   We determined sensitivities and specificities to flag suspect
   resistances. Three microbiologists showed concordance in 814/862 (94.4%)
   phenotypic categories and were used in median eight words (interquartile
   range [IQR] 4-11) for reasoning. Median sensitivity/specificity for
   ESBL, AmpC, and carbapenemase were 98%/99.1%, 96.8%/97.1%, and
   95.5%/98.5%, respectively. Three prompts of EUCAST-GPT-expert showed
   concordance in 706/862 (81.9%) categories but were used in median 158
   words (IQR 140-174) for reasoning. Sensitivity/specificity for ESBL,
   AmpC, and carbapenemase prediction were 95.4%/69.23%, 96.9%/86.3%, and
   100%/98.8%, respectively. Non-customized GPT-4 could interpret 169/862
   (19.6%) categories, and 137/169 (81.1%) agreed with routine diagnostics.
   Non-customized GPT-4 was used in median 85 words (IQR 72-105) for
   reasoning. Microbiologists showed higher concordance and shorter
   argumentations compared to GPT-agents. Humans showed higher
   specificities compared to GPT-agents. GPT-agent's unspecific flagging of
   ESBL and AmpC potentially results in additional testing, diagnostic
   delays, and higher costs. GPT-4 is not approved by regulatory bodies,
   but validation of large language models is needed.IMPORTANCEThe study
   titled "GPT-4-based AI agents-the new expert system for detection of
   antimicrobial resistance mechanisms?" is critically important as it
   explores the integration of advanced artificial intelligence (AI)
   technologies, like generative pre-trained transformer (GPT)-4, into the
   field of laboratory medicine, specifically in the diagnostics of
   antimicrobial resistance (AMR). With the growing challenge of AMR, there
   is a pressing need for innovative solutions that can enhance diagnostic
   accuracy and efficiency. This research assesses the capability of AI to
   support the existing two-step confirmatory process recommended by the
   European Committee on Antimicrobial Susceptibility Testing for detecting
   beta-lactamases in Gram-negative bacteria. By potentially speeding up
   and improving the precision of initial screenings, AI could reduce the
   time to appropriate treatment interventions. Furthermore, this study is
   vital for validating the reliability and safety of AI tools in clinical
   settings, ensuring they meet stringent regulatory standards before they
   can be broadly implemented. This could herald a significant shift in how
   laboratory diagnostics are performed, ultimately leading to better
   patient outcomes.
   The study titled "GPT-4-based AI agents-the new expert system for
   detection of antimicrobial resistance mechanisms?" is critically
   important as it explores the integration of advanced artificial
   intelligence (AI) technologies, like generative pre-trained transformer
   (GPT)-4, into the field of laboratory medicine, specifically in the
   diagnostics of antimicrobial resistance (AMR). With the growing
   challenge of AMR, there is a pressing need for innovative solutions that
   can enhance diagnostic accuracy and efficiency. This research assesses
   the capability of AI to support the existing two-step confirmatory
   process recommended by the European Committee on Antimicrobial
   Susceptibility Testing for detecting beta-lactamases in Gram-negative
   bacteria. By potentially speeding up and improving the precision of
   initial screenings, AI could reduce the time to appropriate treatment
   interventions. Furthermore, this study is vital for validating the
   reliability and safety of AI tools in clinical settings, ensuring they
   meet stringent regulatory standards before they can be broadly
   implemented. This could herald a significant shift in how laboratory
   diagnostics are performed, ultimately leading to better patient
   outcomes.
ZB 0
ZS 0
Z8 0
ZR 0
ZA 0
TC 3
Z9 3
DA 2024-10-23
UT WOS:001333898200001
PM 39417635
ER

PT J
AU Amini, Maziar
   Chang, Patrick
   Nguyen, Denis
   Davis, Rio O.
   Dodge, Jennifer
   Phan, Jennifer
   Buxbaum, James L.
   Sahakian, Ara B.
TI COMPARING CHATGPT3.5 AND BARD IN RECOMMENDING COLONOSCOPY INTERVALS:
   BRIDGING THE GAP IN HEALTHCARE SETTINGS
SO GASTROENTEROLOGY
VL 166
IS 5
MA Tu1991
BP S1482
EP S1482
SU S
DT Meeting Abstract
PD MAY 2024
PY 2024
CT Digestive Disease Week (DDW)
CY MAY 18-21, 2024
CL Washington, DC
ZS 0
ZB 0
Z8 0
TC 0
ZR 0
ZA 0
Z9 0
DA 2024-10-30
UT WOS:001282837706089
ER

PT J
AU Ong, Hannah
   Ong, Joshua
   Cheng, Rebekah
   Wang, Calvin
   Lin, Murong
   Ong, Dennis
TI GPT Technology to Help Address Longstanding Barriers to Care in Free
   Medical Clinics
SO ANNALS OF BIOMEDICAL ENGINEERING
VL 51
IS 9
BP 1906
EP 1909
DI 10.1007/s10439-023-03256-4
EA JUN 2023
DT Article
PD SEP 2023
PY 2023
AB The implementation of technology in healthcare has revolutionized
   patient-centered decision making by providing contextualized information
   about a patient's healthcare journey, leading to increased efficiency
   (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018,
   https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has
   been integrated within Electronic Health Records (EHR) to prompt
   screenings or diagnostic tests based on a patient's holistic health
   profile. While larger hospitals have already widely adopted these
   technologies, free clinics hold lower utilization of these advanced
   capability EHRs. The patient population at a free clinic faces a
   multitude of factors that limits their access to comprehensive care,
   thus requiring necessary efforts and measures to close the gap in
   healthcare disparities. Emerging Artificial Intelligence (AI)
   technology, such as OpenAI's ChatGPT, GPT-4, and other large language
   models (LLMs) have remarkable potential to improve patient care
   outcomes, promote health equity, and enhance comprehensive and holistic
   care in resource-limited settings. This paper aims to identify areas in
   which integrating these LLM AI advancements into free clinics operations
   can optimize and streamline healthcare delivery to underserved patient
   populations. This paper also identifies areas of improvements in GPT
   that are necessary to deliver those services.
ZR 0
TC 11
ZA 0
ZB 4
Z8 0
ZS 0
Z9 11
DA 2023-07-14
UT WOS:001019903200001
PM 37355478
ER

PT J
AU Omar, Mahmud
   Levkovich, Inbar
TI Exploring the efficacy and potential of large language models for
   depression: A systematic review
SO JOURNAL OF AFFECTIVE DISORDERS
VL 371
BP 234
EP 244
DI 10.1016/j.jad.2024.11.052
EA NOV 2024
DT Review
PD FEB 15 2025
PY 2025
AB Background and objective: Depression is a substantial public health
   issue, with global ramifications. While initial literature reviews
   explored the intersection between artificial intelligence (AI) and
   mental health, they have not yet critically assessed the specific
   contributions of Large Language Models (LLMs) in this domain. The
   objective of this systematic review was to examine the usefulness of
   LLMs in diagnosing and managing depression, as well as to investigate
   their incorporation into clinical practice. Methods: This review was
   based on a thorough search of the PubMed, Embase, Web of Science, and
   Scopus databases for the period January 2018 through March 2024. The
   search used PROSPERO and adhered to PRISMA guidelines. Original research
   articles, preprints, and conference papers were included, while
   non-English and non-research publications were excluded. Data extraction
   was standardized, and the risk of bias was evaluated using the ROBINS-I,
   QUADAS-2, and PROBAST tools. Results: Our review included 34 studies
   that focused on the application of LLMs in detecting and classifying
   depression through clinical data and social media texts. LLMs such as
   RoBERTa and BERT demonstrated high effectiveness, particularly in early
   detection and symptom classification. Nevertheless, the integration of
   LLMs into clinical practice is in its nascent stage, with ongoing
   concerns about data privacy and ethical implications. Conclusion: LLMs
   exhibit significant potential for transforming strategies for diagnosing
   and treating depression. Nonetheless, full integration of LLMs into
   clinical practice requires rigorous testing, ethical considerations, and
   enhanced privacy measures to ensure their safe and effective use.
TC 5
Z8 0
ZA 0
ZS 0
ZR 0
ZB 0
Z9 5
DA 2024-12-07
UT WOS:001367911600001
PM 39581383
ER

PT J
AU Klarak, Jaromir
   Brito, Ana Caroline M.
   Moreira, Luan F.
   Silva, Filipi N.
   Amancio, Diego R.
   Andok, Robert
   Oliveira, Maria Cristina F.
   Bardosova, Maria
   Oliveira Jr, Osvaldo N.
TI Using network analysis and large-language models to obtain a landscape
   of the literature on dressing materials for wound healing: The
   predominance of chitosan and other biomacromolecules: A review
SO INTERNATIONAL JOURNAL OF BIOLOGICAL MACROMOLECULES
VL 306
AR 141565
DI 10.1016/j.ijbiomac.2025.141565
EA MAR 2025
PN 2
DT Review
PD MAY 2025
PY 2025
AB We present an overview of the literature on dressing materials for wound
   healing, combining network analysis and natural language processing
   using large language models. Contributions to this field come from a
   variety of research areas and journals, so we employed multiple
   strategies for searching the OpenAlex database to ensure that the most
   relevant papers were covered, while also focusing on the specific topic
   of interest. Citation networks were created from the retrieved papers,
   identifying clusters that represent major topics. Starting with broad
   searches on 'wound' and 'wound healing' we refined the focus to dressing
   materials by incorporating expert knowledge into the analysis. This
   approach also allowed for a comparison with fully automated analyses.
   The resulting landscape shows significant growth in this area in recent
   years, with most contributions coming from the Northern Hemisphere,
   particularly China and the USA. The most commonly used materials include
   gauze, hydrocolloids, chitosan-based hydrogels, foams, alginates,
   hydrofibers (e.g., those containing nanomaterials such as silver
   nanoparticles), composites, biomaterials, and skin substitutes. Research
   primarily focuses on the antibacterial properties of these materials and
   their application in treating burn-related wounds, which, along with
   diabetes, are common causes of chronic wounds.
ZA 0
ZB 0
Z8 0
ZS 0
ZR 0
TC 2
Z9 2
DA 2025-03-18
UT WOS:001441448600001
PM 40020798
ER

PT J
AU Liu, ChaoXu
   Wei, MinYan
   Qin, Yu
   Zhang, MeiXiang
   Jiang, Huan
   Xu, JiaLe
   Zhang, YuNing
   Hua, Qing
   Hou, YiQing
   Dong, YiJie
   Xia, ShuJun
   Li, Ning
   Zhou, JianQiao
TI Harnessing Large Language Models for Structured Reporting in Breast
   Ultrasound: A Comparative Study of Open AI (GPT-4.0) and Microsoft Bing
   (GPT-4)
SO ULTRASOUND IN MEDICINE AND BIOLOGY
VL 50
IS 11
BP 1697
EP 1703
DI 10.1016/j.ultrasmedbio.2024.07.007
EA SEP 2024
DT Article
PD NOV 2024
PY 2024
AB Objectives To assess the capabilities of large language models (LLMs),
   including Open AI (GPT-4.0) and Microsoft Bing (GPT-4), in generating
   structured reports, the Breast Imaging Reporting and Data System
   (BI-RADS) categories, and management recommendations from free-text
   breast ultrasound reports. Materials and Methods In this retrospective
   study, 100 free-text breast ultrasound reports from patients who
   underwent surgery between January and May 2023 were gathered. The
   capabilities of Open AI (GPT-4.0) and Microsoft Bing (GPT-4) to convert
   these unstructured reports into structured ultrasound reports were
   studied. The quality of structured reports, BI-RADS categories, and
   management recommendations generated by GPT-4.0 and Bing were evaluated
   by senior radiologists based on the guidelines. Results Open AI
   (GPT-4.0) was better than Microsoft Bing (GPT-4) in terms of performance
   in generating structured reports (88% vs. 55%; p < 0.001), giving
   correct BI-RADS categories (54% vs. 47%; p = 0.013) and providing
   reasonable management recommendations (81% vs. 63%; p < 0.001). As the
   ability to predict benign and malignant characteristics, GPT-4.0
   performed significantly better than Bing (AUC, 0.9317 vs. 0.8177; p <
   0.001), while both performed significantly inferior to senior
   radiologists (AUC, 0.9763; both p < 0.001). Conclusion This study
   highlights the potential of LLMs, specifically Open AI (GPT-4.0), in
   converting unstructured breast ultrasound reports into structured ones,
   offering accurate diagnoses and providing reasonable recommendations.
TC 1
ZA 0
ZB 0
Z8 1
ZR 0
ZS 0
Z9 2
DA 2024-10-05
UT WOS:001322000900001
PM 39138026
ER

PT J
AU Beattie, J.
   Neufeld, S.
   Yang, D. X.
   Chukwuma, C.
   Gul, A.
   Desai, N. B.
   Dohopolski, M.
   Jiang, S. B.
TI Utilizing Large Language Models for Enhanced Clinical Trial Matching
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
VL 120
IS 2
MA 3341
BP E611
EP E611
SU S
DT Meeting Abstract
PD OCT 1 2024
PY 2024
CT 66th International Conference on American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 29-OCT 02, 2024
CL Washington, DC
SP Amer Soc Radiat Oncol
TC 0
ZS 0
ZR 0
Z8 0
ZA 0
ZB 0
Z9 0
DA 2024-12-16
UT WOS:001325892302025
ER

PT J
AU Rai, Sunny
   Kornides, Melanie
   Morgan, Jennifer
   Kumar, Aman
   Cappella, Joseph
   Guntuku, Sharath Chandra
TI Detecting and monitoring concerns against HPV vaccination on social
   media using large language models
SO SCIENTIFIC REPORTS
VL 14
IS 1
AR 14362
DI 10.1038/s41598-024-64703-3
DT Article
PD JUN 21 2024
PY 2024
AB Health risks due to preventable infections such as human papillomavirus
   (HPV) are exacerbated by persistent vaccine hesitancy. Due to limited
   sample sizes and the time needed to roll out, traditional methodologies
   like surveys and interviews offer restricted insights into quickly
   evolving vaccine concerns. Social media platforms can serve as fertile
   ground for monitoring vaccine-related conversations and detecting
   emerging concerns in a scalable and dynamic manner. Using
   state-of-the-art large language models, we propose a minimally
   supervised end-to-end approach to identify concerns against HPV
   vaccination from social media posts. We detect and characterize the
   concerns against HPV vaccination pre- and post-2020 to understand the
   evolution of HPV vaccine discourse. Upon analyzing 653 k HPV-related
   post-2020 tweets, adverse effects, personal anecdotes, and vaccine
   mandates emerged as the dominant themes. Compared to pre-2020, there is
   a shift towards personal anecdotes of vaccine injury with a growing call
   for parental consent and transparency. The proposed approach provides an
   end-to-end system, i.e. given a collection of tweets, a list of
   prevalent concerns is returned, providing critical insights for crafting
   targeted interventions, debunking messages, and informing public health
   campaigns.
ZR 0
ZB 1
ZA 0
TC 3
ZS 0
Z8 0
Z9 3
DA 2024-08-02
UT WOS:001255183000047
PM 38906941
ER

PT J
AU Cairns, James
   Frood, Russell
   Patel, Chirag
   Scarsbrook, Andrew
TI The Role of AI in Lymphoma: An Update
SO SEMINARS IN NUCLEAR MEDICINE
VL 55
IS 3
BP 377
EP 386
DI 10.1053/j.semnuclmed.2025.02.007
EA APR 2025
DT Review
PD MAY 2025
PY 2025
AB Malignant lymphomas encompass a range of malignancies with incidence
   rising globally, particularly with age. In younger populations, Hodgkin
   and Burkitt lymphomas predominate, while older populations more commonly
   experience subtypes such as diffuse large B-cell, follicular, marginal
   zone, and mantle cell lymphomas. Positron emission tomography/computed
   tomography (PET/CT) using [18F] fluorodeoxyglucose (FDG) is the gold
   standard for staging, treatment response assessment, and prognostication
   in lymphoma. However, interpretation of PET/CT is complex,
   time-consuming, and reliant on expert imaging specialists, exacerbating
   challenges associated with workforce shortages worldwide. Artificial
   intelligence (AI) offers transformative potential across multiple
   aspects of PET/CT imaging in this setting. AI applications in
   appointment planning have demonstrated utility in reducing nonattendance
   rates and improving departmental efficiency. Advanced reconstruction
   techniques leveraging convolutional neural networks (CNNs) enable
   reduced injected activities of radiopharmaceutical and patient dose
   whilst maintaining diagnostic accuracy, particularly benefiting younger
   patients requiring multiple scans. Automated segmentation tools,
   predominantly using 3D U-Net architectures, have improved quantification
   of metrics such as total metabolic tumour volume (TMTV) and total lesion
   glycolysis (TLG), facilitating prognostication and treatment
   stratification. Despite these advancements, challenges remain, including
   variability in segmentation performance, impact on Deauville Score
   interpretation, and standardization of TMTV/TLG measurements. Emerging
   large language models (LLMs) also show promise in enhancing PET/CT
   reporting, converting free-text reports into structured formats, and
   improving patient communication. Further research is required to address
   limitations such as AI-induced errors, physiological uptake
   differentiation, and the integration of AI models into clinical
   workflows. With robust validation and harmonization, AI integration
   could significantly enhance lymphoma care, improving diagnostic
   precision, workflow efficiency, and patient outcomes. Semin Nucl Med
   55:377-386 (c) 2025 The Author(s). Published by Elsevier Inc. This is an
   open access article under the CC BY license
   (http://creativecommons.org/licenses/by/4.0/)
TC 2
ZR 0
ZS 0
ZB 0
ZA 0
Z8 0
Z9 2
DA 2025-05-01
UT WOS:001472935800001
PM 40069036
ER

PT J
AU Giuffre, Mauro
   Kresevic, Simone
   You, Kisung
   Dupont, Johannes
   Huebner, Jack
   Grimshaw, Alyssa Ann
   Shung, Dennis Legen
TI Systematic review: The use of large language models as medical chatbots
   in digestive diseases
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
VL 60
IS 2
BP 144
EP 166
DI 10.1111/apt.18058
EA MAY 2024
DT Review
PD JUL 2024
PY 2024
AB BackgroundInterest in large language models (LLMs), such as OpenAI's
   ChatGPT, across multiple specialties has grown as a source of
   patient-facing medical advice and provider-facing clinical decision
   support. The accuracy of LLM responses for gastroenterology and
   hepatology-related questions is unknown.AimsTo evaluate the accuracy and
   potential safety implications for LLMs for the diagnosis, management and
   treatment of questions related to gastroenterology and
   hepatology.MethodsWe conducted a systematic literature search including
   Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed,
   Scopus and the Web of Science Core Collection to identify relevant
   articles published from inception until January 28, 2024, using a
   combination of keywords and controlled vocabulary for LLMs and
   gastroenterology or hepatology. Accuracy was defined as the percentage
   of entirely correct answers.ResultsAmong the 1671 reports screened, we
   identified 33 full-text articles on using LLMs in gastroenterology and
   hepatology and included 18 in the final analysis. The accuracy of
   question-responding varied across different model versions. For example,
   accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40%
   and 91.4% with ChatGPT-4. In addition, the absence of standardised
   methodology and reporting metrics for studies involving LLMs places all
   the studies at a high risk of bias and does not allow for the
   generalisation of single-study results.ConclusionsCurrent
   general-purpose LLMs have unacceptably low accuracy on clinical
   gastroenterology and hepatology tasks, which may lead to adverse patient
   safety events through incorrect information or triage recommendations,
   which might overburden healthcare systems or delay necessary care.
   Available large language models are not accurate enough to be deployed
   in real-life clinical practice, despite their user-friendly interfaces
   and rapid improvement cycles. The absence of standardised methods and
   benchmarks will probably delay their safe deployment into real-life
   clinical settings.image
ZA 0
ZR 0
ZB 5
TC 17
Z8 1
ZS 0
Z9 17
DA 2024-05-31
UT WOS:001231121100001
PM 38798194
ER

PT J
AU Yang, Fei
   Li, Xiaochun
   Wang, Xijuan
   Chen, Xuanling
   Niu, Yaqian
   Zhang, Yan
   Zhang, Chengxia
   Liu, Guangfeng
TI Analysis of Optic Disc Morphology and the Peripapillary Retinal and
   Choroidal Thickness by the Swept Source Optical Coherence Tomography in
   Patients with Moyamoya Disease
SO OPHTHALMIC RESEARCH
VL 68
IS 1
BP 61
EP 70
DI 10.1159/000542801
DT Article
PD JAN-DEC 2025
PY 2025
AB Introduction: The study evaluates the performance of large language
   model versions of ChatGPT - ChatGPT-3.5, ChatGPT-4, and ChatGPT-Omni -
   in addressing inquiries related to the diagnosis and treatment of
   gynecological cancers, including ovarian, endometrial, and cervical
   cancers. Methods: A total of 804 questions were equally distributed
   across four categories: true/false, multiple-choice, open-ended, and
   case-scenario, with each question type representing varying levels of
   complexity. Performance was assessed using a six-point Likert scale,
   focusing on accuracy, completeness, and alignment with established
   clinical guidelines. Results: For true/false queries, ChatGPT-Omni
   achieved accuracy rates of 100% for easy, 98% for medium, and 97% for
   complicated questions, higher than ChatGPT-4 (94%, 90%, 85%) and
   ChatGPT-3.5 (90%, 85%, 80%) (p = 0.041, 0.023, 0.014, respectively). In
   multiple-choice, ChatGPT-Omni maintained with 100% for MMD patients was
   significantly less than in controls, while the CDR in MMD patients was
   significantly larger than that in the control group. There was no
   statistically significant difference between the two groups regarding
   disc area, cup area, cup volume, rim volume, vertical and horizontal
   diameter of disc. The retinal thickness at the 7 o'clock position was
   significantly thinner in the MMD group compared to the control group and
   the temporal RNFL thickness, particularly at the 7 o'clock and 9 o'clock
   positions, was significantly reduced in the MMD group (p < 0.05). The
   GCL layer at the 7 o'clock position was thinner in the MMD group than in
   the control group (p < 0.05). The MMD group showed a notably reduced
   average choroidal thickness, particularly in the inferior-temporal
   region (p < 0.05). There was a correlation between peripapillary
   choroidal and GCL layer thickness in the MMD group, but no significant
   correlations were found with rim area, CDR, or RNFL. Conclusions: In
   patients with MMD, there is an increase in the CDR accompanied by a
   decrease in the rim area. Additionally, there is thinning of the
   temporal RNFL, GCL, and choroidal thickness, notably in the
   inferotemporal quadrant of the optic disc.
ZR 0
ZA 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
DA 2025-02-01
UT WOS:001404667800001
PM 39586258
ER

PT J
AU Dayan, Roy
   Uliel, Benjamin
   Koplewitz, Gal
TI Age against the machine-susceptibility of large language models to
   cognitive impairment: cross sectional analysis
SO BMJ-BRITISH MEDICAL JOURNAL
VL 387
AR e081948
DI 10.1136/bmj-2024-081948
DT Editorial Material
PD DEC 20 2024
PY 2024
AB OBJECTIVE To evaluate the cognitive abilities of the leading large
   language models and identify their susceptibility to cognitive
   impairment, using the Montreal Cognitive Assessment (MoCA) and
   additional tests. DESIGN Cross sectional analysis. SETTING Online
   interaction with large language models via text based prompts.
   PARTICIPANTS Publicly available large language models, or "chatbots":
   ChatGPT versions 4 and 4o (developed by OpenAI), Claude 3.5 "Sonnet"
   (developed by Anthropic), and Gemini versions 1 and 1.5 (developed by
   Alphabet). ASSESSMENTS The MoCA test (version 8.1) was administered to
   the leading large language models with instructions identical to those
   given to human patients. Scoring followed official guidelines and was
   evaluated by a practising neurologist. Additional assessments included
   the Navon figure, cookie theft picture, Poppelreuter figure, and Stroop
   test. MAIN OUTCOME MEASURES MoCA scores, performance in
   visuospatial/executive tasks, and Stroop test results. RESULTS ChatGPT
   4o achieved the highest score on the MoCA test (26/30), followed by
   ChatGPT 4 and Claude (25/30), with Gemini 1.0 scoring lowest (16/30).
   All large language models showed poor performance in
   visuospatial/executive tasks. Gemini models failed at the delayed recall
   task. Only ChatGPT 4o succeeded in the incongruent stage of the Stroop
   test. CONCLUSIONS With the exception of ChatGPT 4o, almost all large
   language models subjected to the MoCA test showed signs of mild
   cognitive impairment. Moreover, as in humans, age is a key determinant
   of cognitive decline: "older" chatbots, like older patients, tend to
   perform worse on the MoCA test. These findings challenge the assumption
   that artificial intelligence will soon replace human doctors, as the
   cognitive impairment evident in leading chatbots may affect their
   reliability in medical diagnostics and undermine patients' confidence.
TC 3
ZR 0
ZS 0
ZB 0
Z8 0
ZA 0
Z9 3
DA 2025-01-11
UT WOS:001390741500006
PM 39706600
ER

PT J
AU Lara-Abelenda, Francisco J.
   Chushig-Muzo, David
   Peiro-Corbacho, Pablo
   Wagner, Ana M.
   Granja, Conceicao
   Soguero-Ruiz, Cristina
TI Personalized glucose forecasting for people with type 1 diabetes using
   large language models
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
VL 265
AR 108737
DI 10.1016/j.cmpb.2025.108737
EA APR 2025
DT Article
PD JUN 2025
PY 2025
AB Background and objective: Type 1 Diabetes (T1D) is an autoimmune disease
   that requires exogenous insulin via Multiple Daily Injections (MDIs) or
   subcutaneous pumps to maintain targeted glucose levels. Despite the
   advances in Continuous Glucose Monitoring (CGM), controlling glucose
   levels remains challenging. Large Language Models (LLMs) have produced
   impressive results in text processing, but their performance with other
   data modalities remains unexplored. The aim of this study is three-fold.
   First, to evaluate the effectiveness of LLM-based models for glucose
   forecasting. Second, to compare the performance of different models for
   predicting glucose in T1D individuals treated with MDIs and pumps.
   Lastly, to create a personalized approach based on patient-specific
   training and adaptive model selection. Methods: CGM data from the T1DEXI
   study were used for forecasting glucose levels. Different predictive
   models were evaluated using the mean absolute error (MAE) and the root
   mean squared error and considering the Prediction Horizons (PHs) of 60,
   90, and 120 min. Results: For short-term PHs (60 and 90 min), the
   personalized approach achieved the best results, with an average MAE of
   15.7 and 20.2 for MDIs, and a MAE of 15.2 and 17.2 for pumps. For
   long-term PH (120 min), TIDE obtained an MAE of 19.8 for MDIs, whereas
   Patch-TST obtained a MAE of 18.5. Conclusion: LLM-based models provided
   similar MAE values to state-of-the-art models but presented a reduced
   variability. The proposed personalized approach obtained the best
   results for short-term periods. Our work contributes to developing
   personalized glucose prediction models for enhancing glycemic control,
   reducing diabetes-related complications.
ZA 0
ZB 0
Z8 0
TC 0
ZR 0
ZS 0
Z9 0
DA 2025-04-20
UT WOS:001464793700001
PM 40188577
ER

PT J
AU Ostrowska, Magdalena
   Kacala, Paulina
   Onolememen, Deborah
   Vaughan-Lane, Katie
   Sisily Joseph, Anitta
   Ostrowski, Adam
   Pietruszewska, Wioletta
   Banaszewski, Jacek
   Wrobel, Maciej J.
TI To trust or not to trust: evaluating the reliability and safety of AI
   responses to laryngeal cancer queries
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
VL 281
IS 11
BP 6069
EP 6081
DI 10.1007/s00405-024-08643-8
EA APR 2024
DT Article
PD NOV 2024
PY 2024
AB Purpose As online health information-seeking surges, concerns mount over
   the quality and safety of accessible content, potentially leading to
   patient harm through misinformation. On one hand, the emergence of
   Artificial Intelligence (AI) in healthcare could prevent it; on the
   other hand, questions raise regarding the quality and safety of the
   medical information provided. As laryngeal cancer is a prevalent head
   and neck malignancy, this study aims to evaluate the utility and safety
   of three large language models (LLMs) as sources of patient information
   about laryngeal cancer.Methods A cross-sectional study was conducted
   using three LLMs (ChatGPT 3.5, ChatGPT 4.0, and Bard). A questionnaire
   comprising 36 inquiries about laryngeal cancer was categorised into
   diagnosis (11 questions), treatment (9 questions), novelties and
   upcoming treatments (4 questions), controversies (8 questions), and
   sources of information (4 questions). The population of reviewers
   consisted of 3 groups, including ENT specialists, junior physicians, and
   non-medicals, who graded the responses. Each physician evaluated each
   question twice for each model, while non-medicals only once. Everyone
   was blinded to the model type, and the question order was shuffled.
   Outcome evaluations were based on a safety score (1-3) and a Global
   Quality Score (GQS, 1-5). Results were compared between LLMs. The study
   included iterative assessments and statistical validations.Results
   Analysis revealed that ChatGPT 3.5 scored highest in both safety (mean:
   2.70) and GQS (mean: 3.95). ChatGPT 4.0 and Bard had lower safety scores
   of 2.56 and 2.42, respectively, with corresponding quality scores of
   3.65 and 3.38. Inter-rater reliability was consistent, with less than 3%
   discrepancy. About 4.2% of responses fell into the lowest safety
   category (1), particularly in the novelty category. Non-medical
   reviewers' quality assessments correlated moderately (r = 0.67) with
   response length.Conclusions LLMs can be valuable resources for patients
   seeking information on laryngeal cancer. ChatGPT 3.5 provided the most
   reliable and safe responses among the models evaluated.
TC 11
ZS 1
ZB 1
ZR 0
ZA 0
Z8 0
Z9 10
DA 2024-04-27
UT WOS:001207064800002
PM 38652298
ER

PT J
AU Kaiser, Philippe
   Yang, Shan
   Bach, Michael
   Breit, Christian
   Mertz, Kirsten
   Stieltjes, Bram
   Ebbing, Jan
   Wetterauer, Christian
   Henkel, Maurice
TI The interaction of structured data using openEHR and large Language
   models for clinical decision support in prostate cancer
SO WORLD JOURNAL OF UROLOGY
VL 43
IS 1
AR 67
DI 10.1007/s00345-024-05423-1
DT Article
PD JAN 13 2025
PY 2025
AB BackgroundMultidisciplinary teams (MDTs) are essential for cancer care
   but are resource-intensive. Decision-making processes within MDTs, while
   critical, contribute to increased healthcare costs due to the need for
   specialist time and coordination. The recent emergence of large language
   models (LLMs) offers the potential to improve the efficiency and
   accuracy of clinical decision-making processes, potentially reducing
   costs associated with traditional MDT models.MethodsWe conducted a
   retrospective study of 171 consecutively treated patients with newly
   diagnosed prostate cancer. Relevant structured clinical data and the
   European Association of Urology (EAU) pocket guidelines were provided to
   two LLMs (chatGPT-4, Claude-3-Opus). LLM treatment recommendations were
   compared to actual treatment recommendations of the MDT meeting
   (MDM).ResultsBoth LLMs demonstrated an overall adherence of 93% with the
   MDT treatment recommendations. Discrepancies between LLM and MDT
   recommendations were observed in 15 cases (9%), primarily due to lack of
   clinical information that could be provided to the LLMs. In 5 cases
   (3%), the LLM recommendations were not in line with EAU guidelines
   despite having access to all relevant information.ConclusionsOur
   findings provide evidence that LLMs can provide accurate treatment
   recommendations for newly diagnosed prostate cancer patients. LLMs have
   the potential to streamline MDT workflows, enabling specialists to focus
   on complex cases and patient-centered discussions.Patient SummaryIn this
   study, we explored the potential of artificial intelligence models
   called large language models (LLMs) to assist in treatment
   decision-making for prostate cancer patients. We found that LLMs, when
   provided with patient information and clinical guidelines, can recommend
   treatments that closely match those made by a team of cancer
   specialists, suggesting that LLMs could help streamline the
   decision-making process and potentially reduce healthcare costs.
ZR 0
Z8 0
TC 0
ZB 0
ZS 0
ZA 0
Z9 0
DA 2025-01-20
UT WOS:001397199400002
PM 39804478
ER

PT J
AU Cosma, Claudia
   Radi, Alessio
   Cattano, Rachele
   Zanobini, Patrizio
   Bonaccorsi, Guglielmo
   Lorini, Chiara
   Del Riccio, Marco
TI Exploring Chatbot contributions to enhancing vaccine literacy and
   uptake: A scoping review of the literature
SO VACCINE
VL 44
AR 126559
DI 10.1016/j.vaccine.2024.126559
EA NOV 2024
DT Review
PD JAN 12 2025
PY 2025
AB Background: The increasing integration of chatbots across various
   sectors marks a significant shift in digital communication, and their
   role in healthcare makes no exception. This scoping review aims to
   systematically examine the role of chatbots in the perspective of
   organizational vaccine literacy, particularly in enhancing vaccine
   literacy and facilitating the dissemination of vaccine-related
   information, evaluating the potential of chatbots to transform
   vaccination communication strategies and improve health education
   outcomes. Methods: This scoping review adhered to the Joanna Briggs
   Institute methodology and the PRISMA-ScR checklist. A systematic search
   of MEDLINE, Embase, Scopus, and PsycInfo was conducted from January 2020
   to October 30, 2024, using keywords related to "chatbots" and
   "vaccination." Study selection involved a two-stage screening process,
   focusing on studies reporting the use of chatbots to improve vaccine
   literacy and uptake. Data were thematically analyzed and presented in a
   narrative format. Results: Twenty-two studies were included in the
   review: these studies demonstrate the effectiveness of chatbots in
   enhancing vaccine literacy and acceptance, mainly focusing on COVID-19
   but also addressing HPV and childhood vaccinations. They highlight
   chatbots' role in improving the vaccine-literate environment through
   countering misinformation and improving communication with healthcare
   professionals, showcasing their potential to significantly influence
   public health outcomes and their adaptability to diverse populations and
   geographic regions. Conclusions: These digital assistants could provide
   personalized and up-to-date information, improving not only knowledge
   but also attitudes and intentions towards vaccinations.
ZB 0
Z8 0
ZS 0
TC 2
ZA 0
ZR 0
Z9 2
DA 2024-12-13
UT WOS:001371923900001
PM 39615346
ER

PT J
AU Silverman, Anna L.
   Sushil, Madhumita
   Bhasuran, Balu
   Ludwig, Dana
   Buchanan, James
   Racz, Rebecca
   Parakala, Mahalakshmi
   El-Kamary, Samer
   Ahima, Ohenewaa
   Belov, Artur
   Choi, Lauren
   Billings, Monisha
   Li, Yan
   Habal, Nadia
   Liu, Qi
   Tiwari, Jawahar
   Butte, Atul J.
   Rudrapatna, Vivek A.
TI Algorithmic Identification of Treatment-Emergent Adverse Events From
   Clinical Notes Using Large Language Models: A Pilot Study in
   Inflammatory Bowel Disease
SO CLINICAL PHARMACOLOGY & THERAPEUTICS
VL 115
IS 6
BP 1391
EP 1399
DI 10.1002/cpt.3226
EA MAR 2024
DT Article
PD JUN 2024
PY 2024
AB Outpatient clinical notes are a rich source of information regarding
   drug safety. However, data in these notes are currently underutilized
   for pharmacovigilance due to methodological limitations in text mining.
   Large language models (LLMs) like Bidirectional Encoder Representations
   from Transformers (BERT) have shown progress in a range of natural
   language processing tasks but have not yet been evaluated on adverse
   event (AE) detection. We adapted a new clinical LLM, University of
   California - San Francisco (UCSF)-BERT, to identify serious AEs (SAEs)
   occurring after treatment with a non-steroid immunosuppressant for
   inflammatory bowel disease (IBD). We compared this model to other
   language models that have previously been applied to AE detection. We
   annotated 928 outpatient IBD notes corresponding to 928 individual
   patients with IBD for all SAE-associated hospitalizations occurring
   after treatment with a non-steroid immunosuppressant. These notes
   contained 703 SAEs in total, the most common of which was failure of
   intended efficacy. Out of eight candidate models, UCSF-BERT achieved the
   highest numerical performance on identifying drug-SAE pairs from this
   corpus (accuracy 88-92%, macro F1 61-68%), with 5-10% greater accuracy
   than previously published models. UCSF-BERT was significantly superior
   at identifying hospitalization events emergent to medication use (P <
   0.01). LLMs like UCSF-BERT achieve numerically superior accuracy on the
   challenging task of SAE detection from clinical notes compared with
   prior methods. Future work is needed to adapt this methodology to
   improve model performance and evaluation using multicenter data and
   newer architectures like Generative pre-trained transformer (GPT). Our
   findings support the potential value of using large language models to
   enhance pharmacovigilance.
Z8 0
ZB 0
ZR 0
ZA 0
ZS 0
TC 6
Z9 6
DA 2024-03-28
UT WOS:001181392200001
PM 38459719
ER

PT J
AU McCoy Jr, Thomas H.
   Perlis, Roy H.
TI Dimensional Measures of Psychopathology in Children and Adolescents
   Using Large Language Models
SO BIOLOGICAL PSYCHIATRY
VL 96
IS 12
BP 940
EP 947
DI 10.1016/j.biopsych.2024.05.008
EA NOV 2024
DT Article
PD DEC 15 2024
PY 2024
AB BACKGROUND: To enable greater use of National Institute of Mental Health
   Research Domain Criteria (RDoC) in real- world settings, we applied
   large language models (LLMs) to estimate dimensional psychopathology
   from narrative clinical notes. METHODS: We conducted a cohort study
   using health records from individuals age #18 years evaluated in the
   psychiatric emergency department of a large academic medical center
   between November 2008 and March 2015. Outcomes were hospital admission
   and length of emergency department stay. RDoC domains were estimated
   using a Health Insurance Portability and Accountability Act-compliant
   LLM (gpt-4-1106-preview) and compared with a previously validated
   token-based approach. RESULTS: The cohort included 3059 individuals
   (median age 16 years [interquartile range, 13-18]; 1580 [52%] female,
   1479 [48%] male; 105 [3.4%] identified as Asian, 329 [11%] as Black, 288
   [9.4%] as Hispanic, 474 [15%] as other race, and 1863 [61%] as White),
   of whom 1695 (55%) were admitted. Correlation between LLM-extracted RDoC
   scores and the token-based scores ranged from small to medium as
   assessed by Kendall's tau (0.14-0.22). In logistic regression models
   adjusting for sociodemographic and clinical features, admission
   likelihood was associated with greater scores on all domains, with the
   exception of the sensorimotor domain, which was inversely associated (p
   < .001 for all adjusted associations). Tests for bias suggested modest
   but statistically significant differences in positive valence scores by
   race (p < .05 for Asian, Black, and Hispanic individuals). CONCLUSIONS:
   An LLM extracted estimates of 6 RDoC domains in an explainable manner,
   which were associated with clinical outcomes. This approach can
   contribute to a new generation of prediction models or biological
   investigations based on dimensional psychopathology.
ZS 0
TC 6
Z8 0
ZB 3
ZR 0
ZA 0
Z9 6
DA 2024-11-23
UT WOS:001356681000001
PM 38866172
ER

PT J
AU Amacher, Simon A.
   Baumann, Sira M.
   Berger, Sebastian
   Arpagaus, Armon
   Egli, Simon B.
   Grzonka, Pascale
   Kliem, Paulina S. C.
   Hunziker, Sabina
   Fisch, Urs
   Gebhard, Caroline E.
   Sutter, Raoul
TI Can the large language model ChatGPT-4omni predict outcomes in adult
   patients with status epilepticus?
SO EPILEPSIA
VL 66
IS 3
BP 674
EP 685
DI 10.1111/epi.18215
EA DEC 2024
DT Article
PD MAR 2025
PY 2025
AB ObjectiveLarge language models (LLMs) have recently gained attention for
   clinical decision-making and diagnosis. This study evaluates the
   performance of the recently updated LLM (ChatGPT-4o) in predicting
   clinical outcomes in patients with status epilepticus and compares its
   prognostic performance to the Status Epilepticus Severity Score
   (STESS).MethodsThis retrospective single-center cohort study was
   performed at the University Hospital Basel (tertiary academic medical
   center) from January 2005 to December 2022. It included consecutive
   adult patients (>= 18 years of age) with a diagnosis of status
   epilepticus. The primary outcome was survival at hospital discharge, and
   the secondary outcome was return to premorbid neurological function at
   hospital discharge. The performance characteristics of ChatGPT4-o
   (sensitivity, specificity, Youden Index) were evaluated and compared to
   those of the STESS.ResultsOf 760 patients, 689 patients (90.7%) survived
   to discharge, and 317 survivors (41.7%) regained their premorbid
   neurological function at discharge. ChatGPT-4o predicted survival in 567
   of 760 patients (74.6%), of which 45 died. ChatGPT-4o predicted death in
   193 of 760 patients (25.4%), of which 167 survived, resulting in a
   sensitivity of 75.8% and a specificity of 36.6% (Youden Index 0.12, 95%
   confidence interval [CI] 0-.28) for predicting survival. ChatGPT-4o
   predicted return to premorbid neurologic function in 249 of 760 patients
   (32.8%), of which 112 did not return to their premorbid neurological
   function. ChatGPT-4o predicted no return to premorbid function in 511 of
   760 patients (67.2%), of which 180 returned to their premorbid function,
   resulting in a sensitivity of 43.2% and a specificity of 74.7% (Youden
   Index .12, 95% CI .08-.28) for predicting return to premorbid
   neurological function. There was no difference in the prognostic
   performance of ChatGPT-4o and the STESS. A second round of prompting did
   not increase the predictive performance of ChatGPT-4o.ResultsOf 760
   patients, 689 patients (90.7%) survived to discharge, and 317 survivors
   (41.7%) regained their premorbid neurological function at discharge.
   ChatGPT-4o predicted survival in 567 of 760 patients (74.6%), of which
   45 died. ChatGPT-4o predicted death in 193 of 760 patients (25.4%), of
   which 167 survived, resulting in a sensitivity of 75.8% and a
   specificity of 36.6% (Youden Index 0.12, 95% confidence interval [CI]
   0-.28) for predicting survival. ChatGPT-4o predicted return to premorbid
   neurologic function in 249 of 760 patients (32.8%), of which 112 did not
   return to their premorbid neurological function. ChatGPT-4o predicted no
   return to premorbid function in 511 of 760 patients (67.2%), of which
   180 returned to their premorbid function, resulting in a sensitivity of
   43.2% and a specificity of 74.7% (Youden Index .12, 95% CI .08-.28) for
   predicting return to premorbid neurological function. There was no
   difference in the prognostic performance of ChatGPT-4o and the STESS. A
   second round of prompting did not increase the predictive performance of
   ChatGPT-4o.ResultsOf 760 patients, 689 patients (90.7%) survived to
   discharge, and 317 survivors (41.7%) regained their premorbid
   neurological function at discharge. ChatGPT-4o predicted survival in 567
   of 760 patients (74.6%), of which 45 died. ChatGPT-4o predicted death in
   193 of 760 patients (25.4%), of which 167 survived, resulting in a
   sensitivity of 75.8% and a specificity of 36.6% (Youden Index 0.12, 95%
   confidence interval [CI] 0-.28) for predicting survival.
   ChatGPT-4o predicted return to premorbid neurologic function in 249 of
   760 patients (32.8%), of which 112 did not return to their premorbid
   neurological function. ChatGPT-4o predicted no return to premorbid
   function in 511 of 760 patients (67.2%), of which 180 returned to their
   premorbid function, resulting in a sensitivity of 43.2% and a
   specificity of 74.7% (Youden Index .12, 95% CI .08-.28) for predicting
   return to premorbid neurological function. There was no difference in
   the prognostic performance of ChatGPT-4o and the STESS. A second round
   of prompting did not increase the predictive performance of
   ChatGPT-4o.SignificanceChatGPT-4o unreliably predicts outcomes in
   patients with status epilepticus. Clinicians should refrain from using
   ChatGPT-4o for prognostication in these patients.
ZB 0
ZR 0
TC 0
ZA 0
Z8 0
ZS 0
Z9 0
DA 2024-12-30
UT WOS:001383243100001
PM 39723845
ER

PT J
AU Arasteh, Soroosh Tayebi
   Han, Tianyu
   Lotfinia, Mahshad
   Kuhl, Christiane
   Kather, Jakob Nikolas
   Truhn, Daniel
   Nebelung, Sven
TI Large language models streamline automated machine learning for clinical
   studies
SO NATURE COMMUNICATIONS
VL 15
IS 1
AR 1603
DI 10.1038/s41467-024-45879-8
DT Article
PD FEB 21 2024
PY 2024
AB A knowledge gap persists between machine learning (ML) developers (e.g.,
   data scientists) and practitioners (e.g., clinicians), hampering the
   full utilization of ML for clinical data analysis. We investigated the
   potential of the ChatGPT Advanced Data Analysis (ADA), an extension of
   GPT-4, to bridge this gap and perform ML analyses efficiently.
   Real-world clinical datasets and study details from large trials across
   various medical specialties were presented to ChatGPT ADA without
   specific guidance. ChatGPT ADA autonomously developed state-of-the-art
   ML models based on the original study's training data to predict
   clinical outcomes such as cancer development, cancer progression,
   disease complications, or biomarkers such as pathogenic gene sequences.
   Following the re-implementation and optimization of the published
   models, the head-to-head comparison of the ChatGPT ADA-crafted ML models
   and their respective manually crafted counterparts revealed no
   significant differences in traditional performance metrics (p >= 0.072).
   Strikingly, the ChatGPT ADA-crafted ML models often outperformed their
   counterparts. In conclusion, ChatGPT ADA offers a promising avenue to
   democratize ML in medicine by simplifying complex data analyses, yet
   should enhance, not replace, specialized training and resources, to
   promote broader applications in medical research and practice.
   A knowledge gap persists between machine learning developers and
   clinicians. Here, the authors show that the Advanced Data Analysis
   extension of ChatGPT could bridge this gap and simplify complex data
   analyses, making them more accessible to clinicians.
ZA 0
ZS 0
ZB 8
TC 34
Z8 1
ZR 0
Z9 35
DA 2024-03-28
UT WOS:001173879300030
PM 38383555
ER

PT J
AU Kong, Qing-Zhou
   Ju, Kun-Ping
   Wan, Meng
   Liu, Jing
   Wu, Xiao-Qi
   Li, Yue-Yue
   Zuo, Xiu-Li
   Li, Yan-Qing
TI Comparative analysis of large language models in medical counseling: A
   focus on Helicobacter pylori infection
SO HELICOBACTER
VL 29
IS 1
AR e13055
DI 10.1111/hel.13055
DT Article
PD JAN 2024
PY 2024
AB Background: Large language models (LLMs) are promising medical
   counseling tools, but the reliability of responses remains unclear. We
   aimed to assess the feasibility of three popular LLMs as counseling
   tools for Helicobacter pylori infection in different counseling
   languages. Materials and Methods: This study was conducted between
   November 20 and December 1, 2023. Three large language models (ChatGPT
   4.0 [LLM1], ChatGPT 3.5 [LLM2], and ERNIE Bot 4.0 [LLM3]) were input 15
   H. pylori related questions each, once in English and once in Chinese.
   Each chat was conducted using the "New Chat" function to avoid bias from
   correlation interference. Responses were recorded and blindly assigned
   to three reviewers for scoring on three established Likert scales:
   accuracy (ranged 1-6 point), completeness (ranged 1-3 point), and
   comprehensibility (ranged 1-3 point). The acceptable thresholds for the
   scales were set at a minimum of 4, 2, and 2, respectively. Final various
   source and interlanguage comparisons were made. Results: The overall
   mean (SD) accuracy score was 4.80 (1.02), while 1.82 (0.78) for
   completeness score and 2.90 (0.36) for comprehensibility score. The
   acceptable proportions for the accuracy, completeness, and
   comprehensibility of the responses were 90%, 45.6%, and 100%,
   respectively. The acceptable proportion of overall completeness score
   for English responses was better than for Chinese responses (p = 0.034).
   For accuracy, the English responses of LLM3 were better than the Chinese
   responses (p = 0.0055). As for completeness, the English responses of
   LLM1 was better than the Chinese responses (p = 0.0257). For
   comprehensibility, the English responses of LLM1 was better than the
   Chinese responses (p = 0.0496). No differences were found between the
   various LLMs. Conclusions: The LLMs responded satisfactorily to
   questions related to H. pylori infection. But further improving
   completeness and reliability, along with considering language nuances,
   is crucial for optimizing overall performance.
ZA 0
TC 5
Z8 0
ZB 1
ZS 0
ZR 0
Z9 5
DA 2024-02-16
UT WOS:001158133100001
PM 39078641
ER

PT J
AU Zhao, Fang-Fang
   He, Han-Jie
   Liang, Jia-Jian
   Cen, Jingyun
   Wang, Yun
   Lin, Hongjie
   Chen, Feifei
   Li, Tai-Ping
   Yang, Jian-Feng
   Chen, Lan
   Cen, Ling-Ping
TI Benchmarking the performance of large language models in uveitis: a
   comparative analysis of ChatGPT-3.5, ChatGPT-4.0, Google Gemini, and
   Anthropic Claude3
SO EYE
VL 39
IS 6
BP 1132
EP 1137
DI 10.1038/s41433-024-03545-9
EA DEC 2024
DT Article
PD APR 2025
PY 2025
AB Background/Objective This study aimed to evaluate the accuracy,
   comprehensiveness, and readability of responses generated by various
   Large Language Models (LLMs) (ChatGPT-3.5, Gemini, Claude 3, and
   GPT-4.0) in the clinical context of uveitis, utilizing a meticulous
   grading methodology. Methods Twenty-seven clinical uveitis questions
   were presented individually to four Large Language Models (LLMs):
   ChatGPT (versions GPT-3.5 and GPT-4.0), Google Gemini, and Claude. Three
   experienced uveitis specialists independently assessed the responses for
   accuracy using a three-point scale across three rounds with a 48-hour
   wash-out interval. The final accuracy rating for each LLM response
   ('Excellent', 'Marginal', or 'Deficient') was determined through a
   majority consensus approach. Comprehensiveness was evaluated using a
   three-point scale for responses rated 'Excellent' in the final accuracy
   assessment. Readability was determined using the Flesch-Kincaid Grade
   Level formula. Statistical analyses were conducted to discern
   significant differences among LLMs, employing a significance threshold
   of p < 0.05. Results Claude 3 and ChatGPT 4 demonstrated significantly
   higher accuracy compared to Gemini (p < 0.001). Claude 3 also showed the
   highest proportion of 'Excellent' ratings (96.3%), followed by ChatGPT 4
   (88.9%). ChatGPT 3.5, Claude 3, and ChatGPT 4 had no responses rated as
   'Deficient', unlike Gemini (14.8%) (p = 0.014). ChatGPT 4 exhibited
   greater comprehensiveness compared to Gemini (p = 0.008), and Claude 3
   showed higher comprehensiveness compared to Gemini (p = 0.042). Gemini
   showed significantly better readability compared to ChatGPT 3.5, Claude
   3, and ChatGPT 4 (p < 0.001). Gemini also had fewer words, letter
   characters, and sentences compared to ChatGPT 3.5 and Claude 3.
   Conclusions Our study highlights the outstanding performance of Claude 3
   and ChatGPT 4 in providing precise and thorough information regarding
   uveitis, surpassing Gemini. ChatGPT 4 and Claude 3 emerge as pivotal
   tools in improving patient understanding and involvement in their
   uveitis healthcare journey.
ZB 0
ZS 0
TC 6
ZR 0
ZA 0
Z8 0
Z9 6
DA 2024-12-25
UT WOS:001380600200001
PM 39690303
ER

PT J
AU Cai, Louis Z.
   Shaheen, Abdulla
   Jin, Andrew
   Fukui, Riya
   Yi, Jonathan S.
   Yannuzzi, Nicolas
   Alabiad, Chrisfouad
TI Performance of Generative Large Language Models on Ophthalmology
   Board-Style Questions
SO AMERICAN JOURNAL OF OPHTHALMOLOGY
VL 254
BP 141
EP 149
DI 10.1016/j.ajo.2023.05.024
EA JUL 2023
DT Article
PD OCT 2023
PY 2023
AB & BULL; PURPOSE: To investigate the ability of generative artifi-cial
   intelligence models to answer ophthalmology board-style questions.&
   BULL; DESIGN: Experimental study.& BULL; METHODS: This study evaluated 3
   large language mod -els (LLMs) with chat interfaces, Bing Chat
   (Microsoft) and ChatGPT 3.5 and 4.0 (OpenAI), using 250 ques-tions from
   the Basic Science and Clinical Science Self-Assessment Program. Although
   ChatGPT is trained on information last updated in 2021, Bing Chat
   incorporates a more recently indexed internet search to generate its
   answers. Performance was compared with human respon-dents. Questions
   were categorized by complexity and pa-tient care phase, and instances of
   information fabrication or nonlogical reasoning were documented.& BULL;
   MAIN OUTCOME MEASURES: Primary outcome was re-sponse accuracy. Secondary
   outcomes were performance in question subcategories and hallucination
   frequency.& BULL; RESULTS: Human respondents had an average ac-curacy of
   72.2%. ChatGPT-3.5 scored the lowest (58.8%), whereas ChatGPT-4.0
   (71.6%) and Bing Chat (71.2%) performed comparably. ChatGPT-4.0 excelled
   in workup-type questions (odds ratio [OR], 3.89, 95% CI, 1.19-14.73, P =
   .03) compared with diagnostic ques-tions, but struggled with image
   interpretation (OR, 0.14, 95% CI, 0.05-0.33, P < . 01) when compared
   with single-step reasoning questions. Against single-step ques-tions,
   Bing Chat also faced difficulties with image in-terpretation (OR, 0.18,
   95% CI, 0.08-0.44, P < . 01) and multi-step reasoning (OR, 0.30, 95% CI,
   0.11-0.84, P = .02). ChatGPT-3.5 had the highest rate of halluci-nations
   and nonlogical reasoning (42.4%), followed by ChatGPT-4.0 (18.0%) and
   Bing Chat (25.6%).& BULL; CONCLUSIONS: LLMs (particularly ChatGPT-4.0
   and Bing Chat) can perform similarly with human respon-dents answering
   questions from the Basic Science and Clinical Science Self-Assessment
   Program. The fre-quency of hallucinations and nonlogical reasoning
   sug-gests room for improvement in the performance of con-versational
   agents in the medical domain. (Am J Oph-thalmol 2023;254: 141-149.&
   COPY; 2023 Elsevier Inc. All rights reserved.)
ZB 19
ZA 0
TC 74
Z8 0
ZR 0
ZS 0
Z9 74
DA 2023-08-21
UT WOS:001044630000001
PM 37339728
ER

PT J
AU Zheng, Neil S.
   Keloth, Vipina K.
   You, Kisung
   Kats, Daniel
   Li, Darrick K.
   Deshpande, Ohm
   Sachar, Hamita
   Xu, Hua
   Laine, Loren
   Shung, Dennis L.
TI Detection of Gastrointestinal Bleeding With Large Language Models to Aid
   Quality Improvement and Appropriate Reimbursement
SO GASTROENTEROLOGY
VL 168
IS 1
DI 10.1053/j.gastro.2024.09.014
EA DEC 2024
DT Article
PD JAN 2025
PY 2025
AB BACKGROUND & AIMS: Early identification and accurate characterization of
   overt gastrointestinal bleeding (GIB)enables opportunities to optimize
   patient management and ensures appropriately risk-adjusted coding for
   claims-based quality measures and reimbursement. Recent advancements in
   generative artificial intelligence, particularly large language models
   (LLMs), create opportunities to support accurate identification of
   clinical conditions. In this study, we present the fi rst LLM-based
   pipeline for identification of overt GIB in the electronic health record
   (EHR). We demonstrate 2 clinically relevant applications: the automated
   detection of recurrent bleeding and appropriate reimbursement coding for
   patients with GIB. METHODS: Development of the LLMbased pipeline was
   performed on 17,712 nursing notes from 1108 patients who were
   hospitalized with acute GIB and underwent endoscopy in the hospital from
   2014 to 2023. The pipeline was used to train an EHR-based machine
   learning model for detection of recurrent bleeding on 546 patients
   presenting to 2 hospitals and externally validated on 562 patients
   presenting to 4 different hospitals. The pipeline was used to develop an
   algorithm for appropriate reimbursement coding on 7956 patients who
   underwent endoscopy in the hospital from 2019 to 2023. RESULTS: The
   LLM-based pipeline accurately detected melena (positive predictive
   value, 0.972; sensitivity, 0.900), hematochezia (positive predictive
   value, 0.900; sensitivity, 0.908), and hematemesis (positive predictive
   value, 0.859; sensitivity, 0.932). The EHRbased machine learning model
   identified recurrent bleeding with area under the curve of 0.986,
   sensitivity of 98.4%, and specificity of 97.5%. The reimbursement coding
   algorithm resulted in an average per-patient reimbursement increase of
   $1299 to $3247 with a total difference of $697,460 to $1,743,649.
   CONCLUSIONS: An LLM-based pipeline can robustly detect overt GIB in the
   EHR with clinically relevant applications in detection of recurrent
   bleeding and appropriate reimbursement coding.
ZR 0
TC 2
Z8 0
ZA 0
ZB 1
ZS 0
Z9 2
DA 2025-01-13
UT WOS:001391995700001
PM 39304088
ER

PT J
AU Malek, Ehsan
   Wang, Gi-Ming
   Madabhushi, Anant
   Cullen, Jennifer
   Tatsuoka, Curtis
   James, Driscoll J., II
TI Toward AI-Assisted Clinical Assessment for Patients with Multiple
   Myeloma: Feature Selection for Large Language Models
SO BLOOD
VL 142
DI 10.1182/blood-2023-172710
EA NOV 2023
SU 1
DT Meeting Abstract
PD NOV 2 2023
PY 2023
CT 65th Annual Meeting of the American-Society-of-Hematology (ASH)
CY DEC 09-12, 2023
CL San Diego, CA
SP Amer Soc Hematol
ZR 0
Z8 0
ZA 0
ZS 0
ZB 0
TC 2
Z9 2
DA 2024-03-02
UT WOS:001159740300029
ER

PT C
AU Niraula, Trishna
   Stubblefield, Jonathan
GP ACM
TI Using Large Language Models to Translate Machine Results to Human
   Results
SO 14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH
   INFORMATICS, BCB 2023
DI 10.1145/3584371.3613036
DT Proceedings Paper
PD 2023
PY 2023
AB Chest x-rays are among the most common diagnostic studies used in most
   both inpatient and outpatient settings, and they represent a significant
   portion of the workload for radiologists. Many different machine
   learning models have been developed for the analysis of chest x-rays,
   including models capable of detecting and labeling the location and type
   of pathological findings. In addition, large language models (LLMs) such
   as ChatGPT have also been growing in popularity and have proven to be
   effective at a variety of writing tasks [2]. For this project, we will
   attempt to use LLMs to translate machine learning results into
   automatically generated radiology reports. This would provide quick
   pre-reads of chest x-rays which can later be corrected or validated by
   radiologists in a similar workflow used by cardiologists when reading
   electrocardiograms (ECGs).
   To perform this task, we will make use of the Open-I dataset of chest
   x-rays with associated radiology reports [1]. Additionally, we will use
   a top performing model from the competition on the CheXpert dataset [3,
   4]. This dataset consists of multiple chest xrays with expert-annotated
   bounding boxes labeling pathological findings [3]. We will use the
   top-performing model to label the type and location of pathological
   findings in the Open-I dataset [4]. Following this, we will
   algorithmically transform the bounding boxes into simple descriptions of
   the type and location of the pathological finding (i.e., consolidation
   lower left quadrant, atelectasis upper right quadrant, cardiomegaly). We
   will then train a LLM to translate these simple descriptions into a full
   radiology report.
   To evaluate the efficacy of our method, we will present a mixture of
   expert written and automatically generated radiology reports to
   volunteers to assess if the generated reports. Volunteers will be
   selected from a variety of expertise levels and backgrounds in medicine,
   including non-medical laymen, medical students, and physicians.
   Volunteers will be asked to evaluate whether they can distinguish
   between automatically generated and expert written reports and if both
   reports adequately convey the relevant information from the associated
   chest x-ray.
   If the LLMs can use simple descriptors of machine learning results to
   produce radiology reports, this would significantly improve patient care
   and the workload for physicians. Patients and nonradiologist physicians
   would benefit from immediately available results following the
   acquisition of a chest x-ray. Radiologists will be able to overread the
   chest x-rays later, either verifying the AI-generated results or
   providing corrections, similar to the practice of Cardiologists with
   ECGs.
CT 14th ACM Conference on Bioinformatics, Computational Biology, and Health
   Informatics (ACM-BCB)
CY SEP 03-06, 2023
CL Houston, TX
SP Assoc Comp Machinery; ACM Special Interest Grp Bioinformat, Computat
   Biol, & Biomed Informat
ZS 0
ZA 0
Z8 0
TC 0
ZR 0
ZB 0
Z9 0
DA 2024-03-19
UT WOS:001143941200096
ER

PT J
AU Kerr, Wesley T.
   Mcfarlane, Katherine N.
   Pucci, Gabriela Figueiredo
   Carns, Danielle R.
   Israel, Alex
   Vighetti, Lianne
   Pennell, Page B.
   Stern, John M.
   Xia, Zongqi
   Wang, Yanshan
TI Supervised machine learning compared to large language models for
   identifying functional seizures from medical records
SO EPILEPSIA
VL 66
IS 4
BP 1155
EP 1164
DI 10.1111/epi.18272
EA FEB 2025
DT Article
PD APR 2025
PY 2025
AB Objective The Functional Seizures Likelihood Score (FSLS) is a
   supervised machine learning-based diagnostic score that was developed to
   differentiate functional seizures (FS) from epileptic seizures (ES). In
   contrast to this targeted approach, large language models (LLMs) can
   identify patterns in data for which they were not specifically trained.
   To evaluate the relative benefits of each approach, we compared the
   diagnostic performance of the FSLS to two LLMs: ChatGPT and GPT-4.
   Methods In total, 114 anonymized cases were constructed based on
   patients with documented FS, ES, mixed ES and FS, or physiologic
   seizure-like events (PSLEs). Text-based data were presented in three
   sequential prompts to the LLMs, showing the history of present illness
   (HPI), electroencephalography (EEG) results, and neuroimaging results.
   We compared the accuracy (number of correct predictions/number of cases)
   and area under the receiver-operating characteristic (ROC) curves (AUCs)
   of the LLMs to the FSLS using mixed-effects logistic regression. Results
   The accuracy of FSLS was 74% (95% confidence interval [CI] 65%-82%) and
   the AUC was 85% (95% CI 77%-92%). GPT-4 was superior to both the FSLS
   and ChatGPT (p <.001), with an accuracy of 85% (95% CI 77%-91%) and AUC
   of 87% (95% CI 79%-95%). Cohen's kappa between the FSLS and GPT-4 was
   40% (fair). The LLMs provided different predictions on different days
   when the same note was provided for 33% of patients, and the LLM's
   self-rated certainty was moderately correlated with this observed
   variability (Spearman's rho(2): 30% [fair, ChatGPT] and 63%
   [substantial, GPT-4]). Significance Both GPT-4 and the FSLS identified a
   substantial subset of patients with FS based on clinical history. The
   fair agreement in predictions highlights that the LLMs identified
   patients differently from the structured score. The inconsistency of the
   LLMs' predictions across days and incomplete insight into their own
   consistency was concerning. This comparison highlights both benefits and
   cautions about how machine learning and artificial intelligence could
   identify patients with FS in clinical practice.
ZB 0
TC 0
ZR 0
ZA 0
ZS 0
Z8 0
Z9 0
DA 2025-02-23
UT WOS:001423350000001
PM 39960122
ER

PT J
AU Hao, Boran
   Hu, Yang
   Adams, William G.
   Assoumou, Sabrina A.
   Hsu, Heather E.
   Bhadelia, Nahid
   Paschalidis, Ioannis Ch.
TI A GPT-based EHR modeling system for unsupervised novel disease detection
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 157
AR 104706
DI 10.1016/j.jbi.2024.104706
EA AUG 2024
DT Article
PD SEP 2024
PY 2024
AB Objective: To develop an Artificial Intelligence (AI)-based anomaly
   detection model as a complement of an "astute physician" in detecting
   novel disease cases in a hospital and preventing emerging outbreaks. .
   Methods: Data included hospitalized patients (n = 120,714) at a
   safety-net hospital in Massachusetts. A novel Generative Pre-trained
   Transformer (GPT)-based clinical anomaly detection system was designed
   and further trained using Empirical Risk Minimization (ERM), , which can
   model a hospitalized patient's Electronic Health Records (EHR) and
   detect atypical patients. Methods and performance metrics, similar to
   the ones behind the recent Large Language Models (LLMs), , were
   leveraged to capture the dynamic evolution of the patient's clinical
   variables and compute an Out-Of-Distribution (OOD) anomaly score.
   Results: In a completely unsupervised setting, hospitalizations for
   Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) infection
   could have been predicted by our GPT model at the beginning of the
   COVID-19 pandemic, with an Area Under the Receiver Operating
   Characteristic Curve (AUC) of 92.2 %, using 31 extracted clinical
   variables and a 3-day detection window. Our GPT achieves individual
   patient-level anomaly detection and mortality prediction AUC of 78.3 %
   and 94.7 %, outperforming traditional linear models by 6.6 % and 9 %,
   respectively. Different types of clinical trajectories of a SARS-CoV-2
   infection are captured by our model to make interpretable detections,
   while a trend of over-pessimistic outcome prediction yields a more
   effective detection pathway. Furthermore, our comprehensive GPT model
   can potentially assist clinicians with forecasting patient clinical
   variables and developing personalized treatment plans. Conclusion: This
   study demonstrates that an emerging outbreak can be accurately detected
   within a hospital, by using a GPT to model patient EHR time sequences
   and labeling them as anomalous when actual outcomes are not supported by
   the model. Such a GPT is also a comprehensive model with the
   functionality of generating future patient clinical variables, which can
   potentially assist clinicians in developing personalized treatment
   plans.
ZB 0
TC 1
ZS 0
Z8 0
ZR 0
ZA 0
Z9 1
DA 2024-08-27
UT WOS:001295776900001
PM 39121932
ER

PT J
AU Panagoulias, Dimitrios P.
   Tsoureli-Nikita, Evridiki
   Virvou, Maria
   Tsihrintzis, George A.
TI Dermacen analytica: A novel methodology integrating multi-modal large
   language models with machine learning in dermatology
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 199
AR 105898
DI 10.1016/j.ijmedinf.2025.105898
EA MAR 2025
DT Article
PD JUL 2025
PY 2025
AB Objective: To design, implement, evaluate, and quantify a novel and
   adaptable Artificial Intelligence-empowered methodology aimed at
   supporting a dermatologist's workflow in assessing and diagnosing skin
   conditions, leveraging AI's deep image analytic power and reasoning.
   Skin presents diverse conditions that no single AI solution can
   comprehensively address, suggesting that mimicking a medical
   professional's diagnostic process and creating strategic AI
   interventions may enhance decision-making. Patients and Methods: We
   employ large language, transformer-based vision models for image
   analysis, sophisticated machine learning tools for guideline-based
   segmentation, and measuring tasks in our system. As no single technology
   is sufficient on its own for efficient use by dermatologists, we apply a
   sequential logic with agency to improve outcomes. Results: Using natural
   language processing methods and incorporating human expert evaluation,
   our system achieved a weighted accuracy of 87% on the dataset used,
   demonstrating its reasoning and diagnostic capabilities. Conclusions:
   This study serves as a proof of concept for the application of AI in
   dermatology, highlighting its potential to enhance the patient journey
   for which we approximate the value of such interventions in healthcare
   using graph theory with an associated cost-optimization objective
   function.
Z8 0
TC 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 0
DA 2025-04-08
UT WOS:001458155100001
PM 40153891
ER

PT J
AU Yu, Zehao
   Peng, Cheng
   Yang, Xi
   Dang, Chong
   Adekkanattu, Prakash
   Patra, Braja Gopal
   Peng, Yifan
   Pathak, Jyotishman
   Wilson, Debbie L.
   Chang, Ching -Yuan
   Lo-Ciganic, Wei-Hsuan
   George, Thomas J.
   Hogan, William R.
   Guo, Yi
   Bian, Jiang
   Wu, Yonghui
TI Identifying social determinants of health from clinical narratives: A
   study of performance, documentation ratio, and potential bias
SO JOURNAL OF BIOMEDICAL INFORMATICS
VL 153
AR 104642
DI 10.1016/j.jbi.2024.104642
EA APR 2024
DT Article
PD MAY 2024
PY 2024
AB Objective: To develop a natural language processing (NLP) package to
   extract social determinants of health (SDoH) from clinical narratives,
   examine the bias among race and gender groups, test the generalizability
   of extracting SDoH for different disease groups, and examine
   population-level extraction ratio.
   Methods: We developed SDoH corpora using clinical notes identified at
   the University of Florida (UF) Health. We systematically compared 7
   transformer-based large language models (LLMs) and developed an
   open-source package - SODA (i.e., SOcial DeterminAnts) to facilitate
   SDoH extraction from clinical narratives. We examined the performance
   and potential bias of SODA for different race and gender groups, tested
   the generalizability of SODA using two disease domains including cancer
   and opioid use, and explored strategies for improvement. We applied SODA
   to extract 19 categories of SDoH from the breast (n = 7,971), lung (n
   =11,804), and colorectal cancer (n = 6,240) cohorts to assess
   patient-level extraction ratio and examine the differences among race
   and gender groups.
   Results: We developed an SDoH corpus using 629 clinical notes of cancer
   patients with annotations of 13,193 SDoH concepts/attributes from 19
   categories of SDoH, and another cross-disease validation corpus using
   200 notes from opioid use patients with 4,342 SDoH concepts/attributes.
   We compared 7 transformer models and the GatorTron model achieved the
   best mean average strict/lenient F1 scores of 0.9122 and 0.9367 for SDoH
   concept extraction and 0.9584 and 0.9593 for linking attributes to SDoH
   concepts. There is a small performance gap (similar to 4%) between Males
   and Females, but a large performance gap (>16 %) among race groups. The
   performance dropped when we applied the cancer SDoH model to the opioid
   cohort; fine-tuning using a smaller opioid SDoH corpus improved the
   performance. The extraction ratio varied in the three cancer cohorts, in
   which 10 SDoH could be extracted from over 70 % of cancer patients, but
   9 SDoH could be extracted from less than 70 % of cancer patients.
   Individuals from the White and Black groups have a higher extraction
   ratio than other minority race groups.
   Conclusions: Our SODA package achieved good performance in extracting 19
   categories of SDoH from clinical narratives. The SODA package with
   pre-trained transformer models is available at https://github.com/uf-hob
   i-informatics-lab/SODA_Docker.
TC 8
ZB 3
ZS 0
ZA 0
ZR 0
Z8 0
Z9 8
DA 2024-06-05
UT WOS:001230611200001
PM 38621641
ER

PT J
AU Giannuzzi, Federico
   Carla, Matteo Mario
   Hu, Lorenzo
   Cestrone, Valentina
   Caputo, Carmela Grazia
   Sammarco, Maria Grazia
   Savino, Gustavo
   Rizzo, Stanislao
   Blasi, Maria Antonietta
   Pagliara, Monica Maria
TI Artificial intelligence with ChatGPT 4: a large language model in
   support of ocular oncology cases
SO INTERNATIONAL OPHTHALMOLOGY
VL 45
IS 1
AR 59
DI 10.1007/s10792-024-03399-w
DT Article
PD FEB 7 2025
PY 2025
AB PurposeTo evaluate ChatGPT's ability to analyze comprehensive case
   descriptions of patients with uveal melanoma and provide recommendations
   for the most appropriate management.DesignRetrospective analysis of
   ocular oncology patients' medical records.Subjects.Forty patients
   treated for uveal melanoma between May 2019 and October
   2023.DesignRetrospective analysis of ocular oncology patients' medical
   records.Subjects.Forty patients treated for uveal melanoma between May
   2019 and October 2023.DesignRetrospective analysis of ocular oncology
   patients' medical records.Subjects.Forty patients treated for uveal
   melanoma between May 2019 and October 2023.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.MethodsWe uploaded each case description into the ChatGPT
   interface (version 4.0) and asked the model to provide realistic
   treatment options by asking the question, "What type of treatment do you
   recommend?" The accuracy of decisions produced by ChatGPT was compared
   to those recorded in patients' files and the treatment recommendations
   provided by three ocular oncologists, each with more than 10 years of
   experience.Main outcome measures.The primary objective of this research
   was to assess the accuracy of ChatGPT replies in ocular oncology cases,
   analyzing its competence in both straightforward and intricate
   situations. Our secondary purpose was to assess the concordance between
   the responses of ChatGPT and those of ocular oncology specialists when
   faced with analogous clinical scenarios.MethodsWe uploaded each case
   description into the ChatGPT interface (version 4.0) and asked the model
   to provide realistic treatment options by asking the question, "What
   type of treatment do you recommend?" The accuracy of decisions produced
   by ChatGPT was compared to those recorded in patients' files and the
   treatment recommendations provided by three ocular oncologists, each
   with more than 10 years of experience.Main outcome measures.The primary
   objective of this research was to assess the accuracy of ChatGPT replies
   in ocular oncology cases, analyzing its competence in both
   straightforward and intricate situations. Our secondary purpose was to
   assess the concordance between the responses of ChatGPT and those of
   ocular oncology specialists when faced with analogous clinical
   scenarios.ResultsChatGPT's surgical choices matched those in patients'
   files in 55% of cases (22 out of 40). ChatGPT options were agreed upon
   by 50%, 55%, and 57% of the three ocular oncology specialists. The
   investigation revealed significant differences between ChatGPT's
   responses and those of the three cancer specialists when compared to
   patients' files (p = 0.003, p = 0.001, and p = 0.001). ChatGPT's
   surgical responses matched with patient data in 18 out of 24 cases
   (75%), excluding enucleation cases.
   The decisions matched with the three ocular oncology specialists in
   17/24, 18/24, and 18/24 cases, reflecting agreements of 70%, 75%, and
   75%, respectively. The decisions made by ChatGPT were not significantly
   different from those of the three professionals in this cohort (p =
   0.50, p = 0.36, and p = 0.36 for ChatGPT compared to specialists 1, 2,
   and 3).ConclusionChatGPT exhibited a level of proficiency that was
   comparable to that of trained ocular oncology specialists. However, it
   exhibited its limitations when evaluating more complex scenarios, such
   as extrascleral extension or infiltration of the optic nerve, when a
   comprehensive evaluation of the patient is therefore necessary.
ZS 0
Z8 0
ZB 0
ZR 0
TC 0
ZA 0
Z9 0
DA 2025-04-25
UT WOS:001468330700001
PM 39918656
ER

PT J
AU Schwieger, Arne
   Angst, Katrin
   de Bardeci, Mateo
   Burrer, Achim
   Cathomas, Flurin
   Ferrea, Stefano
   Gratz, Franziska
   Knorr, Marius
   Kronenberg, Golo
   Spiller, Tobias
   Troi, David
   Seifritz, Erich
   Weber, Samantha
   Olbrich, Sebastian
TI Large language models can support generation of standardized discharge
   summaries - A retrospective study utilizing ChatGPT-4 and electronic
   health records
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
VL 192
AR 105654
DI 10.1016/j.ijmedinf.2024.105654
EA OCT 2024
DT Article
PD DEC 2024
PY 2024
AB Objective: To evaluate whether psychiatric discharge summaries (DS)
   generated with ChatGPT-4 from electronic health records (EHR) can match
   the quality of DS written by psychiatric residents. Methods: At a
   psychiatric primary care hospital, we compared 20 inpatient DS, written
   by residents, to those written with ChatGPT-4 from pseudonymized
   residents' notes of the patients' EHRs and a standardized prompt. 8
   blinded psychiatry specialists rated both versions on a custom Likert
   scale from 1 to 5 across 15 quality subcategories. The primary outcome
   was the overall rating difference between the two groups. The secondary
   outcomes were the rating differences at the level of individual
   question, case, and rater. Results: Human-written DS were rated
   significantly higher than AI (mean ratings: human 3.78, AI 3.12, p <
   0.05). They surpassed AI significantly in 12/15 questions and 16/20
   cases and were favored significantly by 7/8 raters. For "low expected
   correction effort", human DS were rated as 67 % favorable, 19 % neutral,
   and 14 % unfavorable, whereas AI-DS were rated as 22 % favorable, 33 %
   neutral, and 45 % unfavorable. Hallucinations were present in 40 % of
   AI-DS, with 37.5 % deemed highly clinically relevant. Minor content
   mistakes were found in 30 % of AI and 10 % of human DS. Raters correctly
   identified AI-DS with 81 % sensitivity and 75 % specificity. Discussion:
   Overall, AI-DS did not match the quality of resident-written DS but
   performed similarly in 20% of cases and were rated as favorable for "low
   expected correction effort" in 22% of cases. AI-DS lacked most in
   content specificity, ability to distill key case information, and
   coherence but performed adequately in conciseness, adherence to
   formalities, relevance of included content, and form. Conclusion:
   LLM-written DS show potential as templates for physicians to finalize,
   potentially saving time in the future.
ZA 0
ZR 0
Z8 0
ZS 0
ZB 1
TC 5
Z9 5
DA 2024-11-07
UT WOS:001343302900001
PM 39437512
ER

EF