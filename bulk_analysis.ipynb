{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Technical Analysis of Automated Bibliographic Search Results\n",
        "\n",
        "**Authors:** EMR, DGO, BJU\n",
        "**Date:** 13/06/2024\n",
        "**Reference Paper:** SotA LLM, RAG, KG, Agents - Health\n",
        "\n",
        "---\n",
        "\n",
        "#### Description\n",
        "\n",
        "This notebook documents the technical process of collecting, processing, and analyzing scientific literature through automated queries on Arxiv and PubMed databases.\n",
        "\n",
        "#### Structure\n",
        "\n",
        "1.  **Definition of search queries and domains**\n",
        "2.  **Automation of sweeps on Arxiv and PubMed**\n",
        "3.  **Concatenation, deduplication, and cleaning of results**\n",
        "4.  **Extraction and analysis of technical keywords**\n",
        "\n",
        "---\n",
        "\n",
        "> **Note:** This notebook is designed to be reproducible and extensible, facilitating the traceability and validation of the results presented in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "outputs": [],
      "source": [
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#data folder\n",
        "data_folder = 'data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L72EijaFHUQu"
      },
      "source": [
        "#### Query Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#query tree\n",
        "list_1= [\"large language model\",\"LLM\"]\n",
        "list_3= [\"medicine\",\"healthcare\",\"cancer\"]\n",
        "list_2 = [\n",
        "\"Retrieved augmented generation\",\n",
        "\"Knowledge graph\",\n",
        "\"Graph database\",\n",
        "\"Knowledge base\",\n",
        "\"Agents\",\n",
        "\"agentic\",\n",
        "\"chatgpt\",\n",
        "\"llama\",\n",
        "\"ULM\"]\n",
        "list_4 =[\n",
        "\"patient care\",\n",
        "\"patient monitoring\",\n",
        "\"imaging\",\n",
        "\"decision support\",\n",
        "\"diagnosis\",\n",
        "\"treatment\",\n",
        "\"question answering\",\n",
        "\"hallucination\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsXmrnIDHh2G"
      },
      "source": [
        "LomgFormat: This list the whole query, as [main_domain] AND [tools] AND [medical_designation] AND [medical_domain]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "blRGZnSqW9Rl"
      },
      "outputs": [],
      "source": [
        "combined_list = []\n",
        "for el1 in list_1:\n",
        "    for el2 in list_2:\n",
        "        for el3 in list_3:\n",
        "            for el4 in list_4:\n",
        "                combined_element = f'\"{el1}\" AND \"{el2}\" AND \"{el3}\" AND \"{el4}\"'\n",
        "                combined_list.append(combined_element)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mdWKFcrIY6e"
      },
      "source": [
        "ShortFormat: This query list skips tool , as [main_domain]  AND [medical_designation] AND [medical_domain]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Dh-q_gJ5MkXD"
      },
      "outputs": [],
      "source": [
        "combined_list = []\n",
        "for el1 in list_1:\n",
        "        for el3 in list_3:\n",
        "            for el4 in list_4:\n",
        "                combined_element = f'\"{el1}\" AND \"{el3}\" AND \"{el4}\"'\n",
        "                combined_list.append(combined_element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbiAbs_KIy3e",
        "outputId": "5565602a-c838-4d4e-bb82-303a5d7b62cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"large language model\" AND \"medicine\" AND \"patient care\"',\n",
              " '\"large language model\" AND \"medicine\" AND \"patient monitoring\"',\n",
              " '\"large language model\" AND \"medicine\" AND \"imaging\"',\n",
              " '\"large language model\" AND \"medicine\" AND \"decision support\"',\n",
              " '\"large language model\" AND \"medicine\" AND \"diagnosis\"']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#sample\n",
        "combined_list[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4ESw4UGJNCG"
      },
      "source": [
        "#### Arxiv Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "year_start=2024\n",
        "year_end =  datetime.now().year\n",
        "date_range = (year_start, year_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZttbGJGNgI6",
        "outputId": "6e389c5c-f3ff-40c4-9724-91b998a6db0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"patient care\"\n",
            "Obtenidos 10 resultados en este lote (total: 10)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"patient care\"\n",
            "Totalresultados: 10\n",
            "Query:\"large language model\" AND \"medicine\" AND \"patient care\"(10, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"patient monitoring\"\n",
            "Obtenidos 1 resultados en este lote (total: 1)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"patient monitoring\"\n",
            "Totalresultados: 1\n",
            "Query:\"large language model\" AND \"medicine\" AND \"patient monitoring\"(1, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"imaging\"\n",
            "Obtenidos 25 resultados en este lote (total: 25)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"imaging\"\n",
            "Totalresultados: 25\n",
            "Query:\"large language model\" AND \"medicine\" AND \"imaging\"(25, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"decision support\"\n",
            "Obtenidos 21 resultados en este lote (total: 21)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"decision support\"\n",
            "Totalresultados: 21\n",
            "Query:\"large language model\" AND \"medicine\" AND \"decision support\"(21, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"diagnosis\"\n",
            "Obtenidos 37 resultados en este lote (total: 37)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"diagnosis\"\n",
            "Totalresultados: 37\n",
            "Query:\"large language model\" AND \"medicine\" AND \"diagnosis\"(37, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"treatment\"\n",
            "Obtenidos 31 resultados en este lote (total: 31)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"treatment\"\n",
            "Totalresultados: 31\n",
            "Query:\"large language model\" AND \"medicine\" AND \"treatment\"(31, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"question answering\"\n",
            "Obtenidos 55 resultados en este lote (total: 55)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"question answering\"\n",
            "Totalresultados: 55\n",
            "Query:\"large language model\" AND \"medicine\" AND \"question answering\"(55, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"hallucination\"\n",
            "Obtenidos 38 resultados en este lote (total: 38)\n",
            "Consultando arXiv: \"large language model\" AND \"medicine\" AND \"hallucination\"\n",
            "Totalresultados: 38\n",
            "Query:\"large language model\" AND \"medicine\" AND \"hallucination\"(38, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"patient care\"\n",
            "Obtenidos 50 resultados en este lote (total: 50)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"patient care\"\n",
            "Totalresultados: 50\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"patient care\"(50, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"patient monitoring\"\n",
            "Obtenidos 1 resultados en este lote (total: 1)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"patient monitoring\"\n",
            "Totalresultados: 1\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"patient monitoring\"(1, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"imaging\"\n",
            "Obtenidos 84 resultados en este lote (total: 84)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"imaging\"\n",
            "Totalresultados: 84\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"imaging\"(84, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"decision support\"\n",
            "Obtenidos 51 resultados en este lote (total: 51)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"decision support\"\n",
            "Totalresultados: 51\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"decision support\"(51, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"diagnosis\"\n",
            "Obtenidos 84 resultados en este lote (total: 84)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"diagnosis\"\n",
            "Totalresultados: 84\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"diagnosis\"(84, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"treatment\"\n",
            "Obtenidos 67 resultados en este lote (total: 67)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"treatment\"\n",
            "Totalresultados: 67\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"treatment\"(67, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"question answering\"\n",
            "Obtenidos 119 resultados en este lote (total: 119)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"question answering\"\n",
            "Totalresultados: 119\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"question answering\"(119, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"hallucination\"\n",
            "Obtenidos 84 resultados en este lote (total: 84)\n",
            "Consultando arXiv: \"large language model\" AND \"healthcare\" AND \"hallucination\"\n",
            "Totalresultados: 84\n",
            "Query:\"large language model\" AND \"healthcare\" AND \"hallucination\"(84, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"patient care\"\n",
            "Obtenidos 7 resultados en este lote (total: 7)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"patient care\"\n",
            "Totalresultados: 7\n",
            "Query:\"large language model\" AND \"cancer\" AND \"patient care\"(7, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"patient monitoring\"\n",
            "Obtenidos 1 resultados en este lote (total: 1)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"patient monitoring\"\n",
            "Totalresultados: 1\n",
            "Query:\"large language model\" AND \"cancer\" AND \"patient monitoring\"(1, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"imaging\"\n",
            "Obtenidos 25 resultados en este lote (total: 25)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"imaging\"\n",
            "Totalresultados: 25\n",
            "Query:\"large language model\" AND \"cancer\" AND \"imaging\"(25, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"decision support\"\n",
            "Obtenidos 2 resultados en este lote (total: 2)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"decision support\"\n",
            "Totalresultados: 2\n",
            "Query:\"large language model\" AND \"cancer\" AND \"decision support\"(2, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"diagnosis\"\n",
            "Obtenidos 18 resultados en este lote (total: 18)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"diagnosis\"\n",
            "Totalresultados: 18\n",
            "Query:\"large language model\" AND \"cancer\" AND \"diagnosis\"(18, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"treatment\"\n",
            "Obtenidos 36 resultados en este lote (total: 36)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"treatment\"\n",
            "Totalresultados: 36\n",
            "Query:\"large language model\" AND \"cancer\" AND \"treatment\"(36, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"question answering\"\n",
            "Obtenidos 4 resultados en este lote (total: 4)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"question answering\"\n",
            "Totalresultados: 4\n",
            "Query:\"large language model\" AND \"cancer\" AND \"question answering\"(4, 12)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"hallucination\"\n",
            "Obtenidos 10 resultados en este lote (total: 10)\n",
            "Consultando arXiv: \"large language model\" AND \"cancer\" AND \"hallucination\"\n",
            "Totalresultados: 10\n",
            "Query:\"large language model\" AND \"cancer\" AND \"hallucination\"(10, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"patient care\"\n",
            "Obtenidos 9 resultados en este lote (total: 9)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"patient care\"\n",
            "Totalresultados: 9\n",
            "Query:\"LLM\" AND \"medicine\" AND \"patient care\"(9, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"patient monitoring\"\n",
            "Obtenidos 1 resultados en este lote (total: 1)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"patient monitoring\"\n",
            "Totalresultados: 1\n",
            "Query:\"LLM\" AND \"medicine\" AND \"patient monitoring\"(1, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"imaging\"\n",
            "Obtenidos 17 resultados en este lote (total: 17)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"imaging\"\n",
            "Totalresultados: 17\n",
            "Query:\"LLM\" AND \"medicine\" AND \"imaging\"(17, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"decision support\"\n",
            "Obtenidos 19 resultados en este lote (total: 19)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"decision support\"\n",
            "Totalresultados: 19\n",
            "Query:\"LLM\" AND \"medicine\" AND \"decision support\"(19, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"diagnosis\"\n",
            "Obtenidos 36 resultados en este lote (total: 36)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"diagnosis\"\n",
            "Totalresultados: 36\n",
            "Query:\"LLM\" AND \"medicine\" AND \"diagnosis\"(36, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"treatment\"\n",
            "Obtenidos 28 resultados en este lote (total: 28)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"treatment\"\n",
            "Totalresultados: 28\n",
            "Query:\"LLM\" AND \"medicine\" AND \"treatment\"(28, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"question answering\"\n",
            "Obtenidos 56 resultados en este lote (total: 56)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"question answering\"\n",
            "Totalresultados: 56\n",
            "Query:\"LLM\" AND \"medicine\" AND \"question answering\"(56, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"hallucination\"\n",
            "Obtenidos 35 resultados en este lote (total: 35)\n",
            "Consultando arXiv: \"LLM\" AND \"medicine\" AND \"hallucination\"\n",
            "Totalresultados: 35\n",
            "Query:\"LLM\" AND \"medicine\" AND \"hallucination\"(35, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"patient care\"\n",
            "Obtenidos 43 resultados en este lote (total: 43)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"patient care\"\n",
            "Totalresultados: 43\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"patient care\"(43, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"patient monitoring\"\n",
            "Obtenidos 1 resultados en este lote (total: 1)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"patient monitoring\"\n",
            "Totalresultados: 1\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"patient monitoring\"(1, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"imaging\"\n",
            "Obtenidos 54 resultados en este lote (total: 54)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"imaging\"\n",
            "Totalresultados: 54\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"imaging\"(54, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"decision support\"\n",
            "Obtenidos 42 resultados en este lote (total: 42)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"decision support\"\n",
            "Totalresultados: 42\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"decision support\"(42, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"diagnosis\"\n",
            "Obtenidos 73 resultados en este lote (total: 73)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"diagnosis\"\n",
            "Totalresultados: 73\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"diagnosis\"(73, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"treatment\"\n",
            "Obtenidos 60 resultados en este lote (total: 60)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"treatment\"\n",
            "Totalresultados: 60\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"treatment\"(60, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"question answering\"\n",
            "Obtenidos 110 resultados en este lote (total: 110)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"question answering\"\n",
            "Totalresultados: 110\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"question answering\"(110, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"hallucination\"\n",
            "Obtenidos 81 resultados en este lote (total: 81)\n",
            "Consultando arXiv: \"LLM\" AND \"healthcare\" AND \"hallucination\"\n",
            "Totalresultados: 81\n",
            "Query:\"LLM\" AND \"healthcare\" AND \"hallucination\"(81, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"patient care\"\n",
            "Obtenidos 6 resultados en este lote (total: 6)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"patient care\"\n",
            "Totalresultados: 6\n",
            "Query:\"LLM\" AND \"cancer\" AND \"patient care\"(6, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"patient monitoring\"\n",
            "Obtenidos 1 resultados en este lote (total: 1)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"patient monitoring\"\n",
            "Totalresultados: 1\n",
            "Query:\"LLM\" AND \"cancer\" AND \"patient monitoring\"(1, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"imaging\"\n",
            "Obtenidos 14 resultados en este lote (total: 14)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"imaging\"\n",
            "Totalresultados: 14\n",
            "Query:\"LLM\" AND \"cancer\" AND \"imaging\"(14, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"decision support\"\n",
            "Obtenidos 2 resultados en este lote (total: 2)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"decision support\"\n",
            "Totalresultados: 2\n",
            "Query:\"LLM\" AND \"cancer\" AND \"decision support\"(2, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"diagnosis\"\n",
            "Obtenidos 14 resultados en este lote (total: 14)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"diagnosis\"\n",
            "Totalresultados: 14\n",
            "Query:\"LLM\" AND \"cancer\" AND \"diagnosis\"(14, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"treatment\"\n",
            "Obtenidos 36 resultados en este lote (total: 36)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"treatment\"\n",
            "Totalresultados: 36\n",
            "Query:\"LLM\" AND \"cancer\" AND \"treatment\"(36, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"question answering\"\n",
            "Obtenidos 4 resultados en este lote (total: 4)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"question answering\"\n",
            "Totalresultados: 4\n",
            "Query:\"LLM\" AND \"cancer\" AND \"question answering\"(4, 12)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"hallucination\"\n",
            "Obtenidos 10 resultados en este lote (total: 10)\n",
            "Consultando arXiv: \"LLM\" AND \"cancer\" AND \"hallucination\"\n",
            "Totalresultados: 10\n",
            "Query:\"LLM\" AND \"cancer\" AND \"hallucination\"(10, 12)\n"
          ]
        }
      ],
      "source": [
        "filename_tosave= 'queries_arxiv_v2_1.xlsx'\n",
        "df_arxiv=pd.DataFrame()\n",
        "for query in combined_list:\n",
        "  df_temp =search_and_export(query, 1000, year_start=None, year_end=None, filename=None)# search_arxiv(query, max_results=2000, start=0, sort_by='relevance', date_range=None)\n",
        "  try:\n",
        "    print(\"Query:\"+query+str(df_temp.shape))\n",
        "  except:\n",
        "    print(\"Query:\"+query+str(None))\n",
        "  df_arxiv=pd.concat([df_arxiv,df_temp])\n",
        "  df_arxiv.to_excel(os.path.join(data_folder, filename_tosave=filename_tosave), index=False)\n",
        "  time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH7NZbkQJcq2",
        "outputId": "dd911b95-370e-4f12-81dd-84ff46d6f6c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arvix queries accounts 1613 rows and 12 columns.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Arvix queries accounts {df_arxiv.shape[0]} rows and {df_arxiv.shape[1]} columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFa7NOmcYrSu",
        "outputId": "963064b7-656c-4889-a577-a89d4c9e068f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['title', 'summary', 'published', 'updated', 'arxiv_url', 'pdf_url',\n",
              "       'authors', 'categories', 'doi', 'year', 'primary_category', 'query'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_arxiv.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "ddZbWueu1bde",
        "outputId": "cc75279e-57d3-4be8-c7ea-1468b981eea1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>published</th>\n",
              "      <th>updated</th>\n",
              "      <th>arxiv_url</th>\n",
              "      <th>pdf_url</th>\n",
              "      <th>authors</th>\n",
              "      <th>categories</th>\n",
              "      <th>doi</th>\n",
              "      <th>year</th>\n",
              "      <th>primary_category</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GIT-Mol: A Multi-modal Large Language Model fo...</td>\n",
              "      <td>Large language models have made significant st...</td>\n",
              "      <td>2023-08-14</td>\n",
              "      <td>2024-02-06</td>\n",
              "      <td>http://arxiv.org/abs/2308.06911v3</td>\n",
              "      <td>http://arxiv.org/pdf/2308.06911v3</td>\n",
              "      <td>Pengfei Liu, Yiming Ren, Jun Tao, Zhixiang Ren</td>\n",
              "      <td>cs.LG, cs.CL, q-bio.BM</td>\n",
              "      <td>http://dx.doi.org/10.1016/j.compbiomed.2024.10...</td>\n",
              "      <td>2023</td>\n",
              "      <td>cs.LG</td>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"ima...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Enhancing LLM Generation with Knowledge Hyperg...</td>\n",
              "      <td>Evidence-based medicine (EBM) plays a crucial ...</td>\n",
              "      <td>2025-03-18</td>\n",
              "      <td>2025-03-18</td>\n",
              "      <td>http://arxiv.org/abs/2503.16530v1</td>\n",
              "      <td>http://arxiv.org/pdf/2503.16530v1</td>\n",
              "      <td>Chengfeng Dou, Ying Zhang, Zhi Jin, Wenpin Jia...</td>\n",
              "      <td>cs.CL, cs.AI, cs.IR</td>\n",
              "      <td>None</td>\n",
              "      <td>2025</td>\n",
              "      <td>cs.CL</td>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"hallucination\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Bias in Large Language Models Across Clinical ...</td>\n",
              "      <td>Background: Large language models (LLMs) are r...</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>2025-04-03</td>\n",
              "      <td>http://arxiv.org/abs/2504.02917v1</td>\n",
              "      <td>http://arxiv.org/pdf/2504.02917v1</td>\n",
              "      <td>Thanathip Suenghataiphorn, Narisara Tribuddhar...</td>\n",
              "      <td>cs.CL, cs.AI</td>\n",
              "      <td>None</td>\n",
              "      <td>2025</td>\n",
              "      <td>cs.CL</td>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "1   GIT-Mol: A Multi-modal Large Language Model fo...   \n",
              "42  Enhancing LLM Generation with Knowledge Hyperg...   \n",
              "14  Bias in Large Language Models Across Clinical ...   \n",
              "\n",
              "                                              summary   published     updated  \\\n",
              "1   Large language models have made significant st...  2023-08-14  2024-02-06   \n",
              "42  Evidence-based medicine (EBM) plays a crucial ...  2025-03-18  2025-03-18   \n",
              "14  Background: Large language models (LLMs) are r...  2025-04-03  2025-04-03   \n",
              "\n",
              "                            arxiv_url                            pdf_url  \\\n",
              "1   http://arxiv.org/abs/2308.06911v3  http://arxiv.org/pdf/2308.06911v3   \n",
              "42  http://arxiv.org/abs/2503.16530v1  http://arxiv.org/pdf/2503.16530v1   \n",
              "14  http://arxiv.org/abs/2504.02917v1  http://arxiv.org/pdf/2504.02917v1   \n",
              "\n",
              "                                              authors              categories  \\\n",
              "1      Pengfei Liu, Yiming Ren, Jun Tao, Zhixiang Ren  cs.LG, cs.CL, q-bio.BM   \n",
              "42  Chengfeng Dou, Ying Zhang, Zhi Jin, Wenpin Jia...     cs.CL, cs.AI, cs.IR   \n",
              "14  Thanathip Suenghataiphorn, Narisara Tribuddhar...            cs.CL, cs.AI   \n",
              "\n",
              "                                                  doi  year primary_category  \\\n",
              "1   http://dx.doi.org/10.1016/j.compbiomed.2024.10...  2023            cs.LG   \n",
              "42                                               None  2025            cs.CL   \n",
              "14                                               None  2025            cs.CL   \n",
              "\n",
              "                                                query  \n",
              "1   \"large language model\" AND \"medicine\" AND \"ima...  \n",
              "42         \"LLM\" AND \"healthcare\" AND \"hallucination\"  \n",
              "14  \"large language model\" AND \"healthcare\" AND \"i...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_arxiv.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8PCY35EKAOF"
      },
      "source": [
        "#### Pubmed Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Axp0XIV2xLo",
        "outputId": "6aadf1df-ad9b-448a-a747-d68de6be5c91"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'combined_list' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueries_pubmed_v2_1.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m df_pubmed\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcombined_list\u001b[49m:\n\u001b[0;32m      4\u001b[0m   df_temp \u001b[38;5;241m=\u001b[39msearch_pubmed_and_save_csv(query, year_start , year_end, drive_folder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPubMed_Results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m# search_arxiv(query, max_results=2000, start=0, sort_by='relevance', date_range=None)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'combined_list' is not defined"
          ]
        }
      ],
      "source": [
        "filename = 'queries_pubmed_v2_1.xlsx'\n",
        "df_pubmed=pd.DataFrame()\n",
        "for query in combined_list:\n",
        "  df_temp =search_pubmed_and_save_csv(query, year_start , year_end, drive_folder_name=\"PubMed_Results\")# search_arxiv(query, max_results=2000, start=0, sort_by='relevance', date_range=None)\n",
        "  try:\n",
        "    print(\"Query:\"+query+str(df_temp.shape))\n",
        "  except:\n",
        "    print(\"Query:\"+query+str(None))\n",
        "  df_pubmed=pd.concat([df_pubmed,df_temp])\n",
        "  df_pubmed.to_excel(os.path.join(data_folder, filename))\n",
        "  time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "fjijxuAO4NPO",
        "outputId": "421a0dba-60f4-4e07-cf7d-07a3b5afd5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pubmed queries accounts 2342 rows and 14 columns.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Pubmed queries accounts {df_pubmed.shape[0]} rows and {df_pubmed.shape[1]} columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['PubMed ID', 'title', 'summary', 'Journal', 'Publication Date',\n",
              "       'authors', 'MeSH Terms', 'Keywords', 'Article Type', 'Volume', 'Issue',\n",
              "       'Pages', 'DOI', 'query'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pubmed.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PubMed ID</th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>Journal</th>\n",
              "      <th>Publication Date</th>\n",
              "      <th>authors</th>\n",
              "      <th>MeSH Terms</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Article Type</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Pages</th>\n",
              "      <th>DOI</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>39560053</td>\n",
              "      <td>Cross-modal embedding integrator for disease-g...</td>\n",
              "      <td></td>\n",
              "      <td>Pharmacology research &amp; perspectives</td>\n",
              "      <td></td>\n",
              "      <td>Chang, Munyoung; Ahn, Junyong; Kang, Bong Gyun...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>e70034</td>\n",
              "      <td></td>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"treatment\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>39176947</td>\n",
              "      <td>Unveiling Medical Insights: Advanced Topic Ext...</td>\n",
              "      <td></td>\n",
              "      <td>Studies in health technology and informatics</td>\n",
              "      <td></td>\n",
              "      <td>Bitaraf, Ehsan; Jafarpour, Maryam; Shool, Sina...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>316</td>\n",
              "      <td></td>\n",
              "      <td>944-948</td>\n",
              "      <td></td>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"patient care\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>38504034</td>\n",
              "      <td>Utilizing large language models in breast canc...</td>\n",
              "      <td></td>\n",
              "      <td>Journal of cancer research and clinical oncology</td>\n",
              "      <td></td>\n",
              "      <td>Sorin, Vera; Glicksberg, Benjamin S; Artsi, Ya...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>140</td>\n",
              "      <td></td>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"question answering\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PubMed ID                                              title summary  \\\n",
              "90  39560053  Cross-modal embedding integrator for disease-g...           \n",
              "5   39176947  Unveiling Medical Insights: Advanced Topic Ext...           \n",
              "9   38504034  Utilizing large language models in breast canc...           \n",
              "\n",
              "                                             Journal Publication Date  \\\n",
              "90              Pharmacology research & perspectives                    \n",
              "5       Studies in health technology and informatics                    \n",
              "9   Journal of cancer research and clinical oncology                    \n",
              "\n",
              "                                              authors MeSH Terms Keywords  \\\n",
              "90  Chang, Munyoung; Ahn, Junyong; Kang, Bong Gyun...                       \n",
              "5   Bitaraf, Ehsan; Jafarpour, Maryam; Shool, Sina...                       \n",
              "9   Sorin, Vera; Glicksberg, Benjamin S; Artsi, Ya...                       \n",
              "\n",
              "   Article Type Volume Issue    Pages DOI  \\\n",
              "90                  12     6   e70034       \n",
              "5                  316        944-948       \n",
              "9                  150     3      140       \n",
              "\n",
              "                                          query  \n",
              "90         \"LLM\" AND \"medicine\" AND \"treatment\"  \n",
              "5         \"LLM\" AND \"cancer\" AND \"patient care\"  \n",
              "9   \"LLM\" AND \"cancer\" AND \"question answering\"  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pubmed.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### WoS sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[{'D-WoS-lar&cancer&diag-17062025.txt': 'D-WoS-lar&cancer&diag-17062025.txt'},{'D-WoS-lar&cancer&DS-17062025':'D-WoS-lar&cancer&DS-17062025'},{'D-WoS-lar&cancer&hall-17062025':'D-WoS-lar&cancer&hall-17062025'},{'D-WoS-lar&cancer&imaging-17062025':'D-WoS-lar&cancer&imaging-17062025'},{'D-WoS-lar&cancer&monitoring-17062025':'D-WoS-lar&cancer&monitoring-17062025'},{'D-WoS-lar&cancer&treatment-17062025':'D-WoS-lar&cancer&treatment-17062025'}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_parse=[]\n",
        "for file_name in os.listdir(wos_path):\n",
        "    list_parse.append(({file_name: file_name}))\n",
        "list_parse\n",
        "query_mapping={'D-WoS-lar&cancer&diag-17062025.txt': '\"large language model\" AND \"cancer\" AND \"diagnosis\"',\n",
        " 'D-WoS-lar&cancer&DS-17062025.txt': '\"large language model\" AND \"cancer\" AND \"decision support\"',\n",
        " 'D-WoS-lar&cancer&hall-17062025.txt': '\"large language model\" AND \"cancer\" AND \"hallucination\"',\n",
        " 'D-WoS-lar&cancer&img-17062025.txt': '\"large language model\" AND \"cancer\" AND \"imaging\"',\n",
        " 'D-WoS-lar&cancer&PC-17062025.txt': '\"large language model\" AND \"cancer\" AND \"patient care\"',\n",
        " 'D-WoS-lar&cancer&PM-17062025.txt': '\"large language model\" AND \"cancer\" AND \"patient monitoring\"',\n",
        " 'D-WoS-lar&cancer&QA-17062025.txt': '\"large language model\" AND \"cancer\" AND \"question answering\"',\n",
        " 'D-WoS-lar&cancer&treat-17062025.txt': '\"large language model\" AND \"cancer\" AND \"treatment\"},',\n",
        " 'D-WoS-lar&HC&diag-17062025.txt': '\"large language model\" AND \"healthcare\" AND \"diagnosis\"',\n",
        " 'D-WoS-lar&HC&DS-17062025.txt': '\"large language model\" AND \"healthcare\" AND \"decision support\"',\n",
        " 'D-WoS-lar&HC&hall-17062025.txt': '\"large language model\" AND \"healthcare\" AND \"hallucination\"',\n",
        " 'D-WoS-lar&HC&img-17062025.txt': '\"large language model\" AND \"healthcare\" AND \"imaging\"',\n",
        " 'D-WoS-lar&HC&PC-17062025.txt': '\"large language model\" AND \"healthcare\" AND \"patient care\"',\n",
        " 'D-WoS-lar&HC&QA-17062025.txt': '\"large language model\" AND \"healthcare\" AND \"question answering\"',\n",
        " 'D-WoS-lar&HC&treat-17062025.txt': '\"large language model\" AND \"healthcare\" AND \"treatment\"',\n",
        " 'D-WoS-lar&med&diag-17062025.txt': '\"large language model\" AND \"medicine\" AND \"diagnosis\"',\n",
        " 'D-WoS-lar&med&DS-17062025.txt': '\"large language model\" AND \"medicine\" AND \"decision support\"',\n",
        " 'D-WoS-lar&med&hall-17062025.txt': '\"large language model\" AND \"medicine\" AND \"hallucination\"',\n",
        " 'D-WoS-lar&med&img-17062025.txt': '\"large language model\" AND \"medicine\" AND \"imaging\"',\n",
        " 'D-WoS-lar&med&PC-17062025.txt': '\"large language model\" AND \"medicine\" AND \"patient care\"',\n",
        " 'D-WoS-lar&med&PM-17062025.txt': '\"large language model\" AND \"medicine\" AND \"patient monitoring\"',\n",
        " 'D-WoS-lar&med&QA-17062025.txt': '\"large language model\" AND \"medicine\" AND \"question answering\"',\n",
        " 'D-WoS-lar&med&treat-17062025.txt': '\"large language model\" AND \"medicine\" AND \"treatment\"',\n",
        " 'D-WoS-LLM&cancer&diag-17062025.txt': '\"LLM\" AND \"cancer\" AND \"diagnosis\"',\n",
        " 'D-WoS-LLM&cancer&DS-17062025.txt': '\"LLM\" AND \"cancer\" AND \"decision support\"',\n",
        " 'D-WoS-LLM&cancer&hall-17062025.txt': '\"LLM\" AND \"cancer\" AND \"hallucination\"',\n",
        " 'D-WoS-LLM&cancer&img-17062025.txt': '\"LLM\" AND \"cancer\" AND \"imaging\"',\n",
        " 'D-WoS-LLM&cancer&PC-17062025.txt': '\"LLM\" AND \"cancer\" AND \"patient care\"',\n",
        " 'D-WoS-LLM&cancer&PM-17062025.txt': '\"LLM\" AND \"cancer\" AND \"patient monitoring\"',\n",
        " 'D-WoS-LLM&cancer&QA-17062025.txt': '\"LLM\" AND \"cancer\" AND \"question answering\"',\n",
        " 'D-WoS-LLM&cancer&treat-17062025.txt': '\"LLM\" AND \"cancer\" AND \"treatment\"',\n",
        " 'D-WoS-LLM&HC&diag-17062025.txt': '\"LLM\" AND \"healthcare\" AND \"diagnosis\"',\n",
        " 'D-WoS-LLM&HC&DS-17062025.txt': '\"LLM\" AND \"healthcare\" AND \"decision support\"',\n",
        " 'D-WoS-LLM&HC&hall-17062025.txt': '\"LLM\" AND \"healthcare\" AND \"hallucination\"',\n",
        " 'D-WoS-LLM&HC&img-17062025.txt': 'LLM\" AND \"healthcare\" AND \"imaging\"',\n",
        " 'D-WoS-LLM&HC&PC-17062025.txt': '\"LLM\" AND \"healthcare\" AND \"patient care\"',\n",
        " 'D-WoS-LLM&HC&PM-17062025.txt': '\"LLM\" AND \"healthcare\" AND \"patient monitoring\"',\n",
        " 'D-WoS-LLM&HC&QA-17062025.txt': '\"LLM\" AND \"healthcare\" AND \"question answering\"',\n",
        " 'D-WoS-LLM&HC&treat-17062025.txt': '\"LLM\" AND \"healthcare\" AND \"treatment\"',\n",
        " 'D-WoS-LLM&med&diag-17062025.txt': '\"LLM\" AND \"medicine\" AND \"diagnosis\"',\n",
        " 'D-WoS-LLM&med&DS-17062025.txt': 'LLM\" AND \"medicine\" AND \"decision support\"',\n",
        " 'D-WoS-LLM&med&hall-17062025.txt': 'LLM\" AND \"medicine\" AND \"hallucination\"',\n",
        " 'D-WoS-LLM&med&img-17062025.txt': 'LLM\" AND \"medicine\" AND \"imaging\"',\n",
        " 'D-WoS-LLM&med&PC-17062025.txt': 'LLM\" AND \"medicine\" AND \"patient care\"',\n",
        " 'D-WoS-LLM&med&PM-17062025.txt': 'LLM\" AND \"medicine\" AND \"patient monitoring\"',\n",
        " 'D-WoS-LLM&med&QA-17062025.txt': 'LLM\" AND \"medicine\" AND \"question answering\"',\n",
        " 'D-WoS-LLM&med&treat-17062025.txt': 'LLM\" AND \"medicine\" AND \"treatment\"'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully parsed 99 records from wos_queries\\D-WoS-lar&cancer&diag-17062025.txt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Series([], Name: count, dtype: int64)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_name = 'D-WoS-lar&cancer&diag-17062025.txt'\n",
        "df_temp= parse_wos_file(os.path.join(wos_path, file_name))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "title\n",
            "Accuracy of ChatGPT in diagnosis and management of dermoscopic images                                                           1\n",
            "Large language model produces high accurate diagnosis of cancer from end-motif profiles of cell-free DNA                        1\n",
            "Can a large language model be an effective assistant for literature reviews? An example in Radiomics                            1\n",
            "From pixels to patients: the evolution and future of deep learning in cancer diagnostics.                                       1\n",
            "Artificial intelligence                                                                                                         1\n",
            "                                                                                                                               ..\n",
            "Large language models streamline automated machine learning for clinical studies                                                1\n",
            "Artificial intelligence with ChatGPT 4: a large language model in support of ocular oncology cases                              1\n",
            "Applying Language Models to Radiology Text for Identifying Oligometastatic Non-Small Cell Lung Cancer                           1\n",
            "Pathology report generation from whole slide images with knowledge retrieval and multi-level regional feature selection         1\n",
            "Comparing the Management Recommendations of Large Language Model and Colorectal Cancer Multidisciplinary Team: A Pilot Study    1\n",
            "Name: count, Length: 99, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "conteo_valores_ascendente =df_temp['title'].value_counts().sort_values(ascending=True)\n",
        "print(conteo_valores_ascendente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully parsed 99 records from wos_queries\\D-WoS-lar&cancer&diag-17062025.txt\n",
            "Successfully parsed 18 records from wos_queries\\D-WoS-lar&cancer&DS-17062025.txt\n",
            "Successfully parsed 9 records from wos_queries\\D-WoS-lar&cancer&hall-17062025.txt\n",
            "Successfully parsed 71 records from wos_queries\\D-WoS-lar&cancer&img-17062025.txt\n",
            "Successfully parsed 32 records from wos_queries\\D-WoS-lar&cancer&PC-17062025.txt\n",
            "Successfully parsed 1 records from wos_queries\\D-WoS-lar&cancer&PM-17062025.txt\n",
            "Successfully parsed 9 records from wos_queries\\D-WoS-lar&cancer&QA-17062025.txt\n",
            "Successfully parsed 109 records from wos_queries\\D-WoS-lar&cancer&treat-17062025.txt\n",
            "Successfully parsed 110 records from wos_queries\\D-WoS-lar&HC&diag-17062025.txt\n",
            "Successfully parsed 38 records from wos_queries\\D-WoS-lar&HC&DS-17062025.txt\n",
            "Successfully parsed 12 records from wos_queries\\D-WoS-lar&HC&hall-17062025.txt\n",
            "Successfully parsed 44 records from wos_queries\\D-WoS-lar&HC&img-17062025.txt\n",
            "Successfully parsed 62 records from wos_queries\\D-WoS-lar&HC&PC-17062025.txt\n",
            "Successfully parsed 28 records from wos_queries\\D-WoS-lar&HC&QA-17062025.txt\n",
            "Successfully parsed 94 records from wos_queries\\D-WoS-lar&HC&treat-17062025.txt\n",
            "Successfully parsed 306 records from wos_queries\\D-WoS-lar&med&diag-17062025.txt\n",
            "Successfully parsed 70 records from wos_queries\\D-WoS-lar&med&DS-17062025.txt\n",
            "Successfully parsed 32 records from wos_queries\\D-WoS-lar&med&hall-17062025.txt\n",
            "Successfully parsed 114 records from wos_queries\\D-WoS-lar&med&img-17062025.txt\n",
            "Successfully parsed 87 records from wos_queries\\D-WoS-lar&med&PC-17062025.txt\n",
            "Successfully parsed 2 records from wos_queries\\D-WoS-lar&med&PM-17062025.txt\n",
            "Successfully parsed 42 records from wos_queries\\D-WoS-lar&med&QA-17062025.txt\n",
            "Successfully parsed 192 records from wos_queries\\D-WoS-lar&med&treat-17062025.txt\n",
            "Successfully parsed 75 records from wos_queries\\D-WoS-LLM&cancer&diag-17062025.txt\n",
            "Successfully parsed 20 records from wos_queries\\D-WoS-LLM&cancer&DS-17062025.txt\n",
            "Successfully parsed 7 records from wos_queries\\D-WoS-LLM&cancer&hall-17062025.txt\n",
            "Successfully parsed 50 records from wos_queries\\D-WoS-LLM&cancer&img-17062025.txt\n",
            "Successfully parsed 21 records from wos_queries\\D-WoS-LLM&cancer&PC-17062025.txt\n",
            "Successfully parsed 1 records from wos_queries\\D-WoS-LLM&cancer&PM-17062025.txt\n",
            "Successfully parsed 10 records from wos_queries\\D-WoS-LLM&cancer&QA-17062025.txt\n",
            "Successfully parsed 100 records from wos_queries\\D-WoS-LLM&cancer&treat-17062025.txt\n",
            "Successfully parsed 118 records from wos_queries\\D-WoS-LLM&HC&diag-17062025.txt\n",
            "Successfully parsed 59 records from wos_queries\\D-WoS-LLM&HC&DS-17062025.txt\n",
            "Successfully parsed 19 records from wos_queries\\D-WoS-LLM&HC&hall-17062025.txt\n",
            "Successfully parsed 45 records from wos_queries\\D-WoS-LLM&HC&img-17062025.txt\n",
            "Successfully parsed 81 records from wos_queries\\D-WoS-LLM&HC&PC-17062025.txt\n",
            "Successfully parsed 5 records from wos_queries\\D-WoS-LLM&HC&PM-17062025.txt\n",
            "Successfully parsed 38 records from wos_queries\\D-WoS-LLM&HC&QA-17062025.txt\n",
            "Successfully parsed 84 records from wos_queries\\D-WoS-LLM&HC&treat-17062025.txt\n",
            "Successfully parsed 203 records from wos_queries\\D-WoS-LLM&med&diag-17062025.txt\n",
            "Successfully parsed 63 records from wos_queries\\D-WoS-LLM&med&DS-17062025.txt\n",
            "Successfully parsed 26 records from wos_queries\\D-WoS-LLM&med&hall-17062025.txt\n",
            "Successfully parsed 79 records from wos_queries\\D-WoS-LLM&med&img-17062025.txt\n",
            "Successfully parsed 66 records from wos_queries\\D-WoS-LLM&med&PC-17062025.txt\n",
            "Successfully parsed 3 records from wos_queries\\D-WoS-LLM&med&PM-17062025.txt\n",
            "Successfully parsed 35 records from wos_queries\\D-WoS-LLM&med&QA-17062025.txt\n",
            "Successfully parsed 155 records from wos_queries\\D-WoS-LLM&med&treat-17062025.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wos_path = 'wos_queries'\n",
        "wos_file_list = []\n",
        "for file_name in os.listdir(wos_path):\n",
        "\n",
        "              #  try:\n",
        "                    df_temp= parse_wos_file(os.path.join(wos_path, file_name))\n",
        "                    df_temp['query'] = query_mapping.get(file_name, None)\n",
        "                    if df_temp is not None and not df_temp.empty:\n",
        "                        wos_file_list.append(df_temp)\n",
        "               # except Exception as e:\n",
        "               #     print(f\"Error procesando el fichero {os.path.join(wos_path, file_pth)}: {e}\")\n",
        "        \n",
        "    \n",
        "df_wos= pd.concat( wos_file_list, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Publication Type</th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>Source Title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Article Number</th>\n",
              "      <th>Document Type</th>\n",
              "      <th>Publication Date</th>\n",
              "      <th>Publication Year</th>\n",
              "      <th>...</th>\n",
              "      <th>Conference Location</th>\n",
              "      <th>Conference Sponsor</th>\n",
              "      <th>Supplement</th>\n",
              "      <th>Book Group Authors</th>\n",
              "      <th>Author Keywords</th>\n",
              "      <th>query</th>\n",
              "      <th>Group Authors</th>\n",
              "      <th>Special Issue</th>\n",
              "      <th>Part Number</th>\n",
              "      <th>Editors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>J</td>\n",
              "      <td>Trager, Megan H. Gordon, Emily R. Breneman, Al...</td>\n",
              "      <td>Accuracy of ChatGPT in diagnosis and managemen...</td>\n",
              "      <td>ARCHIVES OF DERMATOLOGICAL RESEARCH</td>\n",
              "      <td>317</td>\n",
              "      <td>1</td>\n",
              "      <td>184 DI 10.1007/s00403-024-03729-z</td>\n",
              "      <td>Letter</td>\n",
              "      <td>JAN 7 2025</td>\n",
              "      <td>2025 ZA 0 ZR 0 Z8 0 ZB 0 ZS 0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"diagn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>J</td>\n",
              "      <td>Yuan, Yue Zhang, Guolong Gu, Yuqi Hao, Sicheng...</td>\n",
              "      <td>Artificial intelligence-assisted machine learn...</td>\n",
              "      <td>ASIA-PACIFIC JOURNAL OF ONCOLOGY NURSING</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100680 DI 10.1016/j.apjon.2025.100680 EA MAR 2025</td>\n",
              "      <td>Article</td>\n",
              "      <td>DEC 2025</td>\n",
              "      <td>2025</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"diagn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>Marques, Adriell Gomes Candido de Figueiredo, ...</td>\n",
              "      <td>New approach Generative AI Melanoma Data Fusio...</td>\n",
              "      <td>2024 37TH SIBGRAPI CONFERENCE ON GRAPHICS, PAT...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Proceedings Paper</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024</td>\n",
              "      <td>...</td>\n",
              "      <td>Manaus, BRAZIL</td>\n",
              "      <td>SIBGRAPI; Univ Estado Amazonas, Escola Super T...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"diagn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>J</td>\n",
              "      <td>Liu, Jilei Shen, Hongru Chen, Kexin Li, Xiangchun</td>\n",
              "      <td>Large language model produces high accurate di...</td>\n",
              "      <td>BRIEFINGS IN BIOINFORMATICS</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>bbae430 DI 10.1093/bib/bbae430</td>\n",
              "      <td>Article</td>\n",
              "      <td>SEP 2 2024</td>\n",
              "      <td>2024</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"diagn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J</td>\n",
              "      <td>Orlhac, Fanny Bradshaw, Tyler Buvat, Irene</td>\n",
              "      <td>Can a large language model be an effective ass...</td>\n",
              "      <td>JOURNAL OF NUCLEAR MEDICINE</td>\n",
              "      <td>65 MA 241031</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Meeting Abstract</td>\n",
              "      <td>JUN 1 2024</td>\n",
              "      <td>2024</td>\n",
              "      <td>...</td>\n",
              "      <td>Toronto, CANADA</td>\n",
              "      <td>Soc Nuclear Med &amp; Mol Imaging Z8 0 ZB 0 ZA 0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"diagn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Publication Type                                            authors  \\\n",
              "0                J  Trager, Megan H. Gordon, Emily R. Breneman, Al...   \n",
              "1                J  Yuan, Yue Zhang, Guolong Gu, Yuqi Hao, Sicheng...   \n",
              "2                C  Marques, Adriell Gomes Candido de Figueiredo, ...   \n",
              "3                J  Liu, Jilei Shen, Hongru Chen, Kexin Li, Xiangchun   \n",
              "4                J         Orlhac, Fanny Bradshaw, Tyler Buvat, Irene   \n",
              "\n",
              "                                               title  \\\n",
              "0  Accuracy of ChatGPT in diagnosis and managemen...   \n",
              "1  Artificial intelligence-assisted machine learn...   \n",
              "2  New approach Generative AI Melanoma Data Fusio...   \n",
              "3  Large language model produces high accurate di...   \n",
              "4  Can a large language model be an effective ass...   \n",
              "\n",
              "                                        Source Title        Volume Issue  \\\n",
              "0                ARCHIVES OF DERMATOLOGICAL RESEARCH           317     1   \n",
              "1           ASIA-PACIFIC JOURNAL OF ONCOLOGY NURSING            12   NaN   \n",
              "2  2024 37TH SIBGRAPI CONFERENCE ON GRAPHICS, PAT...           NaN   NaN   \n",
              "3                        BRIEFINGS IN BIOINFORMATICS            25     5   \n",
              "4                        JOURNAL OF NUCLEAR MEDICINE  65 MA 241031   NaN   \n",
              "\n",
              "                                      Article Number      Document Type  \\\n",
              "0                  184 DI 10.1007/s00403-024-03729-z             Letter   \n",
              "1  100680 DI 10.1016/j.apjon.2025.100680 EA MAR 2025            Article   \n",
              "2                                                NaN  Proceedings Paper   \n",
              "3                     bbae430 DI 10.1093/bib/bbae430            Article   \n",
              "4                                                NaN   Meeting Abstract   \n",
              "\n",
              "  Publication Date               Publication Year  ... Conference Location  \\\n",
              "0       JAN 7 2025  2025 ZA 0 ZR 0 Z8 0 ZB 0 ZS 0  ...                 NaN   \n",
              "1         DEC 2025                           2025  ...                 NaN   \n",
              "2             2024                           2024  ...      Manaus, BRAZIL   \n",
              "3       SEP 2 2024                           2024  ...                 NaN   \n",
              "4       JUN 1 2024                           2024  ...     Toronto, CANADA   \n",
              "\n",
              "                                  Conference Sponsor Supplement  \\\n",
              "0                                                NaN        NaN   \n",
              "1                                                NaN        NaN   \n",
              "2  SIBGRAPI; Univ Estado Amazonas, Escola Super T...        NaN   \n",
              "3                                                NaN        NaN   \n",
              "4       Soc Nuclear Med & Mol Imaging Z8 0 ZB 0 ZA 0          2   \n",
              "\n",
              "  Book Group Authors Author Keywords  \\\n",
              "0                NaN             NaN   \n",
              "1                NaN             NaN   \n",
              "2                NaN             NaN   \n",
              "3                NaN             NaN   \n",
              "4                NaN             NaN   \n",
              "\n",
              "                                               query Group Authors  \\\n",
              "0  \"large language model\" AND \"cancer\" AND \"diagn...           NaN   \n",
              "1  \"large language model\" AND \"cancer\" AND \"diagn...           NaN   \n",
              "2  \"large language model\" AND \"cancer\" AND \"diagn...           NaN   \n",
              "3  \"large language model\" AND \"cancer\" AND \"diagn...           NaN   \n",
              "4  \"large language model\" AND \"cancer\" AND \"diagn...           NaN   \n",
              "\n",
              "  Special Issue Part Number Editors  \n",
              "0           NaN         NaN     NaN  \n",
              "1           NaN         NaN     NaN  \n",
              "2           NaN         NaN     NaN  \n",
              "3           NaN         NaN     NaN  \n",
              "4           NaN         NaN     NaN  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_wos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Publication Type', 'authors', 'title', 'Source Title', 'Volume',\n",
              "       'Issue', 'Article Number', 'Document Type', 'Publication Date',\n",
              "       'Publication Year', 'Times Cited', 'Total Times Cited',\n",
              "       'Date Processed', 'Accession Number', 'summary', 'Series Title',\n",
              "       'Beginning Page', 'Ending Page', 'Conference Title', 'Conference Date',\n",
              "       'Conference Location', 'Conference Sponsor', 'Supplement',\n",
              "       'Book Group Authors', 'Author Keywords', 'Group Authors',\n",
              "       'Special Issue', 'Part Number', 'Editors'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_wos.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Publication Type</th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>Source Title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Article Number</th>\n",
              "      <th>Document Type</th>\n",
              "      <th>Publication Date</th>\n",
              "      <th>...</th>\n",
              "      <th>Conference Date</th>\n",
              "      <th>Conference Location</th>\n",
              "      <th>Conference Sponsor</th>\n",
              "      <th>Supplement</th>\n",
              "      <th>Book Group Authors</th>\n",
              "      <th>Author Keywords</th>\n",
              "      <th>Group Authors</th>\n",
              "      <th>Special Issue</th>\n",
              "      <th>Part Number</th>\n",
              "      <th>Editors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>J</td>\n",
              "      <td>Trager, Megan H. Gordon, Emily R. Breneman, Al...</td>\n",
              "      <td>Accuracy of ChatGPT in diagnosis and managemen...</td>\n",
              "      <td>ARCHIVES OF DERMATOLOGICAL RESEARCH</td>\n",
              "      <td>317</td>\n",
              "      <td>1</td>\n",
              "      <td>184 DI 10.1007/s00403-024-03729-z</td>\n",
              "      <td>Letter</td>\n",
              "      <td>JAN 7 2025</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>J</td>\n",
              "      <td>Yuan, Yue Zhang, Guolong Gu, Yuqi Hao, Sicheng...</td>\n",
              "      <td>Artificial intelligence-assisted machine learn...</td>\n",
              "      <td>ASIA-PACIFIC JOURNAL OF ONCOLOGY NURSING</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100680 DI 10.1016/j.apjon.2025.100680 EA MAR 2025</td>\n",
              "      <td>Article</td>\n",
              "      <td>DEC 2025</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>C</td>\n",
              "      <td>Marques, Adriell Gomes Candido de Figueiredo, ...</td>\n",
              "      <td>New approach Generative AI Melanoma Data Fusio...</td>\n",
              "      <td>2024 37TH SIBGRAPI CONFERENCE ON GRAPHICS, PAT...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Proceedings Paper</td>\n",
              "      <td>2024</td>\n",
              "      <td>...</td>\n",
              "      <td>SEP 30-OCT 03, 2024</td>\n",
              "      <td>Manaus, BRAZIL</td>\n",
              "      <td>SIBGRAPI; Univ Estado Amazonas, Escola Super T...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>J</td>\n",
              "      <td>Liu, Jilei Shen, Hongru Chen, Kexin Li, Xiangchun</td>\n",
              "      <td>Large language model produces high accurate di...</td>\n",
              "      <td>BRIEFINGS IN BIOINFORMATICS</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>bbae430 DI 10.1093/bib/bbae430</td>\n",
              "      <td>Article</td>\n",
              "      <td>SEP 2 2024</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>J</td>\n",
              "      <td>Orlhac, Fanny Bradshaw, Tyler Buvat, Irene</td>\n",
              "      <td>Can a large language model be an effective ass...</td>\n",
              "      <td>JOURNAL OF NUCLEAR MEDICINE</td>\n",
              "      <td>65 MA 241031</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Meeting Abstract</td>\n",
              "      <td>JUN 1 2024</td>\n",
              "      <td>...</td>\n",
              "      <td>JUN 08-11, 2024</td>\n",
              "      <td>Toronto, CANADA</td>\n",
              "      <td>Soc Nuclear Med &amp; Mol Imaging Z8 0 ZB 0 ZA 0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Publication Type  \\\n",
              "0           0                J   \n",
              "1           1                J   \n",
              "2           2                C   \n",
              "3           3                J   \n",
              "4           4                J   \n",
              "\n",
              "                                             authors  \\\n",
              "0  Trager, Megan H. Gordon, Emily R. Breneman, Al...   \n",
              "1  Yuan, Yue Zhang, Guolong Gu, Yuqi Hao, Sicheng...   \n",
              "2  Marques, Adriell Gomes Candido de Figueiredo, ...   \n",
              "3  Liu, Jilei Shen, Hongru Chen, Kexin Li, Xiangchun   \n",
              "4         Orlhac, Fanny Bradshaw, Tyler Buvat, Irene   \n",
              "\n",
              "                                               title  \\\n",
              "0  Accuracy of ChatGPT in diagnosis and managemen...   \n",
              "1  Artificial intelligence-assisted machine learn...   \n",
              "2  New approach Generative AI Melanoma Data Fusio...   \n",
              "3  Large language model produces high accurate di...   \n",
              "4  Can a large language model be an effective ass...   \n",
              "\n",
              "                                        Source Title        Volume Issue  \\\n",
              "0                ARCHIVES OF DERMATOLOGICAL RESEARCH           317     1   \n",
              "1           ASIA-PACIFIC JOURNAL OF ONCOLOGY NURSING            12   NaN   \n",
              "2  2024 37TH SIBGRAPI CONFERENCE ON GRAPHICS, PAT...           NaN   NaN   \n",
              "3                        BRIEFINGS IN BIOINFORMATICS            25     5   \n",
              "4                        JOURNAL OF NUCLEAR MEDICINE  65 MA 241031   NaN   \n",
              "\n",
              "                                      Article Number      Document Type  \\\n",
              "0                  184 DI 10.1007/s00403-024-03729-z             Letter   \n",
              "1  100680 DI 10.1016/j.apjon.2025.100680 EA MAR 2025            Article   \n",
              "2                                                NaN  Proceedings Paper   \n",
              "3                     bbae430 DI 10.1093/bib/bbae430            Article   \n",
              "4                                                NaN   Meeting Abstract   \n",
              "\n",
              "  Publication Date  ...      Conference Date Conference Location  \\\n",
              "0       JAN 7 2025  ...                  NaN                 NaN   \n",
              "1         DEC 2025  ...                  NaN                 NaN   \n",
              "2             2024  ...  SEP 30-OCT 03, 2024      Manaus, BRAZIL   \n",
              "3       SEP 2 2024  ...                  NaN                 NaN   \n",
              "4       JUN 1 2024  ...      JUN 08-11, 2024     Toronto, CANADA   \n",
              "\n",
              "                                  Conference Sponsor Supplement  \\\n",
              "0                                                NaN        NaN   \n",
              "1                                                NaN        NaN   \n",
              "2  SIBGRAPI; Univ Estado Amazonas, Escola Super T...        NaN   \n",
              "3                                                NaN        NaN   \n",
              "4       Soc Nuclear Med & Mol Imaging Z8 0 ZB 0 ZA 0          2   \n",
              "\n",
              "  Book Group Authors Author Keywords Group Authors Special Issue Part Number  \\\n",
              "0                NaN             NaN           NaN           NaN         NaN   \n",
              "1                NaN             NaN           NaN           NaN         NaN   \n",
              "2                NaN             NaN           NaN           NaN         NaN   \n",
              "3                NaN             NaN           NaN           NaN         NaN   \n",
              "4                NaN             NaN           NaN           NaN         NaN   \n",
              "\n",
              "  Editors  \n",
              "0     NaN  \n",
              "1     NaN  \n",
              "2     NaN  \n",
              "3     NaN  \n",
              "4     NaN  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_wos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = 'queries_wos_v2_1.xlsx'\n",
        "df_wos.to_excel(os.path.join(data_folder, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Concatenate & deduplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load queries from Excel files\n",
        "import os\n",
        "filename = 'queries_arxiv_v2_1.xlsx'\n",
        "df_arxiv = pd.read_excel(os.path.join(data_folder, filename))\n",
        "filename = 'queries_pubmed_v2_1.xlsx'\n",
        "df_pubmed = pd.read_excel(os.path.join(data_folder, filename))\n",
        "filename = 'queries_wos_v2_1.xlsx'\n",
        "df_wos = pd.read_excel(os.path.join(data_folder, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6753, 47)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_combined = pd.concat([df_pubmed, df_arxiv,df_wos], ignore_index=True)\n",
        "df_combined['short_title'] = df_combined['title']#.str[:50]\n",
        "df_combined=df_combined.drop_duplicates(subset=['query','title'], keep='first')\n",
        "df_combined.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Due to diferent sources, we are deduplicating pandas from common title field name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>count_arxiv</th>\n",
              "      <th>count_pubmed</th>\n",
              "      <th>count_wos</th>\n",
              "      <th>count_unique</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"q...</td>\n",
              "      <td>119.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"question answering\"</td>\n",
              "      <td>110.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"h...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"i...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"d...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"hallucination\"</td>\n",
              "      <td>81.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"diagnosis\"</td>\n",
              "      <td>73.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"t...</td>\n",
              "      <td>67.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"treatment\"</td>\n",
              "      <td>60.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"question answering\"</td>\n",
              "      <td>56.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"que...</td>\n",
              "      <td>55.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"imaging\"</td>\n",
              "      <td>54.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"d...</td>\n",
              "      <td>51.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"p...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"patient care\"</td>\n",
              "      <td>43.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"decision support\"</td>\n",
              "      <td>42.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"hal...</td>\n",
              "      <td>38.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"dia...</td>\n",
              "      <td>37.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"treatment\"</td>\n",
              "      <td>36.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"treat...</td>\n",
              "      <td>36.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"diagnosis\"</td>\n",
              "      <td>36.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"hallucination\"</td>\n",
              "      <td>35.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"tre...</td>\n",
              "      <td>31.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"treatment\"</td>\n",
              "      <td>28.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"imaging\"</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"ima...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"dec...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"decision support\"</td>\n",
              "      <td>19.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"diagn...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"imaging\"</td>\n",
              "      <td>17.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"diagnosis\"</td>\n",
              "      <td>14.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"imaging\"</td>\n",
              "      <td>14.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"pat...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"hallucination\"</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"hallu...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"patient care\"</td>\n",
              "      <td>9.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"patie...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"patient care\"</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"quest...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"question answering\"</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"decis...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"decision support\"</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>\"LLM\" AND \"healthcare\" AND \"patient monitoring\"</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>\"LLM\" AND \"medicine\" AND \"patient monitoring\"</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"pat...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>\"LLM\" AND \"cancer\" AND \"patient monitoring\"</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"patie...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>\"large language model\" AND \"healthcare\" AND \"p...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>LLM\" AND \"medicine\" AND \"treatment\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>155.0</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>\"large language model\" AND \"cancer\" AND \"treat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>109.0</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>LLM\" AND \"medicine\" AND \"imaging\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>LLM\" AND \"medicine\" AND \"patient care\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>66.0</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>LLM\" AND \"medicine\" AND \"decision support\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63.0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>LLM\" AND \"healthcare\" AND \"imaging\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>LLM\" AND \"medicine\" AND \"question answering\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>LLM\" AND \"medicine\" AND \"hallucination\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>LLM\" AND \"medicine\" AND \"patient monitoring\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                query  count_arxiv  \\\n",
              "0   \"large language model\" AND \"healthcare\" AND \"q...        119.0   \n",
              "1     \"LLM\" AND \"healthcare\" AND \"question answering\"        110.0   \n",
              "2   \"large language model\" AND \"healthcare\" AND \"h...         84.0   \n",
              "3   \"large language model\" AND \"healthcare\" AND \"i...         84.0   \n",
              "4   \"large language model\" AND \"healthcare\" AND \"d...         84.0   \n",
              "5          \"LLM\" AND \"healthcare\" AND \"hallucination\"         81.0   \n",
              "6              \"LLM\" AND \"healthcare\" AND \"diagnosis\"         73.0   \n",
              "7   \"large language model\" AND \"healthcare\" AND \"t...         67.0   \n",
              "8              \"LLM\" AND \"healthcare\" AND \"treatment\"         60.0   \n",
              "9       \"LLM\" AND \"medicine\" AND \"question answering\"         56.0   \n",
              "10  \"large language model\" AND \"medicine\" AND \"que...         55.0   \n",
              "11               \"LLM\" AND \"healthcare\" AND \"imaging\"         54.0   \n",
              "12  \"large language model\" AND \"healthcare\" AND \"d...         51.0   \n",
              "13  \"large language model\" AND \"healthcare\" AND \"p...         50.0   \n",
              "14          \"LLM\" AND \"healthcare\" AND \"patient care\"         43.0   \n",
              "15      \"LLM\" AND \"healthcare\" AND \"decision support\"         42.0   \n",
              "16  \"large language model\" AND \"medicine\" AND \"hal...         38.0   \n",
              "17  \"large language model\" AND \"medicine\" AND \"dia...         37.0   \n",
              "18                 \"LLM\" AND \"cancer\" AND \"treatment\"         36.0   \n",
              "19  \"large language model\" AND \"cancer\" AND \"treat...         36.0   \n",
              "20               \"LLM\" AND \"medicine\" AND \"diagnosis\"         36.0   \n",
              "21           \"LLM\" AND \"medicine\" AND \"hallucination\"         35.0   \n",
              "22  \"large language model\" AND \"medicine\" AND \"tre...         31.0   \n",
              "23               \"LLM\" AND \"medicine\" AND \"treatment\"         28.0   \n",
              "24  \"large language model\" AND \"cancer\" AND \"imaging\"         25.0   \n",
              "25  \"large language model\" AND \"medicine\" AND \"ima...         25.0   \n",
              "26  \"large language model\" AND \"medicine\" AND \"dec...         21.0   \n",
              "27        \"LLM\" AND \"medicine\" AND \"decision support\"         19.0   \n",
              "28  \"large language model\" AND \"cancer\" AND \"diagn...         18.0   \n",
              "29                 \"LLM\" AND \"medicine\" AND \"imaging\"         17.0   \n",
              "30                 \"LLM\" AND \"cancer\" AND \"diagnosis\"         14.0   \n",
              "31                   \"LLM\" AND \"cancer\" AND \"imaging\"         14.0   \n",
              "32  \"large language model\" AND \"medicine\" AND \"pat...         10.0   \n",
              "33             \"LLM\" AND \"cancer\" AND \"hallucination\"         10.0   \n",
              "34  \"large language model\" AND \"cancer\" AND \"hallu...         10.0   \n",
              "35            \"LLM\" AND \"medicine\" AND \"patient care\"          9.0   \n",
              "36  \"large language model\" AND \"cancer\" AND \"patie...          7.0   \n",
              "37              \"LLM\" AND \"cancer\" AND \"patient care\"          6.0   \n",
              "38  \"large language model\" AND \"cancer\" AND \"quest...          4.0   \n",
              "39        \"LLM\" AND \"cancer\" AND \"question answering\"          4.0   \n",
              "40  \"large language model\" AND \"cancer\" AND \"decis...          2.0   \n",
              "41          \"LLM\" AND \"cancer\" AND \"decision support\"          2.0   \n",
              "42    \"LLM\" AND \"healthcare\" AND \"patient monitoring\"          1.0   \n",
              "43      \"LLM\" AND \"medicine\" AND \"patient monitoring\"          1.0   \n",
              "44  \"large language model\" AND \"medicine\" AND \"pat...          1.0   \n",
              "45        \"LLM\" AND \"cancer\" AND \"patient monitoring\"          1.0   \n",
              "46  \"large language model\" AND \"cancer\" AND \"patie...          1.0   \n",
              "47  \"large language model\" AND \"healthcare\" AND \"p...          1.0   \n",
              "48                LLM\" AND \"medicine\" AND \"treatment\"          NaN   \n",
              "49  \"large language model\" AND \"cancer\" AND \"treat...          NaN   \n",
              "50                  LLM\" AND \"medicine\" AND \"imaging\"          NaN   \n",
              "51             LLM\" AND \"medicine\" AND \"patient care\"          NaN   \n",
              "52         LLM\" AND \"medicine\" AND \"decision support\"          NaN   \n",
              "53                LLM\" AND \"healthcare\" AND \"imaging\"          NaN   \n",
              "54       LLM\" AND \"medicine\" AND \"question answering\"          NaN   \n",
              "55            LLM\" AND \"medicine\" AND \"hallucination\"          NaN   \n",
              "56       LLM\" AND \"medicine\" AND \"patient monitoring\"          NaN   \n",
              "\n",
              "    count_pubmed  count_wos  count_unique  \n",
              "0            9.0       28.0           154  \n",
              "1           17.0       38.0           160  \n",
              "2            5.0       12.0           100  \n",
              "3           43.0       44.0           166  \n",
              "4           74.0      110.0           262  \n",
              "5            9.0       19.0           107  \n",
              "6           70.0      118.0           249  \n",
              "7           57.0       94.0           213  \n",
              "8           52.0       84.0           191  \n",
              "9           33.0        NaN            89  \n",
              "10          23.0       42.0           120  \n",
              "11          52.0        NaN           106  \n",
              "12          25.0       38.0           113  \n",
              "13          37.0       62.0           145  \n",
              "14          44.0       81.0           160  \n",
              "15          45.0       59.0           139  \n",
              "16          20.0       31.0            87  \n",
              "17         224.0      306.0           559  \n",
              "18          66.0      100.0           193  \n",
              "19          57.0        NaN            93  \n",
              "20         223.0      203.0           453  \n",
              "21          23.0        NaN            58  \n",
              "22         142.0      191.0           354  \n",
              "23         159.0        NaN           187  \n",
              "24          46.0       71.0           136  \n",
              "25         124.0      114.0           262  \n",
              "26          65.0       69.0           152  \n",
              "27          93.0        NaN           112  \n",
              "28          54.0       99.0           167  \n",
              "29         149.0        NaN           166  \n",
              "30          46.0       75.0           130  \n",
              "31          42.0       50.0           102  \n",
              "32          53.0       87.0           145  \n",
              "33           8.0        7.0            23  \n",
              "34           6.0        9.0            23  \n",
              "35          75.0        NaN            84  \n",
              "36          10.0       32.0            49  \n",
              "37           8.0       21.0            34  \n",
              "38           7.0        9.0            19  \n",
              "39          11.0       10.0            22  \n",
              "40          12.0       18.0            31  \n",
              "41          19.0       20.0            39  \n",
              "42           NaN        5.0             6  \n",
              "43           1.0        NaN             2  \n",
              "44           1.0        2.0             4  \n",
              "45           NaN        1.0             2  \n",
              "46           NaN        1.0             2  \n",
              "47           1.0        NaN             2  \n",
              "48           NaN      155.0           155  \n",
              "49           NaN      109.0           109  \n",
              "50           NaN       79.0            79  \n",
              "51           NaN       66.0            66  \n",
              "52           NaN       63.0            63  \n",
              "53           NaN       45.0            45  \n",
              "54           NaN       35.0            35  \n",
              "55           NaN       26.0            26  \n",
              "56           NaN        3.0             3  "
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pubmed=df_pubmed.drop_duplicates(subset=['title','query'], keep='first')\n",
        "df_pubmed_query_values= df_pubmed['query'].value_counts().reset_index().astype({'count': int})\n",
        "df_arxiv=df_arxiv.drop_duplicates(subset=['title','query'], keep='first')\n",
        "df_arxiv_query_values= df_arxiv['query'].value_counts().reset_index().astype({'count': int})\n",
        "df_wos=df_wos.drop_duplicates(subset=['title','query'], keep='first')\n",
        "df_wos_query_values= df_wos['query'].value_counts().reset_index().astype({'count': int})\n",
        "df_combined_query_values= df_combined['query'].value_counts().reset_index().astype({'count': int}).fillna(0)\n",
        "df_merged_query_values = df_arxiv_query_values.merge(df_pubmed_query_values, on='query', how='outer', suffixes=('_arxiv', '_pubmed'))\n",
        "df_merged_query_values = df_merged_query_values.merge(df_wos_query_values,on='query', how='outer', suffixes=( '_ss','_wos'))\n",
        "df_merged_query_values = df_merged_query_values.merge(df_combined_query_values,on='query', how='outer', suffixes=( '_wos','_unique'))\n",
        "df_merged_query_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#etls\n",
        "df_merged_query = df_merged_query_values.copy() \n",
        "for columna in df_merged_query.columns:\n",
        "\n",
        "    if df_merged_query[columna].dtype == 'object':\n",
        "        df_merged_query[columna] = pd.to_numeric(df_merged_query[columna], errors='coerce')\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(df_merged_query[columna]):\n",
        "        df_merged_query[columna] = df_merged_query[columna].fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\\\begin{tabular}{|c|c|c|c|}{rrrr}\\n\\\\hline\\\\hline\\n\\\\textbf{query} & \\\\textbf{count_arxiv} & \\\\textbf{count_pubmed} & \\\\textbf{count} \\\\\\\\\\n\\\\hline\\\\hline\\n0 & 119 & 9 & 128 \\\\\\\\\\n0 & 110 & 17 & 127 \\\\\\\\\\n0 & 84 & 5 & 89 \\\\\\\\\\n0 & 84 & 43 & 127 \\\\\\\\\\n0 & 84 & 74 & 158 \\\\\\\\\\n0 & 81 & 9 & 90 \\\\\\\\\\n0 & 73 & 70 & 143 \\\\\\\\\\n0 & 67 & 57 & 124 \\\\\\\\\\n0 & 60 & 52 & 112 \\\\\\\\\\n0 & 56 & 33 & 89 \\\\\\\\\\n0 & 55 & 23 & 78 \\\\\\\\\\n0 & 54 & 52 & 106 \\\\\\\\\\n0 & 51 & 25 & 76 \\\\\\\\\\n0 & 50 & 37 & 87 \\\\\\\\\\n0 & 43 & 44 & 87 \\\\\\\\\\n0 & 42 & 45 & 87 \\\\\\\\\\n0 & 38 & 20 & 58 \\\\\\\\\\n0 & 37 & 225 & 262 \\\\\\\\\\n0 & 36 & 66 & 102 \\\\\\\\\\n0 & 36 & 57 & 93 \\\\\\\\\\n0 & 36 & 223 & 259 \\\\\\\\\\n0 & 35 & 23 & 58 \\\\\\\\\\n0 & 31 & 143 & 174 \\\\\\\\\\n0 & 28 & 159 & 187 \\\\\\\\\\n0 & 25 & 46 & 71 \\\\\\\\\\n0 & 25 & 124 & 149 \\\\\\\\\\n0 & 21 & 65 & 86 \\\\\\\\\\n0 & 19 & 93 & 112 \\\\\\\\\\n0 & 18 & 54 & 72 \\\\\\\\\\n0 & 17 & 149 & 166 \\\\\\\\\\n0 & 14 & 46 & 60 \\\\\\\\\\n0 & 14 & 42 & 56 \\\\\\\\\\n0 & 10 & 53 & 63 \\\\\\\\\\n0 & 10 & 8 & 18 \\\\\\\\\\n0 & 10 & 6 & 16 \\\\\\\\\\n0 & 9 & 75 & 84 \\\\\\\\\\n0 & 7 & 10 & 17 \\\\\\\\\\n0 & 6 & 8 & 14 \\\\\\\\\\n0 & 4 & 7 & 11 \\\\\\\\\\n0 & 4 & 11 & 15 \\\\\\\\\\n0 & 2 & 12 & 14 \\\\\\\\\\n0 & 2 & 19 & 21 \\\\\\\\\\n0 & 1 & 0 & 1 \\\\\\\\\\n0 & 1 & 1 & 2 \\\\\\\\\\n0 & 1 & 1 & 2 \\\\\\\\\\n0 & 1 & 0 & 1 \\\\\\\\\\n0 & 1 & 0 & 1 \\\\\\\\\\n0 & 1 & 1 & 2 \\\\\\\\\\n\\\\hline\\n\\\\hline\\n\\\\end{tabular}\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename_tosave = 'queries_concat_latex.txt'\n",
        "df_to_latex_with_integers( df_merged_query,os.path.join(data_folder, filename_tosave))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined, de-duplicated dataqueries accounts 1502 rows and 24 columns.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "count_arxiv     1613.0\n",
              "count_pubmed    2342.0\n",
              "count           3955.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unique_combined  = df_combined.drop_duplicates(subset=['title'], keep='first')\n",
        "print(f\"Combined, de-duplicated dataqueries accounts {df_unique_combined.shape[0]} rows and {df_unique_combined.shape[1]} columns.\")\n",
        "df_merged_query_values.drop(columns='query').sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1502, 24)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unique_combined.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Extraction and analysis of technical keywords**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\BJUR\\AppData\\Local\\Temp\\ipykernel_26588\\2897555893.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_unique_combined['keywords'] = df_unique_combined.apply(\n"
          ]
        }
      ],
      "source": [
        "df_unique_combined['keywords'] = df_unique_combined.apply(\n",
        "        lambda row: detect_keywords(row, domain_keywords ), axis=1\n",
        "    )\n",
        "\n",
        "filename = 'queries_concat_unique_v2_1.xlsx'\n",
        "df_unique_combined.to_excel(os.path.join(data_folder, filename), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frecuencia de keywords en la columna 'keywords':\n",
            "keywords\n",
            "llm                   1096\n",
            "domain                 563\n",
            "diag                   327\n",
            "rag                    270\n",
            "eval                   265\n",
            "cllm                   262\n",
            "qa                     212\n",
            "decision support       207\n",
            "image                  185\n",
            "cancer                 184\n",
            "treatment              155\n",
            "neg                    132\n",
            "rev                    130\n",
            "mm                     118\n",
            "hallucination          115\n",
            "graph                  104\n",
            "nlp                     89\n",
            "osllm                   80\n",
            "finetune                77\n",
            "patient care            63\n",
            "chatbot                 57\n",
            "sur                     55\n",
            "ner                     54\n",
            "KG                      49\n",
            "agents                  41\n",
            "vlms                    17\n",
            "speech                  10\n",
            "agentic                  7\n",
            "conversational AI        5\n",
            "patient monitoring       3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Número total de keywords únicas: 30\n"
          ]
        }
      ],
      "source": [
        "nombre_columna_keywords = 'keywords' \n",
        "keywords_series = df_unique_combined[nombre_columna_keywords].astype(str).str.split(',')\n",
        "todas_las_keywords = keywords_series.explode()\n",
        "keywords_limpias = todas_las_keywords.str.strip().dropna()\n",
        "keywords_finales = keywords_limpias[keywords_limpias != '']\n",
        "frecuencia_keywords = keywords_finales.value_counts()\n",
        "print(f\"Frecuencia de keywords en la columna '{nombre_columna_keywords}':\")\n",
        "print(frecuencia_keywords)\n",
        "print(f\"\\nNúmero total de keywords únicas: {frecuencia_keywords.size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>KG</th>\n",
              "      <th>agentic</th>\n",
              "      <th>agents</th>\n",
              "      <th>cancer</th>\n",
              "      <th>chatbot</th>\n",
              "      <th>cllm</th>\n",
              "      <th>conversational AI</th>\n",
              "      <th>decision support</th>\n",
              "      <th>diag</th>\n",
              "      <th>domain</th>\n",
              "      <th>eval</th>\n",
              "      <th>finetune</th>\n",
              "      <th>graph</th>\n",
              "      <th>hallucination</th>\n",
              "      <th>image</th>\n",
              "      <th>llm</th>\n",
              "      <th>mm</th>\n",
              "      <th>neg</th>\n",
              "      <th>ner</th>\n",
              "      <th>nlp</th>\n",
              "      <th>osllm</th>\n",
              "      <th>patient care</th>\n",
              "      <th>patient monitoring</th>\n",
              "      <th>qa</th>\n",
              "      <th>rag</th>\n",
              "      <th>rev</th>\n",
              "      <th>speech</th>\n",
              "      <th>sur</th>\n",
              "      <th>treatment</th>\n",
              "      <th>vlms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KG</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>38</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>agentic</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>agents</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cancer</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>184</td>\n",
              "      <td>10</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>54</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>143</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chatbot</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cllm</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>262</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>65</td>\n",
              "      <td>95</td>\n",
              "      <td>53</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>31</td>\n",
              "      <td>139</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>41</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>conversational AI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>decision support</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>34</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>207</td>\n",
              "      <td>70</td>\n",
              "      <td>125</td>\n",
              "      <td>61</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>194</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>62</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>diag</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>41</td>\n",
              "      <td>8</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>70</td>\n",
              "      <td>327</td>\n",
              "      <td>183</td>\n",
              "      <td>87</td>\n",
              "      <td>22</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>52</td>\n",
              "      <td>272</td>\n",
              "      <td>39</td>\n",
              "      <td>46</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>81</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>75</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>domain</td>\n",
              "      <td>38</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>54</td>\n",
              "      <td>19</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>125</td>\n",
              "      <td>183</td>\n",
              "      <td>563</td>\n",
              "      <td>167</td>\n",
              "      <td>52</td>\n",
              "      <td>68</td>\n",
              "      <td>83</td>\n",
              "      <td>98</td>\n",
              "      <td>506</td>\n",
              "      <td>70</td>\n",
              "      <td>68</td>\n",
              "      <td>31</td>\n",
              "      <td>51</td>\n",
              "      <td>54</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>178</td>\n",
              "      <td>69</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>86</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>eval</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>87</td>\n",
              "      <td>167</td>\n",
              "      <td>265</td>\n",
              "      <td>23</td>\n",
              "      <td>19</td>\n",
              "      <td>38</td>\n",
              "      <td>40</td>\n",
              "      <td>242</td>\n",
              "      <td>29</td>\n",
              "      <td>42</td>\n",
              "      <td>19</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>80</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>finetune</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>23</td>\n",
              "      <td>77</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>76</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>graph</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>35</td>\n",
              "      <td>68</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "      <td>19</td>\n",
              "      <td>96</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>38</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>hallucination</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>21</td>\n",
              "      <td>83</td>\n",
              "      <td>38</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>115</td>\n",
              "      <td>9</td>\n",
              "      <td>114</td>\n",
              "      <td>11</td>\n",
              "      <td>26</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>59</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>image</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>52</td>\n",
              "      <td>98</td>\n",
              "      <td>40</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>185</td>\n",
              "      <td>148</td>\n",
              "      <td>71</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>47</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>llm</td>\n",
              "      <td>47</td>\n",
              "      <td>7</td>\n",
              "      <td>39</td>\n",
              "      <td>143</td>\n",
              "      <td>36</td>\n",
              "      <td>139</td>\n",
              "      <td>5</td>\n",
              "      <td>194</td>\n",
              "      <td>272</td>\n",
              "      <td>506</td>\n",
              "      <td>242</td>\n",
              "      <td>76</td>\n",
              "      <td>96</td>\n",
              "      <td>114</td>\n",
              "      <td>148</td>\n",
              "      <td>1096</td>\n",
              "      <td>106</td>\n",
              "      <td>124</td>\n",
              "      <td>50</td>\n",
              "      <td>81</td>\n",
              "      <td>72</td>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "      <td>205</td>\n",
              "      <td>253</td>\n",
              "      <td>110</td>\n",
              "      <td>10</td>\n",
              "      <td>46</td>\n",
              "      <td>139</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>mm</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>39</td>\n",
              "      <td>70</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>71</td>\n",
              "      <td>106</td>\n",
              "      <td>118</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>neg</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>46</td>\n",
              "      <td>68</td>\n",
              "      <td>42</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>124</td>\n",
              "      <td>21</td>\n",
              "      <td>132</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>39</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ner</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>31</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>nlp</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>51</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>81</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>89</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>osllm</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>54</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>72</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>patient care</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>43</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>patient monitoring</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>qa</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>168</td>\n",
              "      <td>87</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>205</td>\n",
              "      <td>29</td>\n",
              "      <td>35</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>32</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>212</td>\n",
              "      <td>85</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>rag</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>81</td>\n",
              "      <td>178</td>\n",
              "      <td>80</td>\n",
              "      <td>30</td>\n",
              "      <td>38</td>\n",
              "      <td>59</td>\n",
              "      <td>47</td>\n",
              "      <td>253</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>270</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>41</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>rev</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>30</td>\n",
              "      <td>69</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>110</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>130</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>speech</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>sur</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>27</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>46</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>treatment</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>75</td>\n",
              "      <td>86</td>\n",
              "      <td>34</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>139</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>41</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>155</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>vlms</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 index  KG  agentic  agents  cancer  chatbot  cllm  \\\n",
              "0                   KG  49        0       2       3        1     3   \n",
              "1              agentic   0        7       3       1        0     1   \n",
              "2               agents   2        3      41       1        0     1   \n",
              "3               cancer   3        1       1     184       10    29   \n",
              "4              chatbot   1        0       0      10       57     7   \n",
              "5                 cllm   3        1       1      29        7   262   \n",
              "6    conversational AI   0        0       1       0        0     3   \n",
              "7     decision support  10        2      15      34        7    35   \n",
              "8                 diag  19        1      18      41        8    65   \n",
              "9               domain  38        4      25      54       19    95   \n",
              "10                eval   9        2      18      24       11    53   \n",
              "11            finetune   2        0       1      13        2    12   \n",
              "12               graph  48        1       3      12        4    10   \n",
              "13       hallucination  13        1       9      12        6    21   \n",
              "14               image   4        2       6      30        4    31   \n",
              "15                 llm  47        7      39     143       36   139   \n",
              "16                  mm   5        1       8      15        3    12   \n",
              "17                 neg   6        0       8      12        3    15   \n",
              "18                 ner   4        0       0       8        0    12   \n",
              "19                 nlp   4        1       3       9        0    10   \n",
              "20               osllm   8        1       6       8        4    28   \n",
              "21        patient care   0        1       2       7        3    18   \n",
              "22  patient monitoring   0        0       0       1        0     0   \n",
              "23                  qa  16        2       9       8        7    35   \n",
              "24                 rag  23        4      10      31        9    41   \n",
              "25                 rev   3        1       4      14        4    21   \n",
              "26              speech   0        0       1       0        0     0   \n",
              "27                 sur   2        0       1       4        2     9   \n",
              "28           treatment  13        2       6      56        7    19   \n",
              "29                vlms   1        0       0       3        0     2   \n",
              "\n",
              "    conversational AI  decision support  diag  domain  eval  finetune  graph  \\\n",
              "0                   0                10    19      38     9         2     48   \n",
              "1                   0                 2     1       4     2         0      1   \n",
              "2                   1                15    18      25    18         1      3   \n",
              "3                   0                34    41      54    24        13     12   \n",
              "4                   0                 7     8      19    11         2      4   \n",
              "5                   3                35    65      95    53        12     10   \n",
              "6                   5                 1     3       3     1         1      0   \n",
              "7                   1               207    70     125    61        16     25   \n",
              "8                   3                70   327     183    87        22     35   \n",
              "9                   3               125   183     563   167        52     68   \n",
              "10                  1                61    87     167   265        23     19   \n",
              "11                  1                16    22      52    23        77      9   \n",
              "12                  0                25    35      68    19         9    104   \n",
              "13                  1                29    21      83    38        12     22   \n",
              "14                  1                29    52      98    40        16     19   \n",
              "15                  5               194   272     506   242        76     96   \n",
              "16                  1                24    39      70    29         7     14   \n",
              "17                  0                34    46      68    42        12     20   \n",
              "18                  0                 9    16      31    19         6      6   \n",
              "19                  0                12    24      51    23        13     10   \n",
              "20                  0                16    24      54    25        13     11   \n",
              "21                  1                17    21      43    19         7      1   \n",
              "22                  0                 1     0       1     0         0      0   \n",
              "23                  0                32    40     168    87        29     27   \n",
              "24                  1                62    81     178    80        30     38   \n",
              "25                  1                26    30      69    24         2      5   \n",
              "26                  0                 0     3       5     1         1      0   \n",
              "27                  0                12    17      27     9         0      4   \n",
              "28                  0                40    75      86    34        16     24   \n",
              "29                  0                 4     6      14     3         1      2   \n",
              "\n",
              "    hallucination  image   llm   mm  neg  ner  nlp  osllm  patient care  \\\n",
              "0              13      4    47    5    6    4    4      8             0   \n",
              "1               1      2     7    1    0    0    1      1             1   \n",
              "2               9      6    39    8    8    0    3      6             2   \n",
              "3              12     30   143   15   12    8    9      8             7   \n",
              "4               6      4    36    3    3    0    0      4             3   \n",
              "5              21     31   139   12   15   12   10     28            18   \n",
              "6               1      1     5    1    0    0    0      0             1   \n",
              "7              29     29   194   24   34    9   12     16            17   \n",
              "8              21     52   272   39   46   16   24     24            21   \n",
              "9              83     98   506   70   68   31   51     54            43   \n",
              "10             38     40   242   29   42   19   23     25            19   \n",
              "11             12     16    76    7   12    6   13     13             7   \n",
              "12             22     19    96   14   20    6   10     11             1   \n",
              "13            115      9   114   11   26    5   13     14             4   \n",
              "14              9    185   148   71   31    5    8      5             5   \n",
              "15            114    148  1096  106  124   50   81     72            62   \n",
              "16             11     71   106  118   21    3    5      3             3   \n",
              "17             26     31   124   21  132    5   16     12             6   \n",
              "18              5      5    50    3    5   54   12      6             2   \n",
              "19             13      8    81    5   16   12   89      6            11   \n",
              "20             14      5    72    3   12    6    6     80             6   \n",
              "21              4      5    62    3    6    2   11      6            63   \n",
              "22              0      0     3    1    1    0    0      0             0   \n",
              "23             34     33   205   29   35   21   23     32             6   \n",
              "24             59     47   253   30   39   14   29     27            18   \n",
              "25             12     22   110   16   17    7   10      3            10   \n",
              "26              0      1    10    1    0    1    3      1             3   \n",
              "27              3     11    46   10   12    3    8      3             4   \n",
              "28             14      8   139   13   23   12   13     11             9   \n",
              "29              3     16    17    9    7    0    1      0             0   \n",
              "\n",
              "    patient monitoring   qa  rag  rev  speech  sur  treatment  vlms  \n",
              "0                    0   16   23    3       0    2         13     1  \n",
              "1                    0    2    4    1       0    0          2     0  \n",
              "2                    0    9   10    4       1    1          6     0  \n",
              "3                    1    8   31   14       0    4         56     3  \n",
              "4                    0    7    9    4       0    2          7     0  \n",
              "5                    0   35   41   21       0    9         19     2  \n",
              "6                    0    0    1    1       0    0          0     0  \n",
              "7                    1   32   62   26       0   12         40     4  \n",
              "8                    0   40   81   30       3   17         75     6  \n",
              "9                    1  168  178   69       5   27         86    14  \n",
              "10                   0   87   80   24       1    9         34     3  \n",
              "11                   0   29   30    2       1    0         16     1  \n",
              "12                   0   27   38    5       0    4         24     2  \n",
              "13                   0   34   59   12       0    3         14     3  \n",
              "14                   0   33   47   22       1   11          8    16  \n",
              "15                   3  205  253  110      10   46        139    17  \n",
              "16                   1   29   30   16       1   10         13     9  \n",
              "17                   1   35   39   17       0   12         23     7  \n",
              "18                   0   21   14    7       1    3         12     0  \n",
              "19                   0   23   29   10       3    8         13     1  \n",
              "20                   0   32   27    3       1    3         11     0  \n",
              "21                   0    6   18   10       3    4          9     0  \n",
              "22                   3    0    1    0       0    0          1     0  \n",
              "23                   0  212   85   15       2   11         11     5  \n",
              "24                   1   85  270   20       3    6         41     8  \n",
              "25                   0   15   20  130       3   21         12     1  \n",
              "26                   0    2    3    3      10    2          1     0  \n",
              "27                   0   11    6   21       2   55          9     1  \n",
              "28                   1   11   41   12       1    9        155     2  \n",
              "29                   0    5    8    1       0    1          2    17  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "concurrence_kwrds = crear_matriz_coocurrencia_keywords(df_unique_combined, columna_keywords='keywords').reset_index()\n",
        "concurrence_kwrds.to_excel(os.path.join(data_folder, 'concurrence_keywords.xlsx'), index=False)\n",
        "concurrence_kwrds\n",
        "concurrence_kwrds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frecuencia de keywords en la columna 'keywords':\n",
            "keywords\n",
            "llm                   1093\n",
            "domain                 563\n",
            "rag                    270\n",
            "cllm                   262\n",
            "decision support       207\n",
            "diag                   195\n",
            "image                  185\n",
            "qa                     167\n",
            "treatment              155\n",
            "cancer                 152\n",
            "neg                    132\n",
            "rev                    130\n",
            "hallucination          115\n",
            "mm                      98\n",
            "osllm                   80\n",
            "finetune                71\n",
            "patient care            63\n",
            "chatbot                 57\n",
            "sur                     55\n",
            "KG                      46\n",
            "agents                  41\n",
            "vlms                    17\n",
            "agentic                  7\n",
            "conversational AI        5\n",
            "patient monitoring       3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Número total de keywords únicas: 25\n"
          ]
        }
      ],
      "source": [
        "nombre_columna_keywords = 'keywords' \n",
        "keywords_series = df_unique_combined[nombre_columna_keywords].astype(str).str.split(',')\n",
        "todas_las_keywords = keywords_series.explode()\n",
        "keywords_limpias = todas_las_keywords.str.strip().dropna()\n",
        "keywords_finales = keywords_limpias[keywords_limpias != '']\n",
        "frecuencia_keywords = keywords_finales.value_counts()\n",
        "print(f\"Frecuencia de keywords en la columna '{nombre_columna_keywords}':\")\n",
        "print(frecuencia_keywords)\n",
        "print(f\"\\nNúmero total de keywords únicas: {frecuencia_keywords.size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\\\begin{tabular}{|c|c|}{lr}\\n\\\\hline\\\\hline\\n\\\\textbf{keywords} & \\\\textbf{count} \\\\\\\\\\n\\\\hline\\\\hline\\nllm & 1093 \\\\\\\\\\ndomain & 563 \\\\\\\\\\nrag & 270 \\\\\\\\\\ncllm & 262 \\\\\\\\\\ndecision support & 207 \\\\\\\\\\ndiag & 195 \\\\\\\\\\nimage & 185 \\\\\\\\\\nqa & 167 \\\\\\\\\\ntreatment & 155 \\\\\\\\\\ncancer & 152 \\\\\\\\\\nneg & 132 \\\\\\\\\\nrev & 130 \\\\\\\\\\nhallucination & 115 \\\\\\\\\\nmm & 98 \\\\\\\\\\nosllm & 80 \\\\\\\\\\nfinetune & 71 \\\\\\\\\\npatient care & 63 \\\\\\\\\\nchatbot & 57 \\\\\\\\\\nsur & 55 \\\\\\\\\\nKG & 46 \\\\\\\\\\nagents & 41 \\\\\\\\\\nvlms & 17 \\\\\\\\\\nagentic & 7 \\\\\\\\\\nconversational AI & 5 \\\\\\\\\\npatient monitoring & 3 \\\\\\\\\\n\\\\hline\\n\\\\hline\\n\\\\end{tabular}\\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filrnsmr_tosave = 'freckyw_G.txt'\n",
        "df_to_latex_with_integers(pd.DataFrame(frecuencia_keywords).reset_index(), os.path.join(data_folder, filename_tosave))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>PubMed ID</th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>Journal</th>\n",
              "      <th>Publication Date</th>\n",
              "      <th>authors</th>\n",
              "      <th>MeSH Terms</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Article Type</th>\n",
              "      <th>...</th>\n",
              "      <th>query</th>\n",
              "      <th>published</th>\n",
              "      <th>updated</th>\n",
              "      <th>arxiv_url</th>\n",
              "      <th>pdf_url</th>\n",
              "      <th>categories</th>\n",
              "      <th>doi</th>\n",
              "      <th>year</th>\n",
              "      <th>primary_category</th>\n",
              "      <th>short_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>40505763.0</td>\n",
              "      <td>RadGPT: A system based on a large language mod...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Journal of the American College of Radiology :...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Herwald, Sanna E; Shah, Preya; Johnston, Andre...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"pat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RadGPT: A system based on a large language mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>40491696.0</td>\n",
              "      <td>Evaluating the Application of Artificial Intel...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Clinical ophthalmology (Auckland, N.Z.)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patel, Neeket R; Lacher, Corey R; Huang, Alan ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"pat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Evaluating the Application of Artificial Intel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>40435166.0</td>\n",
              "      <td>Physician awareness of, interest in, and curre...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PloS one</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Solmonovich, Rachel L; Kouba, Insaf; Lee, Ji Y...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"pat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Physician awareness of, interest in, and curre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>40423065.0</td>\n",
              "      <td>The Accuracy of ChatGPT-4o in Interpreting Che...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Journal of personalized medicine</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lacaita, Pietro G; Galijasevic, Malik; Swoboda...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"pat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Accuracy of ChatGPT-4o in Interpreting Che...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>40378254.0</td>\n",
              "      <td>Semi-automated pipeline to accelerate multi-si...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Journal of the American Medical Informatics As...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fan, Hao; Rossetti, Sarah C; Thate, Jennifer; ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>\"large language model\" AND \"medicine\" AND \"pat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Semi-automated pipeline to accelerate multi-si...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   PubMed ID                                              title  \\\n",
              "0           0  40505763.0  RadGPT: A system based on a large language mod...   \n",
              "1           1  40491696.0  Evaluating the Application of Artificial Intel...   \n",
              "2           2  40435166.0  Physician awareness of, interest in, and curre...   \n",
              "3           3  40423065.0  The Accuracy of ChatGPT-4o in Interpreting Che...   \n",
              "4           4  40378254.0  Semi-automated pipeline to accelerate multi-si...   \n",
              "\n",
              "  summary                                            Journal  \\\n",
              "0     NaN  Journal of the American College of Radiology :...   \n",
              "1     NaN            Clinical ophthalmology (Auckland, N.Z.)   \n",
              "2     NaN                                           PloS one   \n",
              "3     NaN                   Journal of personalized medicine   \n",
              "4     NaN  Journal of the American Medical Informatics As...   \n",
              "\n",
              "   Publication Date                                            authors  \\\n",
              "0               NaN  Herwald, Sanna E; Shah, Preya; Johnston, Andre...   \n",
              "1               NaN  Patel, Neeket R; Lacher, Corey R; Huang, Alan ...   \n",
              "2               NaN  Solmonovich, Rachel L; Kouba, Insaf; Lee, Ji Y...   \n",
              "3               NaN  Lacaita, Pietro G; Galijasevic, Malik; Swoboda...   \n",
              "4               NaN  Fan, Hao; Rossetti, Sarah C; Thate, Jennifer; ...   \n",
              "\n",
              "   MeSH Terms  Keywords  Article Type  ...  \\\n",
              "0         NaN       NaN           NaN  ...   \n",
              "1         NaN       NaN           NaN  ...   \n",
              "2         NaN       NaN           NaN  ...   \n",
              "3         NaN       NaN           NaN  ...   \n",
              "4         NaN       NaN           NaN  ...   \n",
              "\n",
              "                                               query published updated  \\\n",
              "0  \"large language model\" AND \"medicine\" AND \"pat...       NaN     NaN   \n",
              "1  \"large language model\" AND \"medicine\" AND \"pat...       NaN     NaN   \n",
              "2  \"large language model\" AND \"medicine\" AND \"pat...       NaN     NaN   \n",
              "3  \"large language model\" AND \"medicine\" AND \"pat...       NaN     NaN   \n",
              "4  \"large language model\" AND \"medicine\" AND \"pat...       NaN     NaN   \n",
              "\n",
              "   arxiv_url pdf_url categories  doi year primary_category  \\\n",
              "0        NaN     NaN        NaN  NaN  NaN              NaN   \n",
              "1        NaN     NaN        NaN  NaN  NaN              NaN   \n",
              "2        NaN     NaN        NaN  NaN  NaN              NaN   \n",
              "3        NaN     NaN        NaN  NaN  NaN              NaN   \n",
              "4        NaN     NaN        NaN  NaN  NaN              NaN   \n",
              "\n",
              "                                         short_title  \n",
              "0  RadGPT: A system based on a large language mod...  \n",
              "1  Evaluating the Application of Artificial Intel...  \n",
              "2  Physician awareness of, interest in, and curre...  \n",
              "3  The Accuracy of ChatGPT-4o in Interpreting Che...  \n",
              "4  Semi-automated pipeline to accelerate multi-si...  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unique_combined.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filter= df_unique_combined[df_unique_combined['keywords'].astype(str).str.contains(r'\\bKG\\b', case=False, na=False)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(49, 25)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_filter.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filter.to_excel(os.path.join(data_folder, 'kg_queries.xlsx'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Analisys RAW Listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = 'raw_listing_v1.xlsx'\n",
        "df_v1 =pd.read_excel(os.path.join(data_folder, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_v1['keywords'] = df_v1.apply(\n",
        "        lambda row: detect_keywords(row, my_keywords), axis=1\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frecuencia de keywords en la columna 'keywords':\n",
            "keywords\n",
            "llm                   5039\n",
            "domain                4250\n",
            "cllm                  4043\n",
            "rag                   3016\n",
            "rev                   1679\n",
            "neg                   1556\n",
            "decision support      1467\n",
            "image                 1249\n",
            "treatment             1247\n",
            "KG                    1169\n",
            "diag                  1062\n",
            "chatbot                954\n",
            "cancer                 909\n",
            "sur                    587\n",
            "osllm                  583\n",
            "qa                     526\n",
            "hallucination          516\n",
            "finetune               448\n",
            "mm                     433\n",
            "patient care           369\n",
            "agents                 260\n",
            "GD                     184\n",
            "conversational AI       46\n",
            "vlms                    35\n",
            "agentic                 35\n",
            "MAS                     13\n",
            "patient monitoring      12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Las 10 keywords más comunes:\n",
            "keywords\n",
            "llm                 5039\n",
            "domain              4250\n",
            "cllm                4043\n",
            "rag                 3016\n",
            "rev                 1679\n",
            "neg                 1556\n",
            "decision support    1467\n",
            "image               1249\n",
            "treatment           1247\n",
            "KG                  1169\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Número total de keywords únicas: 27\n"
          ]
        }
      ],
      "source": [
        "nombre_columna_keywords = 'keywords' # <-- CAMBIA ESTO\n",
        "keywords_series = df_v1[nombre_columna_keywords].astype(str).str.split(',')\n",
        "todas_las_keywords = keywords_series.explode()\n",
        "keywords_limpias = todas_las_keywords.str.strip().dropna()\n",
        "keywords_finales = keywords_limpias[keywords_limpias != '']\n",
        "\n",
        "if not keywords_finales.empty:\n",
        "        # Contar la frecuencia de cada keyword\n",
        "        frecuencia_keywords = keywords_finales.value_counts()\n",
        "\n",
        "        print(f\"Frecuencia de keywords en la columna '{nombre_columna_keywords}':\")\n",
        "        print(frecuencia_keywords)\n",
        "\n",
        "        # Para ver las N keywords más comunes (ej. las 10 primeras)\n",
        "        top_n = 10\n",
        "        print(f\"\\nLas {top_n} keywords más comunes:\")\n",
        "        print(frecuencia_keywords.head(top_n))\n",
        "        \n",
        "        # Número total de keywords únicas\n",
        "        print(f\"\\nNúmero total de keywords únicas: {frecuencia_keywords.size}\")\n",
        "else:\n",
        "        print(f\"No se encontraron keywords válidas en la columna '{nombre_columna_keywords}' después del preprocesamiento.\")\n",
        "        print(\"Verifica si la columna contiene datos o si el delimitador es correcto.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se encontraron 2232 filas donde 'llm' y 'domain' existen como keywords exactas separadas.\n",
            "Procediendo a contar todas las keywords individuales de estas filas...\n",
            "\n",
            "Conteo de todas las keywords individuales de las filas filtradas:\n",
            "keywords\n",
            "domain                2232\n",
            "llm                   2232\n",
            "cllm                   981\n",
            "rag                    749\n",
            "decision support       499\n",
            "rev                    445\n",
            "diag                   322\n",
            "image                  300\n",
            "treatment              289\n",
            "neg                    282\n",
            "osllm                  250\n",
            "qa                     231\n",
            "hallucination          195\n",
            "chatbot                188\n",
            "finetune               188\n",
            "cancer                 160\n",
            "mm                     147\n",
            "patient care           138\n",
            "kg                     129\n",
            "sur                    123\n",
            "agents                  68\n",
            "vlms                    19\n",
            "agentic                 17\n",
            "conversational ai        8\n",
            "patient monitoring       3\n",
            "mas                      2\n",
            "gd                       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Las 10 keywords más comunes de estas filas:\n",
            "keywords\n",
            "domain              2232\n",
            "llm                 2232\n",
            "cllm                 981\n",
            "rag                  749\n",
            "decision support     499\n",
            "rev                  445\n",
            "diag                 322\n",
            "image                300\n",
            "treatment            289\n",
            "neg                  282\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Número total de keywords únicas encontradas en estas filas: 27\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nombre_columna_keywords = 'keywords' \n",
        "\n",
        "if nombre_columna_keywords in df_v1.columns:\n",
        "    # 1. Preparar la columna de keywords para el filtrado\n",
        "    #    Convertir a minúsculas para que la búsqueda exacta sea insensible al caso original\n",
        "    columna_keywords_para_filtrar = df_v1[nombre_columna_keywords].astype(str).str.lower()\n",
        "\n",
        "    # 2. Definir la función para la condición de filtro de filas\n",
        "    def ambas_keywords_exactas_presentes(texto_keywords_celda):\n",
        "        if pd.isna(texto_keywords_celda): # Manejar NaNs originales\n",
        "            return False\n",
        "        # Separar por comas y limpiar cada keyword individual\n",
        "        keywords_individuales_limpias = [kw.strip() for kw in texto_keywords_celda.split(',')]\n",
        "        # Verificar si \"llm\" Y \"domain\" están presentes como keywords exactas\n",
        "        return 'llm' in keywords_individuales_limpias and 'domain' in keywords_individuales_limpias\n",
        "\n",
        "    # 3. Aplicar la función para crear la condición de filtro\n",
        "    condicion_filtro_filas = columna_keywords_para_filtrar.apply(ambas_keywords_exactas_presentes)\n",
        "\n",
        "    # 4. Filtrar el DataFrame original\n",
        "    df_filas_filtradas = df_v1[condicion_filtro_filas]\n",
        "\n",
        "    if not df_filas_filtradas.empty:\n",
        "        print(f\"Se encontraron {len(df_filas_filtradas)} filas donde 'llm' y 'domain' existen como keywords exactas separadas.\")\n",
        "        print(\"Procediendo a contar todas las keywords individuales de estas filas...\\n\")\n",
        "\n",
        "        # 5. Tomar solo la columna de keywords de ESTAS FILAS FILTRADAS para el conteo\n",
        "        keywords_para_conteo = df_filas_filtradas[nombre_columna_keywords].astype(str).str.lower()\n",
        "\n",
        "        # 6. Procesar estas keywords para el conteo: split, explode, clean\n",
        "        series_de_listas_k = keywords_para_conteo.str.split(',')\n",
        "        k_individuales = series_de_listas_k.explode()\n",
        "        k_limpias = k_individuales.str.strip().dropna()\n",
        "        k_validas = k_limpias[k_limpias != ''] # Filtrar strings vacíos\n",
        "\n",
        "        if not k_validas.empty:\n",
        "            conteo_final_keywords_sorted = k_validas.value_counts()\n",
        "            print(f\"Conteo de todas las keywords individuales de las filas filtradas:\")\n",
        "            print(conteo_final_keywords_sorted)\n",
        "\n",
        "            top_n = 10\n",
        "            print(f\"\\nLas {top_n} keywords más comunes de estas filas:\")\n",
        "            print(conteo_final_keywords_sorted.head(top_n))\n",
        "            \n",
        "            print(f\"\\nNúmero total de keywords únicas encontradas en estas filas: {conteo_final_keywords_sorted.size}\")\n",
        "        else:\n",
        "            print(\"No se encontraron keywords válidas para contar en las filas filtradas (después de split y limpieza).\")\n",
        "\n",
        "    else:\n",
        "        print(f\"No se encontraron filas que cumplan con la condición de tener 'llm' Y 'domain' como keywords exactas separadas.\")\n",
        "else:\n",
        "    print(f\"Error: La columna '{nombre_columna_keywords}' no se encuentra en el DataFrame.\")\n",
        "    print(f\"Columnas disponibles: {df_v1.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keywords\n",
              "llm                   5039\n",
              "domain                4250\n",
              "cllm                  4043\n",
              "rag                   3016\n",
              "rev                   1679\n",
              "neg                   1556\n",
              "decision support      1467\n",
              "image                 1249\n",
              "treatment             1247\n",
              "KG                    1169\n",
              "diag                  1062\n",
              "chatbot                954\n",
              "cancer                 909\n",
              "sur                    587\n",
              "osllm                  583\n",
              "qa                     526\n",
              "hallucination          516\n",
              "finetune               448\n",
              "mm                     433\n",
              "patient care           369\n",
              "agents                 260\n",
              "GD                     184\n",
              "conversational AI       46\n",
              "vlms                    35\n",
              "agentic                 35\n",
              "MAS                     13\n",
              "patient monitoring      12\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frecuencia_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count_freq</th>\n",
              "      <th>count_conteo</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keywords</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>llm</th>\n",
              "      <td>5039.0</td>\n",
              "      <td>2232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>domain</th>\n",
              "      <td>4250.0</td>\n",
              "      <td>2232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cllm</th>\n",
              "      <td>4043.0</td>\n",
              "      <td>981.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rag</th>\n",
              "      <td>3016.0</td>\n",
              "      <td>749.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rev</th>\n",
              "      <td>1679.0</td>\n",
              "      <td>445.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neg</th>\n",
              "      <td>1556.0</td>\n",
              "      <td>282.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decision support</th>\n",
              "      <td>1467.0</td>\n",
              "      <td>499.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image</th>\n",
              "      <td>1249.0</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>treatment</th>\n",
              "      <td>1247.0</td>\n",
              "      <td>289.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KG</th>\n",
              "      <td>1169.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diag</th>\n",
              "      <td>1062.0</td>\n",
              "      <td>322.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chatbot</th>\n",
              "      <td>954.0</td>\n",
              "      <td>188.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cancer</th>\n",
              "      <td>909.0</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sur</th>\n",
              "      <td>587.0</td>\n",
              "      <td>123.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>osllm</th>\n",
              "      <td>583.0</td>\n",
              "      <td>250.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qa</th>\n",
              "      <td>526.0</td>\n",
              "      <td>231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hallucination</th>\n",
              "      <td>516.0</td>\n",
              "      <td>195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finetune</th>\n",
              "      <td>448.0</td>\n",
              "      <td>188.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mm</th>\n",
              "      <td>433.0</td>\n",
              "      <td>147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>patient care</th>\n",
              "      <td>369.0</td>\n",
              "      <td>138.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agents</th>\n",
              "      <td>260.0</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GD</th>\n",
              "      <td>184.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conversational AI</th>\n",
              "      <td>46.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agentic</th>\n",
              "      <td>35.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vlms</th>\n",
              "      <td>35.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAS</th>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>patient monitoring</th>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conversational ai</th>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gd</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kg</th>\n",
              "      <td>NaN</td>\n",
              "      <td>129.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mas</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    count_freq  count_conteo\n",
              "keywords                                    \n",
              "llm                     5039.0        2232.0\n",
              "domain                  4250.0        2232.0\n",
              "cllm                    4043.0         981.0\n",
              "rag                     3016.0         749.0\n",
              "rev                     1679.0         445.0\n",
              "neg                     1556.0         282.0\n",
              "decision support        1467.0         499.0\n",
              "image                   1249.0         300.0\n",
              "treatment               1247.0         289.0\n",
              "KG                      1169.0           NaN\n",
              "diag                    1062.0         322.0\n",
              "chatbot                  954.0         188.0\n",
              "cancer                   909.0         160.0\n",
              "sur                      587.0         123.0\n",
              "osllm                    583.0         250.0\n",
              "qa                       526.0         231.0\n",
              "hallucination            516.0         195.0\n",
              "finetune                 448.0         188.0\n",
              "mm                       433.0         147.0\n",
              "patient care             369.0         138.0\n",
              "agents                   260.0          68.0\n",
              "GD                       184.0           NaN\n",
              "conversational AI         46.0           NaN\n",
              "agentic                   35.0          17.0\n",
              "vlms                      35.0          19.0\n",
              "MAS                       13.0           NaN\n",
              "patient monitoring        12.0           3.0\n",
              "conversational ai          NaN           8.0\n",
              "gd                         NaN           1.0\n",
              "kg                         NaN         129.0\n",
              "mas                        NaN           2.0"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_fusionado = pd.merge(\n",
        "    frecuencia_keywords, \n",
        "    conteo_final_keywords_sorted, \n",
        "    left_index=True, \n",
        "    right_index=True, \n",
        "    how='outer',\n",
        "    suffixes=('_freq', '_conteo')  # Añadir sufijos a columnas con nombres duplicados\n",
        ")\n",
        "df_fusionado.sort_values('count_freq', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\\\begin{tabular}{|c|c|c|}{lrr}\\n\\\\hline\\\\hline\\n\\\\textbf{keywords} & \\\\textbf{count_freq} & \\\\textbf{count_conteo} \\\\\\\\\\n\\\\hline\\\\hline\\nllm & 5039 & 2232 \\\\\\\\\\ndomain & 4250 & 2232 \\\\\\\\\\ncllm & 4043 & 981 \\\\\\\\\\nrag & 3016 & 749 \\\\\\\\\\nrev & 1679 & 445 \\\\\\\\\\nneg & 1556 & 282 \\\\\\\\\\ndecision support & 1467 & 499 \\\\\\\\\\nimage & 1249 & 300 \\\\\\\\\\ntreatment & 1247 & 289 \\\\\\\\\\nKG & 1169 & 0 \\\\\\\\\\ndiag & 1062 & 322 \\\\\\\\\\nchatbot & 954 & 188 \\\\\\\\\\ncancer & 909 & 160 \\\\\\\\\\nsur & 587 & 123 \\\\\\\\\\nosllm & 583 & 250 \\\\\\\\\\n\\\\hline\\n\\\\hline\\n\\\\end{tabular}\\n'"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_to_latex_with_integers(df_fusionado.sort_values('count_freq', ascending=False).reset_index().head(15), 'freckyw_G.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Series' object has no attribute 'merge'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9588\\3826552561.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrecuencia_keywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconteo_final_keywords_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\BJUR\\Desktop\\DOC_UPM\\phase1_soa\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'merge'"
          ]
        }
      ],
      "source": [
        "frecuencia_keywords.merge(conteo_final_keywords_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo de uso\n",
        "latex_code = df_to_latex_with_integers(\n",
        "    df, \n",
        "    filename='tabla_formateada.tex',\n",
        "    caption='Resultados de búsqueda bibliográfica',\n",
        "    label='tab:resultados'\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
